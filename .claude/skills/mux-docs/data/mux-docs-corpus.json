[
  {
    "id": "211-_guides_todo/data/",
    "title": "_guides_todo/data/",
    "path": "_guides_todo/data/index.mdx",
    "sourceUrl": "https://docs.mux.com/_guides_todo/data/",
    "content": "move this file to guides/data/index.mdx\n---\ntitle:\nproduct:\ndescription:\nsteps:\n  - title:\n    description:\n  - title:\n    description:\n---\n\nMux Data is the best way to monitor video streaming performance.\n\nIntegration is easy - just initialize the Mux SDK, pass in some metadata, and you're up and running in minutes.\n[block:api-header]\n{\n  \"title\": \"1. Choose an Environment\"\n}\n[/block]\nAn Environment represents the highest grouping of data you want to combine and compare within. Multiple websites/apps or video platforms can use the same environment, but we suggest not combining staging and production data.\n\nThere are four types of environments: Development, QA, Staging, and Production. Use Production for your integration with your Production video players, Staging or QA if you have a staging or QA environment, and Development for your local testing.\n\nTwo environments are created automatically at time of sign-up: Development and Production. Choose the one you want to use or create a new environment by clicking \"Add Environment\" on the Environments page.\n[block:image]\n{\n  \"images\": [\n    {\n      \"image\": [\n        \"https://files.readme.io/6313a49-Screen_Shot_2018-01-31_at_7.57.59_PM.png\",\n        \"Screen Shot 2018-01-31 at 7.57.59 PM.png\",\n        1290,\n        682,\n        \"f4fbfa\"\n      ]\n    }\n  ]\n}\n[/block]\nIf you integrate with Mux Video, be sure that you use the same Environment on both sides, so that the data from Mux Data correctly optimizes your Mux Video streaming.\n[block:api-header]\n{\n  \"title\": \"2. Integrate with your player\"\n}\n[/block]\nAfter you create an environment, you'll see an Env Key and a link to \"Track video performance\". Use this link to choose a player integration, or just jump to your player:\n\n - Web Integration Guide\n - iOS Integration Guide\n - Android Integration Guide\n - Integration Guide: Chromecast\n - Integration Guide: Roku\n - Integration Guide: Samsung TVs\n - Integration Guide: LG Smart TVs\n[block:image]\n{\n  \"images\": [\n    {\n      \"image\": [\n        \"https://files.readme.io/23d709e-Screen_Shot_2020-06-26_at_11.06.25_AM.png\",\n        \"Screen Shot 2020-06-26 at 11.06.25 AM.png\",\n        2004,\n        250,\n        \"f8f9f9\"\n      ]\n    }\n  ]\n}\n[/block]\n\n[block:api-header]\n{\n  \"title\": \"3. Add metadata\"\n}\n[/block]\nBy default, Mux Data will automatically capture as much metadata about the video view as possible from the player and the environment. In addition, Mux Data is more useful as you add more metadata about the views so we encourage you to add more metadata to your views in order to make it easier to identify areas for improvement in your video platform.\n\nYou can add information about the view such as video title, type of viewer connection (wired, wifi, etc.), content delivery network (CDN) used, and more. Most metadata you would like to capture for your reporting can be added to the Mux Data metadata about a view.\n\nIf you are implementing a custom SDK integration, you should collect as much of the same metadata as possible.\n\nThe most useful metadata is Video Title and Video ID but many other types of metadata can be specified. Please refer to the Metadata integration guide for a complete list of dimensions and filters supported by Mux Data.\n[block:api-header]\n{\n  \"title\": \"4. Start seeing data\"\n}\n[/block]\nAfter you've integrated, use the Mux Data dashboard to dive deep into your video streaming performance. Data should start showing up a few minutes after you integrate.\n[block:image]\n{\n  \"images\": [\n    {\n      \"image\": [\n        \"https://files.readme.io/fab0c35-Screen_Shot_2018-01-31_at_8.06.55_PM.png\",\n        \"Screen Shot 2018-01-31 at 8.06.55 PM.png\",\n        2376,\n        1400,\n        \"edeaeb\"\n      ]\n    }\n  ]\n}\n[/block]\n\n[block:api-header]\n{\n  \"title\": \"5. (Optional) Integrate with the Mux Data API\"\n}\n[/block]\nThe Mux Data dashboard is entirely powered by APIs, and these APIs are available to customers on certain plans. Visit the Mux Data API Docs for details."
  },
  {
    "id": "212-_guides_todo/video/",
    "title": "_guides_todo/video/",
    "path": "_guides_todo/video/index.mdx",
    "sourceUrl": "https://docs.mux.com/_guides_todo/video/",
    "content": "move this file to guides/video/index.mdx\n---\ntitle:\nproduct:\ndescription:\nsteps:\n  - title:\n    description:\n  - title:\n    description:\n---\n\nMux Video is the API that makes you a video expert. With just a few simple API calls, add and stream videos that play anywhere and look beautiful, every time, at scale.\n\nFor interacting with the Mux API we created open source language-specific SDKs for most popular server-side languages. Find more information about them here:\n\n   ruby\n   go\n   python\n   php\n   node\n   elixir\n[block:api-header]\n{\n  \"title\": \"1. Get an API Access Token\"\n}\n[/block]\nThe Mux Video API uses a token key pair that consists of a Token ID and Token Secret for authentication. If you haven't already, generate a new Access Token in the Access Token settings of your Mux account dashboard.\n[block:image]\n{\n  \"images\": [\n    {\n      \"image\": [\n        \"https://files.readme.io/3848f6d-Screen_Shot_2018-01-25_at_5.11.18_PM.png\",\n        \"Screen Shot 2018-01-25 at 5.11.18 PM.png\",\n        1790,\n        644,\n        \"e7e7e7\"\n      ]\n    }\n  ]\n}\n[/block]\nThe Access Token should be set to \"Full Access\" for Mux Video.\n[block:image]\n{\n  \"images\": [\n    {\n      \"image\": [\n        \"https://files.readme.io/f5498b5-Screen_Shot_2018-01-25_at_5.12.17_PM.png\",\n        \"Screen Shot 2018-01-25 at 5.12.17 PM.png\",\n        1152,\n        478,\n        \"fbfbfb\"\n      ]\n    }\n  ]\n}\n[/block]\nAccess Tokens also belong to an Environment. Be sure to use the same Environment when using Mux Video and Mux Data together, so the data from Mux Data can be used to optimize your Mux Video streams.\n[block:image]\n{\n  \"images\": [\n    {\n      \"image\": [\n        \"https://files.readme.io/bf0a53d-Screen_Shot_2018-01-31_at_8.17.39_PM.png\",\n        \"Screen Shot 2018-01-31 at 8.17.39 PM.png\",\n        1140,\n        374,\n        \"fdfdfd\"\n      ]\n    }\n  ]\n}\n[/block]\n\n[block:api-header]\n{\n  \"title\": \"2. POST a video\"\n}\n[/block]\n(Detailed API Reference)\n\nVideos stored in Mux are called assets. To create your first video asset, send a POST request to the /assets endpoint and set the \"input\" property to the URL of a video file that's accessible online.\n\nNote that Mux does not store the original file in its exact form, so if you want to retain your masters, don't delete them after submitting to Mux. Mux will also never need to download your video file again, unless you use it to create more assets.\n[block:html]\n{\n  \"html\": \"\\n\\n\\n  Fill in the form details to auto-populate the example code.\\n  \\n  \\n    Enter a URL to a video file (or use the default)\\n    \\n  \\n  \\n    Enter your API Access Token\\n    \\n  \\n  \\n    Enter your Secret Key\\n    \\n  \\n\\n\\n\\n\\n\\n  .MuxDocForm label {\\n    display: block;\\n    line-height: 2em;\\n    font-weight: bold;\\n    color: 777;\\n    font-size: 13px;\\n    padding-bottom: 3px;\\n  }\\n\\n  .MuxDocForm input {\\n    box-sizing: border-box;\\n    width: 100%;\\n    margin-bottom: 20px;\\n    padding: 8px 10px;\\n  }\\n  \\n  .MuxDocForm input::placeholder {\\n  \\tcolor: ccc;\\n  }\\n  \\n  .CopyButton {\\n    margin: 10px 5px 5px 0;\\n  \\tpadding: 10px;\\n  }\\n\"\n}\n[/block]\n\n[block:code]\n{\n  \"codes\": [\n    {\n      \"code\": \"curl https://api.mux.com/video/v1/assets \\\\\\n  -H \\\"Content-Type: application/json\\\" \\\\\\n  -X POST \\\\\\n  -d '{ \\\"input\\\": \\\"{INPUT_URL}\\\", \\\"playback_policy\\\": \\\"public\\\" }' \\\\\\n  -u ${MUX_TOKEN_ID}:${MUX_TOKEN_SECRET} | json_pp\",\n      \"language\": \"curl\"\n    }\n  ]\n}\n[/block]\nThe response will include an Asset ID and a Playback ID.\n\n- Asset IDs are used to manage assets using api.mux.com (e.g. to read or delete an asset).\n- Playback IDs are used to stream an asset to a video player through stream.mux.com. You can add multiple playback IDs to an asset to create playback URLs with different viewing permissions, and you can delete playback IDs to remove access without deleting the asset.\n[block:code]\n{\n  \"codes\": [\n    {\n      \"code\": \"{\\n   \\\"data\\\" : {\\n      \\\"id\\\" : \\\"ymDhKE00YZ12XxJLFo76DIVqCzL15bVf2\\\",\\n      \\\"created_at\\\" : \\\"1517531451\\\",\\n      \\\"playback_ids\\\" : [\\n         {\\n            \\\"id\\\" : \\\"EsxKJmzkfLvGV01cbThYHDcEz7TKcbR31\\\",\\n            \\\"policy\\\" : \\\"public\\\"\\n         }\\n      ],\\n      \\\"status\\\" : \\\"preparing\\\"\\n   }\\n}\",\n      \"language\": \"json\",\n      \"name\": \"Example API Response Body (JSON)\"\n    }\n  ]\n}\n[/block]\n\n[block:api-header]\n{\n  \"title\": \"3. Wait for \\\"ready\\\"\"\n}\n[/block]\n(Detailed API Reference)\n\nAs soon as you POST a video, Mux begins downloading and processing the video. For shorter files, this often takes just a few seconds. Very large files over poor connections may take a few minutes (or longer).\n\nWhen the video is ready for playback, the asset \"status\" changes to \"ready\".\n\nThe best way to do this is via webhooks. Mux can send a webhook notification as soon as the asset is ready. See the Webhooks documentation for details.\n\nIf you can't use webhooks for some reason, you can manually poll the asset API to see asset status. Note that this only works at low volume. Try this example:\n[block:html]\n{\n  \"html\": \"\\n  Fill in the form details to auto-populate the example code.\\n  \\n  \\n    Enter the Asset ID from the API response\\n    \\n  \\n\\n\\n\"\n}\n[/block]\n\n[block:code]\n{\n  \"codes\": [\n    {\n      \"code\": \"curl -X GET https://api.mux.com/video/v1/assets/{ASSET_ID} \\\\\\n  -u ${MUX_TOKEN_ID}:${MUX_TOKEN_SECRET} | json_pp\",\n      \"language\": \"curl\"\n    }\n  ]\n}\n[/block]\nPlease don't poll this API more than once per second.\n[block:api-header]\n{\n  \"title\": \"4. Watch it\"\n}\n[/block]\nTo play back an asset, just create a playback URL using the PLAYBACK_ID you received when you created the asset.\n[block:html]\n{\n  \"html\": \"\\n  Fill in the form details to auto-populate the example code.\\n  \\n  \\n    Enter the Playback ID from the API response (be sure it's the Playback ID and not the Asset ID)\\n    \\n  \\n\\n\\n\"\n}\n[/block]\n\n[block:code]\n{\n  \"codes\": [\n    {\n      \"code\": \"https://stream.mux.com/{PLAYBACK_ID}.m3u8\",\n      \"language\": \"http\"\n    }\n  ]\n}\n[/block]\nThe easiest way to test asset playback is to try this playback URL in Safari (Mac) or Edge (Windows), which can natively play back HTTP Live Streaming (HLS) video.\n[block:image]\n{\n  \"images\": [\n    {\n      \"image\": [\n        \"https://files.readme.io/8813587-Screen_Shot_2018-01-25_at_4.59.06_PM.png\",\n        \"Screen Shot 2018-01-25 at 4.59.06 PM.png\",\n        1936,\n        936,\n        \"908b77\"\n      ]\n    }\n  ]\n}\n[/block]\n\n[block:api-header]\n{\n  \"title\": \"5. Configure playback\"\n}\n[/block]\nPlayback Guide\n\nNow you're ready to integrate with a video player. Mux Video supports any modern video player capable of playing the HLS streaming format: most web players, iOS, Android, and many connected TV devices.\n[block:api-header]\n{\n  \"title\": \"6. Generate thumbnails\"\n}\n[/block]\nThumbnail Guide\n\nNow see what else you can do with the API, starting with thumbnails. Generate images directly from the video in real time.\n\n[block:api-header]\n{\n  \"title\": \"7. Configure Mux Data for monitoring\"\n}\n[/block]\nData Implementation Guide\n\nMux Video is optimized by real-world performance monitoring, via Mux Data. Use Mux Data to monitor your whole video playback stack, including your player and application performance. Installing Mux Data is easy, and usually just involves pasting in a bit of Javascript (or Objective-C, or Java) alongside your video player."
  },
  {
    "id": "2-_guides/core/content-security-policy",
    "title": "Content Security Policy for Mux",
    "path": "_guides/core/content-security-policy.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/core/content-security-policy",
    "content": "Content Security Policy (CSP) is a security feature that helps protect your web application from cross-site scripting (XSS) attacks and other code injection attacks. CSP works by restricting the resources (such as scripts, stylesheets, images, and network connections) that a web page can load.\n\nWhen integrating Mux Video and Mux Data into your application, you'll need to configure your CSP to allow connections to Mux services. This guide will help you set up the appropriate CSP directives to ensure your Mux integration works securely.\n\n  If you're new to Content Security Policy, we recommend reading Google's CSP guide for a comprehensive introduction to CSP concepts and implementation.\n\nFor most applications, the simplest approach is to use a basic CSP that allows all Mux services. This configuration ensures compatibility with all current and future Mux features:\n\n\n```\nContent-Security-Policy: default-src 'self' *.mux.com *.litix.io storage.googleapis.com\n```\n\n\nThis CSP directive allows your application to:\n- Load resources from your own domain ('self')\n- Connect to all Mux Video services (.mux.com)\n- Connect to all Mux Data services (.litix.io)\n- Connect to Google Cloud Storage (storage.googleapis.com) -- this is needed for Direct Uploads\n\nThe wildcard approach for mux.com and litix.io is recommended because Mux utilizes multiple CDNs and subdomains to provide optimal performance globally. These hostnames may change without notice as we optimize our infrastructure.\n\nIf your security requirements call for a more restrictive CSP, you can use specific directives instead of the broad default-src approach. Here's a granular configuration that covers all Mux functionality:\n\n\n```\nContent-Security-Policy:\n  connect-src 'self' https://*.mux.com https://*.litix.io https://storage.googleapis.com;\n  media-src 'self' blob: https://*.mux.com;\n  img-src 'self' https://image.mux.com https://*.litix.io;\n  script-src 'self' https://src.litix.io;\n  worker-src 'self' blob:\n```\n\n\n  The above configuration must be merged with your existing CSP directives. Each directive should combine values from both your current policy and the Mux requirements.\n\nIf your application uploads media files to Mux via Direct Uploads, you'll need additional CSP directives to handle binary data and file uploads:\n\n\n```\nContent-Security-Policy:\n  connect-src 'self' https://*.mux.com https://*.litix.io https://storage.googleapis.com;\n  media-src 'self' blob: https://*.mux.com;\n  img-src 'self' https://image.mux.com https://*.litix.io;\n  script-src 'self' https://src.litix.io;\n  worker-src 'self' blob:;\n  form-action 'self' https://*.mux.com https://storage.googleapis.com\n```\n\n\nThe key additions for upload functionality are:\n\n| Directive | Purpose |\n| :-------- | :------ |\n| https://storage.googleapis.com in connect-src | Allows uploads to Google Cloud Storage endpoints used by Mux |\n| form-action directive | Permits form submissions and PUT/POST requests to upload endpoints |\n| blob: in media-src and worker-src | Enables handling of binary file data during upload processing |\n\nDifferent Mux features have specific CSP requirements. Here's what you need for each:\n\nMux Video Playback\n\nFor video playback functionality, you must include:\n\n\n```\nconnect-src https://*.mux.com;\nmedia-src blob: https://*.mux.com;\nworker-src blob:\n```\n\n\nThis is required because:\n- HLS manifests and video segments are delivered via https://stream.mux.com and other .mux.com subdomains\n- Video players use web workers and blob URLs for optimal performance\n- Mux uses multiple CDNs with different hostnames for global performance\n\nVideo Thumbnails and Storyboards\n\nIf you're displaying video thumbnails or timeline hover previews, include:\n\n\n```\nimg-src https://image.mux.com;\nconnect-src https://image.mux.com\n```\n\n\nThe connect-src directive is needed for dynamic thumbnail loading in timeline hover previews, while img-src covers standard image embedding.\n\nMux Data Integration\n\nFor Mux Data analytics, you must allow:\n\n\n```\nconnect-src https://*.litix.io;\nimg-src https://*.litix.io\n```\n\n\nThis covers:\n- Data collection endpoints across multiple subdomains\n- Fallback beacon loading through image tags\n- Various monitoring and analytics endpoints\n\n  For tighter security, you can replace https://.litix.io with https://img.litix.io and https://.litix.io where `` is your Mux environment key. However, the wildcard approach is recommended for maximum compatibility.\n\nHosted Mux Data Integrations\n\nIf you're loading pre-built Mux Data integrations from our hosted domain (rather than installing via NPM), add:\n\n\n```\nscript-src https://src.litix.io\n```\n\n\nThis is not required if you bundle the Mux Data SDK directly into your application code.\n\nComplete Example\n\nHere's a complete CSP that supports all Mux features including uploads:\n\n\n```\nContent-Security-Policy:\n  default-src 'self';\n  connect-src 'self' https://*.mux.com https://*.litix.io https://storage.googleapis.com;\n  media-src 'self' blob: https://*.mux.com;\n  img-src 'self' https://image.mux.com https://*.litix.io;\n  script-src 'self' https://src.litix.io;\n  worker-src 'self' blob:;\n  form-action 'self' https://*.mux.com https://storage.googleapis.com\n```\n\n\n  After implementing your CSP, test all Mux functionality in your application including video playback, uploads, thumbnails, and analytics to ensure everything works as expected."
  },
  {
    "id": "3-_guides/core/listen-for-webhooks",
    "title": "Listen for webhooks",
    "path": "_guides/core/listen-for-webhooks.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/core/listen-for-webhooks",
    "content": "Mux uses webhooks to let your application know when things happen asynchronously, outside of an API request cycle. For example, you may want to update something on your end when an asset transitions its status from processing to ready, or when a live stream starts or ends. When these asynchronous events happen, we'll make a POST request to the address you give us and you can do whatever you need with it on your end.\n\nAfter a webhook is configured for an environment, notifications will be sent for all events for that environment.\n\n  Note that webhooks are scoped per environment. If you have configured webhooks and you are not seeing them show up, double check that the webhook is correctly configured for the environment you are working in.\n\nIf Mux doesn't receive a 2xx response from your system, we will continue to try the message for the next 24 hours (with an increasing delay between attempts).\n\n  Mux makes an effort to deliver each message successfully once, but in certain\n  situations duplicate webhook messages may be sent even if your service\n  responds with a 2xx response code. Please ensure that your webhook handling\n  mechanism treats duplicated event delivery appropriately.\n\nWebhooks vs. polling\n\nPlease use webhooks to track asset status rather than polling the Asset API. Webhooks are much more efficient for both you and Mux, and we rate limit GET requests to the /assets endpoint, which means polling the /assets API doesn't scale.\n\nHandling webhooks locally\n\nA common gotcha for anyone new to working with webhooks is figuring out how to receive them when working in a local environment.\n\nIf your application is running on a local URL such as https://localhost:3000 or https://localhost:8080, you'll need to create a secure tunnel to this port on your machine to expose it to the world.\n\nOne approach to accomplishing this is using a tool like ngrok to expose your local application to the internet.\n\n> Note: you'll need to create an ngrok account in order to take this approach – a free account should be fine for most testing purposes.\n\nAs an example, if your application is running on https://localhost:3000, you can run ngrok http 3000 in your terminal to get a public URL to your local application\n\nIf you're using a free ngrok account, you'll receive an auto-generated URL that will look something like this:\n\nhttps://025c-2603-6010-fd04-a497-8cc9-f31e-1e0d-1406.ngrok.io/\n\nYou can then append your application's webhook handler path to the end of that URL and use it as the webhook endpoint within the Mux dashboard. A complete example webhook endpoint provided by ngrok might look something like this:\n\nhttps://025c-2603-6010-fd04-a497-8cc9-f31e-1e0d-1406.ngrok.io/api/webhooks/mux\n\nThere is more detail on Mux and ngrok's integration and what is possible with it in ngrok's documentation here.\n\nConfiguring endpoints\n\nWebhook endpoints are configured in the Mux dashboard under \"Settings.\"\n\nEnter a URL from your application that Mux will call for event notifications.\n\nReceiving events\n\nMux will submit a POST request to the configured URL, which your application can treat the same as any other route. Your event handler can do things like update the state of the specified asset in your database, or trigger other work.\n\nNote that a single request attempt will timeout after 5 seconds, after which the attempt is considered failed and will be reattempted. If you expect this will be a problem in your workflow, consider doing the work in an asynchronous task so you can respond to the event immediately.\n\nFor more details on the Webhook event object definition, see the example response.\n\nExample response\n\n\n```json\n{\n  \"type\": \"video.asset.ready\",\n  \"object\": {\n    \"type\": \"asset\",\n    \"id\": \"0201p02fGKPE7MrbC269XRD7LpcHhrmbu0002\"\n  },\n  \"id\": \"3a56ac3d-33da-4366-855b-f592d898409d\",\n  \"environment\": {\n    \"name\": \"Demo pages\",\n    \"id\": \"j0863n\"\n  },\n  \"data\": {\n    \"tracks\": [\n      {\n        \"type\": \"video\",\n        \"max_width\": 1280,\n        \"max_height\": 544,\n        \"max_frame_rate\": 23.976,\n        \"id\": \"0201p02fGKPE7MrbC269XRD7LpcHhrmbu0002\",\n        \"duration\": 153.361542\n      },\n      {\n        \"type\": \"audio\",\n        \"max_channels\": 2,\n        \"max_channel_layout\": \"stereo\",\n        \"id\": \"FzB95vBizv02bYNqO5QVzNWRrVo5SnQju\",\n        \"duration\": 153.361497\n      }\n    ],\n    \"status\": \"ready\",\n    \"max_stored_resolution\": \"SD\",\n    \"max_stored_frame_rate\": 23.976,\n    \"id\": \"0201p02fGKPE7MrbC269XRD7LpcHhrmbu0002\",\n    \"duration\": 153.361542,\n    \"created_at\": \"2018-02-15T01:04:45.000Z\",\n    \"aspect_ratio\": \"40:17\"\n  },\n  \"created_at\": \"2018-02-15T01:04:45.000Z\",\n  \"accessor_source\": null,\n  \"accessor\": null,\n  \"request_id\": null\n}\n```\n\n\nTypes of Events\n\nAsset Events\n\n| Event | Description |\n|-------|-------------|\n| video.asset.created | Asset has been created |\n| video.asset.ready | Asset is ready for playback. You can now use the asset's playback_id to successfully start streaming this asset. |\n| video.asset.errored | Asset has encountered an error. Use this to notify your server about assets with errors. Asset errors can happen for a number of reasons, most commonly an input URL that Mux is unable to download or a file that is not a valid video file. |\n| video.asset.updated | Asset has been updated. Use this to make sure your server is notified about changes to assets. |\n| video.asset.deleted | Asset has been deleted. Use this so that your server knows when an asset has been deleted, at which point it will no longer be playable. |\n| video.asset.live_stream_completed | The live stream for this asset has completed. Every time a live stream starts and ends a new asset gets created and this event fires. |\n| video.asset.static_renditions.ready | Static renditions for this asset are ready. Static renditions are streamable mp4 files that are most commonly used for allowing users to download files for offline viewing. |\n| video.asset.static_renditions.preparing | Static renditions for this asset are being prepared. After requesting static renditions you will get this webhook when they are being prepared. |\n| video.asset.static_renditions.deleted | Static renditions for this asset have been deleted. The static renditions (mp4 files) for this asset will no longer be available. |\n| video.asset.static_renditions.errored | Preparing static renditions for this asset has encountered an error. This indicates that there was some error when creating static renditions (mp4s) of your asset. This should be rare and if you see it unexpectedly please open a support ticket. |\n| video.asset.master.ready | Master access for this asset is ready. Master access is used when downloading an asset for purposes of editing or post-production work. The master access file is not intended to be streamed or downloaded by end-users. |\n| video.asset.master.preparing | Master access for this asset is being prepared. After requesting master access you will get this webhook while it is being prepared. |\n| video.asset.master.deleted | Master access for this asset has been deleted. Master access for this asset has been removed. You will no longer be able to download the master file. If you want it again you should re-request it. |\n| video.asset.master.errored | Master access for this asset has encountered an error. This indicates that there was some error when creating master access for this asset. This should be rare and if you see it unexpectedly please open a support ticket. |\n| video.asset.track.created | A new track for this asset has been created, for example a subtitle text track. |\n| video.asset.track.ready | A track for this asset is ready. In the example of a subtitle text track the text track will now be delivered with your HLS stream. |\n| video.asset.track.errored | A track for this asset has encountered an error. There was some error preparing this track. Most commonly this could be a text track file that Mux was unable to download for processing. |\n| video.asset.track.deleted | A track for this asset has been deleted. |\n| video.asset.warning | This event fires when Mux has encountered a non-fatal issue with the recorded asset of the live stream. At this time, the event is only fired when Mux is unable to download a slate image from the URL set as reconnect_slate_url parameter value. More details on this event is available here. |\n\nUpload Events\n\n| Event | Description |\n|-------|-------------|\n| video.upload.asset_created | An asset has been created from this upload. This is useful to know what a user of your application has finished uploading a file using the URL created by a Direct Upload. |\n| video.upload.cancelled | Upload has been canceled. This event fires after hitting the cancel direct upload API. |\n| video.upload.created | Upload has been created. This event fires after creating a direct upload. |\n| video.upload.errored | Upload has encountered an error. This event fires when the asset created by the direct upload fails. Most commonly this happens when an end-user uploads a non-video file. |\n\nLive Stream Events\n\n| Event | Description |\n|-------|-------------|\n| video.live_stream.created | A new live stream has been created. Broadcasters with a stream_key can start sending encoder feed to this live stream. |\n| video.live_stream.connected | An encoder has successfully connected to this live stream. |\n| video.live_stream.recording | Recording on this live stream has started. Mux has successfully processed the first frames from the encoder. If you show a _red dot_ icon in your UI, this would be a good time to show it. |\n| video.live_stream.active | This live stream is now \"active\". The live streams playback_id OR the playback_id associated with this live stream's asset can be used right now to created HLS URLs (https://stream.mux.com/{PLAYBACK_ID}.m3u8 and start streaming in your player. Note that before the live stream is \"active\", trying to stream the HLS URL will result in HTTP 412 errors. |\n| video.live_stream.disconnected | An encoder has disconnected from this live stream. Note that while disconnected the live stream is still status: \"active\". |\n| video.live_stream.idle | The reconnect_window for this live stream has elapsed. The live stream status will now transition to \"idle\". |\n| video.live_stream.updated | This live stream has been updated. For example, after resetting the live stream's stream key. |\n| video.live_stream.enabled | This live stream has been enabled. This event fires after enable live stream API. |\n| video.live_stream.disabled | This live stream has been disabled. This event fires after disable live stream API. Disabled live streams will no longer accept new RTMP connections. |\n| video.live_stream.deleted | This live stream has been deleted. This event fires after delete live stream API API. |\n| video.live_stream.warning | This live stream event fires when Mux has encountered a non-fatal issue. There is no disruption to the live stream ingest and playback. At this time, the event is only fired when Mux is unable to download an image from the URL set as reconnect_slate_url parameter value. More details on this event is available here. |\n\nSimulcast Target Events\n\nThese simulcast target events are useful when creating a UI that shows your users the status of their configured 3rd party endpoints. These events are handy when you want to build a UI that shows the state of each simulcast target and keep track of the state changes as they happen.\n\n| Event | Description |\n|-------|-------------|\n| video.live_stream.simulcast_target.created | A new simulcast target has been created for this live stream. |\n| video.live_stream.simulcast_target.idle | When the parent live stream is \"disconnected\", all simulcast targets will have be \"idle\". |\n| video.live_stream.simulcast_target.starting | When the parent live stream fires \"connected\" then the simulcast targets transition to \"starting\". |\n| video.live_stream.simulcast_target.broadcasting | This fires when Mux has successfully connected to the simulcast target and has begun pushing content to that third party. |\n| video.live_stream.simulcast_target.errored | This fires when Mux has encountered an error either while attempting to connect to the third party streaming service or while broadcasting. Mux will try to re-establish the connection and if it does successfully the simulcast target will transition back to \"broadcasting\". |\n| video.live_stream.simulcast_target.updated | This simulcast target has been updated. |\n| video.live_stream.simulcast_target.deleted | This simulcast target has been deleted. |"
  },
  {
    "id": "4-_guides/core/make-api-requests",
    "title": "Make API requests",
    "path": "_guides/core/make-api-requests.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/core/make-api-requests",
    "content": "| Term         | Description                                            |\n| :----------- | :----------------------------------------------------- |\n| Token ID     | access token ID, the \"username\" in HTTP basic auth     |\n| Token secret | access token secret, the \"password\" in HTTP basic auth |\n\nEvery request to the API is authenticated via an Access Token, which includes the ID and the secret key. You can think of the Access Token’s ID as its username and secret as the password. Mux only stores a hash of the secret, not the secret itself. If you lose the secret key for your access token, Mux cannot recover it; you will have to create a new Access Token. If the secret key for an Access Token is leaked you should revoke that Access Token on the settings page: https://dashboard.mux.com/settings/access-tokens.\n\nNote that in order to access the settings page for access tokens you must be an admin on the Mux organization.\n\nAPI requests are authenticated via HTTP Basic Auth, where the username is the Access Token ID, and the password is the Access Token secret key. Due to the use of Basic Authentication and because doing so is just a Really Good Idea™, all API requests must made via HTTPS (to https://api.mux.com).\n\n  Access tokens are scoped to an environment, for example: a development token cannot be used in requests to production. Verify the intended environment when creating an access token.\n\nThis is an example of authenticating a request with cURL, which automatically handles HTTP Basic Auth. If you run this request yourself it will not work, you should replace the Access Token ID (44c819de-4add-4c9f-b2e9-384a0a71bede) and secret (INKxCoZ+cX6l1yrR6vqzYHVaeFEcqvZShznWM1U/No8KsV7h6Jxu1XXuTUQ91sdiGONK3H7NE7H) in this example with your own credentials.\n\n\n```shell\ncurl https://api.mux.com/video/v1/assets \\\n  -H \"Content-Type: application/json\" \\\n  -X POST \\\n  -d '{ \"inputs\": [{ \"url\": \"https://muxed.s3.amazonaws.com/leds.mp4\" }], \"playback_policies\": [\"public\"], \"video_quality\": \"basic\" }' \\\n  -u 44c819de-4add-4c9f-b2e9-384a0a71bede:INKxCoZ+cX6l1yrR6vqzYHVaeFEcqvZShznWM1U/No8KsV7h6Jxu1XXuTUQ91sdiGONK3H7NE7H\n```\n\n\nHTTP basic auth works by base64 encoding the username and password in an Authorization header on the request.\n\nSpecifically, the header looks something like this:\n\n\n```bash\n'Authorization': 'Basic base64(MUX_TOKEN_ID:MUX_TOKEN_SECRET)'\n```\n\n\n1. The access token ID and secret are concatenated with a : and the string is base64 encoded.\n1. The value for the Authorization header is the string Basic plus a space   followed by the base64 encoded result from Step 1.\n\nIn the cURL example above, the cURL library is taking care of the base64 encoding and setting the header value internally. The HTTP library you use in your server-side language will probably have something similar for handling basic auth. You should be able to pass in the username (Access Token ID) and password (Access Token secret) and the library will handle the details of formatting the header.\n\n  If you're just getting started with Mux Video, use Read and Write.\n\nIf you are creating or modifying resources with Mux Video then you need Read and Write permissions. This includes things like:\n\n- Creating new assets\n- Creating direct uploads\n- Creating new live streams\n\nIf you need to create signed tokens for secure video playback, your access token needs System write permissions. Learn more about secure video playback and signing keys.\n\nMux Data only requires Write permissions if you need to create Annotations via API. Annotations created in the Dashboard do not require Write permissions.\n\n<Image\n  src=\"/docs/images/new-access-token.png\"\n  width={760}\n  height={376}\n  alt=\"Mux access token permissions\"\n  sm\n/>\n\nIf your code is not creating anything and only doing GET requests then you can restrict the access token to Read only.\n\nMux API endpoints do not have CORS headers, which means if you try to call the Mux API from the browser you will get an error:\n\n  request has been blocked by CORS policy: Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource.\n\nThis is expected. Although making API requests directly from the browser or your mobile app would be convenient, it leaves a massive security hole in your application by the fact that your client side code would contain your API keys. Anyone who accesses your application would have the ability to steal your API credentials and make requests to Mux on your behalf. An attacker would be able to gain full control of your Mux account.\n\nMux API Credentials should never be stored in a client application. All Mux API calls should be made from a trusted server.\n\nInstead of trying to make API requests from the client, the flow that your application should follow is:\n\n1. Client makes a request to your server\n1. Your server makes an authenticated API request to Mux\n1. Your server saves whatever it needs in your database\n1. Your server responds to the client with only the information that the client needs. For example, with live streaming that's the stream key for a specific stream, for uploads that's just the direct upload URL\n\nServerless functions are a great way to add pieces of secure server-side code to your client heavy application. Examples of services that help you run serverless functions are:\n\n- AWS Lambda\n- Firebase Cloud Functions\n- Cloudflare Workers\n- Vercel Functions\n- Netlify Functions\n\nThe basic idea behind serverless functions is that you can write a bit of server code and deploy it to run on these platforms. Your client application can make requests to these endpoints to perform specific actions. Below is an example from with-mux-video of a serverless function endpoint that makes an API call to create a Mux Direct Upload.\n\n\n```js\n// pages/api/upload.js\n// see: https://github.com/vercel/next.js/tree/canary/examples/with-mux-video\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux();\n\nexport default async function uploadHandler(req, res) {\n  const { method } = req;\n\n  switch (method) {\n    case 'POST':\n      try {\n        const upload = await mux.video.uploads.create({\n          new_asset_settings: { playback_policy: ['public'], video_quality: 'basic' },\n          cors_origin: '*',\n        });\n        res.json({\n          id: upload.id,\n          url: upload.url,\n        });\n      } catch (e) {\n        console.error('Request error', e);\n        res.status(500).json({ error: 'Error creating upload' });\n      }\n      break;\n    default:\n      res.setHeader('Allow', ['POST']);\n      res.status(405).end(`Method ${method} Not Allowed`);\n  }\n}\n```\n\n\nOur list endpoints (such as List Assets) do not return every single relevant record.\nTo offer everyone the best performance we limit the amount of records you can receive and offer pagination parameters to help you navigate through your list.\n\nPage/limit pagination\nOur most common pagination controls are page and limit.\n\n| Parameter | Default | Maximum | Description                                      |\n| :-------- | :------ | :---- | :--------------------------------------------------|\n| page    | 1     | None | The page number to return. The first page is 1.   |\n| limit   | 10    | 100 | The number of records to return per page.          |\n\nIf you have 100 assets and you want to get the first 10, you would make a request like this:\n\n\n```http\nGET /video/v1/assets?page=1&limit=10\n```\n\n\nAnd if you want to get the next 10, you would increment the page parameter from 1 to 2 and make a request like this:\n\n\n```http\nGET /video/v1/assets?page=2&limit=10\n```\n\n\nCursor pagination\nIn addition to page/limit, the List Assets endpoint also supports cursor pagination.\nCursor pagination is a more efficient and reliable way of paginating through very large collections.\n\nCursor pagination is only available on the List Assets endpoint, but we plan to add it to more endpoints in the future. If you want it added to any specific endpoints please let us know!\n\nWhen you make a request to the list assets endpoint we return a next_cursor value.\n\n\n```json\n// GET /video/v1/assets\n{\n  \"data\": [\n    {\n      \"id\": \"asset_id\",\n      \"status\": \"ready\",\n      ...\n    }\n  ],\n  \"next_cursor\": \"eyJwYWdlX2xpbWl0IjoxMDAwLCJwYWdlX2NvdW50IjoxfQ\"\n}\n```\n\n\nTake that next_cursor value and make a new request to the list assets endpoint with the cursor parameter.\n\n\n```json\n// GET /video/v1/assets?cursor=eyJwYWdlX2xpbWl0IjoxMDAwLCJwYWdlX2NvdW50IjoxfQ\n{\n  \"data\": [\n    {\n      \"id\": \"asset_id\",\n      \"status\": \"ready\",\n      ...\n    }\n  ],\n  \"next_cursor\": null\n}\n```\n\n\nIf next_cursor is null, you've reached the end of your list. If next_cursor is not null you can use that value to get the next page, repeating this pattern until next_cursor is null.\n\nMux Video implements a simple set of rate limits. Rate limits are set per account (not per environment). These rate limits exist for two reasons:\n\n1. First, to protect you, or customers from runaway scripts or batch process - we don't want you to accidentally delete all your content, or run up a large bill if you're not expecting it.\n1. Second, to ensure that there's always Mux infrastructure available when our customers need it, for example to start that critical live stream, or ingest that urgent video.\n\nWhen the rate limit threshold is exceeded, the API will return a HTTP status code 429.\n\nVideo API\n\n1. All Video API activities that include a POST request to https://api.mux.com/video/ are rate limited to a sustained 1 request per second (RPS) with the ability to burst above this for short periods of time. This includes creating new Assets, Live Streams, and Uploads.\n\n1. All other request methods are limited to 5 sustained requests per second (RPS) with the ability to burst above this for short periods of time. This includes GET, PUT, PATCH, & DELETE verbs. Examples include (but not limited to) requests for retrieving an asset, updating mp4 support, & listing delivery usage.\n\nPlayback\n\nThere are no limits as to the number of viewers that your streams can have, all we ask is that you let us know if you're planning an event expected to receive more than 100,000 concurrent live viewers.\n\nMonitoring Data API\n\nRequests against the Monitoring Data APIs are rate limited to a sustained 1 request per second (RPS) with the ability to burst above this for short periods of time.\n\nGeneral Data API\n\nRequests against the all other General Data APIs are rate limited to a sustained 5 request per second (RPS) with the ability to burst above this for short periods of time."
  },
  {
    "id": "5-_guides/core/mux-fundamentals",
    "title": "Mux fundamentals",
    "path": "_guides/core/mux-fundamentals.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/core/mux-fundamentals",
    "content": "Whether you're just getting started with Mux or need a quick refresher on how the pieces fit together, this guide covers the fundamental concepts you'll encounter when building video, audio, and live streaming applications.\n\nQuick reference\n\n| Term | Description |\n| :--- | :---------- |\n| Organization | The top-level account container. You can belong to multiple organizations, each with its own billing, team members, and environments. |\n| Environment | A container within an organization for organizing your Mux resources (assets, live streams, API tokens, etc.). Each organization can have multiple environments. |\n| Access Token | A credential pair (Token ID + Token Secret) used to authenticate API requests. Scoped to a single environment. |\n| Asset | A video or audio file that has been uploaded to Mux and processed for streaming playback. |\n| Playback ID | A unique identifier used to stream an asset or live stream to viewers. |\n| Live Stream | A resource representing a live broadcast that can receive RTMP/SRT input and deliver to viewers. |\n| Stream Key | A secret credential that allows a broadcaster to push video to a specific live stream. |\n| Signing Key | A public/private key pair used to create signed tokens (JWTs) for secure playback. |\n| Webhook | An HTTP callback that Mux sends to your server when events occur (e.g., asset ready, live stream started). |\n\nOrganizations\n\nAn organization is your top-level Mux account. It's the highest container in the Mux hierarchy and contains everything else: environments, team members, and billing settings.\n\nKey things to know about organizations:\n\n- You can belong to multiple organizations. This is useful if you work with different companies or clients, each with their own Mux account.\n- Each organization has its own billing. Usage charges are tracked and billed per organization.\n- Team members are managed at the organization level. You can invite collaborators and assign roles (Admin, Member) within each organization.\n- Organizations contain environments. All your media resources live inside environments, which live inside organizations.\n\nYou can switch between organizations and create new ones from the Mux Dashboard.\n\nEnvironments\n\nAn environment is a container within an organization for organizing your Mux resources. Each environment has its own isolated set of assets, live streams, access tokens, signing keys, and webhooks.\n\nCommon use cases for multiple environments:\n- Separate development and production resources\n- Isolate resources for different websites or domains (e.g., site1.com, site2.com)\n- Organize by project or use case (e.g., CMS media, marketing site, customer uploads)\n- Keep test data separate from production content\n\nResources are scoped to their environment. An access token created in Development cannot be used to manage assets in Production, and webhooks configured for one environment won't fire for events in another.\n\nYou can view and manage environments in the Mux Dashboard.\n\nAccess Tokens\n\nAccess tokens are credentials that authenticate your API requests to Mux. Each token consists of two parts:\n\n| Part | Description |\n| :--- | :---------- |\n| Token ID | The \"username\" portion of your credential. Safe to log (but not expose publicly). |\n| Token Secret | The \"password\" portion. Keep this secure and never expose it in client-side code. |\n\nMux only stores a hash of your token secret. If you lose it, you'll need to create a new access token.\n\nMux API requests must be made from a server, not from client-side code. The API does not support CORS, and exposing your credentials in a browser or mobile app is a security risk.\n\nToken permissions\n\nWhen creating an access token, you configure which permissions it has:\n\n| Permission | Use case |\n| :--------- | :------- |\n| Mux Video Read | Retrieve information about assets and live streams |\n| Mux Video Write | Create, update, and delete assets and live streams |\n| Mux Data Read | Access playback performance metrics |\n| Mux Data Write | Create Data annotations |\n| System Read | View signing keys and other system resources |\n| System Write | Create and manage signing keys |\n\nFor most use cases when getting started, you'll want Mux Video Read and Write permissions.\n\nYou can create and manage access tokens in the Mux Dashboard.\n\nLearn more: Make API requests | Use an SDK\n\nAssets\n\nAn asset is a video or audio file that has been ingested into Mux and processed for adaptive bitrate streaming. When you create an asset, Mux:\n\n1. Downloads the file from your provided URL (or receives it via direct upload)\n2. Transcodes it into multiple quality levels\n3. Packages it for HLS streaming\n4. Generates a unique asset ID\n\n\n```json\n// Example asset response\n{\n  \"data\": {\n    \"id\": \"01itgOBvgjAbES7Inwvu4kEBtsQ44HFL6\",\n    \"status\": \"ready\",\n    \"playback_ids\": [\n      {\n        \"id\": \"TXjw00EgPBPS6acv7gBUEJ14PEr5XNWOe\",\n        \"policy\": \"public\"\n      }\n    ],\n    \"duration\": 120.5,\n    \"aspect_ratio\": \"16:9\"\n  }\n}\n```\n\n\nAsset status lifecycle\n\nAssets progress through several statuses:\n\n| Status | Description |\n| :----- | :---------- |\n| preparing | Mux is downloading and processing the file |\n| ready | The asset is ready for playback |\n| errored | Something went wrong during processing |\n\nRather than polling the API to check status, use webhooks to be notified when an asset is ready.\n\nLearn more: Stream videos in five minutes | Assets API\n\nPlayback IDs\n\nA playback ID is what you use to actually stream content to viewers. While asset IDs are used to _manage_ your content (via api.mux.com), playback IDs are used to _stream_ your content (via stream.mux.com).\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8\n```\n\n\nPlayback policies\n\nEach playback ID has a policy that controls how it can be accessed:\n\n| Policy | Description |\n| :----- | :---------- |\n| public | Anyone with the URL can access the content |\n| signed | Viewers need a valid JWT token to watch |\n\nAn asset can have multiple playback IDs with different policies. This lets you, for example, have a public playback ID for trailers and a signed playback ID for the full content.\n\nYou can add and remove playback IDs without affecting the underlying asset. This is useful for revoking access without re-encoding your content.\n\nLearn more: Play your videos | Secure video playback\n\nLive streams\n\nA live stream represents a live broadcast channel. Unlike assets (which are created from existing files), live streams receive real-time input and deliver it to viewers with low latency.\n\nKey live stream components\n\n| Component | Description |\n| :-------- | :---------- |\n| Stream Key | A secret credential broadcasters use to connect their encoder to Mux |\n| RTMP URL | The ingest endpoint (rtmp://global-live.mux.com:5222/app) |\n| SRT URL | Alternative ingest endpoint for SRT protocol |\n| Playback ID | Used to stream to viewers (same concept as asset playback IDs) |\n\nAnyone with your stream key can broadcast to your live stream. Treat it like a password.\n\nLive stream lifecycle\n\n| Status | Description |\n| :----- | :---------- |\n| idle | No one is broadcasting; waiting for input |\n| active | A broadcaster is connected and viewers can watch |\n| disabled | The live stream has been disabled and won't accept connections |\n\nWhen a live stream ends, Mux automatically creates a new asset from the recording (if recording is enabled).\n\nLearn more: Configure broadcast software | Handle disconnections | Live Streams API\n\nSigning keys\n\nSigning keys are cryptographic key pairs used to generate JWTs (JSON Web Tokens) for secure video playback. When you have assets or live streams with signed playback policies, you need signing keys to create valid playback tokens.\n\n| Component | Description |\n| :-------- | :---------- |\n| Key ID | A unique identifier for the signing key |\n| Private Key | Used by your server to sign JWTs. Keep this secret. |\n\nYour server uses the private key to create short-lived tokens that grant access to specific content. The token can include claims for:\n\n- Expiration time - When the token becomes invalid\n- Playback restrictions - Additional rules like allowed domains\n\nSigning keys and access tokens serve different purposes:\n- Access tokens authenticate your server-to-Mux API requests\n- Signing keys create tokens that authenticate viewer playback requests\n\nYou can create and manage signing keys in the Mux Dashboard.\n\nLearn more: Secure video playback | Signing Keys API\n\nWebhooks\n\nWebhooks are HTTP callbacks that Mux sends to your application when events occur. Instead of repeatedly polling the API to check if an asset is ready, you configure a webhook URL and Mux notifies you automatically.\n\nCommon webhook events:\n\n| Event | Description |\n| :---- | :---------- |\n| video.asset.ready | An asset has finished processing and is ready for playback |\n| video.asset.errored | An asset failed to process |\n| video.live_stream.active | A live stream has started broadcasting |\n| video.live_stream.idle | A live stream has stopped broadcasting |\n| video.upload.asset_created | A direct upload has completed and created an asset |\n\nWebhooks are configured per environment. Make sure your webhook is set up in the same environment where your resources are created.\n\nLearn more: Listen for webhooks | Verify webhook signatures\n\nIDs at a glance\n\nMux uses several different types of identifiers. Here's a quick reference:\n\n| ID Type | Format Example | Purpose |\n| :------ | :------------- | :------ |\n| Organization ID | abc123 | Identify your organization |\n| Environment ID | j0863n | Identify specific environments within an organization |\n| Asset ID | 01itgOBvgj... | Identify and manage assets via the API |\n| Playback ID | TXjw00EgPB... | Stream content to viewers |\n| Live Stream ID | aA02skpHX... | Identify and manage live streams via the API |\n| Upload ID | OA02dANZ... | Track direct upload status |\n| Token ID | 44c819de-4add-... | Identify access tokens (part of API auth) |\n| Signing Key ID | JjPXgkqO... | Identify signing keys for JWT creation |\n\nSDKs\n\nMux provides official SDKs for several languages that handle authentication and make it easier to work with the API:\n\n- Node.js\n- Python\n- Ruby\n- PHP\n- Java\n- C/ .NET\n- Elixir\n\nFor client-side playback, see Mux Player and the various player SDK guides.\n\nLearn more: Use an SDK\n\nWhat's next?\n\nNow that you understand the fundamentals, here are some recommended next steps:\n\n  <GuideCard\n    title=\"Stream videos in five minutes\"\n    description=\"Upload your first video to Mux and play it back in your application.\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/core/stream-video-files\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Listen for webhooks\"\n    description=\"Set up webhooks to receive real-time notifications when events occur.\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/core/listen-for-webhooks\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Secure video playback\"\n    description=\"Learn how to protect your content with signed URLs and playback restrictions.\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/secure-video-playback\"},\n    ]}\n  />"
  },
  {
    "id": "6-_guides/core/postman",
    "title": "Make API requests with Postman",
    "path": "_guides/core/postman.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/core/postman",
    "content": "We recommend Postman as a way to easily explore and interact with our API.\n\nSimilar to forking a repository on GitHub, forking a collection on Postman allows you to create a new instance of the collection.\nHere, you can send requests, collaborate, and submit changes to the original collection.\nWithout forking the collection, the collection will be read-only and you will not be able to make requests unless you're a member of the workspace — even if the collection is public.\n\nIf you're already a Postman user, you can fork our officially supported Postman collection and add it to your workspace by clicking the button below.\n\nYou can then stay up to date with future changes to our API specification by pulling changes. More on that in the sections below.\n\n![Run in Postman](https://god.gw.postman.com/run-collection/18282356-97f1767e-f35a-4fca-b1c5-bf612e6f8e76?action=collection%2Ffork&collection-url=entityId%3D18282356-97f1767e-f35a-4fca-b1c5-bf612e6f8e76%26entityType%3Dcollection%26workspaceId%3D2bcc854d-f831-4c9f-ac0a-3b4382f3a5cd)\n\n| Term         | Description                                                |\n| :----------- | :--------------------------------------------------------- |\n| Token ID     | access token ID, the \"username\" in basic auth              |\n| Token secret | access token secret key, the \"password\" in basic auth      |\n\nSet up credentials\n\nOnce you've created your access tokens via your Mux account, you can input them into their respective fields under authorization.\n\n<Image\n  src=\"/docs/images/postman-auth.png\"\n  width={1217}\n  height={723}\n  alt=\"Basic authentication in Postman\"\n/>\n\nEnvironment variables\n\nYou can use environment variables to store and reuse values — like your credentials —\nacross requests and collections. Variables can either be scoped to the environment or globally, available to all collections within a workspace.\n\nTo create environment variables, click the eye icon on the right-hand side of the collection and choose the scope you want your credentials to apply to.\n\n<Image\n  src=\"/docs/images/postman-env-variables.png\"\n  width={1217}\n  height={723}\n  alt=\"Environment variables menu in Postman\"\n/>\n\nNext, add your credentials and set the type to secret. This will hide values on-screen. Once you've finished setting up your environment variables,\nyou can go back to basic authentication and use the variables instead of the values directly. To do this, use {{variable_name}} in the form field.\n\n<Image\n  src=\"/docs/images/postman-hidden-auth.png\"\n  width={1217}\n  height={723}\n  alt=\"Hidden authentication in Postman\"\n/>\n\nEven with extensive documentation, it can be hard to navigate an API for the first time. To help you make requests and understand their responses, we use Postman's\nexamples feature for all Mux Video and Mux Data endpoints.\n\nYou can view an endpoint's sample request body by clicking the endpoint on the left-hand API menu and then clicking body in the main section of the interface.\n\n<Image\n  src=\"/docs/images/postman-sample-request-body.png\"\n  width={1217}\n  height={723}\n  alt=\"Sample API request body in Postman\"\n/>\n\nYou can view an endpoint's sample request response by clicking the right-facing carat on the endpoint. A new item will appear in the collection with the icon e.g..\n\n<Image\n  src=\"/docs/images/postman-sample-request-response.png\"\n  width={1217}\n  height={523}\n  alt=\"Sample API request response in Postman\"\n/>\n\nSimilar to a forked repository on GitHub, your Postman fork will only stay up to date with the origin collection if you periodically pull changes\nto keep your fork in sync.\n\nYou can pull changes by clicking the three dots next to the name of your fork. This will open a sub-menu. Click on merge changes near the bottom of the menu.\n\n<Image\n  src=\"/docs/images/postman-fork-sub-menu.png\"\n  width={517}\n  height={123}\n  alt=\"Forked Postman collection's sub-menu\"\n/>\n\nIf your fork is not in sync with the origin collection, there will be a yellow banner that states, \"The destination has been modified since you last updated the fork. We’d recommend pulling changes.\" Click pull changes on the right.\n\nYou will then see a diff where source is the origin and destination is your fork.\n\n<Image\n  src=\"/docs/images/postman-pull-changes-diff.png\"\n  width={617}\n  height={323}\n  alt=\"API diff when pulling changes\"\n/>\n\nSometimes there will be merge conflicts. If you encounter them, you can choose whether you keep the source or destination version of a change.\n\nOnce everything looks good, click the orange button labeled pull changes."
  },
  {
    "id": "7-_guides/core/sdks",
    "title": "Use a Mux SDK",
    "path": "_guides/core/sdks.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/core/sdks",
    "content": "Mux has API SDKs for several major languages. You are not required to use them, but these SDKs handle the details of authentication for you and make it a little nicer to send API requests to Mux; in languages with static typing or type hints, they also will help you form correct requests and reduce development time.\n\n- Node\n- Python\n- PHP\n- Ruby\n- Elixir\n- Java\n- Cand other .NET languages"
  },
  {
    "id": "8-_guides/core/stream-video-files",
    "title": "Stream videos in five minutes",
    "path": "_guides/core/stream-video-files.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/core/stream-video-files",
    "content": "The Mux Video API uses a token key pair that consists of a Token ID and Token Secret for authentication. If you haven't already, generate a new Access Token in the Access Token settings of your Mux account dashboard.\n\nYou'll be presented with a form to create your new Access Token.\n\n- Access Tokens belong to an Environment — a container for the various Access Tokens, Signing Keys, and assets that you'll come to add to Mux. For this guide, you can keep the Production environment selected.\n- Access Tokens can have varying permissions to control what kinds of changes they have the ability to make. For this guide, your Access Token should have Mux Video Read and Write permissions.\n- You can give your Access Token an internal-only name like \"Onboarding\" so you know where you've used it within your application.\n\nNow, click the Generate token button.\n\nYou'll be presented with your new Access Token ID and Secret Key.\n\nOnce you have your new Access Token ID and Secret Key, you're ready to upload your first video.\n\n<LinkedHeader\n  step={steps[1]}\n  apiRef={{ href: \"/docs/api-reference/video/assets/create-asset\" }}\n/>\n\nVideos stored in Mux are called assets. To create your first video asset, you need to send a POST request to the /assets endpoint and set the input value to the URL of a video file that's accessible online.\n\nHere are a few demo videos you can use that are stored on common cloud storage services:\n\n- Amazon S3: https://muxed.s3.amazonaws.com/leds.mp4\n- Google Drive: https://drive.google.com/uc?id=13ODlJ-Dxrd7aJ7jy6lsz3bwyVW-ncb3v\n- Dropbox: https://www.dropbox.com/scl/fi/l2sm1zyk6pydtosk3ovwo/get-started.mp4?rlkey=qjb34b0b7wgjbs5xj9vn4yevt&dl=0\n\nTo start making API requests to Mux, you might want to install one of our officially supported API SDKs. These are lightweight wrapper libraries that use your API credentials to make authenticated HTTP requests to the Mux API.\n\n<CodeExamples\n  product=\"video\"\n  example=\"installSdk\"\n/>\n\n  For an example of how to make API Requests from your local environment, see the Make API Requests guide.\n\n<CodeExamples\n  product=\"video\"\n  example=\"createAsset\"\n/>\n\nThe response will include an Asset ID and a Playback ID.\n\n- Asset IDs are used to manage assets using api.mux.com (e.g. to read or delete an asset).\n- Playback IDs are used to stream an asset to a video player through stream.mux.com. You can add multiple playback IDs to an asset to create playback URLs with different viewing permissions, and you can delete playback IDs to remove access without deleting the asset.\n\n\n```json\n{\n  \"data\": {\n    \"status\": \"preparing\",\n    \"playback_ids\": [\n      {\n        \"policy\": \"public\",\n        \"id\": \"TXjw00EgPBPS6acv7gBUEJ14PEr5XNWOe\"\n      }\n    ],\n    \"video_quality\": \"basic\",\n    \"mp4_support\": \"none\",\n    \"master_access\": \"none\",\n    \"id\": \"01itgOBvgjAbES7Inwvu4kEBtsQ44HFL6\",\n    \"created_at\": \"1607876845\"\n  }\n}\n```\n\n\n  Mux does not store the original file in its exact form, so if your original quality files are important to you, don't delete them after submitting them to Mux.\n\n<LinkedHeader\n  step={steps[2]}\n  apiRef={{ href: \"/docs/api-reference/video/assets/get-asset\" }}\n/>\n\nAs soon as you make the POST request, Mux begins downloading and processing the video. For shorter files, this often takes just a few seconds. Very large files over poor connections may take a few minutes (or longer).\n\nWhen the video is ready for playback, the asset status changes to ready. You should wait until the asset status is ready before you attempt to play the video.\n\nThe best way to be notified of asset status updates is via webhooks. Mux can send a webhook notification as soon as the asset is ready. See the webhooks guide for details.\n\nIf you can't use webhooks for some reason, you can manually poll the asset API to see asset status. Note that this only works at low volume. Try this example:\n\nTry an example request\n\n<CodeExamples\n  product=\"video\"\n  example=\"retrieveAsset\"\n/>\n\nPlease don't poll this API more than once per second.\n\nTo play back an asset, create a playback URL using the PLAYBACK_ID you received when you created the asset.\n\n\n```curl\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8\n```\n\n\nPreview in a player\n\n<CodeExamples\n  product=\"video\"\n  example=\"hlsPlayback\"\n  exampleOrder=\"html,react,embed,swift,android\"\n/>\n\nSee the playback guide for more information about how to integrate with a video player.\n\nPreview with stream.new\n\nStream.new is an open source project by Mux that allows you to add a video and get a shareable link to stream it.\n\nGo to stream.new/v/{PLAYBACK_ID} to preview your video streaming. This URL is shareable and automatically generated using the video playback ID. Copy the link below and open it in a browser to view your video.\n\n\n```\nhttps://stream.new/v/{PLAYBACK_ID}\n```\n\n\nAfter you have everything working integrate Mux Data with your player for monitoring playback performance.\n\nAfter you have assets created in your Mux environment, you may find some of these other endpoints handy:\n\n- Create an asset\n- List assets\n- Retrieve an asset\n- Delete an asset\n- Retrieve asset input info\n- Create asset playback ID\n- Retrieve asset playback ID\n- Delete asset playback ID\n- Update MP4 support on asset\n- Update master access on asset\n- Update asset track\n- Delete an asset track\n\nMore Video methods and descriptions are available at the API Docs.\n\nNext Steps\n\n  <GuideCard\n    title=\"Play your videos\"\n    description=\"Set up your iOS application, Android application or web application to start playing your Mux assets\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/play-your-videos\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Preview your video\"\n    description=\"Now that you have Mux assets, build rich experiences into your application by previewing your videos with Thumbnails and Storyboards\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/get-images-from-a-video\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Integrate Mux Data\"\n    description=\"Add the Mux Data SDK to your player and start collecting playback performance metrics.\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/track-your-video-performance\"},\n    ]}\n  />"
  },
  {
    "id": "9-_guides/core/verify-webhook-signatures",
    "title": "Verify webhook signatures",
    "path": "_guides/core/verify-webhook-signatures.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/core/verify-webhook-signatures",
    "content": "Obtain your signing secret\n\nBefore you get started, you will need your signing secret for your webhook. You can find that where you configure webhooks on the webhooks settings page. Please note that the signing secret is different for each webhook endpoint that we notify.\n\nWebhooks contain a header called mux-signature with the timestamp and a signature. The timestamp is prefixed by t= and the signature is prefixed by a scheme. Schemes start with v, followed by an integer. Currently, the only valid signature scheme is v1. Mux generates signatures using HMAC with SHA-256.\n\n```text\nMux-Signature: t=1565220904,v1=20c75c1180c701ee8a796e81507cfd5c932fc17cf63a4a55566fd38da3a2d3d2`\n```\n\n\nHow to verify webhook signatures\n\nStep 1: Extract the timestamp and signature\n\nSplit the header at the , character and get the values for t (timestamp) and v1 (the signature)\n\nStep 2: Prepare the signed_payload string\n\nYou will need:\n   the timestamp from Step 1 as a string (for example: \"1565220904\")\n   the dot character .\n  * the raw request body (this will be JSON in a string format)\n\nStep 3: Determine the expected signature\n\nUse the 3 components from Step 2 to compute an HMAC with the SHA256 hash function. Depending on the language that you are using this will look something like the following:\n\n\n```js\nsecret = 'my secret' // your signing secret\npayload = timestamp + \".\" + request_body\nexpected_signature = createHmacSha256(payload, secret)\n```\n\n\nStep 4: Compare signature\n\nCompare the signature in the header to the expected signature. If the signature matches, compute the difference between the current timestamp and the received timestamp, then check to make sure that the timestamp is within our tolerance. By default, our SDKs allow a tolerance of 5 minutes.\n\nExamples\n\nOur official SDKs for Node and Elixir contain helper methods for verifying Mux webhooks. If you're using one of these languages it's best to use our available helper methods. Note that the helper methods use the raw request body instead of a payload including the timestamp."
  },
  {
    "id": "10-_guides/developer/add-alternate-audio-tracks-to-your-videos",
    "title": "Add alternate audio tracks to videos",
    "path": "_guides/developer/add-alternate-audio-tracks-to-your-videos.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/add-alternate-audio-tracks-to-your-videos",
    "content": "Introduction to multi-track audio\n\nThe multi-track audio feature allows you to add alternate audio tracks to the video assets in your Mux account.\n\nVideos with multi-track audio can be used for increased accessibility or multi-language support, or just to allow viewers to opt into a different audio experience, like a director's commentary.\n\n(Optional) Set the language and name for your primary audio track\n\n  Optional but highly recommended to increase accessibility if you're delivering alternate audio tracks.\n\nWhen you create an asset in Mux, you can also specify the language_code and name of the primary audio track that's embedded in your first input file.\n\n\n```json\n// POST https://api.mux.com/video/assets\n\n{\n  \"inputs\": [\n    {\n      \"url\": \"{VIDEO_INPUT_URL}\",\n      \"language_code\" : \"en\",\n      \"name\" : \"English\"\n    }\n  ],\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"video_quality\": \"basic\"\n}\n```\n\n\nA name is optional but highly recommended. If you don't specify it, we'll generate it for you based on the language_code you provided. The language_code must be a BCP-47 language tag, such as en for English, or es for Spanish. You can find a list of common BCP-47 language tags here.\n\nYou can still use multi-track audio with assets that don't have a language or name set on your initial upload; we'll just call your primary audio track \"Default,\" with no language.\n\nAdd alternate audio tracks to your asset\n\nOnce you've created your asset with a primary audio track, you can add alternate audio tracks using the create asset track API, specifying the URL of the audio file you wish to add, and the language_code of the alternate audio track. This is the same API that you can use to add captions to your assets.\n\nMux supports most audio file formats and codecs, such as M4A, WAV, or MP3 file.  but for fastest processing, you should use standard inputs wherever possible.\n\n\n```json\n// POST https://api.mux.com/video/assets/${ASSET_ID/tracks\n\n{\n  \"url\": \"https://example.com/bar.m4a\",\n  \"type\": \"audio\",\n  \"language_code\": \"fr\",\n  \"name\": \"Français\"\n}\n```\n\n\nAssets must be in the ready state before you can use the create asset track API to add the alternate audio track.\n\nYou always need to specify the language_code for an alternate audio track, but the name is optional. If you don't specify a name, we'll generate it for you based on the language code you provided.\n\nYou will need to call the API once for each alternate audio track that you want to add.\n\nPlay your videos with multi-track audio\n\nWhen the alternate audio track has been processed, Mux will automatically add it to the HLS playback URL for your asset.\n\nMany video players already support multi-track audio right out of the box, including Mux Player, Video.js, ExoPlayer, and AVPlayer. So just drop your usual playback URL into your favorite video player, and click play. If your player doesn't support multi-track audio, you'll just hear the primary audio track.\n\nSwitching between audio tracks differs in each video player, but this will usually be a menu on the bottom right allowing you to change the track. For example below in Mux Player, you need to click the waveform icon."
  },
  {
    "id": "11-_guides/developer/add-autogenerated-captions-and-use-transcripts",
    "title": "Add auto-generated captions to your videos and use transcripts",
    "path": "_guides/developer/add-autogenerated-captions-and-use-transcripts.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/add-autogenerated-captions-and-use-transcripts",
    "content": "How auto-generated captions work\n\nMux uses OpenAI's Whisper model to automatically generate captions for on-demand assets. This guide shows you how to enable this feature, what you can do with it, and what some of the limitations you might encounter are.\n\nGenerally, you should expect auto-generated captions to work well for content with reasonably clear audio. It may work less well with assets that contain a lot of non-speech audio (music, background noise, extended periods of silence).\n\nWe recommend that you try it out on some of your typical content, and see if the results meet your expectations.\n\nThis feature is designed to generate captions in the same language that your content's audio is produced in. It should not be used to programatically generate translated captions in other languages.\n\nEnable auto-generated captions\n\nWhen you create a Mux Asset, you can add a generated_subtitles array to the API call, as follows:\n\n\n```json\n// POST /video/v1/assets\n{\n    \"inputs\": [\n        {\n            \"url\": \"...\",\n            \"generated_subtitles\": [\n                {\n                    \"language_code\": \"en\",\n                    \"name\": \"English CC\"\n                }\n            ]\n        }\n    ],\n    \"playback_policies\": [\n      \"public\"\n    ],\n    \"video_quality\": \"basic\"\n}\n```\n\n\nMux supports the following languages and corresponding language codes for VOD generated captions. Languages labeled as \"beta\" may have lower accuracy.\n\n| Language | Language Code | Status |\n| :-- | :-- | :-- |\n| English | en | Stable |\n| Spanish | es | Stable |\n| Italian | it | Stable |\n| Portuguese | pt | Stable |\n| German | de | Stable |\n| French | fr | Stable |\n| Polish | pl | Beta |\n| Russian | ru | Beta |\n| Dutch | nl | Beta |\n| Catalan | ca |  Beta |\n| Turkish | tr |  Beta |\n| Swedish | sv | Beta |\n| Ukrainian | uk | Beta |\n| Norwegian | no | Beta |\n| Finnish | fi | Beta |\n| Slovak | sk | Beta |\n| Greek | el | Beta |\n| Czech | cs | Beta |\n| Croatian | hr | Beta |\n| Danish | da | Beta |\n| Romanian | ro | Beta |\n| Bulgarian | bg | Beta |\n\nYou can also enable autogenerated captions if you're using Direct Uploads by specifying the generated_subtitles configuration in the first entry of the input list of the new_asset_settings object, like this:\n\n\n```json\n// POST /video/v1/uploads\n{\n    \"new_asset_settings\": {\n        \"playback_policies\": [\n            \"public\"\n        ],\n        \"video_quality\": \"basic\",\n        \"inputs\": [\n            {\n                \"generated_subtitles\": [\n                    {\n                        \"language_code\": \"en\",\n                        \"name\": \"English CC\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"cors_origin\": \"*\"\n}\n```\n\n\nAuto-captioning happens separately from the initial asset ingest, so that this doesn't delay the asset being available for playback. If you want to know when the text track for the captions is ready, listen for the video.asset.track.ready webhook for a track with \"text_source\": \"generated_vod\".\n\nRetroactively enable auto-generated captions\n\nYou can retroactively add captions to any asset by POSTing to the generate-subtitles endpoint on the asset audio track that you want to generate captions for, as shown below:\n\n\n```json\n// POST /video/v1/assets/${ASSET_ID}/tracks/${AUDIO_TRACK_ID}/generate-subtitles\n\n{\n  \"generated_subtitles\": [\n    {\n      \"language_code\": \"en\",\n      \"name\": \"English (generated)\"\n    }\n  ]\n}\n```\n\n\nFor self-service customers: You can add captions to any asset using this API.\n\nFor contract customers: If you need to add captions to assets older than 7 days, please contact support and we'd be happy to help. Please note that there may be a charge for backfilling captions onto large libraries.\n\nRetrieve a transcript\n\nFor assets that have a ready auto-generated captions track, you can also request a transcript (a plain text file) of the speech recognized in your asset.\n\nTo get this, use a playback id for your asset and the track id for the generated_vod text track:\n\n  If you don't know the TRACK_ID, you can retrieve it by listing the asset's tracks using the{' '}\n  Asset endpoint under tracks and the corresponding track.id.\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}/text/{TRACK_ID}.txt\n```\n\n\nSigned assets require a token parameter specifying a JWT with the same aud claim used for video playback:\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}/text/{TRACK_ID}.txt?token={JWT}\n```\n\n\nYou can also retrieve a WebVTT version of the text track by replacing .txt with .vtt in the URL.\n\nYou might find this transcript useful for doing further processing in other systems. For example, content moderation, sentiment analysis, summarization, extracting insights from your content, and many more.\n\nFAQ\n\nHow much does auto-generated captioning cost for on-demand assets?\n\nThere is no additional charge for this feature. It's included as part of the standard encoding and storage charges for Mux Video assets.\n\nHow long does it take to generate captions?\n\nIt depends on the length of the asset, but generally it takes about 0.1x content duration. As an example, a 1 hour asset would take about 6 minutes to generate captions for.\n\nHelp, the captions you generated are full of mistakes!\n\nWe're sorry to hear that! Unfortunately, though automatic speech recognition has improved enormously in recent years, sometimes it can still get things wrong.\n\nOne option you have is to edit and replace the mis-recognized speech in the captions track:\n1. Download the full VTT file we generated at https://stream.mux.com/{PLAYBACK_ID}/text/{TRACK_ID}.vtt\n1. Edit the VTT file using your preferred text editor\n1. Delete the autogenerated track with the 'delete track' API\n1. Add a new track to your asset using the edited VTT file, using the create track API\n\nMy content is in multiple languages\n\nWe currently do not recommend using this feature on mixed-language content.\n\nI want to generate captions in a different language to my content\n\nWe currently do not support automatic translation in generated captions - you should only generate captions in the language that matches your audio track.\n\nMy content is in a language you don't support\n\nWe'd love to hear more about the languages that you'd like to see us support, please reach out with details."
  },
  {
    "id": "12-_guides/developer/add-autogenerated-live-captions",
    "title": "Add Auto-Generated Live Captions",
    "path": "_guides/developer/add-autogenerated-live-captions.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/add-autogenerated-live-captions",
    "content": "Mux is excited to offer auto-generated live closed captions in English, French, German, Italian, Portuguese, and Spanish. Closed captions make video more accessible to people who are deaf or hard of hearing, but the benefits go beyond accessibility. Captions empower your viewers to consume video content in whichever way is best for them, whether it be audio, text, or a combination.\n\nFor auto-generated live closed captions, we use artificial intelligence based speech-to-text technology to generate the closed captions. Closed captions refer to the visual display of the audio in a program.\n\nNon technical content with clear audio and minimal background noise is most suitable for auto-generated live captions. Content with music and multiple speakers speaking over each other are not good use cases for auto-generated live captions.\n\nAccuracy ranges for auto-generated live captions range from 70-95%.\n\nFor all content, we recommend you provide transcription vocabulary of technical terms (e.g. CODEC) and proper nouns. By providing the transcription vocabulary beforehand, you can increase the accuracy of the closed captions.\n\nThe transcription vocabulary helps the speech to text engine transcribe terms that otherwise may not be part of general library. Your use case may involve brand names or proper names that are not normally part of a language model’s library (e.g. \"Mux\"). Or perhaps you have a term, say \"Orchid\" which is a brand name of a toy. The engine will recognize \"orchid\" as a flower but you would want the word transcribed with proper capitalization in the context as a brand.\n\nPlease note that it can take up to 20 seconds for the transcription vocabulary to be applied to your live stream.\n\nYou can create a new transcription library by making a POST request to /video/v1/transcription-vocabularies endpoint API and define the input parameters. Each transcription library can have up to 1,000 phrases.\n\nRequest Body Parameters\n\n| Input parameters | Type     | Description                                                                                                                                           |\n| ---------------- | -------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |\n| name             | string | The human readable description of the transcription library.                                                                                          |\n| phrases          | array  | An array of phrases to populate the transcription library. A phrase can be one word or multiple words, usually describing a single object or concept. |\n\nAPI Request\n\n\n```json\nPOST /video/v1/transcription-vocabularies\n{\n  \"name\": \"TMI vocabulary\",\n  \"phrases\": [\"Mux\", \"Demuxed\", \"The Mux Informational\", \"video.js\", \"codec\", \"rickroll\"]\n}\n```\n\n\nAPI Response\n\n\n```json\n{\n  \"data\": {\n    \"updated_at\": \"1656630612\",\n    \"phrases\": [\"Mux\", \"Demuxed\", \"The Mux Informational\", \"video.js\", \"codec\", \"rickroll\"],\n    \"name\": \"TMI vocabulary\",\n    \"id\": \"4uCfJqluoYxl8KjXxNF00TgB56OyM152B5ZR00cLKXFlc\",\n    \"created_at\": \"1656630612\"\n  }\n}\n```\n\n\nAdd the generated_subtitles array at time of stream creation or to an existing live stream.\n\nRequest Body Parameters\n\n| Input parameters               | Type     | Description                                                                                                                                                                                                                 |\n| ------------------------------ | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| name                         | string | The human readable description for the generated subtitle track. This value must be unique across all the text type and subtitles text type tracks. If not provided, the name is generated from the chosen language_code. |\n| passthrough                  | string | Arbitrary metadata set for the generated subtitle track.                                                                                                                                                                    |\n| language_code                | string | BCP-47 language tag for captions. Defaults to \"en\".                                                                       |\n| transcription_vocabulary_ids | array  | The IDs of existing Transcription Vocabularies that you want to be applied to the live stream. If the vocabularies together contain more than 1,000 unique phrases, only the first 1,000 will be used.                      |\n\nMux supports the following languages and corresponding language codes for live generated captions.\n\n| Language | Language Code |\n| :-- | :-- |\n| English | \"en\" |\n| Spanish | \"es\" |\n| Italian | \"it\" |\n| Portuguese | \"pt\" |\n| German | \"de\" |\n| French | \"fr\" |\n\nLocale codes such as \"en-US\" or \"es-MX\" are accepted and will be parsed down to their language code (e.g., \"en-US\" → \"en\").\n\nStep 1A: Create a live stream in Mux\n\nCreate a live stream using the Live Stream Creation API. Let Mux know that you want auto-generated live closed captions.\n\nAPI Request\n\n\n```json\nPOST /video/v1/live-streams\n\nRequest Body\n{\n  \"playback_policy\" : [\"public\"],\n  \"generated_subtitles\": [\n    {\n      \"name\": \"English CC (auto)\",\n      \"passthrough\": \"English closed captions (auto-generated)\",\n      \"language_code\": \"en\",\n      \"transcription_vocabulary_ids\": [\"4uCfJqluoYxl8KjXxNF00TgB56OyM152B5ZR\"]\n    }\n  ],\n  \"new_asset_settings\" : {\n    \"playback_policy\" : [\"public\"]\n  }\n}\n```\n\n\nAPI Response\n\n\n```json\nResponse\n{\n  \"data\": {\n    \"stream_key\": \"5bd28537-7491-7ffa-050b-bbb506401234\",\n    \"playback_ids\": [\n      {\n        \"policy\": \"public\",\n        \"id\": \"U00gVu02hfLPdaGnlG1dFZ00ZkBUm2m0\"\n      }\n    ],\n    \"new_asset_settings\": {\n      \"playback_policies\": [\n        \"public\"\n      ]\n    },\n    \"generated_subtitles\" : [\n      \"name\": \"English CC (auto)\",\n      \"passthrough\": \"English closed captions (auto-generated)\",\n      \"language_code\": \"en\",\n      \"transcription_vocabulary_ids\": [\"4uCfJqluoYxl8KjXxNF00TgB56OyM152B5ZR\"]\n    ],\n    \"id\": \"e00Ed01C9ws015d5SLU00ZsaUZzh5nYt02u\",\n    \"created_at\": \"1624489336\"\n  }\n}\n\n```\n\n\nStep 1B: Configure live captions for an existing live stream\n\nUse the Generated Subtitles API to configure generated closed captions to an existing live stream. Live closed captions can not be configured to an active live stream.\n\nAPI Request\n\n\n```json\nPUT /video/v1/live-streams/{live_stream_id}/generated-subtitles\n\nRequest Body\n{\n  \"generated_subtitles\": [\n    {\n      \"name\": \"English CC (auto)\",\n      \"passthrough\": \"{\\\"description\\\": \\\"English closed captions (auto-generated)\\\"}\",\n      \"language_code\": \"en\",\n      \"transcription_vocabulary_ids\": [\"4uCfJqluoYxl8KjXxNF00TgB56OyM152B5ZR\"]\n    }\n  ]\n}\n```\n\n\nAPI Response\n\n\n```json\nResponse\n{\n  \"data\": {\n    \"stream_key\": \"5bd28537-7491-7ffa-050b-bbb506401234\",\n    \"playback_ids\": [\n      {\n        \"policy\": \"public\",\n        \"id\": \"U00gVu02hfLPdaGnlG1dFZ00ZkBUm2m0\"\n      }\n    ],\n    \"new_asset_settings\": {\n      \"playback_policies\": [\n        \"public\"\n      ]\n    },\n    \"generated_subtitles\": [\n      {\n        \"name\": \"English CC (auto)\",\n        \"passthrough\": \"{\\\"description\\\": \\\"English closed captions (auto-generated)\\\"}\",\n        \"language_code\": \"en\",\n        \"transcription_vocabulary_ids\": [\"4uCfJqluoYxl8KjXxNF00TgB56OyM152B5ZR\"]\n      }\n    ]\n  }\n}\n```\n\n\nStep 2: Start your live stream\n\n- At the start of the Live Stream, two text tracks will be created for the active asset, with text_source attributes of generated_live and generated_live_final, respectively.\n\n- While the stream is live, the generated_live track will be available and include predicted text for the audio.\n\n- At the end of the stream, the generated_live_final track will transition from the preparing to ready state; this track will include finalized predictions of text and result in higher-accuracy, better-timed text.\n\n- After the live event has concluded, the playback experience of the asset created will only include the more accurate generated_live_final track, but the sidecar VTT files for both tracks will continue to exist.\n\nTo prevent future connections to your live stream from receiving auto-generated closed captions, update the generated_subtitles configuration to null or an empty array.\n\nAPI Request\n\n\n```json\nPUT /video/v1/live-streams/{live_stream_id}/generated-subtitles\n\nRequest Body\n{\n  \"generated_subtitles\" : []\n}\n```\n\n\nUpdate phrases in a transcription vocabulary\n\nPhrases can be updated at any time, but won't go into effect to active live streams with auto-generated live closed captions enabled where the transcription vocabulary has been applied. If the updates are applied to an active live stream, they will not be applied until the next time the stream is active.\n\nAPI Request\n\n\n```json\nPUT /video/v1/transcription-vocabularies/$ID\n{\n  \"phrases\": [\"Demuxed\", \"HLS.js\"]\n}\n```\n\n\nWhat happens if my live stream has participants speaking languages other than the caption stream I've chosen?\n\nIf you've added an auto-generated English caption stream and your audio contains a non-English language, we will attempt to auto-generate captions for all the content in English. e.g. If French and English are spoken, we will create captions for the French language content using the English model and the output would be incomprehensible.\n\nWhen can I edit my live caption configuration?\n\nOnly when the live stream is idle. You cannot make any changes while the live stream is active.\n\nHow do I download my auto-generated closed caption track?\n\n\n```json\nhttps://stream.mux.com/{PLAYBACK_ID}/text/{TRACK_ID}.vtt\n```\n\n\nMore details can be found at Advanced Playback features\n\nDo live captions work with low latency live streams?\n\nNot at this time."
  },
  {
    "id": "13-_guides/developer/add-live-captions",
    "title": "Add your own live closed captions",
    "path": "_guides/developer/add-live-captions.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/add-live-captions",
    "content": "Why are closed captions important?\n\nClosed captions refers to the visual display of the audio in a program. Closed captions make video more accessible to people who are deaf or hard of hearing, but the benefits go beyond accessibility. Closed captions empower your viewers to consume video content in whichever way is best for them, whether it be audio, text, or a combination.\n\nSupported live caption formats\n\nThere are many types of closed caption sources, and each streaming standard may use a different format for embedding captions on the output. Mux supports receiving closed captions embedded in the H.264 video stream using the CEA-608 standard for a single language.\n\nCEA-608 stems from the analog era where closed captions data was carried directly in the transmission in a line of the video content that wasn’t displayed unless the decoder was told to look for it. These were often referred to as “Line 21” captions. CEA-608 is still the primary standard for transmitting closed captions within the same stream as audio/video content.\n\nMost major live caption providers (e.g. AI-Media, EEG Falcon, 3Play, Verbit) will support the CEA-608 standard. Mux will translate the CEA-608 captions into WebVTT that will be delivered as part of the HLS stream/manifest, in a standard HLS-supported manner. We will continue to evaluate demand for supporting captions for multiple languages and other caption formats.\n\nIntegrate your own closed captions\n\nAdd the embedded_subtitles array at time of stream creation or to an existing live stream. Closed captions are a type of subtitle. The resulting Asset's subtitle text track will have closed_captions: true set.\n\n| Input Parameters | Type   | Description                                                                                                                                                                                    |\n| ---------------- | ------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| name             | string | The name of the track containing a human-readable description. This value must be unique across all the text type and subtitles text type tracks. Defaults to language_code if not provided. |\n| passthrough      | string | Arbitrary metadata set for the live closed caption track. Max 255 characters.                                                                                                                  |\n| language_code    | string | The language of the closed caption stream. Value must be BCP 47 compliant. Defaults to en if not provided                                                                                    |\n| language_channel | string | CEA-608 caption channel to read caption data from. Possible values: \"cc1\"                                                                                                                      |\n\nStep 1A: Create a live stream in Mux\n\nCreate a live stream using the Live Stream Creation API. Let Mux know that closed captions will be embedded in the RTMP stream at time of live stream creation.\n\nAPI Request\n\n\n```json\nPOST /video/v1/live-streams\n\nRequest Body\n{\n  \"playback_policy\" : [\n    \"public\"\n  ],\n  \"embedded_subtitles\" : [\n    {\n      \"name\": \"English CC\",\n      \"passthrough\": \"English closed captions\",\n      \"language_code\": \"en-US\",\n      \"language_channel\" : \"cc1\"\n    }\n  ],\n  \"new_asset_settings\" : {\n    \"playback_policy\" : [\n      \"public\"\n    ]\n  }\n}\n```\n\n\nAPI Response\n\n\n```json\n{\n  \"data\": {\n    \"stream_key\": \"5bd28537-7491-7ffa-050b-bbb506401234\",\n    \"playback_ids\": [\n      {\n        \"policy\": \"public\",\n        \"id\": \"U00gVu02hfLPdaGnlG1dFZ00ZkBUm2m0\"\n      }\n    ],\n    \"new_asset_settings\": {\n      \"playback_policies\": [\"public\"]\n    },\n    \"embedded_subtitles\": [\n      {\n        \"name\": \"English CC\",\n        \"passthrough\": \"English closed captions\",\n        \"language_code\": \"en-US\",\n        \"language_channel\": \"cc1\"\n      }\n    ],\n    \"id\": \"e00Ed01C9ws015d5SLU00ZsaUZzh5nYt02u\",\n    \"created_at\": \"1624489336\"\n  }\n}\n```\n\n\nStep 1B: Configure live closed captions for an existing live stream\n\nUse the Live Stream Closed Captions API to configure closed captions to an existing live stream. Live closed captions can not be configured to an active live stream.\n\nAPI Request\n\n\n```json\nPUT / video/v1/live-streams/{live_stream_id}/embedded-subtitles\n\nRequest Body\n{\n  \"embedded_subtitles\": [\n    {\n      \"name\": \"en-US\",\n      \"language_code\": \"en-US\",\n      \"language_channel\": \"cc1\"\n    }\n  ]\n}\n```\n\n\nAPI Response\n\n\n```json\nResponse\n{\n  \"data\": {\n    \"stream_key\": \"5bd28537-7491-7ffa-050b-bbb506401234\",\n    \"playback_ids\": [\n      {\n        \"policy\": \"public\",\n        \"id\": \"U00gVu02hfLPdaGnlG1dFZ00ZkBUm2m0\"\n      }\n    ],\n    \"new_asset_settings\": {\n      \"playback_policies\": [\n        \"public\"\n      ]\n    },\n    \"embedded_subtitles\" : [\n      {\n        \"name\": \"English\",\n        \"language_code\": \"en-US\",\n        \"language_channel\": \"cc1\"\n      }\n    ],\n    \"id\": \"e00Ed01C9ws015d5SLU00ZsaUZzh5nYt02u\",\n    \"created_at\": \"1624489336\"\n  }\n}\n```\n\n\nStep 2: Create an event with your preferred closed caption vendor\n\nLog into your preferred closed caption provider account (e.g. AI-Media, 3Play, Verbit) and create an event that needs to be captioned. To create an event, you will need to provide the following inputs\n\n- Start date and time\n- Language of audio to be captioned\n- Destination Stream URL and Stream Key (Mux). The caption vendor will send video with captions encoded via the 608 standard to this destination.\n\n| RTMP Server URL                     | Description                                                                                                          | Common Applications                                                                                                         |\n| ----------------------------------- | -------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------- |\n| rtmp://global-live.mux.com:5222/app | Mux's standard RTMP ingest URL. Compatible with the majority of streaming applications and services.                | Open Source RTMP SDKs, most app-store streaming applications. |\n| rtmps://global-live.mux.com:443/app | Mux's secure RTMPS ingest URL. Compatible with fewer streaming applications, but offers a higher level of security. | OBS, Wirecast, Streamaxia RTMP SDKs                                                                                         |\n\nMux's global RTMP or RTMPS ingest urls will connect you to the closest ingest region. While these ingest URLs typically provide optimal performance, you can also select a specific region using our regional ingest URLs..\n\nUpon successful event creation, the closed caption provider will provide the following\n\n- Stream URL\n- Stream Key\n\nLearn more about:\n\n- How to setup live captions with AI-Media EEG Falcon\n- How to setup live captions with 3Play Media\n- How to setup live captions with Verbit\n\nStep 3: Point your RTMP stream to your caption provider\n\nConfigure your video encoder with the Stream URL and Stream Key provided by the closed caption provider in Step 2.\n\nStep 4: Start your live stream\n\nWhen the stream goes live, a new live asset is created and tracks will be created for the corresponding captions.\n\nStep 5: Monitor closed caption stream health\n\nWhen your stream is live, visit the Live Health Dashboard to monitor closed caption stream health. The dashboard will show whether Mux is receiving closed captions. More details can be found at Debug live stream issues\n\nUpdate stream to not expect live captioning for future connections\n\nLet Mux know to not expect closed captions when the live stream starts again. This can be done by configuring your live stream to not have any captions. This request can only be made while the live stream is idle.\n\nAPI Request\n\n\n```json\nPUT /video/v1/live-streams/{live_stream_id}/embedded-subtitles\n\nRequest Body\n{\n  \"embedded_subtitles\" : []\n}\n```\n\n\nFAQ\n\nAre there any language restrictions?\n\nYes. The 608 standard only supports the following languages: English, Spanish, French, German, Dutch, and Portuguese, or Italian. We currently only support live closed captions for a single language. We will evaluate supporting multiple languages based off of customer feedback.\n\nIs the 608 standard supported by my closed caption vendor?\n\nCaption vendors known to support the 608 captions: 3Play, AI-Media EEG Falcon, Verbit\n\nCaption vendors known to not support 608 captions: Rev.ai\n\nWhen can I edit my live closed caption configuration?\n\nYou can only edit your live caption configuration while the live stream is idle; you cannot make any changes while the live stream is active.\n\nWill formatting be preserved?\n\nMux will translate the CEA-608 captions into WebVTT. Though Mux attempts to preserve the caption formatting, some formatting may be lost.\n\nDoes live captions work with audio-only?\n\nNo. If you have a use case for this, please let us know.\n\nHow do I download my closed caption track?\n\n\n```json\nhttps://stream.mux.com/{PLAYBACK_ID}/text/{TRACK_ID}.vtt\n```\n\n\nMore details can be found at Advanced Playback features\n\nDoes live closed captions work with low latency?\n\nNot at this time. If you have a use case for this, please let us know."
  },
  {
    "id": "14-_guides/developer/add-subtitles-to-your-videos",
    "title": "Add subtitles/captions to videos",
    "path": "_guides/developer/add-subtitles-to-your-videos.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/add-subtitles-to-your-videos",
    "content": "Introduction to subtitles and captions\n\nSubtitles and captions allow for text overlays on a video to be shown at a specified time. First, let's clarify these two terms which are often used interchangeably.\n\n Subtitles refers to text on screen for translation purposes.\n Captions refers to text on screen for use by deaf and hard of hearing audiences. If you see text like [crowd cheers], you are seeing captions on your screen.\n\nIn any case, Mux supports both in the form of WebVTT or SRT and these files can be human or computer generated. From Mux's perspective these files are converted into \"text tracks\" associated with the asset. If the text track provided is captions then supply the attribute closed_captions: true when creating the text track.\n\nThe rest of this guide will use the term \"subtitles\" to refer to adding text tracks that can be either subtitles or captions.\n\nHow to add subtitles to your video\n\nYou can add subtitles to any video asset in Mux. To add subtitles, you will need to provide either a SRT or WebVTT file containing the subtitle information to the Mux API.\n\nHere's an example of what a WebVTT file looks like:\n\n\n```html\n00:28.000 --> 00:30.000 position:90% align:right size:35%\n...you have your robotics, and I\njust want to be awesome in space.\n\n00:31.000 --> 00:33.000 position:90% align:right size:35%\nWhy don't you just admit that\nyou're freaked out by my robot hand?\n```\n\n\n  Mux can also automatically generate your captions\n\nCreate a subtitle track\n\nWhen you create an asset in Mux, you can also include text tracks as part of the input. There's no limit on the number of tracks you can include when you make the request.\n\nThe first input in your array of inputs must be the video file. After that, the caption tracks should be appended to the list, each including the source URL to the caption track, plus additional metadata. Here's an example of the order to use here:\n\n\n```json\n{\n    \"inputs\": [\n      {\n        \"url\": \"{VIDEO_INPUT_URL}\"\n      },\n      {\n        \"url\": \"https://tears-of-steel-subtitles.s3.amazonaws.com/tears-en.vtt\",\n        \"type\": \"text\",\n        \"text_type\": \"subtitles\",\n        \"closed_captions\": false,\n        \"language_code\": \"en\",\n        \"name\": \"English\"\n      },\n      {\n        \"url\": \"https://tears-of-steel-subtitles.s3.amazonaws.com/tears-fr.vtt\",\n        \"type\": \"text\",\n        \"text_type\": \"subtitles\",\n        \"closed_captions\": false,\n        \"language_code\": \"fr\",\n        \"name\": \"Français\"\n      }\n    ],\n    \"playback_policies\": [\n      \"public\"\n    ],\n    \"video_quality\": \"basic\"\n}\n```\n\n\nThis will enable WebVTT subtitles in the stream URL, which can then be used by many different players.\n\nYou can also add text tracks using the create asset track. This can be helpful for adding captions to live stream recordings once they have finished, or if you need to update or remove additional languages for a video after it was first added to Mux. Assets must be in the ready state before you can use the create asset track API to add a text track.\n\nShowing subtitles by default\n\nTo show subtitles by default, you can include an additional playback modifier with the HLS stream request like this:\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?default_subtitles_lang=en\n```\n\n\nThe default_subtitles_lang playback modifier requires a valid BCP-47 language value to set the DEFAULT attribute value to YES for that language.\nIf there's no exact language match, the closest match of the same language is selected.\n\nFor instance, subtitles text track with language en-US is selected for default_subtitles_lang=en. This helps with regional variations and gives more flexibility.\n\nVideo players play the default text track for autoplaying videos even when muted.\n\nIf you are using signed playback URLs make sure you include the extra parameter in your signed token.\n\nAccessibility\n\nThe A11Y project is a community-driven effort to make digital accessibility easier and includes checking videos for accessibility.\n\nWith Mux videos, the jsx-a11y/media-has-caption rule fails because it looks for a ` attribute on the player. However, Mux videos include subtitles with HLS manifest when you request the stream.\nIf you have added text tracks to your Mux videos you can safely disable this linting rule and still provide accessible video.\n\nWorkflow for generating subtitles\n\nYou may want to generate subtitle tracks for your Mux assets. These might be machine generated or human-generated by yourself or a 3rd party. Some example third-party services you might use to do this are Rev.com and Simon Says.\n\n  Mux can also automatically generate your captions\n\nUsing static renditions and webhooks from Mux, your automated flow might look like this:\n\n1. Create a Mux asset (either with a Direct Upload, an input parameter, or the recording of a live stream).\n2. Add mp4_support to your asset either at asset creation time or add mp4_support to your asset if it is already created. See Download your videos guide for details about how to do this.\n3. Wait for the video.asset.static_renditions.ready` webhook. This lets you know that the mp4 rendition(s) are now available.\n4. Fire off a request to the 3rd party you are using for creating subtitles. You should pass along the mp4 file and get back either an SRT file or WebVTT file when the subtitle track is ready.\n5. Wait for the subtitle track to be ready, when it is, make an API request to add this text track to your asset, as described above."
  },
  {
    "id": "15-_guides/developer/add-video-metadata",
    "title": "Add metadata to your videos",
    "path": "_guides/developer/add-video-metadata.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/add-video-metadata",
    "content": "Metadata provides additional descriptive information about your video assets. Mux currently supports three key optional metadata fields that help you organize and manage your video content across the API and dashboard:\n\n title: A descriptive name for your video content. We limit this to 512 code points.\n creator_id: A value you set to identify the creator or owner of the video. We limit this to 128 code points.\n external_id: Another value you set to reference this asset in your system, such as the video ID in your database. We limit this to 128 code points.\n\n    What is a code point? Many of us use the term \"characters\" when referring to letters in a string, but when storing those characters some cost more than others. This cost is called a \"code point\". While each ASCII character can be stored with a single code point, some unicode characters, such as é, are stored as two code points. One for the e, and one for the  ́. You can easily test this in JavaScript. JavaScript's .length property counts code points, not characters, so \"é\".length will be 2.\n\nHere's an example of what a meta object might look like:\n\n\n```json\n{\n   \"title\": \"Guide: Adding metadata to videos\",\n   \"creator_id\": \"user_23456\",\n   \"external_id\": \"cdef2345\"\n}\n```\n\n\n    Note: Do not include personally identifiable information in these fields. They will be accessible by browsers to display player UI.\n\nOnce set on an asset, you'll find this metadata on assets across the Mux API and dashboard, including asset management, engagement and data.\n\nWe've deeply integrated asset metadata throughout the Mux dashboard:\n\n<Player\n    playbackId=\"trRCuyNyUHeYdQ5ZbvSsRf34Reuc301CDQzAxDUqog1w\"\n    thumbnailTime=\"10\"\n    title=\"Asset metadata demo\"\n    className=\"flex\"\n/>\n\n When uploading, we use your filename as the title - but you can change it at any time\n For live streams, you can set the default metadata for recordings on the stream details page\n When viewers watch your content, all metadata flows into Mux Data and the engagement dashboard - making it easy to find videos by title, or filter by creator id.\n\nCreate an asset with metadata\n\nWhen creating an asset you can include your metadata in the body of the request.\n\nExample request\n\n\n```json\n// POST /video/v1/assets\n{\n    \"inputs\": [\n        {\n            \"url\": \"https://storage.googleapis.com/muxdemofiles/mux.mp4\"\n        }\n    ],\n    \"playback_policies\": [\n        \"public\"\n    ],\n    \"video_quality\": \"basic\",\n    \"meta\": {\n        \"title\": \"Mux demo video\",\n        \"creator_id\": \"abcd1234\",\n        \"external_id\": \"bcde2345\"\n    }\n}\n```\n\n\nNeed more help?\n\n- Check out our getting started guide for a more thorough introduction to creating assets.\n- Check out our Create an asset for a list of all possible parameters.\n\nUpdate the metadata on an asset\n\nOnce an asset has been created the metadata can be changed at any time. Make a request to update the asset and include your metadata in the request body.\n\nExample request\n\n\n```json\n// PATCH /video/v1/assets/{ASSET_ID}\n{\n    \"meta\": {\n        \"title\": \"Updated Mux demo video\",\n        \"creator_id\": \"cdef3456\",\n        \"external_id\": \"defg4567\"\n    }\n}\n```\n\n\nNeed more help?\n\n- Check out our Update asset API reference for more details.\n\nDirectly upload a video with metadata\n\nDirect uploads are a multi-step process, and metadata should be attached in the very first step. When creating your authenticated URL in that first step you can include your metadata alongside the rest of the asset settings in new_asset_settings.\n\nExample Request\n\n\n```json\n// POST /video/v1/uploads\n{\n    \"new_asset_settings\": {\n        \"playback_policies\": [\n            \"public\"\n        ],\n        \"video_quality\": \"basic\",\n        \"meta\": {\n            \"title\": \"Mux demo video\",\n            \"creator_id\": \"abcd1234\",\n            \"external_id\": \"bcde2345\"\n        }\n    },\n    \"cors_origin\": \"*\",\n}\n```\n\n\nNeed more help?\n\n- Check out our direct upload guide for details on every step.\n\nSet live stream metadata defaults for creating assets\n\nMux automatically creates a new asset each time you connect to a live stream. When creating or updating your live stream you can include metadata that gets automatically set on the generated assets in the request body, under new_asset_settings.\n\nExample \"Create Live Stream\" request\n\n\n```json\n// POST /video/v1/live-streams\n{\n    \"playback_policies\": [\n        \"public\"\n    ],\n    \"new_asset_settings\": {\n        \"playback_policies\": [\n            \"public\"\n        ],\n    },\n    \"meta\": {\n        \"title\": \"Mux demo live stream recording\",\n        \"creator_id\": \"abcd1234\",\n        \"external_id\": \"bcde2345\"\n    }\n}\n```\n\n\nNeed more help?\n\n- Check out our \"start live streaming\" guide for a deeper walkthrough."
  },
  {
    "id": "16-_guides/developer/add-watermarks-to-your-videos",
    "title": "Add watermarks to your videos",
    "path": "_guides/developer/add-watermarks-to-your-videos.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/add-watermarks-to-your-videos",
    "content": "A watermark is an image overlaid on a video, often used to brand a video or visually label a specific version of a video.\n\nYou can add a watermark to your video using the overlay_settings in the asset creation API. The first input in your array of inputs must be the video file you want to apply the watermark to, and the second should be the URL to the source watermark image along with placement details. Multiple watermarks are possible using additional inputs as described in our API documentation for creating an asset.\n\n  Valid file types for watermarks are .png and .jpg.\n\n  Other file types such as .gif, .webp, and .svg are not supported at this time.\n\nFor a live stream, the overlay_settings must be embedded under the input array within new_asset_settings in the live stream creation API, and the overlays will apply both to playback through the live stream's playback IDs _and_ all assets created from the live stream. The watermark image will be retrieved from this URL at the start of each live stream, so you should make sure that the image will be available at that URL for as long as you plan to use the live stream.\n\nPositioning with percents vs. pixels\n\nThe overlay settings are made to help you position and size a watermark consistently no matter what the size or shape of the input video. When setting the width, height, and margins you have the option of using either percents or pixels.\n\nWith percent values the watermark width and horizontal_margin will be relative to the width of the video while the height and vertical_margin will be relative to the height of the video. For example if you set the watermark horizontal_margin to 10% for a video that is 1920 pixels wide, the watermark will be 192 pixels from the edge.\n\n\n```json\n{\n  \"inputs\": [\n    {\n      \"url\": \"{VIDEO_INPUT_URL}\"\n    },\n    {\n      \"url\": \"{WATERMARK_URL}\",\n      \"overlay_settings\": {\n        \"vertical_align\": \"top\",\n        \"vertical_margin\": \"10%\",\n        \"horizontal_align\": \"left\",\n        \"horizontal_margin\": \"10%\"\n      }\n    }\n  ],\n  \"playback_policies\": [\"public\"]\n}\n```\n\n\nWhile the result of using percents is probably easiest to understand, the one shortcoming is positioning a watermark with an exact margin. For example you may want your horizontal and vertical margins to be equal, or for there to be the same exact horizontal margin for vertical videos as with horizontal videos. Both of those examples can be a challenge with percents, where the actual result can be different depending on the width and height of the video.\n\nSetting margins with pixels allows you to get exact with your margins, widths, and heights. However, you can't always control the size of the input video, and a watermark that is 80px wide would look very different on a video that is 960 pixels wide compared to a video that is 1920 pixels wide. For that reason, when you use pixel values in your overlay settings they will always be applied as if the video is first scaled to fit 1920x1080 for horizontal videos or 1080x1920 for vertical videos. So in the previous example, the watermark would be 80px wide on the 1920px wide video, and 40px wide on the 960px wide video.\n\n\n```json\n{\n  \"inputs\": [\n    {\n      \"url\": \"{INPUT_URL}\"\n    },\n    {\n      \"url\": \"{WATERMARK_URL}\",\n      \"overlay_settings\": {\n        \"width\": \"80px\",\n        \"vertical_align\": \"top\",\n        \"vertical_margin\": \"40px\",\n        \"horizontal_align\": \"left\",\n        \"horizontal_margin\": \"40px\"\n      }\n    }\n  ],\n  \"playback_policies\": [\"public\"]\n}\n```\n\n\nThe reason behind this is that your watermark should look the same no matter what the original size of the input video, and videos are most often scaled to fit the player window or the screen of the device.\n\nCenter a watermark\n\nTo center a watermark on the video, simply set vertical_align to \"middle\" and horizontal_align to \"center\".\n\n\n```json\n{\n  \"inputs\": [\n    {\n      \"url\": \"{INPUT_URL}\"\n    },\n    {\n      \"url\": \"{WATERMARK_URL}\",\n      \"overlay_settings\": {\n        \"vertical_align\": \"middle\",\n        \"horizontal_align\": \"center\"\n      }\n    }\n  ],\n  \"playback_policies\": [\"public\"]\n}\n```"
  },
  {
    "id": "17-_guides/developer/adjust-audio-levels",
    "title": "Adjust audio levels",
    "path": "_guides/developer/adjust-audio-levels.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/adjust-audio-levels",
    "content": "What is audio normalization?\n\nHere at Mux, When we refer to audio normalization, we are referring to loudness normalization. Loudness normalization adjusts the recording based on perceived loudness.\n\nBelow, is an audio stream _before_ normalization\n\nAn audio stream _after_ normalization\n\nLUFS, which stands for Loudness Units relative to Full Scale, are a measurement of loudness over the entire length of an audio stream. This is the measurement used in the normalization process.\nThe whole goal of normalizing is attaining the gain to bring the average amplitude to a target level; the \"norm\".\n\nWhen to use audio normalization\n\nThe main use of audio normalization is to standardize the perceived loudness of your assets. Whether to use normalization at all depends on the content.\nWhen audio gain is normal and audio quality is high, normalization can be beneficial. Please note however, similar to other video and audio processing, this processing on your audio is going to change it some way.\nSo make an informed decision on whether to use this feature or not.\n\nHow to turn on audio normalization\n\nAt this moment, the only way to enable audio normalization on a Mux asset is through the create asset endpoint. You cannot update this after the asset has been created. This option also only applies to on-demand assets (audio-only included) but not live streams.\n\nTo enable audio normalization on your asset ingest, set the normalize_audio key to true in the body of your asset creation. By default, this boolean is set to false.\n\nA typical request and response might look something like this:\n\nExample request\n\n\n```bash\ncurl https://api.mux.com/video/v1/assets \\\n  -H \"Content-Type: application/json\" \\\n  -X POST \\\n  -d '{\n        \"inputs\": [\n          {\n            \"url\": \"https://example.com/myVideo.mp4\"\n          }\n        ],\n        \"playback_policies\": [\"public\"],\n        \"video_quality\": \"basic\"\n        \"normalize_audio\": true\n    }' \\\n  -u ${MUX_TOKEN_ID}:${MUX_TOKEN_SECRET}\n```\n\n\nExample response\n\n\n```json\n{\n    \"data\": {\n        \"status\": \"preparing\",\n        \"playback_ids\": [\n            {\n                \"policy\": \"public\",\n                \"id\": \"006Hx6bozgZv2sL9700Y8TT02MKdw4nq01ipMVawIGV9j000\"\n            }\n        ],\n        \"normalize_audio\": true,\n        \"mp4_support\": \"none\",\n        \"master_access\": \"none\",\n        \"id\": \"jlJydoVkYh01Z3JrLr02RGcp4mJdLvPRbk9n00000\",\n        \"video_quality\": \"basic\",\n        \"created_at\": \"1612979762\"\n    }\n}\n```\n\n\nTarget loudness\n\nOur target loudness value for audio normalization in our video stack is currently –24 LUFS. So, if possible, master your audio with this value in mind."
  },
  {
    "id": "18-_guides/developer/build-a-custom-dashboard",
    "title": "Build a custom dashboard",
    "path": "_guides/developer/build-a-custom-dashboard.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/build-a-custom-dashboard",
    "content": "What are Custom Dashboards?\n\nCustom dashboards provide a centralized view of your video performance data through configurable components. You can create dashboards with multiple visualization types, apply filters, and customize time periods to focus on specific aspects of your video performance.\n\nKey features:\n\n Four component types: Timeseries, Bar charts, Lists, and Metric numbers\n 10 components per Dashboard\n Dashboard and component-level filtering\n Flexible time period selection\n Comparison intervals\n Dashboard sharing and duplication\n\nCustom Dashboards are available on Mux Data Media plans. Learn more about Mux Data Plans or contact support.\n\nCreating a Dashboard\n\nTo create a new custom dashboard:\n\n1. Navigate to the Dashboards section in Mux Data\n2. Select Create Dashboard from the left menu or main window\n3. Enter a descriptive name for your dashboard\n4. Select Create Dashboard\n\nYour new dashboard will be created and ready for customization with components and filters.\n\n<MultiImage\n  images={[\n    { src: \"/docs/images/build-a-custom-dashboard-A.png\", width: 3935, height: 2018, alt: \"Dashboard screen in the Mux Video application showing an empty custom dashboards view with a “Create Dashboard” button.\" },\n    { src: \"/docs/images/build-a-custom-dashboard-B.png\", width: 1464, height: 794, alt: \"Dialog titled “Create Dashboard” in Mux, with a text input field filled in as “My first Dashboard” and two buttons at the bottom: “Cancel” and “Create Dashboard.”\" },\n  ]}\n/>\n\nDashboard Configuration\n\nTime Periods\n\nConfigure the time period for your entire dashboard to focus on specific date ranges:\n\n Default: Last 24 hours\n Relative periods: Choose from predefined options like last 7 days or last 30 days\n Specific periods: Set exact start and end dates for consistent historical analysis\n\nTime period changes apply to all dashboard components. Save your dashboard to preserve time period settings.\n\nCustom Dashboards are currently only available for the standard 100 days of data. Long-term Metrics are not yet available with Custom Dashboards.\n\nDashboard Filters\n\nDashboard filters apply to all components within the dashboard providing consistent data filtering across visualizations.\n\nDimension Filters\n\nFilter by dimension values such as country, operating system, or player version:\n\n1. Select the Filter Dimensions button\n2. Search for and select the dimension type\n3. Choose specific values to include or exclude\n4. Multiple values use OR logic (e.g., selecting iOS and Android shows views from either platform)\n\n<Image\n  alt=\"New Dashboard creation screen in Mux, showing a dimension filter panel with “Device Model” selected. Viewer Device Model is filtered to “iPhone,” and view counts for different iPhone models are listed.\"\n  src=\"/docs/images/build-a-custom-dashboard-C.png\"\n  width={2420}\n  height={1164}\n/>\n\nMetric Filters\n\nFilter by metric values to focus on specific performance thresholds:\n\n1. Select the Filter Metrics button\n2. Choose a metric (e.g., rebuffering percentage)\n3. Select an operator (≤, ≥, \\=, etc.)\n4. Set the value threshold\n\n<Image\n  alt=\"Metrics filter interface in Mux dashboard builder, showing a filter applied to only include results where Rebuffer Percentage is greater than 5%.\"\n  src=\"/docs/images/build-a-custom-dashboard-D.png\"\n  width={1264}\n  height={500}\n  caption=\"Example: Filter for views with rebuffering percentage ≤ 5% to focus on high-quality playback experiences.\"\n/>\n\nFilter changes can be previewed without saving. Click Save at the bottom of the dashboard to apply filters permanently.\n\nComponent Filters\n\nComponents can have their own filters in addition to Dashboard filters. Dashboard filters act as parent filters affecting all components. Component level filters are additive to Dashboard filters but only apply to the component.\n\nIf dashboard and component filters conflict, the component may show no data. Ensure filter combinations are logical and compatible.\n\nDashboard Components\n\nComponents visualize individual metrics within your dashboard. Each component type serves different analytical purposes and can be customized with specific filters and options.\n\n1. To add a Dashboard component to a new Dashboard, select the Create Component button.\n2. To add a Dashboard component to an existing Dashboard, select the Edit Icon next to the date selector.\n\nMetric Numbers\n\nDisplay key performance indicators in a prominent metrics bar at the top of your dashboard. Up to 5 Metric numbers can be added per dashboard. Metric numbers (up to 5\\) collectively count as 1 component.\n\n<Image\n  alt=\"A dashboard titled “Platform Player Key Metrics” displaying metrics for the last 24 hours, including Views, Unique Viewers, Video Startup Failure Percentage, Playback Failure Percentage, and Rebuffer Percentage.\"\n  src=\"/docs/images/build-a-custom-dashboard-E.png\"\n  width={1999}\n  height={554}\n/>\n\nConfiguration:\n\n1. Select Metric Number as the component type\n2. Choose the metric to display\n3. Provide a descriptive name (50 character limit)\n4. Optional: Add a comparison time period to show rate of change\n5. Optional: Apply component-specific dimension or metric filters\n\nMetric number components appear in creation order and cannot be reordered.\n\nTimeseries\n\n<Image\n  alt=\"Line graph showing “Video Startup Time” over a 24-hour period in Mux, comparing performance for “Last 24 hours” (orange line) versus “One day ago” (purple dashed line).\"\n  src=\"/docs/images/build-a-custom-dashboard-F.png\"\n  width={1134}\n  height={832}\n/>\n\nTrack metrics over time to identify trends, patterns, and anomalies in your video performance.\n\nConfiguration:\n\n1. Select Timeseries as the component type\n2. Choose the metric to chart over time\n3. Set a descriptive component name\n4. Select component size (half or full width)\n5. Optional: Choose either:\n     Comparison interval: Compare current period with a previous timeframe\n     Breakdown values: Chart multiple values for a single dimension type (e.g., different device types)\n6. Optional: Apply component-specific filters\n\nComparison intervals and breakdown values are mutually exclusive options. Also note that breakdown dimensions will take priority over dashboard and component filters of the same dimension.\n\nBars\n\n<Image\n  alt=\"Bar chart titled “Video Startup Failure Percentage” broken down by browser. Chrome has the highest failure rate, followed by Firefox, Safari, and Edge. A tooltip highlights Firefox with a failure percentage of 1.39%.\"\n  src=\"/docs/images/build-a-custom-dashboard-G.png\"\n  width={1134}\n  height={834}\n/>\n\nCompare performance across different dimension values using horizontal bars.\n\nConfiguration:\n\n1. Select Bars as the component type\n2. Choose the metric to measure in the bars visualization\n3. Select component size (half or full width)\n4. Choose breakdown dimension type and values that you wish to display\n5. Optional: Add a comparison interval to compare current period with a previous timeframe\n6. Optional: Apply component-specific filters\n\nBreakdown values must come from a single dimension category.\n\nLists\n\nRank and organize data to quickly identify top performers or problem areas.\n\n<Image\n  alt=\"Table showing Rebuffer Percentage broken down by operating system. Windows has the highest rebuffer rate at 0.70%, followed by iOS and Android, with directional trend indicators in green or red.\"\n  src=\"/docs/images/build-a-custom-dashboard-H.png\"\n  width={1190}\n  height={770}\n/>\n\nConfiguration:\n\n1. Select List as the component type\n2. Choose the metric to measure for each list item\n3. Select the dimension to list (e.g., player names, video titles)\n4. Set sort order (ascending or descending)\n5. Specify the number of items to display in the list component\n6. Provide a descriptive component name\n7. Optional: Add a comparison interval\n8. Optional: Apply component-specific filters\n\nLists are only available in half-width size.\n\nDashboard Management\n\nSharing Dashboards\n\nWhen creating a new dashboard, you can choose to share it with everyone in your environment. Public dashboards appear in the Shared folder for all users in your environment. You can change the sharing level at any time from the More Options dropdown.\n\nAll users can view public dashboards. To save an editable version of a public dashboard, create a duplicate (see below).\n\nSharing via Dashboard Link\n\nAny dashboard can be shared with users who have access to your Mux environment via the dashboard link, even if it's not marked as public. Users who receive a link can:\n\n- View the dashboard\n- Favorite it to save it to their personal list\n- Create a duplicate to make their own editable copy (see below)\n\nEditing Dashboard Permissions\n\nUsers have the ability to edit dashboards they are the owner of but do not have the ability to edit public dashboards they do not own. Admins have full editing abilities for all dashboards.\n\nAdvanced role-based permissions are coming soon.\n\nFavoriting Dashboards\n\nFavorite personal or shared dashboards to allow quick access to your most frequently used dashboards. You can have up to 20 favorited dashboards across your environments.\n\nFavorite a dashboard by pressing the favoriting star in the dashboard menu. When a dashboard is favorited, the star will be highlighted and the dashboard will be added to the top of the custom dashboard navigation sidebar in the favorites section.\n\n<Image\n  sm\n  alt=\"Star a custom dashboard by pressing the star icon\"\n  src=\"/docs/images/build-a-custom-dashboard-K.png\"\n  width={750}\n  height={224}\n/>\n\nSaving Dashboard Copies\n\nSave a modified version without affecting the original:\n\n1. Make your desired changes to the dashboard\n2. Use the Save As option in the save menu\n3. Provide a new name for the copy\n\n<Image\n  alt=\"Bottom section of a Mux dashboard displaying two metric widgets: one for “Exits Before Video Start” (line chart) and another for “Rebuffer Percentage” by Windows. Save, Save As, and Cancel buttons appear below.\"\n  src=\"/docs/images/build-a-custom-dashboard-J.png\"\n  width={1999}\n  height={436}\n/>\n\nExporting Dashboards\n\nExport a dashboard to a PDF to save a snapshot of your dashboard:\n\n1. Select the More Options menu (⋯) next to the favorite button\n2. Choose Export PDF\n\n<Image\n  sm\n  alt=\"Dropdown menu under the time range selector “Last 24 hours” with options to “Export PDF“, “Duplicate“ or “Delete” the dashboard.\"\n  src=\"/docs/images/build-a-custom-dashboard-I.png\"\n  width={774}\n  height={364}\n/>\n\nDuplicating Dashboards\n\nCreate an exact copy of an existing dashboard:\n\n1. Select the More Options menu (⋯) next to the favorite button\n2. Choose Duplicate\n\nDuplication is not available while a dashboard is being edited.\n\nDeleting Dashboards\n\nPermanently remove dashboards you no longer need:\n\n1. Select the More Options menu (⋯) next to the favorite button\n2. Choose Delete\n3. Confirm the deletion\n\nDeleting a dashboard removes it for all users. Duplicate dashboards are not affected.\n\nDashboard Navigation\n\nExploring Metric Details\n\nAccess detailed metric analysis directly from dashboard components:\n\n1. Select the Go To Metrics icon on any component\n2. The metrics page opens with:\n     Selected filters from your dashboard applied\n    * The component's metric pre-selected"
  },
  {
    "id": "19-_guides/developer/build-a-custom-data-integration",
    "title": "Build a Custom Integration",
    "path": "_guides/developer/build-a-custom-data-integration.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/build-a-custom-data-integration",
    "content": "Mux provides pre-built SDKs and integrations for most major platforms, but there are some platforms for which there is no pre-built integration. In this case, Mux provides core SDKs for multiple languages, including JavaScript, Java, and Objective-C. These core libraries encapsulate the majority of the business and metric calculation logic, while exposing a common API for plugging in individual player integrations.\n\nIntegration Overview\nMux Data SDKs operate by tracking the playback events that occur through the idea of a Player. To Mux, a Player is an object that encapsulates the playback of videos, exposing APIs for playback events and retrieving playback state information.\n\nIn most cases, the Player is a single object exposed by the player technology. For instance, for our Video.js integration (videojs-mux), the Player is just the Video.js Player object. However, in some scenarios, there may be one or more underlying player instances that are unified through a single composite API/object. In these cases, the Player would be that higher-level object.\n\nThere are three major steps for building an integration for a Player:\n1. Initialize a monitor for the Player that is being tracked.\n2. Provide a set of callbacks for the core SDK to retrieve player/device information\n3. Emit events for each of the important playback events.\n\nThe core SDKs share the above common architecture, but there are differences driven primarily by each programming language. The individual documentation for each will describe the exact steps for integration:\n- JavaScript - Building a custom Integration\n- Java - Building a custom Integration\n- Objective-C - Building a custom Integration\n\nRead on for an overview of each of these steps.\n\nInitialize a Player monitor\nBecause each core SDK supports the idea of tracking multiple Players (for instance, if more than one video is being played in the same view/web page), each Player must be identifiable with a unique ID. This ID is used when initializing the monitor, as well as when emitting events to the core SDK.\n\nThe first step that a custom integration must do is initialize a monitor for the Player. This is done differently for each core SDK, but the goal is just to allow the core library to prepare the state necessary for tracking a Player.\n\nIn this step, some information must be provided:\n - the Player ID\n - some integration-specific metadata\n - methods to retrieve information from the Player (more on this in a later section)\n\nIntegration-level Metadata\nWhen initializing a monitor for a Player, metadata about the integration itself should be passed. The possible fields that should be passed are the following (all are strings):\n\n - player_software_name: the name of the underlying player software (i.e. 'Video.js')\n - player_software_version: the version of this player software\n - player_mux_plugin_name: the name of the plugin\n - player_mux_plugin_version: the version of the plugin\n\nProvide Callbacks\n\nTo ease the burden of sending a lot of data with each event that is emitted, the Mux core SDKs accept callbacks that allow the core to retrieve information from the player when necessary. The callbacks required differ by core SDK, so read the appropriate section for the core SDK that you are developing with:\n\n- JavaScript SDK Callbacks\n- Java SDK Callbacks\n- Objective-C SDK Callbacks\n\nEmit events\n\nThe majority of the work in an integration is creating and emitting the specific playback events as playback occurs. Most players have a concept of events such as play, pause, error, and others, but these events are often named differently depending on the player in use. The Mux core SDKs expect events named in a consistent manner, as defined in Mux Playback Events.\n\nEach core SDK has a different mechanism for emitting these events, so read the appropriate section for the core SDK that you are developing with:\n- JavaScript SDK Emit Events\n- Java SDK Emit Events\n- Objective-C SDK Emit Events"
  },
  {
    "id": "20-_guides/developer/configure-broadcast-software",
    "title": "Configure Broadcast Software",
    "path": "_guides/developer/configure-broadcast-software.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/configure-broadcast-software",
    "content": "Overview / configuration term glossary\n\nMost broadcasting software uses some standard set of terms. Mux has chosen a set of terms are very commonly used.\n\n- Server URL - This is the URL of the Mux RTMP server, as listed in the table below.\n- Stream Key - The Stream Key is essentially used to authenticate your live stream with the Mux RTMP server. This is your secret key to live streaming. Mux does not use additional authentication.\n\n---\n\n| RTMP Server URL | Description | Common Applications |\n| :-- | :-- | :-- |\n| rtmp://global-live.mux.com:5222/app | Mux's standard RTMP entry point. Compatible with the majority of streaming applications and services | Open Source RTMP SDKs, most app-store streaming applications |\n| rtmps://global-live.mux.com:443/app | Mux's secure RTMPS entry point. Compatible with less streaming applications, but offers a higher level of security | OBS, Wirecast, Streamaxia RTMP SDKs |\n\n---\n\nHere is a list of other terms that we have heard:\n\n- Stream Name - A common alias and the technically correct term (in the RTMP specification) for Stream Key.\n- Location or URL - Many times, broadcast software that just asks for a location or a URL wants a combination of the Stream URL and the Stream Key like rtmp://global-live.mux.com:5222/app/{STREAM_KEY}. If location or URL are asked for with a stream name/key, then this is an alias for Server URL.\n- FMS URL - Flash Media Server URL, an alias for Server URL.\n\nSeen or heard a term that you don't understand? Ask us! Think we missed something that you know? Leave a comment at the bottom of the page!\n\nMux's RTMP server URL uses port number 5222 and not the standard RTMP port number 1935. If your encoder does not provide a method to change the port number, please contact support with your encoder details.\n\nRecommended encoder settings\n\nTwitch has a clear and concise guide to broadcast encoder settings. YouTube has a bit more detailed guide as well. Here's a very simple recommendation of where to start, but we do recommend playing with your settings to see what works best for your content:\n\nCommon\n- Video CODEC - H.264 (Main Profile)\n- Audio CODEC - AAC\n\nGreat - 1080p 30fps\n- Bitrate - 5000 kbps\n- Keyframe Interval - 2 seconds\n\nGood - 720p 30fps\n- Bitrate - 3500 kbps\n- Keyframe Interval - 2 seconds\n\nWorks - 480p 30fps\n- Bitrate - 1000 kbps\n- Keyframe Interval - 5 seconds\n\nYou should also consider your available upload bandwidth when choosing an encoder bitrate. For a more reliable connection, we recommend using no more than ~50% of the available upload bandwidth for your live stream ingest.\n\nAlternate ingest protocols\n\nMux Video also supports Secure Reliable Transport (SRT) for receiving live streams.\n\nAvailable Ingest URLs\n\nMux's regional ingest urls let you manually select your ingest region. This may be useful if you notice DNS is not routing your traffic efficiently, or if you would like to manage your own failover process.\n\n| Region | RTMP Ingest URL | SRT Ingest URL |\n| :-- | :-- | :-- |\n|Global (Auto-Select) | rtmp://global-live.mux.com/app | srt://global-live.mux.com:6001?streamid={STREAM_KEY}&passphrase={SRT_PASSPHRASE} |\n|U.S. East | rtmp://us-east.live.mux.com/app | srt://us-east.live.mux.com:6001?streamid={STREAM_KEY}&passphrase={SRT_PASSPHRASE} |\n|U.S. West | rtmp://us-west.live.mux.com/app | srt://us-west.live.mux.com:6001?streamid={STREAM_KEY}&passphrase={SRT_PASSPHRASE} |\n|Europe\t| rtmp://eu-west.live.mux.com/app | srt://eu-west.live.mux.com:6001?streamid={STREAM_KEY}&passphrase={SRT_PASSPHRASE} |\n\nAll of these RTMP URLs support RTMPS.\n\nFor example, rtmp://us-east.live.mux.com/app becomes rtmps://us-east.live.mux.com/app\n\nChoosing the right ingest URL\n\n- If you want Mux to automatically route to the best region, use global-live.mux.com.\n- If you prefer manual control over routing, use a specific regional ingest URL (e.g., us-east.live.mux.com).\n- For redundancy, configure your encoder to failover to another regional endpoint.\n\nUsing regional ingest URLs in OBS\n\nTo set up OBS with Mux Live Streaming:\n1. Go to: Settings → Stream\n2. Select \"Custom...\" as the service\n3. Enter the Ingest URL based on your preferred region\n\n    rtmps://us-east.live.mux.com/app\n\n4. Enter your Stream Key (found in your Mux Live settings)\n5. Click \"Start Streaming\"\n\nBuilding your SRT URL\n\nNote: Before you use a SRT URL, make sure your encoder supports SRT Caller mode.\n\nThe SRT URL is composed of three parts.\n\n1. The protocol and host: srt://us-east.live.mux.com:6001\n2. A streamid query parameter\n3. A passphrase query parameter\n\nHere's an example:\n\n```\nsrt://us-east.live.mux.com:6001?streamid=abc-123-def-456&passphrase=GHI789JKL101112\n```\n\n\nFor more information on SRT, check out our Use SRT to live stream docs.\n\nSoftware encoders\n\nAny encoder that supports RTMP should work with Mux Video.\n- OBS (Free and Open Source)\n- Wirecast (Commercial)\n- XSplit (Commercial)\n- vMix (Commercial)\n\nHardware encoders\n\nAny encoder that supports RTMP should work with Mux Video.\n- VidiU\n- DataVideo RTMP Encoders\n- Magewell Ultra Stream\n- Osprey Talon (contact sales@ospreyvideo.com for documentation)\n- Videon\n\nMobile devices (iOS, Android)\n\nIf you just want a pre-built iOS application you can stream from, check out our write up here.\n\nIf you want to build your own application, check out this documentation."
  },
  {
    "id": "21-_guides/developer/control-playback-resolution",
    "title": "Control playback resolution",
    "path": "_guides/developer/control-playback-resolution.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/control-playback-resolution",
    "content": "Default playback URL\n\nThe default playback URL will contain all available resolutions of your video. The resolutions available will depend on the video source file.\n\nBy default if the source file contains 1080p or higher, then the highest resolution provided by Mux will be 1080p. If the source file is lower than 1080p, the highest resolution available will be the resolution of the source.\n\nYou can also stream 4K content using Mux Video, which will be delivered at higher resolutions including 2.5K and 4K. For more details see the guide to streaming 4K videos.\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8\n```\n\n\nUse the default playback URL for most use cases. The video player will determine the best resolution based on the available bandwidth of the viewer.\n\nUsing playback modifiers to manipulate playback resolution\n\nMux exposes a set of playback modifiers, which give you extra control over the availiable resolutions of your content.\n\nSpecify maximum resolution\n\nThe playback URL below with the max_resolution query parameter modifies the resolutions available for the player to choose from.\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?max_resolution=720p\n```\n\n\nThe max_resolution parameter can be set to 270p, 360p, 480p, 540p, 720p, 1080p, 1440p, or 2160p. You may want to do this in order to reduce your delivery costs, or build a feature to your product where only certain viewers get lower resolution video.\n\n_Please note that not all resolutions are available for all assets. If you specify a max resolution that is not available for the asset, Mux will limit the resolution to the highest resolution available below the one you specified. For example, if you specify max_resolution=1080p but the highest resolution available for the asset is 720p, then the manifest will be capped at 720p._\n\nSpecify minimum resolution\n\nThe playback URL below with the min_resolution query parameter modifies the resolutions available for the player to choose from.\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?min_resolution=720p\n```\n\n\nThe min_resolution parameter can be set to 270p, 360p, 480p, 540p, 720p, 1080p, 1440p, or 2160p. You may want to use this to omit the lowest quality renditions from the HLS manifest when the visual quality of your content is critical to the delivery, for example in live streams where detailed screen share content is present.\n\n_Please note that not all resolutions are available for all assets. If you specify a min resolution that is not available for the asset, Mux will limit the resolution to the next highest resolution available below the one you specified. For example, if you specify max_resolution=270p but the lowest resolution available for the asset is 360p, then the manifest will start at at 360p._\n\nSpecify rendition order\n\nBy default the top resolution in the playlist is one of the middle resolutions. Many players will start with the first one listed so this default behavior strikes a balance by giving the player something that's not too low in terms of quality but also not too high in terms of bandwidth.\n\nYou may want to change this behavior by specifying rendition_order=desc which will sort the list of renditions from highest (highest quality, most bandwidth) to lowest (lowest quality, least bandwidth). Players that start with the first rendition in the list will now attempt to start playback with the highest resolution. The tradeoff is that users on slow connections will experience increaesed startup time.\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?rendition_order=desc\n```\n\n\nUsage with signed URLs\n\nIf you are using signed Playback IDs according to the Secure video playback guide then your playback modifiers must be encoded in the token that you generate on your server. See the modify playback behaviour guide about embedding extra params in your JWT.\n\nUsing playback modifiers in Mux Player\n\nMux Player supports  min_resolution, max_resolution and rendition_order as attributes on the web component and props on the React component.\n\nFor example to set the max_resolution= parameter with Mux Player, you can set max-resolution=\"720p\" attribute (maxResolution=\"720p\" in React). When setting this attribute Mux Player will internally add it on as a query parameter on the streaming URL.\n\nAs with all playback modifiers, if you're using signed URLs, your parameters should be encoded in the playback-token attribute (tokens.playback in React).\n\nWhen using AVPlayer on iOS\n\nSet the playback modifier by appending a URLQueryItem to the playback URL. Initialize AVPlayer using the URL itself as shown in an example below using max_resolution or initialize with an AVPlayerItem constructed with the URL."
  },
  {
    "id": "22-_guides/developer/control-recording-resolution",
    "title": "Control recording resolution",
    "path": "_guides/developer/control-recording-resolution.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/control-recording-resolution",
    "content": "Android\nThe way you control the resolution of a recorded video depends on the API used to record or encode it. All of Google's major camera and recording APIs have a method for setting either the exact or maximum resolution of the videos they create.\n\nCameraX\nWith the CameraX library provide a QualitySelector that doesn't allow for resolutions beyond 720p (1280x720).\n\n```kotlin\n// Selects only Standard HD (720p) and Standard Definition (480p)\nval selector = QualitySelector.fromOrderedList(\n  listOf(Quality.HD, Quality.SD),\n  FallbackStrategy.lowerQualityOrHigherThan(Quality.SD)\n )\n\nval recorder = Recorder.Builder()\n  .setQualitySelector(selector)\n  ...\n  .build()\n```\n\n\nMediaCodec\nIf you are encoding video yourself via the MediaCodec API, you can set the encoder's output resolution by setting it in the input MediaFormat. For more information on how to configure and use MediaCodec, try the docs\n\n```kotlin\nval mediaCodec = MediaCodec.createByCodecName(codecName)\nval encodeFormat = MediaFormat().apply {\n  setInteger(MediaFormat.KEY_FRAME_RATE, myExampleFrameRate)\n  //... Other required params\n  // Output 720p\n  setInteger(MediaFormat.KEY_HEIGHT, 720)\n  setInteger(MediaFormat.KEY_WIDTH, 1280)\n}\nmediaCodec.configure(\n  encodeFormat,\n  myInputSurface,\n  null,\n  MediaCodec.CONFIGURE_FLAG_ENCODE\n)\n```\n\n\nCamera2\nCamera2 doesn't have an API to set the video resolution directly, but it infers it from the input surface. You have to call SurfaceHolder.setFixedSize() on your capture requests' targets. This can only be done on Lollipop/API 21 or higher. Please refer to the camera2 docs) for more information\n\n```kotlin\nval supportedCameraResolutions = streamConfigMap.getOutputSizes(ImageFormat.NV21)\nval size =\n  supportedCameraResolutions.toList().sortedBy { it.height }.findLast { it.height <= 720 && it.width <= 1280 }\nsize?.let { cameraSurfaceHolder.setFixedSize(it.width, it.height) }\ncameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_RECORD)\n  .apply { addTarget(cameraSurfaceHolder.surface) }\n  // ...\n  .build()\ncameraDevice.createCaptureSession(...)\n```\n\n\nMediaRecord\nMediaRecord's output size can be configured by calling MediaRecord.setVideoSize() before calling prepare().\n\n```kotlin\nmediaRecord.setVideoSize(1280, 720)\nmediaRecord.prepare()\n```\n\n\niOS and iPadOS\n\nThis guide covers setting maximum video resolution when recording video on iOS and iPadOS. The directions and code examples on this page assume you are using AVFoundation to setup and configure your camera. If you’ve never used AVFoundation before we recommend you brush up on the basics before proceeding further, see the official Apple documentation for a quick introduction and sample code.\n\nVideo recording on iOS is managed using AVCaptureSession. The resolution for video output from AVCaptureSession can be configured using a settings preset and this example shows how to configure VCaptureSession to output video at a resolution of 720p (1280 x 720 pixels).\n\n\n```swift\nlet session = fetchYourCaptureSession()\nsession.beginConfiguration()\n\nlet updatedSessionPreset = AVCaptureSession.hd1280x720\nif session.canSetSessionPreset(updatedSessionPreset) {\n    session.sessionPreset = updatedSessionPreset\n}\n\nsession.commitConfiguration()\n```\n\n\nDon’t forget to call beginConfiguration() before applying any configuration changes. When all the configuration changes have been applied, make sure your implementation calls commitConfiguration().\n\nIt is best for any work that is done in-between calls to beginConfiguration() and commitConfiguration() to be synchronous. If you need to perform any asynchronous tasks, such as fetching the preferred resolution from your backend, make sure those are complete before you begin to configure AVCaptureSession.\n\nOBS\n\nStreams initiated via OBS can be configured in Settings > Video > Output (Scaled) Resolution."
  },
  {
    "id": "23-_guides/developer/create-clips-from-your-videos",
    "title": "Create clips from your videos",
    "path": "_guides/developer/create-clips-from-your-videos.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/create-clips-from-your-videos",
    "content": "To drive higher viewer engagement with the videos already on your service, you can create additional videos from your existing library or catalog. These videos could:\n Provide quick previews\n Highlight key moments\n Be polished versions of a live stream with the extra minutes trimmed from the beginning & end (aka preroll and postroll slates) for on-demand replays\n\nMux can now help you quickly create these kinds of videos using the asset clipping functionality.\n\n  If you do not need frame accurate clips, or require immediate availability of clips, you may find that the instant clipping feature may meet your requirements.\n\n1. Create a clip\n\nWhen you POST a new video or start live streaming, Mux creates a new asset for the video file or live stream event recording.\nYou can create a clip from an existing asset by making a POST request to /assets endpoint and defining the input object's clipping parameters.\n url is defined with mux://assets/{asset_id} template where asset_id is the source Asset Identifier to create the clip from.\n start_time is the time offset in seconds from the beginning of the video, indicating the clip's start marker. The default value is 0 when not included.\n end_time is the time offset in seconds from the beginning of the video, indicating the clip's end marker. The default value is the duration of the video when not included.\n\nA request and response might look something like this:\n\nExample request\n\n\n```bash\ncurl https://api.mux.com/video/v1/assets \\\n  -H \"Content-Type: application/json\" \\\n  -X POST \\\n  -d '{\n        \"inputs\": [\n          {\n            \"url\": \"mux://assets/01itgOBvgjAbES7Inwvu4kEBtsQ44HFL6\",\n            \"start_time\": 10.0,\n            \"end_time\": 51.10\n          }\n        ],\n        \"playback_policies\": [\n          \"public\"\n        ],\n        \"video_quality\" : \"basic\"\n      }' \\\n  -u ${MUX_TOKEN_ID}:${MUX_TOKEN_SECRET}\n```\n\n\nExample response\n\n```json\n{\n  \"data\": {\n    \"status\": \"preparing\",\n    \"playback_ids\": [\n      {\n        \"policy\": \"public\",\n        \"id\": \"TXjw00EgPBPS6acv7gBUEJ14PEr5XNWOe\"\n      }\n    ],\n    \"mp4_support\": \"none\",\n    \"master_access\": \"none\",\n    \"id\": \"kcP3wS3pKcEPywS5zjJk7Q1Clu99SS1O\",\n    \"created_at\": \"1607876845\",\n    \"video_quality\" : \"basic\",\n    \"source_asset_id\": \"01itgOBvgjAbES7Inwvu4kEBtsQ44HFL6\"\n  }\n}\n```\n\n\nMux creates a new asset for the clip. And the response will include an Asset ID and a Playback ID.\n\n Asset IDs are used to manage assets using api.mux.com (e.g. to read or delete an asset).\n Playback IDs are used to stream an asset to a video player through stream.mux.com. You can add multiple playback IDs to an asset to create playback URLs with different viewing permissions, and you can delete playback IDs to remove access without deleting the asset.\n* source_asset_id is the video or live stream event recording asset used to create the clip. The source_asset_id can be useful for associating clips with the source video object in your CMS.\n\n2. Wait for \"ready\" event\n\nWhen the clip is ready for playback, the asset \"status\" changes to \"ready\".\n\nThe best way to do this is via webhooks. Mux can send a webhook notification as soon as the asset is ready. See the webhooks guide for details.\n\nIf you can't use webhooks for some reason, you can manually poll the asset API to see asset status. Note that this only works at low volume.\n\nBuild your own request\n\n<CodeExamples\n  product=\"video\"\n  example=\"retrieveAsset\"\n/>\n\nPlease don't poll this API more than once per second.\n\n3. Play your clip\n\nTo play back the video, create a playback URL using the PLAYBACK_ID you received when you created the clip.\n\n\n```curl\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8\n```\n\n\n<CodeExamples\n  product=\"video\"\n  example=\"hlsPlayback\"\n  exampleOrder=\"html,react,embed,swift,android\"\n/>\n\nSee the playback guide for more information about how to integrate with a video player.\n\nFAQs\nA few commonly asked questions:\n\nHow many clips can be created from a single source asset?\n\nUnlimited! Mux creates a new asset for each clip. Hence, there is no limit to how many clips you can create.\n\nIs there a cost to create clips?\n\nEach clip is a new asset and is considered an on-demand video. On-Demand video pricing applies and that includes Encoding, Storage, and Delivery usage.\n\nCan I use basic video quality on clips?\n\nYes! Clips can be created as either basic or plus.\n\nCan I create clips when adding new video files?\n\nMux only allows creating clips from existing videos in your account. That means, clipping specific parameters (start_time and end_time) added to Asset Creation are only applicable for input.url with mux://assets/{asset_id} format.\n\nCan I create clips from live streams?\n\nYes! Mux supports creating clips from the active asset being generated by a live stream while broadcasting. If you clip an asset while the broadcast is active, just remember that the active asset is still growing, so if you don't provide end_time, it will default to the end of the asset at the time of creation. As such, when clipping an active asset during the broadcast, for best results you should always provide an end_time.\n\nMy source asset has subtitles/captions text tracks. Will the clip have them?\n\nMux copies all the text tracks from the source asset to the new asset created for the clip. Mux also trims the text tracks to match the clip's start and end markers.\n\nWhat other data is copied from the source asset?\n\nMux copies the captions and watermark image from the source asset to the clips created. If your source asset does not have a watermark image and you want your clipped\nasset to have a watermark, pass it through in overlay_settings. See more details in the watermark guide.\n\nAll other fields, such as passthrough, are not copied over.\n\nWhat is the minimum duration for a clip?\n\nClips must have a duration of at least 500 milliseconds."
  },
  {
    "id": "24-_guides/developer/create-instant-clips",
    "title": "Create instant clips",
    "path": "_guides/developer/create-instant-clips.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/create-instant-clips",
    "content": "Use cases for instant clipping\n\nInstant clipping allows you to set the start and end times of the streaming URL to make clips that are instantly available without the wait time or expense of a new asset being created. This feature can be used to build a variety of viewer facing workflows.\n\n  If you require frame accurate clips, clipped masters, or clipped MP4s, you should use the asset-based clipping feature.\n\nHere are examples of workflows that can be built with instant clipping:\n\nPre-live workflows\n\nSometimes you need to connect your contribution encoder to a live stream and test that the video is working end-to-end before exposing the live stream to your audience. But when you have DVR mode turned on for your stream, it's often necessary to prevent viewers being able to seek back into the parts of the live stream where your announcers are saying \"testing, testing, 1… 2… 3…\".\n\nInstant clipping can be used to specify a start time to allow playback of a live stream, stopping users from seeking back into the stream beyond where you want. You can also specify an end time if you're worried about extra content at the end of your live events.\n\nPost-live trimming without re-encoding\n\nWith our asset-based clipping feature you're able to create clipped on-demand assets, which are shortened versions of a given asset - this is commonly called \"top and tail editing\". These assets always incur an encoding cost to process the clipped version, and can take some time to process.\n\nWith instant clipping, for any asset generated from a live stream, you can simply specify the start and end times of the content you want clipped directly during playback without the need for time-consuming and costly re-processing.\n\nFor example, if you broadcast multiple sports events back-to-back on a single live stream, you can use instant clipping to generate instant on-demand streams of each match as it ends for no extra cost.\n\nHighlight clips\n\nSometimes a really exciting moment happens on a live stream, and you want to clip out a short highlight for others to enjoy. You can use instant clipping to pull out short clips from a currently active asset for promoting on your homepage or embedding into news articles.\n\nThis can be used for example to instantly show just the 90th-minute equalizer goal on your home page while having extra time and penalties to watch live on your pay-to-view platform.\n\nHow instant clipping works\n\nFrom a live stream\n\nEvery live stream or asset generated from a live stream contains a timestamp that is close (usually within a second) to the time that Mux received the source video from the contribution encoder. This timestamp is known as \"Program Date Time\" or \"PDT\" for short.\n\n  \"PDT\" has nothing to do with the Pacific Daylight time zone; all times are represented in UTC or with unix timestamps.\n\nInstant clipping works by trimming the HLS manifests from live streams and VOD assets originating from live streams using these PDT timestamps, without re-encoding any segments. This means that instant clipping operates at the segment level of accuracy, so you should expect that the content that you clip out may be several seconds longer than you've requested. We always make sure to include the timestamps that you request, but your content may start a few seconds earlier, and end a few seconds later. The exact accuracy depends on the latency settings of the live stream that you're clipping from.\n\nFrom a VOD asset\n\nRegardless if an asset has originated from a live stream or was uploaded, you can create instant clips using relative time markers for the start and end to generate the trimmed HLS manifest.  The relative time markers are based on the beginning of the asset and so specifying a range of 10 - 20 would result in a 10 second clip between 0:00:10 and 0:00:20.\n\nCreating an instant clip URL\n\nInstant clipping is controlled by passing playback modifiers (query string arguments or JWT claims) to the playback URL of your live stream or VOD assets. If you're using signed URLs, these playback modifiers need to be embedded into your JWT.\n\nLive stream instant clips\n\nWhile Mux timestamps video frames when they are received, there is a delay while enough frames are processed to form sufficient segments for a live stream to be started.\n\nThis means that you should expect some delay from wall-clock time to when you can use a given timestamp as a program_start_time.\n\nFor example, if a commentator presses a “Go Live” button at 13:00 UTC, which sets the program_start_time of a Live Stream to that timestamp, you should expect request for the live stream's manifest to respond with a HTTP 412 error for up to 15 seconds after (this will depend on the latency_mode of your live stream).\n\nThe start and end time of your trimmed live stream or on-demand asset are specified by using the following two parameters:\n\nUsing program_start_time\n\nThis parameter accepts an epoch time and can be set on a playback URL, and sets the start time of the content within the live stream or asset, for example:\n\n\n```\n# Format\nhttps://stream.mux.com/${PLAYBACK_ID}.m3u8?program_start_time=${EPOCH_TIME}\n\n# Example\nhttps://stream.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq.m3u8?program_start_time=1707740400\n```\n\n\nWhen used on a live stream, this will cause the live stream to behave as if it is idle prior to this time.\n\nWhen used on an asset, this will trim the start of the streamed media to this timestamp if needed.\n\nUsing program_end_time\n\nThis parameter accepts an epoch time and can be set on a playback URL, and sets the end time of the content within the live stream or asset, for example:\n\n\n```\n# Format\nhttps://stream.mux.com/${PLAYBACK_ID}.m3u8?program_end_time=${EPOCH_TIME}\n\n# Example\nhttps://stream.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq.m3u8?program_end_time=1707740460\n```\n\n\nWhen used on a live stream, this will cause the live stream to behave as if it is idle after this time.\n\nWhen used on an asset, this will trim the end of the streamed media to this timestamp.\n\nCombining program_start_time and program_end_time\n\nThese parameters can be used together to extract a specific clip of a live stream or asset, for example:\n\n\n```\n# Format\nhttps://stream.mux.com/${PLAYBACK_ID}.m3u8?program_start_time=${EPOCH_TIME}&program_end_time=${EPOCH_TIME}\n\n# Example\nhttps://stream.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq.m3u8?program_start_time=1707740400&program_end_time=1707740460\n```\n\n\nVOD instant clips\n\nThe start and end time of your trimmed on-demand asset are specified by using the following two parameters:\n\nUsing asset_start_time\n\nThis parameter accepts relative time and can be set on a Playback URL, and sets the start time of the content within the asset, for example:\n\n\n```\n# Format\nhttps://stream.mux.com/${PLAYBACK_ID}.m3u8?asset_start_time=${RELATIVE_TIME}\n\n# Example\nhttps://stream.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq.m3u8?asset_start_time=10\n```\n\n\nUsing asset_end_time\n\nThis parameter accepts relative time and can be set on a Playback URL, and sets the end time of the content within the asset, for example:\n\n\n```\n# Format\nhttps://stream.mux.com/${PLAYBACK_ID}.m3u8?asset_end_time=${RELATIVE_TIME}\n\n# Example\nhttps://stream.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq.m3u8?asset_end_time=20\n```\n\n\nCombining asset_start_time and asset_end_time\n\nYou can also use both of these parameters to create an instant clip of specific portion of your asset, for example:\n\n\n```\n# Format\nhttps://stream.mux.com/${PLAYBACK_ID}.m3u8?asset_start_time=${RELATIVE_TIME}&asset_end_time=${RELATIVE_TIME}\n\n# Example\nhttps://stream.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq.m3u8?asset_start_time=10&asset_end_time=20\n```\n\n\nThumbnail & Storyboard support\n\nImages for VOD assets\n\nTo generate images for VOD assets, the time query string parameter can be used to retrieve an image from the video, for example:\n\n\n```\n# Format\nhttps://image.mux.com/${PLAYBACK_ID}/thumbnail.png?time=${RELATIVE_TIME}\n\n# Example\nhttps://image.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq/thumbnail.png?time=15\n```\n\n\nStoryboard generation for VOD assets support these parameters as a way to generate storyboard tiles for frames between the asset_start_time and asset_end_time values, for example:\n\n\n```\n#Format\nhttps://image.mux.com/${PLAYBACK_ID}/storyboard.png?asset_start_time=${RELATIVE_TIME}&asset_end_time=${RELATIVE_TIME}\n\n# Example\nhttps://image.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq/storyboard.png?asset_start_time=10&asset_end_time=20\n```\n\n\nImages for live streams\n\nFor thumbnails, you can now pass an absolute time using the program_time parameter, for example:\n\n\n```\n# Format\nhttps://image.mux.com/${PLAYBACK_ID}/thumbnail.png?program_time=${EPOCH_TIME}\n\n# Example\nhttps://image.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq/thumbnail.png?program_time=1707740460\n```\n\n\nYou can pass the same set of playback modifiers (program_start_time and program_end_time) on a request for a storyboard and the storyboard will be trimmed appropriately, for example:\n\n\n```\n#Format\nhttps://image.mux.com/${PLAYBACK_ID}/storyboard.png?program_start_time=${RELATIVE_TIME}&program_end_time=${RELATIVE_TIME}\n\n# Example\nhttps://image.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq/storyboard.png?program_start_time=1707740400&program_end_time=1707740460\n\n```\n\n\nUsing instant clipping in Mux Player\n\nWe've also made sure it's easy to pass these parameters to Mux Player when you're using it for playback.\n\nInstant clipping is supported in Mux Player through two paths:\n\nUsing Public Playback IDs: Via extra source params\n\n  This feature was added in mux-player 2.3.0, but we recommend using the latest version at all times.\n\nHere's an example of using the extra source params for using the asset_start_time and asset_end_time parameters with mux-player for both video delivery and storyboards:\n\n\n```html\n<mux-player\n  playback-id=\"sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq\"\n  extra-source-params=\"asset_start_time=10&asset_end_time=20\"\n  metadata-video-title=\"Instant clipping demo (Public)\"\n  storyboard-src=\"https://image.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq/storyboard.vtt?format=webp&asset_start_time=10&asset_end_time=20\"\n></mux-player>\n```\n\n\nUsing the extra source params can also be used for instant clipping for live streams for video and storyboards as well:\n\n\n```html\n<mux-player\n  playback-id=\"sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq\"\n  extra-source-params=\"program_start_time=1707740400&program_end_time=1707740460\"\n  metadata-video-title=\"Instant clipping demo (Public)\"\n  storyboard-src=\"https://image.mux.com/sp9WNcgcktsmlvFLKgNm3jjSGRD00RPlq/storyboard.vtt?format=webp&program_start_time=1707740400&program_end_time=1707740460\"\n></mux-player>\n```\n\n\nVia signed URLs\n\nWhen using signed URLs, it's required to include the clipping parameters as claims inside the respective JWTs passed to Mux Player.\n\nFor the playback token and the storyboard token, the following parameters should be injected into the JWT claims:\n asset_start_time and/or asset_end_time\n program_start_time and/or program_end_time\n\nFor the thumbnail token, the program_time parameter should be injected into the JWT claim.\n\nThen Mux Player can be loaded in the usual way, passing in the signed tokens:\n\n\n```html\n<mux-player\n  playback-id=\"s6oiUXJ6W1JH02D9ThJZQtyg74ubYTiT7\"\n  playback-token=\"${PLAYBACK_TOKEN}\"\n  storyboard-token=\"${STORYBOARD_TOKEN}\"\n  thumbnail-token=\"${THUMBNAIL_TOKEN}\"\n  metadata-video-title=\"Instant clipping demo (Signed)\"\n></mux-player>\n```\n\n\nStream security considerations\n\nWe strongly recommend using this feature alongside signed URLs. When using this feature without signed URLs, it is possible for users to manipulate the manifest playback URL to expose parts of the media that you want to keep hidden.\n\nChoosing between asset clipping and instant clipping\n\nNot sure if you should be generating a new asset when clipping, or using instant clipping for your workflow? Here are some tips that can help you choose the right approach for your product.\n\nInstant clipping is a great choice when:\n You require a clip to be instantly available\n You need the clips to not incur additional encoding fees\n You need to pre-emptively limit the availability of content to build pre-live workflows for live streaming\n\nYou should use our asset-based clipping when:\n You require frame accuracy in your clips\n* You require trimmed MP4s or masters"
  },
  {
    "id": "25-_guides/developer/create-timeline-hover-previews",
    "title": "Create timeline hover previews",
    "path": "_guides/developer/create-timeline-hover-previews.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/create-timeline-hover-previews",
    "content": "What are timeline hover previews?\n\nTimeline hover previews, also known as trick play or scrub bar previews, make player operations like fast-forward, rewind, and seeking more visual to the user. Here it is in action:\n\nEach image (also called a thumbnail or tile) you see when hovering over the scrub bar (or player timeline) on the video player is part of a larger image called a storyboard.\nA storyboard is a collection of thumbnails or tiles, created from video frames selected at regular time intervals and are arranged in a grid layout.\n\nBelow image an example storyboard for the video, Tears of Steel, the same video used to demo timeline hover previews above:\n\nAdd timeline hover previews to your player\n\nThere are a few different ways to add this functionality to your players, depending on which methods your chosen player exposes to support timeline hover previews.\n\nThe storyboard image can be requested from the following URL in either webp, jpg, or png format from Mux:\n\n<CodeExample\n  lang=\"curl\"\n  code=\"https://image.mux.com/{PLAYBACK_ID}/storyboard.{png|jpg|webp}\"\n/>\n\nEach storyboard has an associated metadata file and can be used as a metadata text track. The storyboard image is referenced from the metadata in this case.\n\nThe storyboard metadata provides the x-axis and y-axis coordinates of each image in the storyboard image and the corresponding time range. The metadata is available in both WebVTT and JSON format.\n\nStoryboard images will contain 50 tiles within the image if the asset is less than 15 minutes in duration. If the asset is more than 15 minutes, then there will be 100 tiles populated in the storyboard image.\nWebVTT\nMost popular video players use WebVTT file for describing individual tiles of the storyboard image. You can request the WebVTT file by making a request to generate a storyboard of the image.\n\n<CodeExample\n  lang=\"curl\"\n  code=\"GET https://image.mux.com/{PLAYBACK_ID}/storyboard.vtt\"\n/>\n\n\n```\nWEBVTT\n\n00:00:00.000 --> 00:01:06.067\nhttps://image.mux.com/Dk8pvMnvTeqDk9dy5nqmXz02MM4YtdElW/storyboard.jpg#xywh=0,0,256,160\n\n00:01:06.067 --> 00:02:14.067\nhttps://image.mux.com/Dk8pvMnvTeqDk9dy5nqmXz02MM4YtdElW/storyboard.jpg#xywh=256,0,256,160\n\n00:02:14.067 --> 00:03:22.067\nhttps://image.mux.com/Dk8pvMnvTeqDk9dy5nqmXz02MM4YtdElW/storyboard.jpg#xywh=512,0,256,160\n\n00:03:22.067 --> 00:04:28.067\nhttps://image.mux.com/Dk8pvMnvTeqDk9dy5nqmXz02MM4YtdElW/storyboard.jpg#xywh=768,0,256,160\n\n00:04:28.067 --> 00:05:36.067\nhttps://image.mux.com/Dk8pvMnvTeqDk9dy5nqmXz02MM4YtdElW/storyboard.jpg#xywh=1024,0,256,160\n\n00:05:36.067 --> 00:06:44.067\nhttps://image.mux.com/Dk8pvMnvTeqDk9dy5nqmXz02MM4YtdElW/storyboard.jpg#xywh=0,160,256,160\n```\n\n\nBy default, this request will generate a jpg for the storyboard image. If you'd like to change the format to webp, you can do so by adding ?format=webp to the end of the request URL:\n\n<CodeExample\n  lang=\"curl\"\n  code=\"GET https://image.mux.com/{PLAYBACK_ID}/storyboard.vtt?format=webp\"\n/>\n\nWebVTT Compatible Video Players\nThe list below shows the various video players supporting the WebVTT files for trick play. If your player isn't listed here, please reach out, and we'll help where we can!\n\n- VideoJS + VTT Thumbnails plugin\n- JW Player\n- THEOplayer\n- Bitmovin\n- Flow Player\n- Plyr\n\nUsing a WebVTT file may be limited to HTML5 browser-based video players and may not be supported in Device specific SDKs including iOS and Android. iOS, Android, and other device platforms use a HLS iFrame Playlist. Generating HLS iFrame Playlists is on Mux's roadmap.\n\nJSON\nThere are many other scenarios for using storyboards. For instance:\n- A quick way of previewing the entire video can save the video editor/reviewer's time without requiring a full video playback\n- Ease of developing trick play like functionality in Chromeless Video players like hls.js\n\nUsing a WebVTT file for metadata can be burdensome to implement. Storyboard metadata expressed in an easy to understand & widely supported format like JSON helps in taking advantage of storyboards in new ways. Mux provides the same storyboard metadata in JSON format.\n\n<CodeExample\n  lang=\"curl\"\n  code=\"https://image.mux.com/Dk8pvMnvTeqDk9dy5nqmXz02MM4YtdElW/storyboard.json\"\n/>\n\n\n```json\n{\n  \"url\": \"https://image.mux.com/Dk8pvMnvTeqDk9dy5nqmXz02MM4YtdElW/storyboard.jpg\",\n  \"tile_width\": 256,\n  \"tile_height\": 160,\n  \"duration\": 6744.1,\n  \"tiles\": [\n    {\n      \"start\": 0,\n      \"x\": 0,\n      \"y\": 0\n    },\n    {\n      \"start\": 66.066667,\n      \"x\": 256,\n      \"y\": 0\n    },\n    {\n      \"start\": 134.066667,\n      \"x\": 512,\n      \"y\": 0\n    },\n    {\n      \"start\": 202.066667,\n      \"x\": 768,\n      \"y\": 0\n    },\n    {\n      \"start\": 268.066667,\n      \"x\": 1024,\n      \"y\": 0\n    },\n    {\n      \"start\": 336.066667,\n      \"x\": 0,\n      \"y\": 160\n    }\n  ]\n}\n```\n\n\nBy default, this request will generate a jpg for the storyboard image. If you'd like to change the format to webp, you can do so by adding ?format=webp to the end of the request URL:\n\n<CodeExample\n  lang=\"curl\"\n  code=\"https://image.mux.com/Dk8pvMnvTeqDk9dy5nqmXz02MM4YtdElW/storyboard.json?format=webp\"\n/>\n\nCross-Origin Resource Sharing (CORS) requirements\nThe storyboards URLs use image.mux.com hostname and stream.mux.com hostname is used for video playback URL. Because the URLs use different hostnames, it is recommended to add crossorigin attribute to the ` HTML tag for access.\n\nRoku trick play\n\nRoku announced changes to their channel certification criteria mandating trick play for on-demand video longer than 15mins starting October 1st, 2020.\nTo support this requirement, you can add this playback modifier for playback on Roku devices when making a playback request:\n\n\n```none\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?roku_trick_play=true\n```\n\n\nMux will include an Image Media Playlist in the HLS manifest to support this requirement on Roku.\n\nIf you are using signed playback URLs make sure you include the extra roku_trick_play in your signed token.\n\nUsing signed URLs\n\nMux videos have two types of playback policy, public or signed. If your playback_id is signed`, you will need to also sign requests made for storyboards.\nYou can check out how to do that in our signed URLs guide."
  },
  {
    "id": "26-_guides/developer/dashboard-environment-restrictions",
    "title": "Limit which Environments a user has access to in the Dashboard",
    "path": "_guides/developer/dashboard-environment-restrictions.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/dashboard-environment-restrictions",
    "content": "This feature allows Admins to limit which Environments a given user can access within the Dashboard.\n\nAdmin use of Environment restrictions\n\nAll management of Environment access is done in the Dashboard under User > Organization.\n\nAdmins have the following permissions:\n  - Access to all Environments\n  - View what Environments any given user has access to\n  - See what users can access a specific Environment\n  - Apply Environment restrictions to a user invitation\n  - Manage Environment restrictions for all users\n\nInviting new users with Environment restrictions\n\nUpon inviting a new user to an organization, Admins must provide at least one (1) Environment that the new user can access.\n\nModify Environment access for existing users\n\nAdmins can modify the Environment restrictions for users at any time. Clicking on a user under User > Organization will display a list of the Environments that user has access to in the Dashboard, which can be toggled on/off and applied on Save. All users must have access to at least one (1) environment."
  },
  {
    "id": "27-_guides/developer/data-custom-java-integration",
    "title": "Custom Java integration",
    "path": "_guides/developer/data-custom-java-integration.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/data-custom-java-integration",
    "content": "Mux has a pre-built integration with Google's ExoPlayer v2 and Android Media Player for Android applications.\n\nIf the player that you use does not expose the ExoPlayer instance directly, swaps between multiple instances during playback, or uses some other playback mechanism completely (for instance, outside of Android), a custom integration may be needed.\n\nImportant Related Docs\nBefore proceeding, read the following overview: Building a Custom Integration.\n\nIn addition, the source code for Mux's integration with Google's ExoPlayer is open source and can be found in the Mux-Stats-SDK-ExoPlayer GitHub repository. This project is a good example of how to use the Java core library in building a player integration.\n\nThe Mux Core Java library is made available as a JAR file which can be installed using the following methods:\n\nOption 1: Add Gradle dependency (preferred)\nAdd the Mux Maven repository to your Gradle file:\n\n\n```text\nrepositories {\n    maven {\n        url \"https://muxinc.jfrog.io/artifactory/default-maven-release-local\"\n    }\n}\n```\n\n\nNext, add a dependency on Mux Core (current version is 7.0.11):\n\n\n```\napi 'com.mux:stats.muxcore:7.0.11'\n```\n\n\nOption 2: Add Maven dependency\nAdd the Mux repository to your Maven pom.xml:\n\n\n```xml\n<repository>\n    <id>mux</id>\n    <name>Mux Maven Repository</name>\n    <url>https://muxinc.jfrog.io/artifactory/default-maven-release-local</url>\n    <releases>\n        <enabled>true</enabled>\n    </releases>\n    <snapshots>\n        <enabled>false</enabled>\n    </snapshots>\n</repository>\n```\n\n\nNext, add a dependency on Mux Core (current version is 7.0.11):\n\n\n```xml\n<dependency>\n    <groupId>com.mux</groupId>\n    <artifactId>stats.muxcore</artifactId>\n    <version>7.0.11</version>\n</dependency>\n```\n\n\nThe core Java SDK is initialized by implementing certain interfaces and providing these back to the SDK. In general, the structure used within MuxBaseExoPlayer should be followed, where you create a class that extends EventBus and implements IPlayerListener, and then follows the following general steps.\n\n\n```java\nimport com.mux.stats.sdk.core.events.EventBus;\nimport com.mux.stats.sdk.core.model.CustomerPlayerData;\nimport com.mux.stats.sdk.core.model.CustomerVideoData;\nimport com.mux.stats.sdk.core.model.CustomerViewData;\nimport com.mux.stats.sdk.muxstats.IPlayerListener;\n\npublic class PlayerListener extends EventBus implements IPlayerListener {\n      MuxStats muxStats;\n\n    PlayerListener(Context ctx, ExoPlayer player, String playerName, CustomerPlayerData customerPlayerData, CustomerVideoData customerVideoData, CustomerViewData customerViewData) {\n        super();\n        this.player = new WeakReference<>(player);\n        state = PlayerState.INIT;\n        MuxStats.setHostDevice(new MuxDevice(ctx));\n        MuxStats.setHostNetworkApi(new MuxNetworkRequests());\n        muxStats = new MuxStats(this, playerName, customerPlayerData, customerVideoData, customerViewData);\n        addListener(muxStats);\n    }\n}\n```\n\n\nThe above does the following:\n1. Initializes the EventBus superclass\n2. Sets the host device to a new instance of a class that implements IDevice\n3. Sets the host network API to a new instance of a class that implements INetworkRequest\n4. Instantiates a new instance of MuxStats, passing itself (a class that implements IPlayerListener) along with metadata\n5. Adds muxStats as a listener for this's events (via EventBus)\n\nThe IDevice, INetworkRequest, and IPlayerListener interfaces are described in the next section, as they provide the majority of the functionality aside from the actual emitting of events.\n\nThe core Java SDK relies heavily on callbacks, via implemented interfaces. These interfaces provide necessary metadata as well as core functionality that may be different depending on your Java environment.\n\nIDevice\nThe IDevice interface provides device-specific information to the core library, which is used as metadata attached to each view.\n\n\n```java\npackage com.mux.stats.sdk.muxstats;\n\npublic interface IDevice {\n    // Return the hardware name (e.g. Build.HARDWARE)\n    String getHardwareArchitecture();\n    // Return the OS (e.g. Android)\n    String getOSFamily();\n    // Return the OS version\n    String getOSVersion();\n    // Return the device manufacturer (e.g. Build.MANUFACTURER)\n    String getManufacturer();\n    // Return the model name (e.g. Build.MODEL)\n    String getModelName();\n    // Return the player version\n    String getPlayerVersion();\n    // Return a unique identifier for this device\n    String getDeviceId();\n    // Return the name of the running application\n    String getAppName();\n    // Return the version of the running application\n    String getAppVersion();\n    // Return the name of the plugin (e.g. exoplayer-mux)\n    String getPluginName();\n    // Return the version of the plugin\n    String getPluginVersion();\n    // Return the player software (e.g. 'ExoPlayer')\n    String getPlayerSoftware();\n    // Return the network connection type (e.g. 'wifi', 'cellular', 'ethernet')\n    String getNetworkConnectionType();\n    // Return milliseconds since epoch, ideally from a\n    // monotonically increasing clock. For instance, in\n    // ExoPlayer and Android, we suggest\n    // android.os.SystemClock.elapsedRealtime\n    long getElapsedRealtime();\n    // Return provide a mechanism to log an output, for instance to logcat\n    void outputLog(String tag, String msg);\n}\n```\n\n\nThere must be an instance of a class that implements the IDevice interface, and this should be provided to MuxStats.setHostDevice prior to instantiating an instance of MuxStats.\n\nYou can see the implementation of IDevice within Mux's ExoPlayer integration within MuxBaseExoPlayer.java.\n\nINetworkRequest\nThe INetworkRequest interface defines the methods that the Mux core SDK requires in order to make the necessary network requests.\n\n\n```java\npackage com.mux.stats.sdk.muxstats;\n\n/**\n * <b>MuxStats</b> will use this interface implementation to send events and metrics to the backend,\n * overlaying player SDK need to implement this interface and set it to the <b>MuxStats</b> via\n * {@link MuxStats#setHostNetworkApi(INetworkRequest)} method.\n * Always set this interface before instantiating the <b>MuxStats</b> instance.\n */\npublic interface INetworkRequest {\n\n  /**\n   * This interface is used to get from the network implementation that\n   * {@link #postWithCompletion(String, String, String, Hashtable, IMuxNetworkRequestsCompletion)}\n   * have succeed or not.\n   *\n   * @deprecated please prefer {@link IMuxNetworkRequestsCompletion2}\n   */\n  @Deprecated\n  interface IMuxNetworkRequestsCompletion {\n\n    /**\n     * Called by the implementation object when\n     * {@link #postWithCompletion(String, String, String, Hashtable,\n     * IMuxNetworkRequestsCompletion)} is called.\n     *\n     * @param result if post was completed successfully or not.\n     */\n    void onComplete(boolean result);\n  }\n\n  interface IMuxNetworkRequestsCompletion2 {\n    void onComplete(boolean result, Map<String, List<String>> headers);\n  }\n\n  /**\n   * Perform a HTTP GET request.\n   *\n   * @param url url to send get request to.\n   */\n  void get(URL url);\n\n  /**\n   * Perform HTTP POST request.\n   *\n   * @param url url to send post request to.\n   * @param body post request body.\n   * @param headers post request headers.\n   */\n  void post(URL url, JSONObject body, Hashtable<String, String> headers);\n\n  /**\n   * Perform network request with confirmation callback, type of request is left to the\n   * implementation.\n   *\n   * @param domain domain to send beacons to.\n   * @param envKey backend key used to authenticate with backend.\n   * @param body request body.\n   * @param headers request headers.\n   * @param callback callback triggered after the request signalling the request status.\n   */\n  void postWithCompletion(String domain, String envKey, String body,\n      Hashtable<String, String> headers, IMuxNetworkRequestsCompletion callback);\n\n  /**\n   * Perform a network request with the given completion handler. If implemented, the completion\n   * handler will also report the response headers for the call\n   *\n   * This method has a default implementation, which does not report response headers, and delegates\n   * to the other postWithCompletion\n   *\n   * @param domain domain to send beacons to.\n   * @param envKey backend key used to authenticate with backend.\n   * @param body request body.\n   * @param headers request headers.\n   * @param callback callback triggered after the request signalling the request status.\n   */\n  default void postWithCompletion(String domain, String envKey, String body,\n      Hashtable<String, String> headers, IMuxNetworkRequestsCompletion2 callback) {\n    postWithCompletion(domain, envKey, body, headers, result -> callback.onComplete(result, null));\n  }\n}\n```\n\n\nThere must be an instance of a class that implements the INetworkRequest interface, and this should be provided to MuxStats.setHostNetworkApi prior to instantiating an instance of MuxStats.\n\nYou can see the implementation of INetworkRequest within Mux's ExoPlayer integration within MuxNetworkRequests.java.\n\nIPlayerListener\nThe IPlayerListener interface defines the callbacks that MuxStats will utilize to retrieve player state information.\n\n\n```java\npackage com.mux.stats.sdk.muxstats;\n\npublic interface IPlayerListener {\n    // Return the current playhead position in milliseconds\n    // The playhead position must be updated at least every 250 milliseconds,\n    // but can be updated more often than this.\n    long getCurrentPosition();\n    // Return the MIME type of the content being played (e.g. \"video/mp4\"\n    // or \"application/x-mpegUrl\" etc)\n    String getMimeType();\n    // Return the width of the source, in pixels\n    Integer getSourceWidth();\n    // Return the height of the source, in pixels\n    Integer getSourceHeight();\n    // Return the current advertised bitrate, in bits per second\n    Integer getSourceAdvertisedBitrate();\n    // Return the current advertised framerate\n    Float getSourceAdvertisedFramerate();\n    // Return the current codec string\n    String getSourceCodec();\n    // Return the source duration, in milliseconds\n    Long getSourceDuration();\n    // Return whether the player is currently paused (i.e. not actively\n    // trying to play the content). This should return true if the player\n    // is not actively playing, rebuffering, or starting up.\n    boolean isPaused();\n    // Return whether the player is currently buffering content (e.g. not\n    // playing back because the buffer is not full enough).\n    boolean isBuffering();\n    // Return the width of the player, in logical pixels\n    int getPlayerViewWidth();\n    // Return the height of the player, in logical pixels\n    int getPlayerViewHeight();\n    // Return the current playback position as based off of the PDT tags\n    Long getPlayerProgramTime();\n    // Return the time of the furthest position in the manifest as based\n    // off of the PDT tags in the stream\n    Long getPlayerManifestNewestTime();\n    // Return the configured holdback value for a live stream (ms)\n    Long getVideoHoldback();\n    // Return the configured holdback value for parts in a low latency live\n    // stream (ms)\n    Long getVideoPartHoldback();\n    // Return the configured target duration for parts in a low latency\n    // live stream (ms)\n    Long getVideoPartTargetDuration();\n    // Return the configured target duration for segments in a live\n    // stream (ms)\n    Long getVideoTargetDuration();\n}\n```\n\n\nThe class that implements IPlayerListener serves as the interface between MuxStats and the actual player API, and is provided when creating an instance of MuxStats.\n\nYou can see the implementation of IPlayerListener within Mux's ExoPlayer integration within MuxBaseExoPlayer.java. This superclass is used to handle the base API interaction, and is subclassed by each individual MuxStatsExoPlayer.java to handle the varying APIs that ExoPlayer exposes with each of its minor versions (such as this one for r2.11.1).\n\nPlayback Events\nFor the Java core SDK, the Mux Playback Events are emitted via the dispatch method that is inherited from the EventBus class. In order to emit a given event, you must first instantiate an instance of the event class that you are trying to emit.\n\n\n```java\nimport com.mux.stats.sdk.core.events.EventBus;\nimport com.mux.stats.sdk.core.model.CustomerPlayerData;\nimport com.mux.stats.sdk.core.model.CustomerVideoData;\nimport com.mux.stats.sdk.muxstats.IPlayerListener;\nimport com.mux.stats.sdk.events.playback.PlayEvent;\n\npublic class PlayerListener extends EventBus implements IPlayerListener {\n      MuxStats muxStats;\n\n    PlayerListener(Context ctx, ExoPlayer player, String playerName, CustomerPlayerData customerPlayerData, CustomerVideoData customerVideoData) {\n        super();\n        this.player = new WeakReference<>(player);\n        state = PlayerState.INIT;\n        MuxStats.setHostDevice(new MuxDevice(ctx));\n        MuxStats.setHostNetworkApi(new MuxNetworkRequests());\n        muxStats = new MuxStats(this, playerName, customerPlayerData, customerVideoData);\n        addListener(muxStats);\n    }\n\n    // When the player begins trying to play back the video\n    public void onPlay() {\n        dispatch(new PlayEvent(null));\n    }\n}\n```\n\n\nWhile not necessary, each playback event can take an optional parameter of PlayerData, if certain information of the player has changed. This object has the following properties:\n\n| Property | Description |\n| --- | --- |\n| playerMuxPluginName | The name of the integration being built, as a string |\n| playerMuxPluginVersion | The version of the integration being built, as a string |\n| playerSoftwareName | The name of the player software (e.g. Exoplayer, etc) |\n| playerSoftwareLanguageCode | The language code (e.g. en-US) of the player UI localization |\n| playerWidth | The width of the player, in logical pixels |\n| playerHeight | The height of the player, in logical pixels |\n| playerIsFullscreen | Boolean of whether the player is currently displayed in full screen or not |\n| playerIsPaused | Boolean of whether the player is currently paused (i.e. not playing or trying to play) |\n| playerPlayheadTime | The current playhead time of the player, in milliseconds |\n\nMost of these properties are pulled automatically via the IPlayerListener interface, so there is no need to provide these values. You will need to emit all required Playback Events in order to make a working integration.\n\n    Prior to v5.0.0, the SeekingEvent was not necessary. As of v5.0.0, this is now a required event to be emitted by the player integration.\n\n    Prior to v6.0.0, the RebufferStartEvent and RebufferEndEvent were not necessary. As of v6.0.0 and newer, these events must be emitted by the player integration.\n\nData Events\nThere is an additional type of event that is permissible, the DataEvent. This event is emitted the same way (via EventBus.dispatch), but should be used when some metadata has changed outside of a playback event. Examples of this are when you may have any of the metadata within CustomerVideoData, CustomerPlayerData, EnvironmentData, VideoData, or ViewerData changes. This event likely will not be needed, but it is provided in the case that it might be useful. Mux does not use this at all within the ExoPlayer integration.\n\nExperiment Values\nValues for Experiments can be tracked via the tags of an HLS stream's main playlist. The values in the SessionTags will override the values provided via objects like CustomerPlayerData or CustomerVideoData. When your player has loaded the experiment values (such as through and HLS stream's X-SESSION-DATA tags), you may pass them to MuxStats::setSessionData(List)\n\nBandwidth Throughput Events\nFor the bandwidth throughput and latency related events, the structure is slightly different. Rather than having a specific class for each event, there is one high level network event, the RequestBandwidthEvent. This event exposes a method, setBandwidthMetricData(BandwidthMetricData), which is used to provide all information about the event. In particular, the BandwidthMetricData class exposes a property (via a getter/setter) named requestEventType, which is a string that will match the event names as defined in Playback Events - Bandwidth Throughput Events.\n\nThe implementation of these events for the Mux ExoPlayer integration can be found here in this file, from the linked line until the end of the file. This can serve as a good example of how to implement these events, though they are not necessary for a functioning integration.\n\nAd Events\nIn the case that your player supports advertising, you should instrument the ad events that are defined in Mux Playback Events - Ad Events. Ad events are emitted just as normal events would be, but the ad events should have the ad metadata included via a ViewData instance that is attached to each event via setViewData. For instance, to emit an AdPlayEvent, you should do the following:\n\n\n```\nAdData adData = new AdData();\nadData.setAdCreativeId(creativeId);\nadData.setAdId(adId);\nAdPlayEvent adPlayEvent = new AdPlayEvent(null);\nadPlayEvent.setAdData(adData);\ndispatch(adPlayEvent);\n```\n\n\nThe implementation of ad events within Mux's ExoPlayer integration, on top of Google's IMA SDK, can be found within AdsImaSDKListener.java, and can serve as a good example.\n\nChanging the video\nRather than requiring an event to be emitted for changing the video, MuxStats exposes two helper methods: videoChange and programChange. These methods encapsulate the logic necessary to end a view and start a new one, and both take an instance of CustomerVideoData containing the metadata about the new video being played.\n\nYou should call one of these methods when a new video is being loaded into an already-tracked player.\n\nThere is one critical difference between videoChange and programChange - programChange is intended to be used in the case that the underlying video changes _within the same stream_. An example of this would be within live linear playback, where the underlying program changes without the player having to reload a new stream.\n\nIn the case that the player is loading a new HLS/Dash/MP4 video, you should use videoChange.\n\n\n```\nCustomerVideoData customerVideoData = new CustomerVideoData(null);\ncustomerVideoData.setVideoTitle(\"New Video Title\");\n// Add other video metadata here\nmuxStats.videoChange(customerVideoData);\n```\n\n\nSending Error events\nYour custom integration is able to dispatch error events associated with the current view. These errors can get alerted on and are also visually indicated on the event timeline shown for that view.\n\nWhen dispatching errors your custom integration can provide additional error metadata with Error Categorization. This section will cover several examples of dispatching errors using the Java SDK. You can find more general information on Error Categorization here.\n\nThis example illustates how to construct and send different categories of error events.\n\nAny error categories specified by your custom integration can be configured to be overridden based on the player error code. See the Error Categorization guide for more details.\n\n\n```java\nimport com.mux.stats.sdk.core.events.EventBus;\nimport com.mux.stats.sdk.core.model.CustomerPlayerData;\nimport com.mux.stats.sdk.core.model.CustomerVideoData;\nimport com.mux.stats.sdk.muxstats.IPlayerListener;\nimport com.mux.stats.sdk.events.playback.PlayEvent;\nimport com.mux.stats.sdk.events.playback.ErrorEvent;\n\npublic class PlayerListener extends EventBus implements IPlayerListener {\n    MuxStats muxStats;\n\n    PlayerListener(Context ctx, ExoPlayer player, String playerName, CustomerPlayerData customerPlayerData, CustomerVideoData customerVideoData) {\n        super();\n        this.player = new WeakReference<>(player);\n        state = PlayerState.INIT;\n        MuxStats.setHostDevice(new MuxDevice(ctx));\n        MuxStats.setHostNetworkApi(new MuxNetworkRequests());\n        muxStats = new MuxStats(this, playerName, customerPlayerData, customerVideoData);\n        addListener(muxStats);\n    }\n\n    // When the player begins trying to play back the video\n    public void onPlay() {\n        dispatch(new PlayEvent(null));\n    }\n\n    // Call from onPlayerError() with parameters appropriate to your integration. Dispatches an error event that Mux will categorize as a fatal playback error by default\n    public void onPlaybackError(String errorCode, String errorMessage, String errorContext) {\n        PlayerData playerData = new PlayerData();\n        playerData.setErrorCode(errorCode);\n        playerData.setErrorMessage(errorMessage);\n\n        ErrorEvent errorEvent = new ErrorEvent(playerData, errorContext);\n\n        dispatch(errorEvent);\n    }\n\n    // Call from onPlayerError() with parameters appropriate to your integration. Dispatches an error event that Mux will categorize as a warning by default\n    public void onPlaybackWarning(String errorCode, String errorMessage, String errorContext) {\n        PlayerData playerData = new PlayerData();\n        playerData.setErrorCode(errorCode);\n        playerData.setErrorMessage(errorMessage);\n\n        ErrorEvent errorEvent = new ErrorEvent(playerData, errorContext, ErrorSeverity.ErrorSeverityWarning);\n\n        dispatch(errorEvent);\n    }\n\n    // Call from onPlayerError() with parameters appropriate to your integration. Dispatches an error event that Mux will categorize as a business exception by default\n    public void onBusinessException(String errorCode, String errorMessage, String errorContext) {\n        PlayerData playerData = new PlayerData();\n        playerData.setErrorCode(errorCode);\n        playerData.setErrorMessage(errorMessage);\n\n        // This method does not set an explicit error severity, see below for an example method that does.\n        ErrorEvent errorEvent = new ErrorEvent(playerData, errorContext);\n        errorEvent.setIsBusinessException(true);\n\n        dispatch(errorEvent);\n    }\n\n    // Call from onPlayerError() with parameters appropriate to your integration. Dispatches an error event that Mux will categorize as a business exception by default\n    public void onBusinessException(String errorCode, String errorMessage, String errorContext, ErrorSeverity severity) {\n        PlayerData playerData = new PlayerData();\n        playerData.setErrorCode(errorCode);\n        playerData.setErrorMessage(errorMessage);\n\n        ErrorEvent errorEvent = new ErrorEvent(playerData, errorContext, severity, true);\n\n        dispatch(errorEvent);\n    }\n}\n```\n\n\nTearing Down\nThere is no destroy event for the core Java SDK. Instead, the release method is exposed on MuxStats that cleans up all tracking and releases all references held within the core library. This method should be called when you release your player instance, and after calling release, the instance of muxStats will be unusable.\n\nCurrent release\n\nv8.7.0\nUpdates:\n Allow error codes as String values\n Add overloads of MuxStats.error() which take code, message, error context and flags directly\n Add ErrorSeverity.WARNING and ErrorSeverity.FATAL. Deprecate ErrorSeverity.errorSeverityWarning and ErrorSeverity.erorrSeverityFatal\n\nPrevious releases\n\nv8.6.0\nUpdates:\n Add playbackModeChange API methods to MuxStats. You can specify your own arbitrary playback modes, or use one of the presets in PlaybackMode\n Add cumulative ad playing time and total content time metric tracking. The metrics track the \"wall-clock\" time spent with video playing during a view, and exclude time spent buffering or paused.\n Add AdData.adType for indicating whether an ad is a preroll, midroll, or postroll\n\nv8.5.3\nFixes:\n do not dedupe error code and message if they were included\n\nv8.5.2\nImprovements:\n Prevent overriding mux_embed_version, mux_api_version, and mux_embed\n Do not flush beacons for non-fatal error events\n\nv8.5.1\nFixes:\n Un-deprecate CustomerVideoData.videoCdn\n\nv8.5.0\nNew:\n Add CdnChangeEvent, which will be sent automatically if using Request Metrics and sending your x-cdn header\nFixes:\n fix: Beacons not sent in v8.4.2 of the SDK\n\nv8.4.2\nFixes:\n fix: duplicate events and incorrect metadata when resuming after a long time\n fix: error severity not reported correctly\n\nv8.4.1\nFixes:\n fix: Incorrect minified key for ViewerClientApplicationName and ViewerClientApplicationVersion\n\nv8.4.0\nUpdates:\n Add CustomerVideoData::videoCreatorId\n\nv8.3.0\nUpdates:\n Add new Standard Dimensions\n\nv8.2.0\nUpdates:\n support 10 more custom dimensions\n\nv8.1.4\nFixes:\n fix: Always send metadata on 'renditionchange'\n fix: resolve conflicting UUIDs in rare cases\n\nv8.1.3\nFixes:\n fix: flush beacons when ad breaks end\n\nv8.1.2\nFixes:\n fix: end rebuffering on seek\n\nv8.1.1\nFixes:\n fix: verbose debug logging logging can break beacon dispatch\n fix: seeking should end any active rebuffering\n\nv8.1.0\nUpdates:\n update: expose enable and disable methods for pausing and resuming data collection\n\nv8.0.2\nImprovements:\n size metrics are now ignored if values are set to -1\n\nv8.0.1\nFixes:\n fix: reported application hang due to event handling\n\nv8.0.0\nImprovements\n Error events can be categorized with warning or fatal severity levels\n Error events can be categorized as business exceptions\n An error translator can be configured to extend or customize the Core SDK error handling logic\n\nFixes:\n Player error details such as error code, error context, error message, error severity, and whether the error is a business exception are only sent to Mux when an error event is dispatched.\n Player error details (same as listed above) are no longer deduplicated and are explicitly included with each error event sent to Mux.\n The SDK continues to track watch time after an error event is dispatched based on player playhead progression. To explicitly indicate that watch time should no longer be tracked after an error during a playback session please dispatch a ViewEnd event.\n\nv7.13.2\nFixes:\n Update json.org to 20231013\n\nv7.13.1\nFixes:\n Update json.org to 20230227\n\nv7.13.0\nFixes:\n fix issue where seeking time would be included in time-to-first-frame if user seeked before playback started\n\nv7.12.0\nUpdates:\n add update() method for CustomerData\n\nv7.11.0\nNew:\n Support video source codec in IPlayerListener\n\nv7.10.0\nNew:\n Add ability to set lower-priority video data, for auto-detected metadata\n\nv7.9.1\nImprovements:\n Additional improvements in reliability during large events\n\nv7.9.0\nImprovements:\n Added drmType to CustomerViewData so customers can override it\n Added x-litix-shard-id header populated with device ID\n\nv7.8.0\nNew:\n Add a field to CustomOptions for controlling beacon update interval. Very few cases require longBeaconDispatch.\n\nv7.7.4\nFixes:\n Fix Beacon interval incorrectly being 10 minutes\n\nv7.7.3\nImprovements:\n Update beacon interval changed from 5s to 10s\n\nv7.7.2\nImprovements:\n Fix Ad metadata not being reported properly\n\nv7.7.0\nNew:\nAdd AdEvent with AdData to represent data about individual, non-preroll ad events during play"
  },
  {
    "id": "28-_guides/developer/data-custom-javascript-integration",
    "title": "Custom JavaScript integration",
    "path": "_guides/developer/data-custom-javascript-integration.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/data-custom-javascript-integration",
    "content": "Mux has a pre-built integration with many HTML5-based video players that are available in the market. Check the SDKs in the Track your video performance guide to see if there is not a pre-built integration for your player.\n\nIf there is no integration for a given player, you can install the Mux core JavaScript library (mux-embed) and build a custom Mux Data integration.\n\nImportant related docs\n\nBefore proceeding, read the following overview: Building a Custom Integration.\n\nIn addition, Mux has made available a template repository. This repo is intended to provide the basics for creating a working integration, after implementing the necessary callbacks and methods.\n\nInclude the mux-embed library\n\nInstall via yarn or npm (preferred)\n\nMux utilizes NPM to distribute the core Mux library, mux-embed. This library includes the internal state machine for tracking playback, as well as helper methods that may be useful while building the integration. Include mux-embed via yarn or npm, whichever you prefer.\n\n\n```sh\nyarn add mux-embed\n```\n\n\nThis will add mux-embed as a dependency to your package, and will allow you to upgrade it at any time as new versions are released. Mux follows the semver standard, so updates within a major version will not have any breaking changes.\n\nLoad from the CDN (not preferred)\n\nIf you do not use a package manager, you can include the source file from https://src.litix.io/core/4/mux.js directly in a vendor folder. The script has been built to support npm/yarn, but will also work in a standalone environment.\n\nIn either case, once the script is included in your library, you can import it as follows:\n\n\n```js\nimport mux from 'mux-embed';\n\n// mux.log - logs message\n// mux.utils - includes multiple helper methods for massaging data\n```\n\n\nInitialize the SDK\n\nLoading and importing mux will initialize the SDK. However, for each new player that is being tracked, you need to initialize the SDK for that player. This is done by calling\n\n\n```js\nmux.init(playerID, options);\n```\n\n\nThe core mux library can track multiple players at once, so it is important to pass in a unique player ID for each player that you want to track. This ID is going to be used in all future calls to the mux library for each player.\n\nThe init method also takes an optional options JSON object. This JSON object supports the following keys:\n\n| Property | Required | Type | Description |\n| --- | --- | --- | --- |\n| debug | No | boolean | Controls whether debug log statements are logged to the console |\n| getPlayheadTime | Yes | function | Callback for playhead position (see below) |\n| getStateData | Yes | function | Callback for player state (see below) |\n| data | No | object | Data about the viewer, video, and integration |\n\nWithin the data object, you should pass any information that is listed in Metadata, which is typically about the viewer or the video itself. In addition, the following should be provided:\n\n| Property | Description | Example |\n| --- | --- | --- |\n| player_software_name | The name of the underlying player software | 'Video.js' |\n| player_software_version | The version of the underlying player software | '1.0.1' |\n| player_mux_plugin_name | The name of the plugin being built | Some descriptive string |\n| player_mux_plugin_version | The version of the plugin being built | A version string |\n\nThe only required property underneath data is the env_key, which is your env_key found for each environment on https://dashboard.mux.com/environments.\n\nFor most integrations, there should be some data that is passed down to the integration at runtime in the page/application, such as viewer information and video information, and often times the env_key. This information should be merged with the above four properties as a whole before being passed to mux.init.\n\nSee the JavaScript Integration Framework for an example of how this is done.\n\nProvide callbacks\n\nThe JavaScript Core SDK expects two callback functions to be passed in the options object to mux.init: getPlayheadTime and getStateData. These callbacks make it so that additional data does not need to be provided when emitting most events.\n\nThe getPlayheadTime callback is a simple function that should return the accurate playhead position, in milliseconds.\n\nThe getStateData callback is a function that should return the following properties:\n\n\n```js\noptions.getStateData = () => {\n  return {\n    // Required properties - these must be provided every time this is called\n    // You _should_ only provide these values if they are defined (i.e. not 'undefined')\n    player_is_paused: player.isPaused(), // Return whether the player is paused, stopped, or complete (i.e. in any state that is not actively trying to play back the video)\n    player_width: player.getWidth(), // Return the width, in pixels, of the player on screen\n    player_height: player.getHeight(), // Return the height, in pixels, of the player on screen\n    video_source_height: player.currentSource().height, // Return the height, in pixels, of the current rendition playing in the player\n    video_source_width: player.currentSource().width, // Return the height, in pixels, of the current rendition playing in the player\n\n    // Preferred properties - these should be provided in this callback if possible\n    // If any are missing, that is okay, but this will be a lack of data for the customer at a later time\n    player_is_fullscreen: player.isFullscreen(), // Return true if the player is fullscreen\n    player_autoplay_on: player.autoplay(), // Return true if the player is autoplay\n    player_preload_on: player.preload(), // Return true if the player is preloading data (metadata, on, auto are all \"true\")\n    video_source_url: player.src().url, // Return the playback URL (i.e. URL to master manifest or MP4 file)\n    video_source_mime_type: player.src().mimeType, // Return the mime type (if possible), otherwise the source type (hls, dash, mp4, flv, etc)\n    video_source_duration: secondsToMs(player.getDuration()), // Return the duration of the source as reported by the player (could be different than is reported by the customer)\n\n    // Optional properties - if you have them, send them, but if not, no big deal\n    video_poster_url: player.poster().url(), // Return the URL of the poster image used\n    player_language_code: player.language() // Return the language code (e.g. `en`, `en-us`)\n  };\n};\n```\n\n\nEmit events\n\nThe Playback Events should be emitted as the events are defined. For the JavaScript core SDK, all events are emitted via mux.emit. This method takes three arguments:\n- the player name (the same used in the call to mux.init\n- the event name (e.g. play)\n- (optional) additional data to send along with the event.\n\nAll playback events should be emitted as defined except for one: viewinit does not need to be emitted for custom JavaScript integrations. This is handled directly by the call to mux.init, and also within the helper mux.emit('videochange', data).\n\nFor the basic Playback Events, no additional metadata is necessary, as it will be pulled via the callbacks defined above. However, for the ad event and network events, there are additional data fields that should be sent, as documented.\n\nLastly, when changing the video, the new video metadata should be included within the third parameter.\n\nFor instance:\n\n\n```js\n// Emit the `play` event\nmux.emit('playerId', 'play');\n\n// Emit an ad event, with additional ad metadata\nmux.emit('playerId', 'adrequest', {\n  ad_tag_url: \"https://pubads.g.doubleclick.net/ads/...\"\n});\n\n// Changing a video\nmux.emit('playerId', 'videochange', {\n  video_title: 'New Video Title',\n    // ... all other metadata about the video\n});\n```\n\nTearing Down\nWhen you are tearing down the player and want to stop monitoring it, make sure to remove any listeners that you have on the player for sending events to mux. After this, make sure to call mux.emit('playerId', 'destroy'); for your player, so that the core library can clean up any monitoring and end the view."
  },
  {
    "id": "29-_guides/developer/data-custom-objectivec-integration",
    "title": "Custom Objective-C integration",
    "path": "_guides/developer/data-custom-objectivec-integration.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/data-custom-objectivec-integration",
    "content": "Mux has a pre-built integration with Apple's AVPlayer for iOS and tvOS applications; for these players, see here: iOS Integration Guide.\n\nIf the player that you use does not expose the AVPlayer instance directly, swaps between multiple instances during playback, or uses some other playback mechanism completely, a custom integration may be needed.\n\nImportant Related Docs\nBefore proceeding, read the following overview: Building a Custom Integration.\n\nIn addition, the source code for Mux's integration with Apple's AVPlayer is open source and can be found in the Mux-Stats-AVPlayer GitHub repository. This project is a good example of how to use the Objective-C core library in building a player integration.\n\nInclude the Mux-Core library\n\nInstalling in Xcode with Swift Package Manager\n\n1. In your Xcode project click \"File\" > \"Add Package\"\n2. In the top-right corner of the modal window paste in the SDK repository URL:\n\n\n```\nhttps://github.com/muxinc/stats-sdk-objc.git\n```\n\n\n3. Click Next.\n4. Since the MuxCore follows SemVer, we recommend setting the \"Rules\" to install the latest version and choosing the option \"Up to Next Major\". Here's an overview of the different SPM Dependency Rules and their semantics.\n\nInstalling in Package.swift\n\nOpen your Package.swift file, add the following to dependencies:\n\n\n```swift\n    .package(\n      url: \"https://github.com/muxinc/stats-sdk-objc\",\n      .upToNextMajor(from: \"5.0.1\")\n    ),\n```\n\n\nInstalling with CocoaPods\n\nTo include the core Objective-C library via CocoaPods, modify your Podfile to use frameworks by including use_frameworks! and then add the following pod to your Podfile:\n\n\n```ruby\npod \"Mux-Stats-Core\", \"~> 5.0\"\n```\n\n\nThis will include our current release of the core Objective-C library. There will be no breaking updates within major versions of this library, so you can safely run pod update.\n\nSince version 3, Mux-Stats-Core has been updated for Xcode 12 and XCFrameworks bundle type.\n\nIncluding Manually (not preferred)\n\nIf you do not you use CocoaPods and wish to include the library manually, view the XCFramework directory in the Mux Objective-C Core SDK and dragging the framework into your Xcode project.\n\nInitialize the SDK\n\nThere is no need to initialize a player monitor for each player that is being tracked, as this happens automatically when events are emitted for a specific player. For the Objective-C library, the Environment and Viewer-specific data should be emitted to the SDK globally as follows.\n\n\n```objc\nMUXSDKEnvironmentData *environmentData = [[MUXSDKEnvironmentData alloc] init];\n[environmentData setMuxViewerId:[[[UIDevice currentDevice] identifierForVendor] UUIDString]];\nMUXSDKViewerData *viewerData = [[MUXSDKViewerData alloc] init];\nNSString *bundleId = [[NSBundle mainBundle] bundleIdentifier];\nif (bundleId) {\n  [viewerData setViewerApplicationName:bundleId];\n}\n// Set additional Viewer data as above\nMUXSDKDataEvent *dataEvent = [[MUXSDKDataEvent alloc] init];\n[dataEvent setEnvironmentData:environmentData];\n[dataEvent setViewerData:viewerData];\n[MUXSDKCore dispatchGlobalDataEvent:dataEvent];\n```\n\n\nThe only field that should be modified within MUXSDKEnvironmentData is the muxViewerId, via setMuxViewerId, which should be a device-specific string. This field is used within the Mux Dashboard as the Viewer ID in the case that a user-specific value is not provided in the metadata, via [MUXSDKCustomerViewerData setViewerUserId:].\n\nIf you are monitoring playback and delivery of Mux Video assets, you may opt-in to Mux Data inferring your environment details from player HTTP traffic. To opt-in, initialize MUXSDKCustomerPlayerData with environmentKey set to nil.\n\nFor MUXSDKViewerData, the fields that may be provided are the following.\n\n\n```objc\n@property (nullable) NSString *viewerApplicationEngine;\n@property (nullable) NSString *viewerApplicationName;\n@property (nullable) NSString *viewerApplicationVersion;\n@property (nullable) NSString *viewerConnectionType;\n@property (nullable) NSString *viewerDeviceCategory;\n@property (nullable) NSString *viewerDeviceManufacturer;\n@property (nullable) NSString *viewerDeviceName;\n@property (nullable) NSString *viewerOsArchitecture;\n@property (nullable) NSString *viewerOsFamily;\n@property (nullable) NSString *viewerOsVersion;\n```\n\n\nSee the AVPlayer integration for example values used.\n\nEmit events\n\nFor the Objective-C core SDK, there are two types of events that should be emitted: data events and playback events. Data events are events that update metadata about the video or view, whereas playback events are those described here: Mux Playback Events.\n\nAll events are emitted to a specific Player, so make sure to include the unique player ID with each event emitted.\n\nData Events\nData events are emitted via [MUXSDKCore dispatchEvent: forPlayer:], and should be emitted when any of the following pieces of metadata change:\n\n - MUXSDKVideoData\n  - videoSourceWidth - width of the video currently being played, in pixels\n  - videoSourceHeight - height of the video currently being played, in pixels\n  - videoSourceIsLive - whether the video currently being played is live or not\n  - videoSourceDuration - the duration, in milliseconds, of the video currently being played\n  - videoSourceAdvertisedBitrate - the bitrate of the current rendition being played, in bits per second\n  - videoSourceFrameDrops - the total number of dropped video frames for the current View\n - Anything in MUXSDKCustomerPlayerData, as defined here: Metadata\n - Anything in MUXSDKCustomerVideoData, as defined here: Metadata\n - Anything in MUXSDKCustomerViewData, as defined here: Metadata\n\nWhen any of the above fields change, do the following:\n - Create one or more instances of MUXSDKVideoData , MUXSDKCustomerPlayerData, MUXSDKCustomerVideoData, and MUXSDKCustomerViewData depending on what changed\n - Assign all properties with the most recent value via the helper methods to the appropriate instance of data\n - Attach these to an instance of MUXSDKDataEvent\n - Emit this MUXSDKDataEvent via [MUXSDKCore dispatchEvent: forPlayer:]\n\nFor example, when the resolution of the video being played back changes (such as in adaptive streaming), the following should be done:\n\n\n```objc\n\"code\": \"// Prepare the data update\\nMUXSDKVideoData *videoData = [[MUXSDKVideoData alloc] init];\\n[videoData setVideoSourceWidth:[NSNumber numberWithInt:width]];\\n[videoData setVideoSourceHeight:[NSNumber numberWithInt:height]];\\n// put it within a MUXSDKDataEvent\\nMUXSDKDataEvent *dataEvent = [[MUXSDKDataEvent alloc] init];\\n[dataEvent setVideoData:videoData];\\n// Emit the event\\n[MUXSDKCore dispatchEvent:dataEvent forPlayer:_playerName];\",\n\"language\": \"objectivec\"\n```\n\n\nPlayback Events\nThe Mux Playback Events should be emitted as the events are defined in the referenced document. With regards to naming, the names should align with those in the document, with the following changes: MUXSDK is appended in front of the name, the name itself should be PascalCased, and Event is appended at the end. For instance, for playerready, the corresponding event is MUXSDKPlayerReadyEvent, as defined in MUXSDKPlayerReadyEvent.h.\n\nWith each playback event that is emitted, the following fields within MUXSDKPlayerData should be included with the latest values:\n - playerMuxPluginName - The name of the integration being built, as a string\n - playerMuxPluginVersion - The version of the integration being built, as a string\n - playerSoftwareName - The name of the player software (e.g. AVPlayer, AVPlayerLayer, etc)\n - playerSoftwareLanguageCode - The language code (e.g. en-US) of the player UI localization\n - playerWidth - The width of the player, in logical pixels\n - playerHeight - The height of the player, in logical pixels\n - playerIsFullscreen - Boolean of whether the player is currently displayed in full screen or not\n - playerIsPaused- Boolean of whether the player is currently paused (i.e. not playing or trying to play)\n - playerPlayheadTime - The current playhead time of the player, in milliseconds\n\nFor instance, when emitting the MUXSDKPlayerReady event, it should look like the following:\n\n\n```objc\n// Get the player data\nMUXSDKPlayerData *playerData = [[MUXSDKPlayerData alloc] init];\n// Set the player data information\n[playerData setPlayerMuxPluginName:@\"Sample Custom Player\"];\n// ... repeat the above for all values within `MUXSDKPlayerData`\n// Emit the event\nMUXSDKPlayerReadyEvent *event = [[MUXSDKPlayerReadyEvent alloc] init];\n[event setPlayerData:playerData];\n[MUXSDKCore dispatchEvent:event forPlayer:_playerName];\n```\n\n\nIn addition to the above data fields, for ad and network events there are additional data fields that should be sent. These are documented alongside the events described in Mux Playback Events, and follow similar naming conventions.\n\nIn particular:\n - Network throughput events should be emitted as MUXSDKRequestBandwidthEvents, with the addition of MUXSDKBandwidthMetricData set on the event via [MUXSDKRequestBandwidthEvent\n setBandwidthMetricData:].\n - If your player gives you access to your streams rendtion list, you can use the renditionLists property of MUXSDKBandwidthMetricData  track a stream's renditions with their resolution, framerate, bitrate, and RFC CODECS tag (ref).\n - Ad events are emitted via a special method, dispatchAdEvent, and details can be seen within Mux's IMA integration for AVPlayer\n\nLastly, for the MUXSDKRenditionChangeEvent, you should make sure to dispatch a MUXSDKDataEvent with the latest updated MUXSDKVideoData immediately before dispatching the MUXSDKRenditionChangeEvent.\n\nSample event sequence\n\nThere are multiple steps in setting up and tracking a view correctly. A very simple sequence of events to track a basic playback would look like the following steps:\n\n1. Dispatch a global data event with the environment and viewer data\n1. Dispatch the MUXSDKViewInitEvent with the current state of the player and video\n1. Dispatch a MUXSDKDataEvent with the updated MUXSDKCustomerVideoData and MUXSDKCustomerPlayerData for the current video view\n1. Dispatch the rest of the Mux Playback Events (e.g. MUXSDKPlayerReadyEvent, MUXSDKPlayEvent, MUXSDKPlayingEvent, MUXSDKTimeUpdateEvent, etc), each time with the updated current state of the player\n\nNote: For each Playback Event and MUXSDKViewInitEvent that is dispatched, the current state of the player and video data (MUXSDKPlayerData and MUXSDKVideoData should be attached to the event prior to dispatching the event.\n\n\n```objc\n// First, emit the global data event setting up the information about\n// the player. This will likely only be called once within your application\n// and does not need to be called for each player that is tracked.\nMUXSDKDataEvent *dataEvent = [[MUXSDKDataEvent alloc] init];\n[dataEvent setEnvironmentData:environmentData];\n[dataEvent setViewerData:viewerData];\n[MUXSDKCore dispatchGlobalDataEvent:_dataEvent];\n\n// Prepare the view before you emit any other playback events\nMUXSDKViewInitEvent *event = [[MUXSDKViewInitEvent alloc] init];\n[event setPlayerData:playerData];\n[MUXSDKCore dispatchEvent:event forPlayer:playerName];\n\n// Dispatch data about the view itself.\n// Note: customerPlayerData must include your environment key.\nMUXSDKDataEvent *dataEvent = [[MUXSDKDataEvent alloc] init];\n[dataEvent setCustomerPlayerData:customerPlayerData];\n[dataEvent setCustomerVideoData:customerVideoData];\n[MUXSDKCore dispatchEvent:dataEvent forPlayer:_playerName];\n\n// Emit playback events\nMUXSDKPlayerReadyEvent *event = [[MUXSDKPlayerReadyEvent alloc] init];\n[event setPlayerData:playerData];\n[MUXSDKCore dispatchEvent:event forPlayer:_playerName];\n\n// When the player begins to attempt playback\nMUXSDKPlayEvent *event = [[MUXSDKPlayEvent alloc] init];\n[event setPlayerData:playerData];\n[MUXSDKCore dispatchEvent:event forPlayer:_playerName];\n\n// When the player actually displays first moving frame\nMUXSDKPlayingEvent *event = [[MUXSDKPlayingEvent alloc] init];\n[event setPlayerData:playerData];\n[MUXSDKCore dispatchEvent:event forPlayer:_playerName];\n\n// ... and repeat for all of the playback events\n```\n\n\nAdditional methods\n\nMost of the events are signaled as listed above. However, there are a few cases of events that require additional work.\n\nChanging the Video\nIn order to change the video within a player, there are a few events that need to be fired in sequence. You can see the implementation of this within the muxinc/mux-stats-sdk-avplayer code. You should do the following:\n1. Dispatch a viewend event\n2. Dispatch a viewinit event\n3. Dispatch a MUXSDKDataEvent with the new video's MUXSDKCustomerVideoData, with the videoChange property set to YES.\n\nIf at various times the same underlying video stream needs to be monitoried as effectively separate videos and separate Data views, two additional events: play and playing need to be dispatched\n\nSee an example implementation of this in the muxinc/mux-stats-sdk-avplayer code.\n\nThe following are the required steps from start to finish:\n1. As before, dispatch a viewend event\n2. As before, dispatch a viewinit event\n3. As before, dispatch a MUXSDKDataEvent with the new video's MUXSDKCustomerVideoData, with the videoChange property set to YES.\n4. Dispatch a play event\n5. Dispatch a playing event\n\nSending Error events\nYour custom integration is able to dispatch error events associated with the current view. These errors can get alerted on and are also visually indicated on the event timeline shown for that view.\n\nWhen dispatching errors your custom integration can provide additional error metadata with Error Categorization. This section will cover several examples of dispatching errors using the Objective-C SDK. You can find more general information on Error Categorization here.\n\nAny error categories specified by your custom integration can be configured to be overridden based on the player error code. See the Error Categorization guide for more details.\n\nThis example dispatches an error event that Mux will categorize as a fatal playback error unless a different default for the player error code applies.\n\n\n```objc\n// Call this method from the source of the fatal playback error (such as an `AVPlayer` key-value property observer, for example) with parameters appropriate to your integration.\n- (void)dispatchPlaybackWarningWithPlayerName:(NSString *)playerName\n                              playerErrorCode:(NSString *)playerErrorCode\n                           playerErrorMessage:(NSString *)playerErrorMessage\n                           playerErrorContext:(NSString *)playerErrorContext\n                           playerPlayheadTime:(NSNumber *)playerPlayheadTime {\n  MUXSDKErrorEvent *errorEvent = [[MUXSDKErrorEvent alloc] initWithContext:playerErrorContext];\n\n  // Configure any custom video or view data if necessary\n  MUXSDKPlayerData *playerData = [[MUXSDKPlayerData alloc] init];\n  [playerData setPlayerErrorCode:playerErrorCode];\n  [playerData setPlayerErrorMessagae:playerErrorMessage];\n  [playerData setPlayerPlayheadTime: playerPlayheadTime];\n  // ... repeat for any other `MUXSDKPlayerData` properties if they've changed\n\n  [MUXSDKCore dispatchEvent:event\n                forPlayer:playerName];\n}\n```\n\n\nThis example dispatches an error that Mux will categorize as a warning unless a different default for the player error code applies.\n\n\n```objc\n// Call this method from the source of the playback warning (such as an `AVPlayer` key-value property observer, for example) with parameters appropriate to your integration.\n- (void)dispatchPlaybackWarningWithPlayerName:(NSString *)playerName\n                              playerErrorCode:(NSString *)playerErrorCode\n                           playerErrorMessage:(NSString *)playerErrorMessage\n                           playerErrorContext:(NSString *)playerErrorContext\n                           playerPlayheadTime:(NSNumber *)playerPlayheadTime {\n  MUXSDKErrorEvent *errorEvent = [[MUXSDKErrorEvent alloc] initWithSeverity:MUXSDKErrorSeverityWarning\n                                                                    context:playerErrorContext];\n\n  // Configure any custom video or view data if necessary\n  MUXSDKPlayerData *playerData = [[MUXSDKPlayerData alloc] init];\n  [playerData setPlayerErrorCode:playerErrorCode];\n  [playerData setPlayerErrorMessagae:playerErrorMessage];\n  [playerData setPlayerPlayheadTime: playerPlayheadTime];\n  // ... repeat for any other `MUXSDKPlayerData` properties if they've changed\n\n  [MUXSDKCore dispatchEvent:errorEvent\n                  forPlayer:playerName];\n}\n```\n\n\nThis example dispatches an error that Mux will catgeorize as a business exception unless a different default for the player error code applies.\n\n```objc\n// Call this method from the source of the business exception with parameters appropriate to your integration.\n- (void)dispatchBusinessExceptionWithPlayerName:(NSString *)playerName\n                                  playerErrorCode:(NSString *)playerErrorCode\n                                  playerErrorMessage:(NSString *)playerErrorMessage\n                                  playerErrorContext:(NSString *)playerErrorContext\n                                  playerPlayheadTime:(NSNumber *)playerPlayheadTime {\n\n  // This method does not set an explicit error severity, see below for an example method that does.\n  MUXSDKErrorEvent *errorEvent = [[MUXSDKErrorEvent alloc] initWithContext:playerErrorContext];\n  [errorEvent setIsBusinessException: YES];\n\n  // Configure any custom video or view data if necessary\n  MUXSDKPlayerData *playerData = [[MUXSDKPlayerData alloc] init];\n  [playerData setPlayerErrorCode:playerErrorCode];\n  [playerData setPlayerErrorMessage:playerErrorMessage];\n  [playerData setPlayerPlayheadTime:playerPlayheadTime];\n  // ... repeat for any other `MUXSDKPlayerData` properties if they've changed\n\n  [MUXSDKCore dispatchEvent:errorEvent\n                  forPlayer:playerName];\n}\n\n// Call this method from the source of the business exception with parameters appropriate to your integration.\n- (void)dispatchBusinessExceptionWithPlayerName:(NSString *)playerName\n                                  playerErrorSeverity:(MUXSDKErrorSeverity)errorSeverity\n                                  playerErrorCode:(NSString *)playerErrorCode\n                                  playerErrorMessage:(NSString *)playerErrorMessage\n                                  playerErrorContext:(NSString *)playerErrorContext\n                                  playerPlayheadTime:(NSNumber *)playerPlayheadTime {\n  MUXSDKErrorEvent *errorEvent = [[MUXSDKErrorEvent alloc] initWithContext:playerErrorContext];\n  [errorEvent setIsBusinessException: YES];\n\n  // Configure any custom video or view data if necessary\n  MUXSDKPlayerData *playerData = [[MUXSDKPlayerData alloc] init];\n  [playerData setPlayerErrorCode:playerErrorCode];\n  [playerData setPlayerErrorMessage:playerErrorMessage];\n  [playerData setPlayerPlayheadTime:playerPlayheadTime];\n  // ... repeat for any other `MUXSDKPlayerData` properties if they've changed\n\n  [MUXSDKCore dispatchEvent:errorEvent\n                  forPlayer:playerName];\n}\n```\n\n\nDestroying the Monitor\nWhen you are tearing down the player and want to stop monitoring it, make sure to remove any listeners that you have on the player for sending events to MUXSDKCore. After this, make sure to call [MUXSDKCore destroyPlayer: _name]; for the name of your player, so that the core library can clean up any monitoring and end the view session.\n\nRelease notes\n\nCurrent release\n\nv5.7.1\n\nFixes:\n Ensure playbackmodechange events are sent\n Restores tvOS-specific seeking detection behavior, where a best-effort attempt is made to count the preceding pause as part of the seek. This behavior was missing in 5.7.0, potentially causing changes in metrics.\n\nPrevious releases\n\nv5.7.0\n\nUpdates:\n playbackmodechange event added for tracking changes to the presentation of a video (ie, fullscreen, pip, etc)\n Added timing metrics for playing time and ad playing time. These metrics track the wall-clock time spent playing (excluding startup time, rebuffering, seeking, etc)\n\nImprovements:\n Added nullability annotations and nil-handling improvements to most public APIs\n Made most properties of MUXSDKPlayerData, MUXSDKVideoData, CustomerData, et al nonatomic\n Handle trackable events via typed delegate method\n Enable link-time optimization by thinLTO\n MUXSDKCore methods may now be called from any thread\n Numerous internal improvements\n\nFixes:\n Fix HTTP retry delay 1000x higher than intentional\n Wait for HTTP connectivity for beacons\n\nv5.6.0\n\nImprovements:\n Allow disabling playhead-based rebuffer tracking via -[MUXSDKCore disablePlayheadRebufferTrackingForPlayerID:] and manual dispatch of MUXSDKRebufferStartEvent and MUXSDKRebufferEndEvent\n\nFixes:\n Prevent overriding muxEmbed, muxEmbedVersion, and muxApiVersion from MUXSDKEnvironmentData\n Individual frameworks within the XCFramework are no longer separately code signed. The parent XCFramework is still signed.\n\nv5.5.1\n\nImprovements:\n Removes the deprecation on MUXSDKCustomerVideoData.videoCDN (added in v5.5.0)\n\nv5.5.0\n\nImprovements:\n Adds CDN change tracking, including automatically via X-CDN headers\n The MuxCore frameworks are now built as Mergeable Libraries. See this WWDC session and the official docs for more info. This is not enabled for the CocoaPods build.\n\nFixes:\n Fixes missing videoData in some instances, including after a rendition change\n Corrects a typo in viewPrerollAdAssetHostname causing it not to be sent\n Fixes an issue leading to incorrect viewPlayingTime and/or viewMaxPlayheadPosition\n Resolves a few naming issues that could cause builds to fail on case-sensitive filesystems\n\nv5.4.1\nFixes:\n fix rebuffering ending while player is still buffering in some cases\n\nv5.4.0\nImprovements:\n Add customer viewer data to MUXSDKDataEvent and MUXSDKTrackableEvent\n Use consistent umbrella header path so import  works on all platforms\n\nv5.3.1\nImprovements:\n Add MUXSDKCustomerVideoData.videoCreatorId\n\nv5.3.0\nImprovements:\n adds additional dimensions\n\nFixes:\n adds missing macCatalyst platform to package spec\n\nv5.2.0\nImprovements:\n expose additional custom dimensions\n\nv5.1.2\nFixes:\n dispatch queued up events when receiving adbreakend, aderror events\n patch memory leak when a player monitor is created and destroyed\n\nv5.1.1\nFixes:\n Fully resets all player metrics associated with a previous view that had ended due to a time out when receiving a viewinit event.\n\nv5.1.0\nImprovements:\n Include codec and rendition name in renditionchange events\n Add safety checks when player identifier is nil\n\nv5.0.1\nImprovements:\n Include privacy manifest file\n\nv5.0.0\nImprovements:\n Error events can be categorized with warning or fatal severity levels\n Error events can be categorized as business exceptions\n An error translator can be configured to extend or customize the Core SDK error handling logic\n\nFixes:\n Player error details such as error code, error context, error message, error severity, and whether the error is a business exception are only sent to Mux when an error event is dispatched.\n Player error details (same as listed above) are no longer deduplicated and are explicitly included with each error event sent to Mux.\n The SDK continues to track watch time after an error event is dispatched based on player playhead progression. To explicitly indicate that watch time should no longer be tracked after an error during a playback session please dispatch a ViewEnd event.\n\nv4.7.1\nImprovements:\n Include privacy manifest file\n\nv4.7.0\nImprovements:\n Add support for monitoring media on visionOS. We recommend testing your visionOS SDK integration on both the simulator and a physical device prior to deploying to the App Store.\n\nFixes:\n Compute correct Video Startup Time if AdPlayingEvent occurs a significant time after the view has started\n Ensure seeks are excluded from Video Startup Time in all cases\n\nKnown Issues:\n Installation using Cocoapods on visionOS is not currently supported. Installation on iOS and tvOS using Cocoapods is not affected.\n\nv4.6.0\nAPI Changes:\n Expose player software name and player software version on MUXSDKPlayerData\n\nImprovements:\n Bump beacon interval to 10 seconds to match the other Core SDKs\n\nv4.5.2\nImprovements:\n Backfill header nullability annotations\n\nv4.5.1\nFixes:\n Include at playback time in the calculation for total playback time\n\nv4.5.0\nUpdated:\n Add DRM Type to MUXSDKCustomerViewData so you can specify it from another source\n\nDeprecated:\n MUXSDKDispatcher's handleBatch beaconCollectionDomain: osFamily: jsonDict: callback: has been deprecated in favor of an overload that takes headers for requests to the collection domain\n MUXSDKNetworkRequestBuilding buildRequestFromURL: eventsJsonDict: error: has been deprecated in favor of an overload that takes headers for requests to the collection domain\n\nImprovements:\n Performance + Reliability improvements during large events\n\nv4.4.2\nFixes:\n Fix ad metadata not being reported\n\nv4.4.1\nImprovements:\n Update beacon interval from 5s to 10s\n\nv4.4.0\n- Ad per-ad metadata for Ad events\n- Fix strange views when a user seeks into an ad break\n\nv4.3.0\n- Add DRM Type and Error Context metadata fields\n\nv4.2.0\n- Add more Custom Dimensions\n\nv4.1.1\n- Fix Rendition::name misnamed\n\nv4.1.0\n- Add framerate, codec, and name to rendition properties\n\nv4.0.0\n- Due to Xcode 14, support for iOS and tvOS versions 9 and 10 have been removed. For more information see the last 'Deprecations' block in the release notes. This may result in a warning for client applications with deployment versions below iOS/tvOS 11\n\nv3.14.0\n- Split Views with >1 hour of inactivity into new views\n\nv3.11.0\n\n- Add inferred environment key support for users of Mux Data and Mux Video\n- Expose MUXSDKEndedEvent in the public headers\n\nv3.10.1\n\n- Add weak self/strong self in closure block to avoid any retain cycles\n\nv3.10.0\n\n- Capture experiments values from HLS Session Data\n\nv3.9.0\n\n- Add Experiment Fields\n- Log sent beacons in debug mode\n- Set Xcode build setting APPLICATION_EXTENSION_API_ONLY = YES\n\nv3.8.0\n\n- Add internal device detection properties\n- Add project binary specification file for Carthage support\n\nv3.7.0\n\n- Use synchronized to make query data objects thread safe.\n\nv3.6.0\n\n- Add transmission time and round trip time to beacon requests\n- Add player_live_edge_program_time\n- Add player_program_time\n\nv3.5.0\n\n- Allow overriding of viewer information (application name)\n- Add nullability specifiers\n- Custom beacon collection domains\n\nv3.4.0\n\n- Adds the MUXSDKCustomerData model\n- Adds support for setting custom dimensions\n\nv3.3.0\n\n- Automatically build statically linked frameworks\n- Remove dependency on UIKit\n\nv3.2.0\n\n- Add Swift PM support\n\nv3.1.0\n\n- Submits a new mux_embed field\n- Fixes bugs with video start-up time for midroll or postroll ads\n- Updates ad tracking to be more accurate\n- Tracks view_playing_time\n\nv3.0.3\n\n- No functional changes, just generating a new release on CocoaPods\n\nv3.0.2\n\n- Include linker flags that enable the framework to be built without support for modules.\n- Move instance variables out of headers\n\nv3.0.0\n\nThis release moves the build process to use XCFramework bundle type. For iOS, there are no changes required to your application code.\n\nIf you are using this SDK with TVOS the name of the module has changed (the Tv suffix is no longer needed):\n\nTVOS before 3.0:\n\n\n```obj-c\n@import MuxCoreTv;\n```\n\n\nTVOS after 3.0:\n\n\n```obj-c\n@import MuxCore;\n```\n\n\nv2.4.1\n\n- (bugfix) Works around an issue where a view with no pre-roll ads, but with midroll and/or postroll ads will cause Mux to update the TTFF value erroneously\n\nv3.0.0-beta.0\n\nThis release moves the build process to use XCFramework bundle type. For iOS, there are no changes required to your application code.\n\nIf you are using this SDK with TVOS the name of the module has changed (the Tv suffix is no longer needed):\n\nTVOS before 3.0:\n\n\n```obj-c\n@import MuxCoreTv;\n```\n\n\nTVOS after 3.0:\n\n\n```obj-c\n@import MuxCore;\n```\n\n\nv2.4.0\n\n Adds support for player_remote_played and view_session_id.\n In addition to existing options that are provided via the MUXSDKCustomerPlayerData and MUXSDKCustomerVideoData objects, there is now support for MUXSDKCustomerViewData. The view_session_id may be set onMUXSDKCustomerViewData.\n\nv2.3.0\n\n- Update build process for Xcode 12 to exclude arm_64 architectures when building for simulator. Before Xcode 12, xcodebuild never built arm_64 slices for the simulator. Now, it does (in preparation for Apple silicon). Because arm_64 slices now get built for the simulator, lipo errors out, because it can't have the same architecture for two different platforms (it already has arm_64 for the device platform). This is a temporary work around until a later major version release which will use the new XCFramework hotness\n- bump iOS deploy target to '9.0' in podspec and project build settings for Xcode 12 compatibility\n\nv2.2.0\n\n- bugfix: Removes erroneously committed logs from the compiled frameworks\n\nv2.2.1\n\n- bugfix - ignore scaling calculations when player or source width or height dimension is 0\n\nv2.2.0\n\n Add support for renditionchange events\n Add support for orientationchange events\n\nv2.1.3\n\n- bugfix for request metrics calculation. If we don't have responseStart, fallback to requestStart in order to calculate throughput\n\nv2.1.2\n\n- bugfix - Use monotonically increasing time in Objc client library. Avoids a bug if system time changes during a view.\n\nv2.1.1\n\n- Expose videoSourceUrl on MUXSDKCustomerVideoData. This allows a user to set the videoSourceUrl (along with their other VideoData, in which case any videoSourceUrl that is inferred from the player will be ignored.\n\nv2.1.0\n\n- Fix build process for Xcode 11\n- Make player_instance_id a full uuid-style string\n- Make sure to always send player_instance_id\n- Bump Mux API versions for new collectors/processors"
  },
  {
    "id": "30-_guides/developer/data-engagement-metric",
    "title": "Viewer Engagement",
    "path": "_guides/developer/data-engagement-metric.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/data-engagement-metric",
    "content": "<Image\n  alt=\"Viewer Engagement Dashboard\"\n  width={2092}\n  height={1686}\n  src=\"/docs/images/viewer-engagement-dashboard.png\"\n/>"
  },
  {
    "id": "31-_guides/developer/data-overall-viewer-experience-metric",
    "title": "Overall Viewer Experience",
    "path": "_guides/developer/data-overall-viewer-experience-metric.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/data-overall-viewer-experience-metric",
    "content": "<Image\n  alt=\"Overall Viewer Experience dashboard\"\n  width={1204}\n  height={940}\n  src=\"/docs/images/overall-viewer-experience-dashboard.png\"\n/>"
  },
  {
    "id": "32-_guides/developer/data-playback-success-metric",
    "title": "Playback Success",
    "path": "_guides/developer/data-playback-success-metric.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/data-playback-success-metric",
    "content": "<Image\n  alt=\"Playback Success\"\n  width={1189}\n  height={881}\n  src=\"/docs/images/playback-success-dashboard.png\"\n/>"
  },
  {
    "id": "33-_guides/developer/data-smoothness-metric",
    "title": "Smoothness",
    "path": "_guides/developer/data-smoothness-metric.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/data-smoothness-metric",
    "content": "<Image\n  alt=\"Smoothness Dashboard\"\n  width={1197}\n  height={958}\n  src=\"/docs/images/smoothness-dashboard.png\"\n/>"
  },
  {
    "id": "34-_guides/developer/data-startup-time-metric",
    "title": "Startup Time",
    "path": "_guides/developer/data-startup-time-metric.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/data-startup-time-metric",
    "content": "<Image\n  alt=\"Startup Time Dashboard\"\n  width={1204}\n  height={993}\n  src=\"/docs/images/startup-time-dashboard.png\"\n/>"
  },
  {
    "id": "35-_guides/developer/data-video-quality-metric",
    "title": "Video Quality",
    "path": "_guides/developer/data-video-quality-metric.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/data-video-quality-metric",
    "content": "<Image\n  alt=\"Video Quality Dashboard\"\n  width={2394}\n  height={1946}\n  src=\"/docs/images/video-quality-dashboard.png\"\n/>"
  },
  {
    "id": "36-_guides/developer/debug-live-stream-issues",
    "title": "Debug live stream issues",
    "path": "_guides/developer/debug-live-stream-issues.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/debug-live-stream-issues",
    "content": "The Live Stream Input Health dashboard is a real-time dashboard that provides visibility on how Mux receives your live stream from the encoder. When a sizable percentage of your viewers complain about their viewing experience or your configured Mux Data Alert fires, a good starting point for identifying the problem is understanding the live stream's health. The video below shows how to navigate to your Live Stream Input Health dashboard.\n\n<Image\n  src=\"/docs/images/navigate-to-live-stream-input-health.gif\"\n  width={1666}\n  height={1088}\n  alt=\"Navigate to live stream input health\"\n/>\n\nLet's first look at a healthy live stream in the dashboard.\n\n<Image\n  src=\"/docs/images/health-live-stream.png\"\n  width={2322}\n  height={724}\n  alt=\"Health live stream\"\n/>\n\nA few key points to notice from this graph that indicate this is a healthy live stream:\n\n Mux is receiving consistent frames per second. Receiving inconsistent frames per second can introduce video stuttering and sometimes cause playback interruptions for all your viewers.\n Consistent non-zero audio bitrate is important for uninterrupted listening. A good encoder always creates a constant non-zero bitrate even when no person is speaking, or no music is being played. A varying audio bitrate can result in a bad listening experience and sometimes a good indicator for Audio-Video sync problems.\n Like Audio, a consistent average video bitrate is equally important for a good viewing experience. A varying video bitrate does not necessarily cause a playback problem but could result in a bad viewing experience.\n   A low variance in the video bitrate typically means optimal network bandwidth availability and encoder hardware resource utilization.\n   A high variance in the video bitrate indicates that the encoder hardware cannot keep up with the encoding load. Try reducing the video bitrate and using a constant bitrate (CBR) for a more reliable live stream input. Alternatively, you can also switch to another encoder like OBS, Wirecast, etc.\n   An unstable/unreliable network bandwidth availability results in transient video bitrate drops, which can cause playback interruptions.\n\nNo actions required.\n\nNow let's look at a few examples of live stream issues and potential next steps for resolution.\n\nExample 1: High video bitrate variance\n\n<Image\n  src=\"/docs/images/unhealthy-live-stream-1.png\"\n  width={2322}\n  height={722}\n  alt=\"Unhealthy live stream high video bitrate variance\"\n/>\n\nBecause of the constant frames per second and audio bitrate this live stream looks good, but the high variance of video bitrate and drop in the average video bitrate mid-stream can impact the viewer experience.\n\nUse lower and constant video bitrate\n\nConfigure your encoder to use a lower video bitrate and a constant video bitrate. Recommended encoder settings are available here.\n\nExample 2: Intermittent loss\n\n<Image\n  src=\"/docs/images/unhealthy-live-stream-2.png\"\n  width={2322}\n  height={722}\n  alt=\"Unhealthy live stream intermittent loss\"\n/>\n\nMux is receiving mostly constant frames per second and audio/video bitrate. This indicates that when the encoder is connected the stream is healthy. However the small spikes as well as intermittent loss in receiving the live stream, indicates transient network bandwidth availability issues.\n\nTry switching to a more reliable network and/or stop other network bandwidth consuming services for the duration of the live stream.\n\nExample 3: Spiky audio and video bitrate\n\n<Image\n  src=\"/docs/images/unhealthy-live-stream-3.png\"\n  width={2340}\n  height={718}\n  alt=\"Unhealthy live stream spiky audio and video bitrate\"\n/>\n\nThere is a high variance in receiving audio and video bitrate in this example. Because connection never fully drops the network connection is probably not the problem in this one. More likely is that the encoder is unable to keep up at a fast enough pace to send consistent video and audio data. One cause of this is that the device running the computer might be running out of available CPU.\n\nConsider using any of these recommended encoders for your live stream.\n\nConfigure your encoder to use a lower video bitrate and a constant video bitrate. Recommended encoder settings are available here.\n\nExample 4: Spiky frame rate\n\n<Image\n  src=\"/docs/images/unhealthy-live-stream-4.png\"\n  width={2296}\n  height={728}\n  alt=\"Unhealthy live stream spiky frame rate\"\n/>\n\nThis is a good example of a very unhealthy live stream. There is high variance in the video bitrate and several instances of the frame rate dipping to nearly zero. The spiky video bitrate mid-stream indicates that the encoder is optimizing the video encoding based on the feed contents. This is not ideal for live streaming.\n\nTry switching to a more reliable network and/or stop other network bandwidth consuming services for the duration of the live stream.\n\nConfigure your encoder to use a constant video bitrate. Recommended encoder settings are available here.\n\nPlease note, this feature is only available to customers who have subscribed to this feature. Contact our Sales team if you would like more information.\n\nLive Stream Input Health data can be integrated with an Amazon Kinesis or Google Pub/Sub endpoint in your cloud account. Health and encoding metadata are sent to Kinesis or Pub/Sub as the events occur and are made available to retrieve from the stream with the same five second interval as the Dashboard.\n\nEach message is either a Live Stream input health update or an metadata update from the encoder. The data can be stored in your long-term storage for immediate display and historical reporting.\n\nThis method of access is most useful for customers who want to embed live stream health in a user-facing application feature or need to build an internal operational tool for stream reporting.\n\nSetting up a streaming export\nStreaming exports can be configured in the Streaming Exports settings in your Mux dashboard. See the setup guide for your platform for more information on setting up an export:\n-  Amazon Kinesis Data Streams\n-  Google Cloud Pub/Sub\n\nMessage Format\nMessages are formatted using Protobuf (proto2) encoding. Every message uses the live_stream_input_health.v1.LiveStreamInputHealth message type defined in the export Protobuf spec.\n\nThe protobuf definition for the Live Stream Input Health is available in the mux-protobuf repository. Please subscribe to this repository for updates to the protobuf definition.\n\nThere are two types of updates that can be specified, though new types may be added in the future. Each message contains one type of update:\n Encoder metadata sent by the RTMP encoder\n Stream Input Health data\n\nThe following are descriptions of the data provided by each type of update:\n\n```javascript\nRTMPMetadataEvent = {\n  // Unless otherwise specified, all the data contained in `video_track` and `audio_track` is as\n  // specified by the encoder (not as observed).\n  \"video_track\": {                           // Video track, present for AV streams\n      \"width\": 1280,                         // Width of the input video\n      \"data_rate\": 4000,                     // Kbps data rate of the video\n      \"codec_id\": \"avc1\",                    // Video codec\n      \"height\": 720,                         // Height of the input video\n      \"frame_rate\": 30                       // Number of frames per second\n  },\n  \"audio_track\": {                           // Audio track, present for AV and audio-only streams\n      \"sample_size\": 16,                     // Bits per audio sample\n      \"sample_rate\": 44100,                  // Sample rate\n      \"data_rate\": 128,                      // Kbps data rate of the audio\n      \"codec_id\": \"mp4a\",                    // Audio codec\n      \"channel_count\": 1                     // Number of audio channels\n  },\n\t\"encoder\": \"ffmpeg\",                       // The encoder used to transcode for the broadcast\n\n  \"live_stream_id\": \"uiwe7gZtIcuyYSCfjfpGjad02RPqN\", // The Mux Live Stream Id for live stream\n  \"asset_id\": \"hfye6sBqRmR8MRJZaWYq602X1rB0\"         // The Mux Asset Id for the asset where the input stream is stored\n}\n```\n\n\n\n```javascript\nHealthUpdateEvent = {\n  \"video_tracks\": [                        // Video tracks, present for AV streams\n    {\n      \"bytes_received\": 3155737,           // Number of video bytes received data during this interval\n      \"stream_start_ms\": 4979091,          // Timestamp of the first video frame in this interval, as measured in milliseconds since start of the stream\n      \"stream_end_ms\": 4985097,            // Timestamp of the last video frame in this interval, as measured in milliseconds since start of the stream\n      \"keyframes_received\": 3,             // Number of keyframes that occurred during this interval\n      \"total_frames_received\": 180         // Total number of video frames received during this interval\n    }\n  ],\n  \"audio_tracks\": [                        // Audio tracks, present for AV and audio-only streams\n    {\n      \"bytes_received\": 94864              // Number of audio bytes received from the encoder during this interval\n    }\n  ],\n  \"caption_tracks\": [                      // Caption tracks\n    {\n      \"bytes_received\": 12354,             // Number of captions bytes received from the encoder during this interval\n      \"channel_count\": 1                   // Number of captions channels that received data during this interval\n    }\n  ],\n\n  \"measurement_start_ms\": 1644313838000,       // Timestamp of the start of the interval in milliseconds since Unix epoc\n  \"measurement_end_ms\": 1644313838000,         // Timestamp of the end of the internval in milliseconds since Unix epoc\n\n  \"live_stream_id\": \"uiwe7gZtIcuyYSCfjfpGjad02RPqN\",   // The Mux Live Stream Id for live stream\n  \"asset_id\": \"hfye6sBqRmR8MRJZaWYq602X1rB0\",           // The Mux Asset Id for the asset where the input stream is stored\n  \"asn\": 25135,                            // The ASN number for the ingest IP address\n  \"asn_name\": \"VODAFONE_UK_ASN (AS2135)\"   // The friendly name associated with the ASN number\n}\n```\n\n\nUpdate Frequency\n Encoder metadata is sent when the RTMP stream connects to Mux. Some encoders also send metadata updates during the live stream.\n Live Stream Input Health updates occur every 5 seconds for each stream that is currently connected."
  },
  {
    "id": "37-_guides/developer/download-for-offline-editing",
    "title": "Download for offline editing",
    "path": "_guides/developer/download-for-offline-editing.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/download-for-offline-editing",
    "content": "Why download the master\n\nWhen a video is ingested into Mux we store a version of the video that's equivalent in quality to the original video, we call this the master. The max_resolution_tier of an asset will determine the master file's resolution e.g. a max_resolution_tier of 2160p will result in a 4K master file. All of the streamed versions of the video are created from the master, and the master itself is never streamed to a video player because it's not optimized for streaming.\n\nThere are a few common use cases where Mux may have the only copy of the original video:\n You're using Mux live streaming and the only copy is the recorded asset after the event\n You're using Mux's direct upload feature so Mux has the only copy\n You deleted the original version from your own cloud storage because Mux is already storing a high quality version for you\n\nWhen this is the case, there are a number of reasons you may want to retrieve the master version from Mux, including:\n Allowing users to download the video and edit it in a tool like Final Cut Pro\n Archiving the video for the future, for example if you're un-publishing (deleting) a video asset from Mux\n Moving your videos to another service\n\nEnabling master access will create a temporary URL to the master version as an MP4 file.\nYou can use this URL to download the video to your own hosting, or provide the URL to a user to download directly from Mux.\n\nThe URL will expire after 24 hours, but you can enable master access on any asset at any time.\n\n  The methods described here are available only via the Mux API; you won't find these features in the Mux Dashboard.\n\nEnable master access\n\nIf you want the master be available soon after a video is uploaded, use the master_access property when creating an asset.\n\n\n```json\n{\n  \"inputs\": [\n    {\n      \"url\": \"VIDEO_URL\"\n    }\n  ],\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"video_quality\": \"basic\",\n  \"master_access\": \"temporary\"\n}\n```\n\n\nYou can also add it afterward by updating the asset.\n\nEnable master access when a live stream finishes\n\nIf you want to download the recorded version of a live stream soon after the live stream is finished, use the master_access property in the new_asset_settings when creating the live stream.\n\n\n```json\n{\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"new_asset_settings\": {\n    \"playback_policies\": [\n      \"public\"\n    ],\n    \"video_quality\": \"basic\",\n    \"master_access\": \"temporary\"\n  }\n}\n```\n\n\nRetrieving the URL to the master\n\nAfter master access has been requested, a new object called master will exist on the asset details object.\n\n\n```json\n{\n  ...all asset details...\n  \"master_access\": \"temporary\",\n  \"master\": {\n    \"status\": \"preparing\"\n  }\n}\n```\n\n\nMaking the master available is an asynchronous process that happens after an Asset is ready, or in the case of a live streamed asset, after the live_stream_completed event. Because of this, the master object has a status property that gives the current state of the master, starting with preparing.\n\nIn most cases, the master will be available very quickly. When it's ready the status will be updated to ready, and a new url property will exist on the object. This is the URL you can use to download the master yourself, or to let a user download the master.\n\n\n```json\n{\n  ...all asset details...\n  \"master_access\": \"temporary\",\n  \"master\": {\n    \"status\": \"ready\",\n    \"url\": \"https://mezzanine.mux.com/ABC123/mezzanine.mp4?skid=foo&signature=bar\"\n  }\n}\n```\n\n\nCustomizing the filename\n\nThe filename of the downloaded file can be controlled by appending the download query parameter to the URL returned from the API, for example:\n\n\n```http\nhttps://mezzanine.mux.com/ABC123/mezzanine.mp4?skid=foo&signature=bar&download=desired_filename.mp4\n```\n\n\nThis will cause the browser to download the file with the name desired_filename.mp4 instead of the default name.\n\n  It is important that you do not modify the URL or query parameters returned from the API in any other way than to add the download parameter.\n\nWebhooks for master access\n\nYour application can be automatically updated with the status of master access for an asset through webhooks.\n\nThere are four related events you can receive.\n\n| Webhook       | Description   |\n| :------------ |:--------------|\n|video.asset.master.preparing | Received when master access is first requested |\n|video.asset.master.ready |Received when the URL to the master is available |\n|video.asset.master.deleted |Received if master access has been set to none via a PUT to the master-access endpoint |\n|video.asset.master.errored |Received if an unexpected error happens while making the master available |"
  },
  {
    "id": "38-_guides/developer/embed-videos-for-social-media",
    "title": "Embed videos for social media",
    "path": "_guides/developer/embed-videos-for-social-media.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/embed-videos-for-social-media",
    "content": "Introduction to Open Graph\n\nThe Open Graph protocol is initialized by using HTML meta tags in the\n```<head>```\n section of a webpage, allowing you to define objects\nfrom your webpage as thumbnails. These can be used in social media posts or appear in search results. Open Graph also helps search engines\nfind videos on your webpage that might be otherwise hidden due to JavaScript.\n\nHere is a list of Open Graph properties for video optimization:\n\n| Property        | Description                                            |\n| :---------------| :----------------------------------------------------- |\n|\n```og:type```\n         | The object’s type e.g video, audio                  |\n|\n```og:url```\n          | The URL of the webpage                                 |\n|\n```og:title```\n       | Title of the video                                     |\n|\n```og:description```\n  | Description of the video                               |\n|\n```og:image```\n        | Thumbnail of the video                                 |\n|\n```og:video```\n        | The URL of the video                                   |\n|\n```og:video:width```\n  | Width of the video in pixels                           |\n|\n```og:video:height```\n | Height of the video in pixels                          |\n|\n```og:site_name```\n    | The website name the contains the video                |\n\nObject types\n\nYou can also use sub types, for example, if your object type is video and you want to create a open graph card\nfor an episode or movie you can use video.episode or video.movie.\n\n\n```html\n<meta property=\"og:type\" content=\"video.episode\">\n<meta property=\"og:type\" content=\"video.movie\">\n<meta property=\"og:type\" content=\"video.tv_show\">\n```\n\n\nOptional meta tags\n\nUse additional properties to provide additional metadata about your object such as the actor and director.\n\n| Property        | Description                                         |\n| :----------- | :----------------------------------------------------- |\n|\n```video:actor```\n | profile array - Actors in the movie. |\n|\n```video:actor:role```\n | string - The role they played. |\n|\n```video:director```\n | profile array - Directors of the movie. |\n|\n```video:writer```\n | profile array - Writers of the movie. |\n|\n```video:duration```\n | integer >=1 - The movie's length in seconds. |\n|\n```video:release_date```\n | datetime - The date the movie was released. |\n|\n```video:tag```\n | string array - Tag words associated with this movie. |\n\nIntegrate the Open Graph meta tags\n\nTo add the Open Graph meta tags into your website, simply implement new meta tags in the\n```<head>```\n section of the webpage.\nBelow is an example of Open Graph tags:\n\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta property=\"og:title\" content=\"Mux Video\" />\n    <meta property=\"og:type\" content=\"video.episode\" />\n    <meta property=\"og:description\" content=\"MP4 video asset for Open Graph Cards\" />\n    <meta property=\"og:image\" content=\"https://image.mux.com/aYKMM7VxaD2InrbhrKlhi00V6R9EpRmQNmBJ10200AK02bE/thumbnail.png\" />\n    <meta property=\"og:video\" content=\"https://stream.mux.com/F9cP5Xgdcp7028hN4gQrOmlF62ZDHNloCTQQao8Pk00kk/medium.mp4\" />\n    <meta property=\"og:video:width\" content=\"350\">\n    <meta property=\"og:video:height\" content=\"200\">\n    <meta property=\"og:video:duration\" content=\"300\">\n    <meta property=\"og:url\" content=\"http://mux.com\">\n  </head>\n  <body>\n    <video\n      id=\"my-player\"\n      controls\n      style=\"width: 100%; max-width: 500px;\"\n    />\n  </body>\n</html>\n```\n\nCreating Twitter/X cards\n\nTwitter cards are implemented using meta tags, but unlike Open Graph cards, they use different property names.\n\nThere are four different types of cards to choose from which is defined in the meta tag property twitter:card:\n\n- photo card\n- player card\n- summary card\n- app card\n\nThe player card provides functionality to play external media files inside of Twitter. Below are the definitions of other Twitter meta tags you can use with the player card.\n\nTwitter/X meta tags\n\n| Property        | Description                                         |\n| :----------- | :----------------------------------------------------- |\n|\n```twitter:card```\n | Type of Twitter card e.g., \"player.\" |\n|\n```twitter:title```\n | The title of your content as it should appear in the card |\n|\n```twitter:site```\n | The Twitter @username the card should be attributed to |\n|\n```twitter:description```\n | Description of the content (optional) |\n|\n```twitter:player```\n | HTTPS URL to I-frame player; this must be a HTTPS URL which does not generate active mixed content warnings in a web browser (URL to the page hosting the player) |\n|\n```twitter:player:width```\n | Width of I-frame specified in twitter:player in pixels |\n|\n```twitter:player:height```\n | Height of I-frame specified in twitter:player in pixels |\n|\n```twitter:image```\n | Image to be displayed in place of the player on platforms that don’t support I-frame or inline players; you should make this image the same dimensions as your player |\n\nExample HTML\n\n\n```html\n<meta name=\"twitter:card\" content=\"player\" />\n<meta name=\"twitter:title\" content=\"Some great video\" />\n<meta name=\"twitter:site\" content=\"@twitter_username\">\n<meta name=\"twitter:description\" content=\"Great video by @twitter_username\" />\n<meta name=\"twitter:player\" content=\"https://link-to-a-videoplayer.com\" />\n<meta name=\"twitter:player:width\" content=\"360\" />\n<meta name=\"twitter:player:height\" content=\"200\" />\n<meta name=\"twitter:image\" content=\"https://link-to-a-image.com/image.jpg\" />\n```\n\n\nPreview your Open Graph cards\n\nYou can preview your Open Graph cards using any one of many services that allow you to simply enter\na URL that generates a preview.\n\nOne such service is Opengraph.xyz that allows you to not only preview\nwhat you have configured, but also helps you to generate more Open Graph meta tags.\n\nBelow is a preview of the example above in Opengraph.xyz"
  },
  {
    "id": "39-_guides/developer/enable-automatic-cdn-detection",
    "title": "Enable automatic CDN detection",
    "path": "_guides/developer/enable-automatic-cdn-detection.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/enable-automatic-cdn-detection",
    "content": "Mux has the capability to track each network request made by the player in order to expose network-level metrics such as throughput and latency measurements. In addition, Mux is able to auto-detect the CDN used to serve each manifest, segment, or fragment by inspecting certain response headers.  Enabling CDN auto-detection requires some minor configuration at each of your CDNs.\n\nPlayer SDK Integration\n\nMux currently supports automatic CDN detection for the following player integrations.\n\nWeb\n\n - HLS.js\n - Dash.js\n - Video.js\n - Shaka player\n\nAndroid\n - ExoPlayer\n - [AndroidX Media3] (/docs/guides/monitor-androidx-media3)\n\nSimply integrate the player SDK and each network request will be tracked.\n\nFor platforms or SDKs that do not support automatic CDN detection using response headers (e.g. iOS, Roku), you can configure your SDK to pass in a CDN value to the corresponding\nSDK key if the player is aware of which CDN is delivering content. Learn more in our [metadata guide](/docs//guides/make-your-data-actionable-with-metadata or in the relevant SDK documentation.\n\nCDN Configuration for automatic CDN detection\n\nIn order for Mux to automatically detect which CDN is serving the content to the player, you need to make a few configuration changes to each of your CDNs. These changes are necessary to expose two specific headers.\n\n| Header | Description |\n| --- | --- |\n| X-CDN | This is a custom header that you need to add to all responses from each of your CDNs. The value of this should be a name describing that specific CDN; you should lowercase the name and replace spaces with _s. For example: fastly, cloudfront, level3, etc. |\n| Access-Control-Expose-Headers | This should be set on each response, with the value being a comma-separated string of headers to expose to the client. At the least, you should set this to X-CDN. It is also suggested that you add other identifying headers that your CDN may use, such as X-Cache, X-Served-By, Via, or similar headers. More information on Access-Control-Expose-Headers, see here: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Expose-Headers. |\n\nMid-stream CDN switching and automatic CDN detection\n\nMid-stream CDN switching changes which CDN is used for content requests. If Mux is automatically detecting the CDN used for video delivery via network events, all detected CDN\nvalues used to deliver video content will be placed in the CDN Trace dimension. The CDN values will be placed in sequential order that they were detected over the course of\nview. A cdn_change event will also be created when the SDK detects that the detected CDN has been updated in the network event."
  },
  {
    "id": "40-_guides/developer/enable-static-mp4-renditions-using-mp4-support",
    "title": "Enable static MP4 renditions using `mp4_support` (Deprecated)",
    "path": "_guides/developer/enable-static-mp4-renditions-using-mp4-support.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/enable-static-mp4-renditions-using-mp4-support",
    "content": "This guide describes using the mp4_support method of creating MP4s. This method is now deprecated though it continues to function. For more information on migrating to the new, more flexible static_renditions API, please refer to enabling static mp4 renditions\n\nHow to enable MP4 support\n\nThere is no additional cost for creating and storing MP4 files for plus and premium quality level assets.\n\nFor basic quality level assets, we do charge for MP4 storage, but encoding is free.\n\nDelivery for MP4s has the same price-per-minute cost as HLS delivery.\n\nEnabling MP4 renditions when you create an asset\n\nYou can add MP4 support to an asset when creating an asset by including the \"mp4_support: \" parameter.\n\nThe supported options are:\n capped-1080p: Produces a single MP4 file with the video resolution up to 1080p.\n audio-only: Produces a single M4A (audio-only MP4) file for a video asset.\n audio-only,capped-1080p: Produces both M4A and MP4 files for assets with video and audio, only the MP4 file for video-only assets, or only the M4A file for audio-only assets.\n standard (deprecated). Depending on the source video resolution, produces up to three MP4 files with different levels of resolution. We strongly recommend using one of the previous options, depending on your use case.\n\nThe files produced by each mp4_support option depends on the source asset type:\n| mp4_support option | video asset | video-only asset | audio-only asset |\n| -------------------| ----------- | ---------------- | ---------------- |\n| capped-1080p | capped-1080p.mp4 | capped-1080p.mp4| audio.m4a |\n| audio-only | audio.m4a  | error | audio.m4a |\n| audio-only,capped-1080p | audio.m4a and capped-1080p.mp4 | capped-1080p.mp4 | audio.m4a |\n| standard | low.mp4, medium.mp4, high.mp4 | low.mp4, medium.mp4, high.mp4 | audio.m4a |\n\nThe standard option generates one or more renditions depending on your source video's resolution.\nA video qualifies for a rendition if either its width or height meets the minimum threshold for that tier, regardless of aspect ratio.\nOutput renditions will never exceed the source video's resolution.\n\n| Rendition | Minimum Resolution |\n| --------- | ------------------- |\n| low.mp4 | (always generated) |\n| medium.mp4 | 640x360 |\n| high.mp4 | 960x540 |\n\nHere's an example of creating an asset with mp4_support enabled using the capped-1080p option:\n\n\n```json\n// POST /video/v1/assets\n{\n  \"inputs\": [\n    {\n      \"url\": \"https://storage.googleapis.com/muxdemofiles/mux.mp4\"\n    }\n  ],\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"mp4_support\": \"capped-1080p\"\n}\n```\n\n\nEnable MP4 renditions after an asset has already been created\n\nYou can also add MP4 support retroactively by calling the update asset MP4 support API, as shown below.\n\n\n```json\n// PUT /video/v1/assets/{ASSET_ID}/mp4-support\n{\n  \"mp4_support\": \"capped-1080p\"\n}\n```\n\n\nIf you already have an asset with the standard option enabled and want to generate new static renditions with one of the capped-1080p, audio-only or audio-only,capped-1080p options, you need to make the following two update asset MP4 support API calls:\n\n1. Update request with the mp4_support option set to none to first delete the existing static renditions\n2. Update request with the mp4_support option set to one of the capped-1080p, audio-only, or audio-only,capped-1080p options\n\nEnable MP4 renditions for a direct upload\n\nTo enable MP4 support for direct upload, you need to specify the same mp4_support field within new_asset_settings, as shown below:\n\n\n```json\n// POST /video/v1/uploads\n{\n  \"cors_origin\": \"https://example.com/\",\n  \"new_asset_settings\": {\n    \"playback_policies\": [\n      \"public\"\n    ],\n    \"mp4_support\" : \"capped-1080p\"\n  }\n}\n```\n\n\nEnable MP4 renditions when a live stream finishes\n\nIf you want to enable MP4 support from the recorded version of a live stream soon after the live stream is finished, use the mp4_support property in the new_asset_settings when creating the live stream.\n\n\n```json\n// POST /video/v1/live-streams\n{\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"new_asset_settings\": {\n    \"playback_policies\": [\n      \"public\"\n    ],\n    \"mp4_support\": \"capped-1080p\"\n  }\n}\n```\n\n\nCreate the MP4 streaming URL\n\nAfter adding MP4 support you'll see an additional key on the asset object called static_renditions. This is the object that will contain the information about which MP4s are available.\n\nThe static_renditions.status parameter refers to the current status of processing the MP4s. MP4s take longer to create than our default HLS version of the video, so they will not be ready immediately when the asset status is ready. Instead they will be ready when the static_renditions.status is ready, and a webhook of video.asset.static_renditions.ready is fired.\n\n\n```json\n{\n  ...all asset details...\n  \"mp4_support\": \"capped-1080p\",\n  \"static_renditions\": {\n    \"status\": \"preparing\"\n  }\n}\n```\n\n\nWhen the static_renditions.status field is ready, you will see the details of the MP4s available in an array under the files key.  The example below shows the files for the audio-only,capped-1080 option:\n\n```json\n{\n  ...all asset details...\n  \"mp4_support\": \"capped-1080p\",\n  \"static_renditions\": {\n    \"status\": \"ready\",\n    \"files\": [\n      {\n        \"name\": \"audio.m4a\",\n        \"ext\": \"m4a\",\n        \"bitrate\":  {M4A_BITRATE},\n        \"filesize\":  {M4A_FILESIZE}\n      },\n      {\n        \"name\": \"capped-1080p.mp4\",\n        \"ext\": \"mp4\",\n        \"height\": {MP4_HEIGHT},\n        \"width\":  {MP4_WIDTH},\n        \"bitrate\":  {MP4_BITRATE},\n        \"filesize\":  {MP4_FILESIZE}\n      }\n    ]\n  }\n}\n```\n\n\nThe MP4 or M4A streaming URL is compiled using the playback ID and one of the static_renditions.\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}/{capped-1080p.mp4, audio.m4a}\n--\nex. https://stream.mux.com/abcd1234/capped-1080p.mp4\nex. https://stream.mux.com/abcd1234/audio.m4a\n```\n\n\nIf you want a browser to download the MP4 file rather than attempt to stream it, you can provide a file name for the MP4 to save it via the download query parameter:\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}/{MP4_FILE_NAME}?download={FILE_NAME}\n--\nex. https://stream.mux.com/abcd1234/capped-1080p.mp4?download=cats\n```\n\n\nFor the deprecated standard option, the file names will be low.mp4, medium.mp4, high.mp4.\n\nWebhooks\n\nYour application can be automatically updated with the status of MP4 downloads for an asset through webhooks.\n\nThere are four related events you can receive.\n\n| Webhook       | Description   |\n| :------------ |:--------------|\n|video.asset.static_renditions.preparing | Received when MP4 support is first requested |\n|video.asset.static_renditions.ready |Received when the MP4 URL(s) are available and ready for use |\n|video.asset.static_renditions.deleted |Received if MP4 support has been set to none via a PUT to the mp4-support endpoint |\n|video.asset.static_renditions.errored |Received if an unexpected error happens while making the MP4 URLs available |\n\n For an audio-only asset: All mp4_support options will only produce a single M4A audio.m4a file.\n For a video asset: The  audio-only or audio-only,capped-1080p mp4_support options will produce an audio.m4a file.\n* For a video-only asset: The audio-only,capped-1080p option will only produce a capped-1080p.mp4 file. MP4 generation will error for the  audio-only option.\n\nSigned URLs with MP4 video\n\nMux videos have two types of playback policy, public or signed. If your playback_id is signed, you will need to also sign requests made for MP4 URLs.\n\nYou can check out how to do that in our signed URLs guide.\n\nIf you run into any trouble signing MP4 requests, please reach out to Mux Support and we'll be able to help.\n\nDisable MP4 renditions\n\nTo disable MP4 support on an asset, you can use the update asset MP4 support APIs, setting mp4_support to none.\n\n\n```json\n// PUT /video/v1/assets/{ASSET_ID}/mp4-support\n{\n  \"mp4_support\": \"none\"\n}\n```"
  },
  {
    "id": "41-_guides/developer/enable-static-mp4-renditions",
    "title": "Use static MP4 and M4A renditions",
    "path": "_guides/developer/enable-static-mp4-renditions.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/enable-static-mp4-renditions",
    "content": "This guide covers using static_renditions to create MP4 files, which replaces the deprecated mp4_support method. While mp4_support continues to function, we recommend using static_renditions for all new implementations.\n\nFor details on the older method, see enabling static mp4 renditions using mp4_support.\n\nWhat are static MP4 and M4A renditions?\n\nStatic renditions are downloadable versions of your video assets in MPEG-4 video (.mp4) or audio (.m4a) format. These files are created alongside the default HLS streaming format and can be used for downloading or streaming the content.\n\nStatic renditions allow you to create downloadable files that can be used for:\n\n Supporting very old devices, like Android < v4.0 (Less than 1% of Android users)\n Supporting assets that are very short in duration (e.g., < 10s) on certain platforms\n Embedding a video in Open Graph cards for sharing on sites like Facebook and Twitter\n Downloading videos for offline viewing\n\nIt also allows users to download M4A audio files, which may be useful for:\n Feeding into transcription services\n Delivering a streamable audio-only file to an audio element\n Downloading an audio-only file, useful for things like podcasts\n\nIn the majority of other cases, you'll want to use our default HLS (.m3u8) format, which provides a better viewing experience by dynamically adjusting the quality level to the viewer's connection speed.\nThe HLS version of a video will also be ready sooner than the MP4 versions, if time-to-ready is important.\n\nHow video quality affects static renditions\n\nStatic renditions are created at the same quality level (Basic, Plus, or Premium) as your original Mux video, and will be the highest quality video rendition possible, a specific desired resolution, or an audio-only version. For videos with multiple versions at the highest resolution (which can happen with Premium quality), we'll use the highest quality version available.\n\nHow to enable static renditions\n\nThere are several points in an asset's lifecycle where you can enable static renditions. You can enable them when initially creating an asset, add them later to an existing asset, or configure them as part of a direct upload. The method you choose will depend on your workflow and when you determine you need the static renditions.\n\nDuring asset creation\n\nYou can add static renditions to an asset when creating an asset by including the \"static_renditions\": [] array parameter and specifying a { \"resolution\":  } object as an array element for each static rendition that should be created.\n\nThere two types of static renditions: standard and advanced. Standard static rendition MP4s provide the most common options for needed for generating static renditions: either the highest video rendition possible, or an audio-only copy of the content. Advanced static rendition MP4s allow you to specify the specific resolution of the static renditions that are generated. Standard static renditions incur a cost for the number of minutes stored and delivered. Advanced static renditions also incur a cost per minute of MP4s that are generated.\n\nStandard Static Rendition Options\n\nThe standard static rendtions options are:\n highest: Produces an MP4 file with the video resolution up to 4K (2160p).\n audio-only: Produces an M4A (audio-only MP4) file for a video asset.\n\nOne or both options can be specified.\n\n For an audio-only asset: The audio-only rendition option will produce an M4A file and highest is skipped.\n For a video-only asset: The highest rendition option will produce an MP4 file and audio-only is skipped.\n\nHere's an example of creating an asset with static_renditions specified using the highest and audio-only options:\n\n\n```json\n// POST /video/v1/assets\n{\n  \"inputs\": [\n    {\n      \"url\": \"https://storage.googleapis.com/muxdemofiles/mux.mp4\"\n    }\n  ],\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"static_renditions\" : [\n    {\n      \"resolution\" : \"highest\"\n    },\n    {\n      \"resolution\" : \"audio-only\"\n    }\n  ]\n}\n```\n\n\nAdvanced Static Rendition Options\n\nThe advanced supported resolutions are:\n 270p\n 360p\n 480p\n 540p\n 720p\n 1080p\n 1440p\n* 2160p\n\nMux will not upscale to produce MP4 renditions - renditions that would cause upscaling are “skipped”.\n\nNote that advanced explicit resolution static renditions cannot be mixed with the highest standard static rendition. However, they can be generated on the same asset as the audio-only rendition.\n\nHere's an example of creating an asset with static_renditions specified using the 720p, 480p, and audio-only options:\n\n\n```json\n// POST /video/v1/assets\n{\n  \"inputs\": [\n    {\n      \"url\": \"https://storage.googleapis.com/muxdemofiles/mux.mp4\"\n    }\n  ],\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"static_renditions\" : [\n    {\n      \"resolution\" : \"720p\"\n    },\n    {\n      \"resolution\" : \"480p\"\n    },\n    {\n      \"resolution\" : \"audio-only\"\n    }\n  ]\n}\n```\n\n\nAfter asset creation\n\nYou can add static renditions to existing assets retroactively by calling the create static rendition API, as shown below. The create static rendition API will need to be called for each static rendition you would like to add to the asset.\n\n\n```json\n// POST /video/v1/assets/{ASSET_ID}/static-renditions\n{\n  \"resolution\" : \"highest\"\n}\n```\n\n\nDuring direct upload\n\nTo enable static renditions for direct upload, you need to specify the same static_renditions field within new_asset_settings, as shown below:\n\n\n```json\n// POST /video/v1/uploads\n{\n  \"cors_origin\": \"https://example.com/\",\n  \"new_asset_settings\": {\n    \"playback_policies\": [\n      \"public\"\n    ],\n    \"static_renditions\" : [\n      {\n        \"resolution\" : \"highest\"\n      }\n    ]\n  }\n}\n```\n\n\nDuring live stream creation\n\nStatic renditions can be created from the recorded version of a live stream. This is useful if you want to create downloadable files from a live stream soon after the live stream is finished.\n\nIf you want to enable static renditions from the recorded version of a future live stream soon after the live stream is finished, use the static_renditions property in the new_asset_settings when creating the live stream.\n\n\n```json\n// POST /video/v1/live-streams\n{\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"new_asset_settings\": {\n    \"playback_policies\": [\n      \"public\"\n    ],\n    \"static_renditions\" : [\n      {\n        \"resolution\" : \"highest\"\n      }\n    ]\n  }\n}\n```\n\n\nAfter live stream creation\n\nTo update the static renditions that are configured to be created from the recorded version of a future live stream, use the update live stream static renditions API..\n\n\n```json\n// PUT /video/v1/live-streams/{LIVE_STREAM_ID}/new-asset-settings/static-renditions\n{\n  \"static_renditions\" : [\n    {\n      \"resolution\" : \"highest\"\n    },\n    {\n      \"resolution\" : \"audio-only\"\n    }\n  ]\n}\n```\n\n\nAccess static renditions\n\nAfter adding static renditions, you'll see an additional key on the asset object called static_renditions. This is the object that will contain the information about which static renditions are available.\n\n\n```json\n{\n  ...all asset details...\n  \"static_renditions\" : [\n    {\n      \"id\" : \"ABC123\",\n      \"type\" : \"standard\",\n      \"status\" : \"preparing\",\n      \"resolution\" : \"highest\",\n      \"name\" : \"highest.mp4\",\n      \"ext\":\"mp4\"\n    },\n    {\n      \"id\" : \"GHI678\",\n      \"type\" : \"standard\",\n      \"status\" : \"preparing\",\n      \"resolution\" : \"audio-only\",\n      \"name\" : \"audio.m4a\",\n      \"ext\":\"m4a\"\n    }\n  ]\n}\n```\n\n\nStatic renditions take longer to create than our default HLS version of the video, so they will not be ready immediately when the asset status is ready.\n\nThe static_renditions[].status parameter refers to the current status of processing for each of the static renditions. Instead each static rendition will be ready when its static_renditions[].status is ready, and a video.asset.static_rendition.ready webhook is fired.\n\nYou can build the streaming URL by combining the playback ID with the name of the static rendition. The URL follows this pattern:\n\n\n```html\nhttps://stream.mux.com/{PLAYBACK_ID}/{STATIC_RENDITION_NAME}\n```\n\n\nThe name field in each static rendition object (like highest.mp4 or audio.m4a) is what you'll use as the STATIC_RENDITION_NAME.\n\n\n```\nex. https://stream.mux.com/abcd1234/highest.mp4\nex. https://stream.mux.com/abcd1234/audio.m4a\n```\n\n\nIf you want a browser to download the MP4 or M4A file rather than attempt to stream it, you can provide a file name for the static rendition to save it via the download query parameter:\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}/{STATIC_RENDITION_NAME}?download={SAVED_FILE_NAME}\n```\n\n\nFor example, if you want to save the highest.mp4 file as cats.mp4, you can use the following URL:\n\n\n```\nex. https://stream.mux.com/abcd1234/highest.mp4?download=cats\n```\n\n\nAccessing static renditions of DRM enabled assets\nYou can not access static renditions using the playback ID of a drm playback policy. If you want to use static renditions you must add a public or signed advanced playback policy alongside the drm policy.\n\n\n```json\n// POST /video/v1/assets\n{\n  \"inputs\": [\n    {\n      \"url\": \"https://storage.googleapis.com/muxdemofiles/mux.mp4\"\n    }\n  ],\n  \"advanced_playback_policies\": [\n    {\n      \"policy\": \"drm\",\n      \"drm_configuration_id\": \"your-drm-configuration-id\"\n    },\n    {\n      \"policy\": \"signed\",\n    }\n  ],\n  \"static_renditions\": [\n    {\n      \"resolution\": \"highest\"\n    }\n  ],\n  \"video_quality\": \"plus\"\n}\n```\n\n\nRemove static renditions\n\nFrom an asset\n\nTo remove static renditions from an asset, you can use the delete static rendition API. You call the delete static rendition API with the id for each rendition to remove from the asset. The static rendition files will be deleted when they are removed from an asset.\n\n\n```json\n// DELETE /video/v1/asset/{ASSET_ID}/static-renditions/{STATIC_RENDITION_ID}\n```\n\n\nTo completely disable static renditions on an asset, delete all of the static renditions configured on the asset.\n\nFrom future live streams\n\nTo remove the static renditions that are configured to be created from the recorded version of a future live stream, use the delete live stream static renditions API.\n\n\n```javascript\n// DELETE /video/v1/live-streams/{LIVE_STREAM_ID}/new-asset-settings/static-renditions\n```\n\n\nWebhooks\n\nYour application can be automatically updated with the status of static renditions for an asset through webhooks.\n\nThere are five events you can receive, which can be fired for each individual static rendition.\n\n| Webhook       | Description   |\n| :------------ |:--------------|\n|video.asset.static_rendition.created |Emitted when a static rendition entry is created and the file is being prepared. |\n|video.asset.static_rendition.ready |Emitted when a static rendition is ready to be downloaded. |\n|video.asset.static_rendition.errored |Emitted when a static rendition fails to be generated. |\n|video.asset.static_rendition.skipped |Emitted when a static rendition is skipped because the requested resolution conflicts with the asset metadata. For example, specifying  audio-only for a video-only asset or  highest for an audio-only asset.\n|video.asset.static_rendition.deleted |Emitted when an individual static rendition is deleted. Note: This event is not emitted when the parent asset is deleted. |\n\nSigned static rendition URLs\n\nMux videos have two types of playback policy, public or signed. If your playback_id is signed, you will need to also sign requests made for MP4 URLs.\n\nYou can check out how to do that in our signed URLs guide.\n\nIf you run into any trouble signing requests, please reach out to Mux Support and we'll be able to help.\n\nMigrate from the deprecated mp4_support parameter\n\nPreviously, MP4 support was specified using the mp4_support parameter on an asset. This method continues to work though it has been deprecated and new functionality will use the static_renditions array.\n\nThe mp4_support parameter and the static_renditions array cannot be used at the same time on an asset.\n\nTo use the static_renditions array with assets that have MP4 support enabled using mp4_support, you need to first use the update asset MP4 support APIs, setting mp4_support to none to remove the mp4_support. Then you can create the static renditions individually as described above.\n\n\n```json\n// PUT /video/v1/assets/{ASSET_ID}/mp4-support\n{\n  \"mp4_support\": \"none\"\n}\n```\n\n\nSimilarly, the mp4_support parameter cannot be used if an asset has existing static_renditions specified. Delete the static renditions and the legacy mp4_support parameter can be enabled.\n\nPricing\n\nAdditional storage fees apply for assets that have static renditions enabled.\n\nStreaming of static renditions is charged at the same rate as HLS streaming.\n\nSee pricing documentation for full details"
  },
  {
    "id": "42-_guides/developer/ensure-data-privacy-compliance",
    "title": "Ensure privacy compliance with Mux Data",
    "path": "_guides/developer/ensure-data-privacy-compliance.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/ensure-data-privacy-compliance",
    "content": "Is Mux Data GDPR/CCPA/VPPA compliant and privacy preserving?\n\nMux takes privacy expectations seriously; we are compliant with the Video Privacy Protection Act (VPPA), California Consumer Privacy Act (CCPA), and General Data Protection Regulation (GDPR). We also make available a detailed Data Processing Addendum (DPA) that details the measures we've taken to achieve compliance. Mux has attested to our data privacy protections and has been certified under the Data Privacy Framework (DPF) program.\n\nMux works to ensure the privacy of viewers while providing development teams using Mux Data with the visibility they need to track audience engagement and their viewers' quality of experience. We don't believe that privacy and insights should be a trade-off for developers or video viewers.\n\nWe also want to ensure that the metadata that developers send to us is also properly anonymized in order to reduce the possibility of personally identifying a viewer with their activity. We strongly urge developers using Mux Data to provide an anonymized viewer id - using a non-personally identifiable id from a system only the customer has access to - that is meaningful to the developer but not to Mux as part of the view metadata.\n\nDo you track sensitive personally identifiable information?\n\nNo. Mux Data does not store information about the user such as email, name, or built-in device identifier (such as the Id for Analytics on iOS). For more information about the data we store - which doesn't include personal viewer information - please reference our Data Processing Addendum.\n\nDoes Mux have a Data Protection Addendum (DPA)?\n\nYes. The Mux Data Protection Addendum (DPA) is available at https://mux.com/dpa/ .\n\nDoes Mux participate in the Data Privacy Framework?\n\nYes, Mux participates in the EU-U.S. Data Privacy Framework (DPF), having self-certified our compliance. The DPF enables lawful transfers of personal data from the EU to the U.S. and is designed to ensure strong privacy protections. As a U.S.-based company handling data from international customers, our participation in the DPF underscores our commitment to data privacy and provides reassurance that we meet the standards required under EU law. You can find more detailed information and view Mux’s certification on the official DPF website at https://www.dataprivacyframework.gov/list .\n\nHow do I make a GDPR or CCPA data erasure request?\n\nMux Data does not knowingly store personally identifiable information, but GDPR and CCPA data erasure requests can be made to the gdpr@mux.com email. This email is monitored and you will receive a response from us that the viewers' data is being removed, if any can be identified.\n\nIs it possible to keep my viewers' IP address data in Europe?\n\nYes. Mux Data has an ingest location in the European Union (EU) that can be used for processing video views. The full IP addresses will only be processed at our location in Germany and the post-processed view data, including corresponding truncated IP address with the last octet removed, will be sent to the United States for aggregation and reporting. For more information on using the EU location, please reach out to your sales contact or email sales@mux.com.\n\nWhat information does Mux Data collect?\n\nMux Data collects non-personally identifiable information about the viewer experience that allows you to track engagement and the quality of experience for your audience.\n- IP address: We process a viewer's IP address in order to look up coarse location information and do bot detection. After processing, we pseudonymize the IP address by truncating it (to /24 for IPv4) and then we store only the pseudonymized value.\n- Geographic location and Autonomous Systems Number (ASN): We generate coarse location information at the country and state-level from the IP address, but we do not collect fine grained latitude/longitude information nor do we access geo-location features of mobile devices.\n- Viewer ID: We generate a unique, random identifier for a viewer that is used as a viewer id if none is provided by the developer implementing the Mux Data SDK. We do not associate these IDs with any activity other than the video views and we do not associate the id with any advertising profile data. Because we do not store identifiable information about viewers, we are not able to associate the video view history with a specific individual.\n- Device information: Information about the device that is used to access video playback, including model, device type, operating system, and browser used.\n- Details about video content watched: Metadata such as type of stream: live or VOD, video format, autoplay status, etc. A list of additional metadata is available for reference and most metadata is optional, to be set by the developer implementing Mux Data.\n\nHow long does Mux Data store viewership data?\n\nPseudonymized video view data is stored for up to 100 days and is then deleted from our systems.\n\nIs Mux Data appropriate for applications targeted to children?\n\nYes. Mux does not store personally identifiable data, use viewer data for advertising, or sell user identifiable data. The Mux Data and Mux Video SDKs can be used in applications and receive approval for children's apps on the app stores.\n\nWhat information is stored in Mux Data's HTTP cookies?\n\nBy default, Mux plugins for HTML5-based players use a cookie to track playback across subsequent page views in order to understand viewing sessions. This cookie includes information about the tracking of the viewer, such as an anonymized viewer ID that Mux generates for each user. None of this information is personally-identifiable, but you can disable the use of this cookie if desired. For example, if your site or application is targeted towards children under 13, you should disable the use of cookies. Please refer to the documentation for the specific Mux Data SDK you are using for info on how to disable cookies.\n\nThe cookie is set as a first party cookie on the domain of the website that is embedding the player and Mux Data SDK. For example, if the video player with Mux Data integrated is located on the page: http://example.com/demo.html the cookie will be set on the domain example.com. The cookies are only available on each individual customer's domain and cannot be used to track viewers across Mux customers.\n\nThe Mux Data cookie contains the following information:\n mux_viewer_id: a randomly generated viewer id that is used as the default anonymous Viewer ID.\n msn: random value used to decide if the viewer will be sampled (tracked) or not\n sid: randomly generated anonymous session id\n sst: the time the session started\n* sex: the time at which the session will expire\n\nDo I need to ask permission to track on iOS when I use a Mux Data SDK in my app?\n\nMux does not access the Identifier for Advertisers (IDFA) in any SDK, nor does it use viewer data for advertising or advertising efficiency measurement so the Apple AppTrackingTransparency (ATT) framework does not require a tracking permission request to use the Mux SDK.\n\nAs of version 2.4.2 of the Mux Data for AVPlayer SDK, the Identifier for Vendors (IDFV) is no longer used and the Mux Data SDK generates a random unique identifier on the device for default Viewer Id. We do not sell the identifier data or attempt to track users across Mux customers.\n\nAs of version 3.6.1 of the Mux Data for AVPlayer SDK and versions 4.7.1 and 5.0.1 of the Mux Data Objective-C Core SDK, a privacy manifest file that satisfies Apple’s requirements for third-party SDKs to outline privacy practices associated with their use. Customers who export data from Mux for additional processing may need to include additional privacy manifest entries with their application subject to their specific practices.\n\nDoes my app need to access a hardware id on Android when I use a Mux Data SDK?\n\nAs of version 2.4.1 of the Mux Data for ExoPlayer SDK, the Mux Data SDK generates a random unique identifier on the device for the default Viewer Id. We do not sell the identifier data or attempt to track users across Mux customers."
  },
  {
    "id": "43-_guides/developer/error-categorization",
    "title": "Focus your operational response with error categorization",
    "path": "_guides/developer/error-categorization.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/error-categorization",
    "content": "Error Categorization allows you to set custom error metadata to provide more actionable data. By using error categorization, you can distinguish between fatal errors or warnings and classify errors as playback failures or business exceptions. Errors categorized as warnings or as business exceptions are not considered playback failures, meaning these errors are excluded from alerting, giving a more accurate picture of the health of your system with less noise from alerts.\n\nPlayback Failure metrics (Playback Failure Percentage and Video Startup Playback Failure Percentage) only include fatal operational failures, while errors categorized as business exceptions and warnings are excluded. Errors that are categorized as a business exception will be included in the Playback Business Exception Percentage and Video Startup Business Exception Percentage metrics.\n\nThere are two dimensions, Playback Business Exception and Video Startup Business Exception, that are available as filters. Like the Playback Failure metrics, the Playback Failure and Video Startup Failure dimensions are not set for business exceptions and warnings.\n\nThe category information for errors can be set from the Mux Dashboard or from the individual player SDKs. You only need to set the categorization on an error in one place and information about the categories that are set in the Dashboard overrides the information set in the SDKs.\n\nCategorizing Errors is available from the Settings page and selecting the \"Categorize Errors\" tab. You must be an admin user to add a new error code categorization.\n\nIn the configuration page, you can categorize errors by code. Click the \"Add an error code\" button. In the dropdown, you will see the error codes your environment has encountered. Select from this dropdown and press \"Add\" to create a new categorization. By default, errors will have fatal error severity and will be tagged as playback failures.\n\nType into the filter box to search for specific error codes. If you are configuring an error code not previously seen in this environment, you can press \"Enter\" to create a new categorization.\n\nAttach severity and type to errors with Mux Data SDKs\n\nError Categorization can also be configured in the Mux Data SDKs in a similar method to other error metadata. If an error code is already configured in the data dashboard, the settings from the dashboard will take precedence.\n\nHTML5 Video Element and other web SDKs\n\nIn web-based SDKs, Error Categorizations can be set by passing through a function to the player. This function will set the relevant error metadata.\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context),\n    player_error_severity: translateSeverity(error.player_error_severity),\n    player_error_business_exception: translateBusinessException(error.player_error_business_exception)\n  };\n}\n\nmux.monitor('#my-player', {\n  debug: false,\n  errorTranslator: errorTranslator,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // ... additional metadata\n  }\n});\n```\n\n\nFor more guidance on using and configuring the error translator in web-based SDKs, please refer to the guide on monitoring the HTML5 video element.\n\nVersion 5.2.0 or later of the HTML5 Video Element monitor is necessary to support Error Categorization.\n\nAndroid\n\nError Categorization is supported for custom integrations that use the Core Java-based SDK v8.0.0 or later.\n\nThis is an example of how to categorize an error event to be a warning.\n\n\n```java\n    import com.mux.stats.sdk.core.events.EventBus;\n    import com.mux.stats.sdk.core.model.CustomerPlayerData;\n    import com.mux.stats.sdk.muxstats.IPlayerListener;\n    import com.mux.stats.sdk.events.playback.ErrorEvent;\n\n    public class PlayerListener extends EventBus implements IPlayerListener {\n    MuxStats muxStats;\n\n    // Call from the source of warning or player callback meant to trigger warning with parameters appropriate to your integration. Dispatches an error event that Mux will categorize as a warning by default\n    public void onPlaybackWarning(String errorCode, String errorMessage, String errorContext) {\n        PlayerData playerData = new PlayerData();\n        playerData.setErrorCode(errorCode);\n        playerData.setErrorMessage(errorMessage);\n\n        ErrorEvent errorEvent = new ErrorEvent(playerData, errorContext, ErrorSeverity.ErrorSeverityWarning);\n\n        dispatch(errorEvent);\n    }\n```\n\n\nFor more guidance and additional examples please refer to the guide on custom integrations in Java.\n\nObjective-C (iOS, tvOS, visionOS)\n\nError Categorization is supported when using the Mux AVPlayer integration v4.0.0 or later and with custom integrations that use the Core Objective-C-based SDK v5.0.0 or later.\n\nAVPlayer Integration\n\nThis is an example of how to categorize an error event to be a warning.\n\n\n```objc\n- (void)dispatchPlaybackWarningWithPlayerName:(NSString *)playerName\n                              playerErrorCode:(NSString *)playerErrorCode\n                           playerErrorMessage:(NSString *)playerErrorMessage\n                           playerErrorContext:(NSString *)playerErrorContext {\n  [MUXSDKStats dispatchError: playerErrorCode,\n                 withMessage: playerErrorMessage,\n                    severity: MUXSDKErrorSeverityWarning,\n                errorContext: playerErrorContext,\n                   forPlayer: playerName];\n}\n```\n\n\nFor more guidance and additional examples please refer to the AVPlayer monitoring guide.\n\nCustom Integrations\n\nThis is an example of how to categorize an error event to be a warning.\n\n\n```objc\n// Call this method from the source of the playback warning (such as an `AVPlayer` key-value property observer, for example) with parameters appropriate to your integration.\n- (void)dispatchPlaybackWarningWithPlayerName:(NSString *)playerName\n                              playerErrorCode:(NSString *)playerErrorCode\n                           playerErrorMessage:(NSString *)playerErrorMessage\n                           playerErrorContext:(NSString *)playerErrorContext\n                           playerPlayheadTime:(NSNumber *)playerPlayheadTime {\n  MUXSDKErrorEvent *errorEvent = [[MUXSDKErrorEvent alloc] initWithSeverity:MUXSDKErrorSeverityWarning\n                                                                    context:playerErrorContext];\n\n  // Configure any custom video or view data if necessary\n  MUXSDKPlayerData *playerData = [[MUXSDKPlayerData alloc] init];\n  [playerData setPlayerErrorCode:playerErrorCode];\n  [playerData setPlayerErrorMessagae:playerErrorMessage];\n  [playerData setPlayerPlayheadTime: playerPlayheadTime];\n  // ... repeat for any other `MUXSDKPlayerData` properties if they've changed\n\n  [MUXSDKCore dispatchEvent:errorEvent\n                  forPlayer:playerName];\n}\n```\n\n\nFor more guidance and additional examples please refer to the guide on custom integrations in Objective-C.\n\nRoku\n\nError categorization is supported when using an SDK v2.0.0 or later.\n\n\n```js\nmux.setField(\"error\", {\n  player_error_code: errorCode,\n  player_error_message: errorMessage,\n  player_error_context: errorContext,\n  player_error_severity: errorSeverity,\n  player_error_business_exception: isBusinessException\n})\n```\n\n\nThe possible values or errorSeverity are \"warning\" or \"fatal\".\n\nFor more guidance on using and configuring the Roku SDK, please refer to the guide on monitoring Roku."
  },
  {
    "id": "44-_guides/developer/example",
    "title": "Guide to writing guides",
    "path": "_guides/developer/example.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/example",
    "content": "Clone the repo muxinc/docs.mux.com. Follow instructions in the README to get the project runnig locally. After you have it running, you're ready to create a new guide.\n\nTo add a new guide, add an .mdx file /docs/_guides folder. You might find it handy to copy this file (docs/_guides/example.mdx) to the file you want to create.\n\nNext, add the guide to the sidebar. The sidebar sections are defined in the docs/_config folder.\n\nAny guide that is not in the sidebar will not display (unless it has its own file in the /app directory -- see spaces-to-livekit for example)\n\nCreate all your changes on a branch and submit a pull request. Vercel will build a deploy preview for your branch for easy sharing.\n\nWait, what's an .mdx file?\nGuides are written in MDX, meaning you can write in Markdown, and you can include shiny components.\n\nWe'll talk more about the shiny components in the rest of the guide. But first, some quick markdown pointers.\n\n_text written like this:_\n\n```md\nParagraphs are written in normal text like this.\nUse two line breaks to start a new paragraph.\n\nUse [markdown link syntax](https://www.mux.com).\nNormal markdown syntax like **bold** and _italic_, ordered lists and unordered lists should all work as expected.\n```\n\n\n_Will render like this:_\n\nParagraphs are written in normal text like this.\nUse two line breaks to start a new paragraph.\n\nUse markdown link syntax.\nNormal markdown syntax like bold and _italic_, ordered lists and unordered lists should all work as expected.\n\nWriting well\n\nGuides should be a holistic story around a problem a customer is trying to solve instead of just our features.\n\nUse the instructions in the image below, coupled with The Writing/voice guideline in notion so that our guides have a consistent tone.\n\n<Image\n  src=\"/docs/images/guide-for-guides.png\"\n  width={2254}\n  height={3016}\n  alt=\"Guide for writing guides\"\n/>\n\nYou should write good, descriptive headers. They're useful for users who are navigating your guide using the table of contents, and it's useful for search engines.\n\nIn some cases, though, the table of contents might not be enough. For example, if you have a guide that has a few, clear, discrete steps that are worth highlighting up front. In these cases, we use the steps frontmatter and the ` component.\n\n> This example guide uses steps and , if you're curious for an example\n\nTo use steps and , begin by defining steps in the frontmatter. For example:\n\n```yaml\nsteps:\n  - title: 1. Add a guide to /docs/_guides\n  - title: 2. Write a guide\n  - title: Decide whether to use `steps`\n    description: You should use good headers in your guide. In some situations, you may want to define those headers with the `<LinkedHeader />` component instead of markdown.\n  - title: Create code examples\n    topic: code\n```\n\nNotice three things about these steps:\n1. if you begin a step with a number, that number will be used in the steps' icon\n2. your step may optionally have a description\n3. your step my optionally have a custom icon. These icons are defined in docs/_components/guide-icons\n\nOnce your steps are defined in your frontmatter, you're ready to add them as a header. Add a  component in your document where you want the header to appear. Reference the step like this:  or .\n\nLinked headers will render as an .\n\nIf your header has a specific API reference associated with it you can pass in a prop for apiRef like this:\n\n\n```jsx\n<LinkedHeader\n  step={steps[2]}\n  apiRef={{ product: \"video\", slug: \"create-an-asset\" }}\n/>\n```\n\n\nAll embedded Video Walkthroughs will reference videos with subtitles that exist in the docs environment under the organization named \"Mux Marketing Videos\". You can add Video walkthrough videos to the docs environment by using the script create-video-walkthrough.js. To add new video walkthroughs to any .mdx file you first must add videos to this Mux environment, then add a reference to their playback ID to the guide header inside GuideVideoWalkthrough element.\n\nIf the video file does not have captions/text track already in it, that here are the steps you'll want to take to generate the video with captions (for accessibility):\n\n1. Get the public video file url for the raw video in [Dropbox > Mux > DevEx > Video Production > Renders (Release)]().\n\nThis process is moving away from Dropbox into Google Drive soon.\n\n2. Log in to the Mux Marketing Videos organization with an admin account and navigate to dashboard.mux.com to view all assets in the docs environment. If you don't have access to this organization, please request access by posting in the devex-dev channel in Slack.\n\n3. Upload your new video, but modify the API request so that it includes autogenerated_subtitles like so:\n\n\n```\n{\n  \"inputs\": [{\n    \"url\": \"https://your_public_url\",\n    \"generated_subtitles\": [{\n      \"language_code\": \"en\",\n      \"name\": \"default\"\n    }]\n  }],\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"max_resolution_tier\": \"2160p\"\n}\n```\n\n\n4. Get the PlaybackId from your new asset. In the Title / header section between \"---\" lines, of any .mdx guide, add the asset's Playback Id to src and thumbnailTime: 25:\n\n\n```\nvideoWalkthrough:\n  src: 01b2r4H6Pg8Q01NJZGppCu6X6tmfP6f6Jtp5oFZaETUwU\n  thumbnailTime: 25\n```\n\n\n6. Test video for usability\n\nInline\n\nFor inline code use backticks like this.\n\nCode Blocks\n\nLanguage\n\nFor blocks of code you can use triple backticks like this and specify the language.\n\nHere is a block of JSON code:\n\n\n```json\n{\n  \"id\": \"123456\"\n}\n```\n\n\nHere is a block of JavaScript code:\n\n\n```js\nimport Mux from \"@mux/mux-node\";\n```\n\n\nCode block props\nYou can also pass the following props to code blocks:\n- filename=file.js\n- withLineNumbers=true/false\n- highlight=1,3-5: blue highlight\n- add=1,3-5: green highlight (will replace line number with +)\n- remove=1,3-5: red highlight (will replace line number with -)\n- warning=1,3-5: yellow highlight\n- error=1,3-5: red highlight\n\nFor example...\n\n```\n```\njs filename=file.js withLineNumbers=false highlight=1,3-5\n\n```\nwill render...\n```\njs filename=file.js withLineNumbers=false highlight=1,3-5\n<Image\n  src=\"/docs/images/settings-access-token-env.png\"\n  width={1140}\n  height={374}\n  alt=\"Mux access token env\"\n/>\n\n```\n\n#### Transformer comments\nYou can also achieve some of the code block arguments with inline transformer comments. Whether you use code block arguments or transformer comments is up to you! Place the following in an inline comment to transform the line:\n- `[!code highlight]`: blue highlight\n- `[!code ++]`: green highlight (will replace line number with `+`)\n- `[!code --]`: red highlight (will replace line number with `-`)\n- `[!code error]`: yellow highlight\n- `[!code warning]`: red highlight\n\nFor example...\n\n```\ntext withLineNumbers=false\n\n```js\n// next.config.js\nconst { withNextVideo } = require('next-video/process') // [!code ++]\n\n/** @type {import('next').NextConfig} */\nconst nextConfig = {}\n\nmodule.exports = withNextVideo(nextConfig, { // [!code ++]\n  provider: 'vercel-blob', // [!code ++]\n}) // [!code ++]\n```\n\n\n...will render...\n\n\n```js\n// next.config.js\nconst { withNextVideo } = require('next-video/process') // [!code ++]\n\n/** @type {import('next').NextConfig} */\nconst nextConfig = {}\n\nmodule.exports = withNextVideo(nextConfig, { // [!code ++]\n  provider: 'vercel-blob', // [!code ++]\n}) // [!code ++]\n```\n\n\nThis works in any language that supports inline comments. For example...\n\n```html\n<p>highlight</p> <!-- [!code highlight] -->\n```\n\n\n```elixir\nIO.puts(\"highlight\") # [!code highlight]\n```\n\n\nMultiple Languages\n\nThis is an example of a complex code example that shows code from multiple languages.\n\nTake a look at the code_examples/video/example.js file to see all the code snippets in there.\n\nAfter creating that file and adding the code snippets in various languages, that file is imported into code_examples/index.ts. Once it is imported to there it can be used with the  component. You can re-order the languages in the example by using the exampleOrder attribute as a comma-separated list of languages. Finally,  by exporting a args object from the example file, you can use code block arguments like filename and highlight. You can also use the displayName argument to override what the example is named in the tabs, and lang to override what language is used to highlight the example.\n\n\n```jsx\n<CodeExamples product=\"video\" example=\"example\" exampleOrder=\"go,php,python\" />\n```\n\n\nInteractive Code Examples\n\nSimilar to multi-language code examples, interactive code examples are defined in the code_examples directory and imported in code_examples/index.ts. Interactive code examples can have the following exports:\n\n- options (default: {})\n- template (default: vanilla)\n- files (default: {})\n- customSetup (default {})\n\n> See code_examples/video-interactive/example.ts for an example\n\nOnce imported, interactive examples can be used with the  component.\n\n\n```jsx\n<InteractiveCodeExample product=\"video\" example=\"example\" />\n```\n\n\nFirst, add an image into the public/images directory. And then use the  component. Be sure to pass in the width, height and alt properties.\n\nThe width and height should be the natural dimensions of the source image. You can find this by the dimensions of the image on the filesystem. Our  component (next/image) will detect the aspect ratio and the container that the image is being rendered into and optimize the size automatically so you don't need to worry about optimizing the image ahead of time. Our  component will also make sure there is no layout shift when the page loads so you don't see any kind of awkward content shift on the initial load.\n\nYou can also include a caption prop. If you provide a caption it will be rendered below the image in italics and if the alt prop is omitted then the caption will be used as the alt.\n\nFor example, this code produces the image below\n\n\n```jsx\n<Image\n  src=\"/docs/images/settings-access-token-env.png\"\n  width={1140}\n  height={374}\n  alt=\"Mux access token env\"\n/>\n```\n\n\n<Image\n  src=\"/docs/images/settings-access-token-env.png\"\n  width={1140}\n  height={374}\n  alt=\"Mux access token env\"\n/>\n\nBy default images will stretch the full width, but sometimes that's too big, so you can constrain them to be small with the sm property with code like this. This works well for vertical images.\n\n\n```jsx\n<Image\n  sm\n  src=\"/docs/images/iOS-quality-options.png\"\n  width={750}\n  height={1334}\n  caption=\"iOS video app with video quality options\"\n/>\n```\n\n\n<Image\n  sm\n  src=\"/docs/images/iOS-quality-options.png\"\n  width={750}\n  height={1334}\n  caption=\"iOS video app with video quality options\"\n/>\n\nThe  component is used to highlight key pieces of information. It comes in 4 flavors:\n\n- info is used for informational kind of things. When something is \"good to know\" but no necessarily critical or dangerous.\n- warning is used for things that area \"gotcha\". Or something that might non-obvious or easy to overlook.\n- error is one level up from warning. This is something mission-critical that would result in an error or a potential security issue if it is overlooked.\n- success is a happy callout. A common case for this is when we want to lead the developer down a default path if they are unsure of something. For example \"Most applications use X. If you're unsure if you should use option A or option B, you probably want option A.\"\n\n\n```jsx\n<Callout type=\"info\">This is an example of an info callout</Callout>\n```\n\n\nThis is an example of an info callout\n\nUsing type=\"warning\" looks like this:\n\nThis is an example of warning callout\n\nUsing type=\"error\" looks like this:\n\nThe error callout looks a little more scary.\n\nYou can have multiple paragraphs\n\nAnd things like lists:\n\n- one\n- two\n- three\n\nMarkdown\nYou can optionally write markdown inside the callout. This is an example of adding a header to a type=\"success\" callout.\n\n\n```jsx\n<Callout type=\"success\">\n  **Hi, I'm bold!**\n</Callout>\n```\n\n\nAnd that will render the following:\n\n  Hi, I'm bold!\n\nTitles\n\nYou can optionally give a callout a title. That looks like this.\n\n\n```jsx\n<Callout type=\"success\" title=\"What a `title`\">\n  A callout with a title\n</Callout>\n```\n\n\nAnd that will render the following:\n\n  A callout with a title\n\nUse the  component as a wrapper and add up to 3  components as children.\n\n  <GuideCard\n    title=\"Configure Playback\"\n    description=\"Set up your iOS application, Android application or web application to start playing your Mux assets\"\n    links={[\n      { title: \"Web\", href: \"/docs/guides/play-your-videos\" },\n      { title: \"iOS\", href: \"/docs/guides/play-your-videos\" },\n      { title: \"Android\", href: \"/docs/guides/play-your-videos\" },\n    ]}\n  />\n  <GuideCard\n    title=\"Preview your video\"\n    description=\"Now that you have Mux assets, build rich experiences into your application by previewing your videos with Thumbnails and Storyboards\"\n  />\n  <GuideCard\n    title=\"Integrate Mux Data\"\n    description=\"Add the Mux Data SDK to your player and start collecting playback performance metrics.\"\n  />\n\nAdd multiple images in one place with . Define your images by passing them to the images prop:\n\n\n```mdx\n<MultiImage\n  images={[\n    { src: \"/docs/images/blurup-loading.png\", width: 409, height: 230 },\n    { src: \"/docs/images/blurup-loaded.png\", width: 409, height: 227 },\n  ]}\n/>\n```\n\n\nWe are a video company, are we not? If your video describes your whole guide, use videoWalkthrough in your frontmatter. If you just need something inline?  is your guy.\n\nIt takes all the normal Mux Player React props, as well as caption and sm (as described above for ).\n\nLink to API References with\nIf you have an inline-link to an API reference use  component like this link to assets.\n\nReuse snippets with\nGot some text you're using over and over across multiple guides you maintain? Use  instead!\n\nStart by adding a snippet to guides/snippets. Then, import it in config/snippets. Finally:\n\n```mdx\n<MdxImport snippet=\"yourSnippetName\" />\n```\n\n\nCurrently, our table of contents can't \"see\" into snippets. This is something I wanna fix but it's a hairy problem, so... um... sorry about that.\n\nDeclutter search and the TOC with\n\nWe often have these loooooooong changelogs at the ends of some of our guides. (Idk why we're not just using the docs changelog for those, but, I'm sure someone has a good explanation.)\n\nWe wrap these long changelogs in a  tag. That tag tells\n1. search to deprioritize these sections\n2. the table of contents to not include these sections\n\nAnd more\n\nLet's be honest. I probably forgot to update these docs with the latest component. See other guides for examples of components in action. And take a look at components/mdx` for a full list of components supported in our guiesguides."
  },
  {
    "id": "45-_guides/developer/export-amazon-kinesis-data-streams",
    "title": "Stream export data to an Amazon Kinesis data stream",
    "path": "_guides/developer/export-amazon-kinesis-data-streams.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/export-amazon-kinesis-data-streams",
    "content": "Streaming Exports are available on Mux Data Media plans. Learn more about Mux Data Plans or contact support.\n\nFor a detailed walkthrough of the Amazon Kinesis Data Streams setup process, see this blog post.\n\nIn order to stream exports from Mux to Amazon Kinesis Data Streams, you’ll need to set up a data stream in your AWS account. This guide covers the high-level steps required for setup.\n\n1. Add a new streaming export\n\nTo add a new streaming export, go to Settings > Streaming Exports in your Mux dashboard. From that tab, click New streaming export to open the configuration modal.\n\nSelect the type of data you want to export, the environment you want to send data from, the export format, and select Amazon Kinesis Data Streams as the service.\n\n2. Set up a data stream in Amazon Kinesis\n\nYou'll need to complete the following setup in your AWS account before you can create a new streaming export in Mux:\n1. Create an Amazon Kinesis data stream.\n2. Create an IAM role for Mux’s AWS account. To create the IAM role, you'll need Mux's AWS account ID and an external ID, which are shown in the configuration modal. See this AWS user guide for more information about how the external ID is used. When creating the role, choose \"AWS account\" for the Trusted entity type. Select \"Another AWS account\" and enter Mux’s AWS account ID. Check \"Require external ID\" and paste in the \"External ID\" that Mux provided to you in the configuration modal.\n3. Provide the IAM role you created with write access to your data stream. Here’s an example of an IAM policy that grants the necessary permissions (replace the resource with your data stream ARN):\n\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n          \"kinesis:ListShards\",\n          \"kinesis:PutRecord\",\n          \"kinesis:PutRecords\"\n      ],\n      \"Resource\": [\n        \"arn:aws:kinesis:{region}:{account-id}:stream/{stream-name}\"\n      ]\n    }\n  ]\n}\n```\n\n\n3. Finish setup in Mux\n\nIn the configuration modal, provide the data stream ARN and IAM role ARN. Make sure the values you provide match these formats:\n\n- Data stream ARN\narn:aws:kinesis:{region}:{account-id}:stream/{data-stream-name}\n- IAM role ARN\narn:aws:iam::{account-id}:role/{role-name}\n\nClick Enable export, and your streaming export will be activated immediately. We will start streaming views as soon as they're completed.\n\nProcess messages\n\nWith your export set up, you can begin consuming incoming messages. For more information on the message format and processing data, see the main Export raw Mux data guide."
  },
  {
    "id": "46-_guides/developer/export-google-cloud-pubsub",
    "title": "Stream export data to a Google Cloud Pub/Sub topic",
    "path": "_guides/developer/export-google-cloud-pubsub.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/export-google-cloud-pubsub",
    "content": "Streaming Exports are available on Mux Data Media plans. Learn more about Mux Data Plans or contact support.\n\nIn order to stream exports from Mux to a Pub/Sub topic, you'll need to set up a topic in your Google Cloud account. Mux will write data to the topic as it becomes available. This guide covers the high-level steps required for setup.\n\n1. Add a new streaming export\n\nTo add a new streaming export, go to Settings > Streaming Exports in your Mux dashboard. From that tab, click New streaming export to open the configuration modal.\n\nSelect the type of data you want to export, the environment you want to send data from, the export format, and select Google Cloud Pub/Sub as the service.\n\n2. Set up a topic in Google Cloud Pub/Sub\n\nYou'll need to complete the following setup in your Google Cloud account before you can create a new streaming export in Mux:\n1. (Optional) If you want to use a schema with your Pub/Sub topic, you can create one using the Protobuf spec for the data you are exporting, which is available in the mux-protobuf repository.\n2. Create a Pub/Sub topic. If you're creating a topic with a schema, set the message encoding to Binary.\n3. Add the Mux service account to the topic as a Principal with the Pub/Sub Publisher role. The Mux service account is shown in the configuration modal.\n\n3. Finish setup in Mux\n\nIn the configuration modal, provide the Pub/Sub topic name. This should be the full topic name, including the project ID, and match the format projects/{project-id}/topics/{topic-id}.\n\nClick Enable export, and your streaming export will be activated immediately. We will start streaming data as soon as it becomes available.\n\nProcess messages\n\nWith your export set up, you can begin consuming incoming messages. For more information on the message format and processing data, see the main Export raw Mux data guide."
  },
  {
    "id": "47-_guides/developer/export-monitoring-data",
    "title": "Export Monitoring data for integration",
    "path": "_guides/developer/export-monitoring-data.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/export-monitoring-data",
    "content": "The Monitoring Samples Stream is only available on Mux Custom Media plans. Learn more about Mux Data Plans or contact support.\n\nMux provides a mechanism for customers to subscribe to a near-realtime, video view-level data stream of events and measurements related to the quality of service for customers with a Mux Data integration.\n\nThis can be used to identify service-level problems, such as widespread rebuffering or playback failures. It can also be used to integrate Mux data with platforms for multi-CDN switching platform, alerting, or constructing your own version of the Mux Data Monitoring dashboard.\n\nA single Monitoring Samples payload may contain multiple samples. Each sample corresponds to a single active video view, with a different view id per sample. The sample can contain multiple records, where each record contains metrics for a point in time for the video view. A record specifies a time period and metrics measured over that time period. All metrics inside a single record will apply to the time range implied by the start timestamp field plus the duration_ms field. If the duration field is zero, the record includes instantaneous metrics. A record MUST contain at least one metric.\n\nSTART_LATENCY_MS\nAlso known as Time To First Frame (TTFF). This is Mux’s Video Startup Time which measures the time that the viewer waits for the video to play after the page is loaded and the player is ready.\n\nEXIT_BEFORE_VIDEO_START\nInstantaneous event metric that is sent when a playback drop is detected. This is sent when Mux has detected an intent to play but playback never begins. Inherently has a delay (up to 1 minute) while waiting to detect play start. The value field contains the playhead time of the player at the time of exit, in milliseconds, typically this value is 0 for videos starting from the beginning. This is NOT sent when the playback is halted due to a PLAYBACK_ERROR.\n\nWATCH_DURATION_MS\nWatch Duration is the amount of time in millisecond that viewers spend attempting to watch a video. This includes all time spent waiting for video to load, including rebuffering and seeking. It does not include time spent paused.\n\nSEEK_LATENCY_MS\nThe Seek Latency metric measures the average amount of time that viewers wait for the video to start playing again after seeking to a new time. Seeking is any time the player is asked to jump backward or forward to a new time in the video, outside of normal playback.\n\nREBUFFER_DURATION_MS\nRebuffer Duration is the amount of time in milliseconds that viewers spend rebuffering during the record window.\n\nREBUFFER_COUNT\nRebuffer Count is the number of independent rebuffer events encountered over the record time window.\n\nPLAYBACK_ERROR\nInstantaneous event metric that is sent when playback has failed due to a fatal technical error. The value is the player playhead timestamp in milliseconds when the error occurred. Non-fatal technical errors and business errors are not included in the Monitoring stream.\n\nMux Data supports streaming the Monitoring Samples to an Amazon Kinesis Data Stream in your cloud account. Monitoring data is sent to the configured destination each 30 second interval.\n\nThe samples stream data can be stored in your long-term storage for processing and aggregation. This method of access is most useful for customers who want real-time updates of the current performance that can be used for aggregations that inform real-time CDN switching, custom alerting, or internal NOC tools.\n\nSetting up a Monitoring Samples stream\nMonitoring Samples streams are enabled by working with the Mux team; they are not currently configured in the Streaming Exports settings in your Mux dashboard. Generally, the steps for configuring realtime sample exports are as follows:\n- Mux will work with the customer to generate the AWS account details.\n- The customer will create the destination and security artifacts in AWS.\n- Send the AWS ARNs to Mux.\n- Mux enables real-time sample exports to the customer Kinesis stream in production & staging.\n\nFor more information on setting up AWS Kinesis, refer to the Amazon Kinesis Data Streams setup guide for more information on setting up an export.\n\nMessage format\nMessages are in either JSON format or Protobuf (proto2) encoding. You can choose between the two formats when setting up the data stream with Mux support.\n\nFor Protobuf encoding, every message uses the com.mux.realtime.Samples message type defined in the export Protobuf spec, which is available in the mux-protobuf repository. Use the latest Protobuf spec when creating schemas or generating code.\n\nThe protobuf definition for the Monitoring Samples stream is available in the mux-protobuf repository. Please subscribe to this repository for updates to the protobuf definition.\n\nThe JSON format payload contains identical fields as the protobuf-encoded format.\n\nBackward compatibility\n\nThe schema provided by Mux Data is backward compatible, meaning that each schema version guarantees that it will still work upon future upgrades. Customers do not need to worry about breaking changes.\n\nWhen to upgrade the schema?\n\nWhen Mux adds new fields or metrics to the Monitoring Samples stream, we will upgrade the schema version. Without taking any actions, new fields will be automatically included in the data stream. For JSON formatted data, the new fields will be included in the data objects as they are added to the stream. For proto encoded streams, the new fields will be available once you upgrade to the latest proto definition."
  },
  {
    "id": "48-_guides/developer/export-raw-video-view-data",
    "title": "Export raw video view data",
    "path": "_guides/developer/export-raw-video-view-data.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/export-raw-video-view-data",
    "content": "View data can be exported from Mux Data for aggregation and reporting in your data infrastructure. Views are available individually using the Views API or in bulk with the export methods: daily CSV exports or streaming exports.\n\nFull data exports are available via the Exports API. This API is available for Mux Data customers on Media plans.\n\nUse this API to get a list of CSV files available for download. Files are available to download for seven days after they are generated. Each CSV file is a single day of data and includes every single dimension collected by Mux, for each single video view. The table below details each of these data fields.\n\nThe Versions column indicates what fields are included in each version. Newer export versions will include the latest columns available. Some columns may be empty based on the features enabled. From version 2 onward, fields are sorted in alphabetical order. Older versions of the export may have fields in a different order, please refer to the export file for the most accurate ordering. Please contact support to change the export version that is generated.\n\nWe strongly suggest you build the file import to use the field names rather than ordinal order so additional fields can be added to the file without causing an error.\n\nStreaming Exports are available on Mux Data Media plans. Learn more about Mux Data Plans or contact support.\n\nMux Data supports streaming exports of video views to an Amazon Kinesis Data Stream or Google Cloud Pub/Sub topic in your cloud account. Views are sent to Kinesis or Pub/Sub as they complete and are made available to retrieve from the stream within about one minute after the view ends.\n\nEach message is a single view, with all of the metadata and metrics, and the event timeline for the view. The view data can be stored in your long-term storage for aggregation and reporting.\n\nThis method of access is most useful for customers who want to update metrics on a rolling basis throughout the day or are embedding metrics in a user-facing application feature and need faster updates than once per day.\n\nSetting up a streaming export\nStreaming exports can be configured in the Streaming Exports settings in your Mux dashboard. See the setup guide for your platform for more information on setting up an export:\n-  Amazon Kinesis Data Streams\n-  Google Cloud Pub/Sub\n\nMessage format\nMessages are in either JSON format or Protobuf (proto2) encoding. You can choose between the two formats when setting up the streaming export in the Mux Dashboard -> Settings -> Streaming Export -> New streaming export page.\n\nFor Protobuf encoding, every message uses the VideoView message type defined in the export Protobuf spec, which is available in the mux-protobuf repository. Use the latest Protobuf spec when creating schemas or generating code.\n\nThe fields in the Protobuf definition match those used in the latest version of the Exports API. The available fields are noted in the table below.\n\nView handling\nA view can be updated after it has been exported. This will be expressed with a record of the latest version of the view being emitted to the stream. When processing views, make sure you're able to handle multiple or duplicate records for each view ID (view_id). The view_id can be used as a unique primary key for each view record.\n\nMux API Value: field name in the CSV file or streaming export\n\nUnit: unit of the field, such as text, percentage, or bits per second. Note that all units of type Time are represented as timestamps in UTC.\n\nType:\n- Dimension: metadata about the view\n- Metric: metrics calculated by Mux\n- Score: score calculated by Mux\n\nVersions: export version in which the fields are included\n\n| Mux API Value | Unit | Type | Definition | Versions |\n|---------------|------|------|------------|----------|\n|asn |Integer |Dim. | Autonomous System Number uniquely identifying each network| v1+ |\n|asset_id |Text |Dim. | If Mux Video is used, the Asset Id of the video.| v4+ |\n|audio_codec |Text |Dim. | The codec of the audio that played during the view. | v13+ |\n|browser |Text |Dim.| Browser used for the video view (Safari, Chrome, etc.).| v2+ |\n|browser (viewer_application_name) |Text |Dim.| Deprecated - see browser| v1 |\n|browser_version |Version |Dim. | Browser version (e.g. 66.0.3359.158).| v2+ |\n|browser_version (viewer_application_version) |Version |Dim. | Deprecated - see browser_version (viewer_application_version)| v1 |\n|cdn |Text |Dim. | CDN delivering the video view, either determined by response header auto-detection or provided as video_cdn.| v1+ |\n|city |Text |Dim. | City of the viewer.| v1+ |\n|client_application_name |Text |Dim. | Name of the customer application that the viewer is using to watch the content. e.g 'OurBrand iOS App'. | v13+ |\n|client_application_version |Text |Dim. | Version of the customer application that the viewer is using to view the content. | v13+ |\n|continent_code |ISO Code |Dim. | 2-letter ISO code identifying the Continent of the viewer (e.g. NA, EU).| v1+ |\n|country |ISO Code |Dim. | 2-letter Country Code.| v2+ |\n|country (country_code) |ISO Code |Dim. | Deprecated - see country| v1 |\n|country_name |Text |Dim. | Country of the viewer.| v1+ |\n|custom_1 |Text |Dim. | Customer-defined metadata.| v2+ |\n|custom_2 |Text |Dim. | Customer-defined metadata.| v2+ |\n|custom_3 |Text |Dim. | Customer-defined metadata.| v2+ |\n|custom_4 |Text |Dim. | Customer-defined metadata.| v2+ |\n|custom_5 |Text |Dim. | Customer-defined metadata.| v2+ |\n|custom_6 |Text |Dim. | Customer-defined metadata.| v5+ |\n|custom_7 |Text |Dim. | Customer-defined metadata.| v5+ |\n|custom_8 |Text |Dim. | Customer-defined metadata.| v5+ |\n|custom_9 |Text |Dim. | Customer-defined metadata.| v5+ |\n|custom_10 |Text |Dim. | Customer-defined metadata.| v5+ |\n|environment_id|Unique ID |Dim. | Mux Environment ID, linked with a specific environment| v4+ |\n|error_type |Unique ID |Dim. | Mux-internal ID used to categorize errors.| v2+ |\n|error_type (error_type_id) |Unique ID |Dim. | Deprecated - see error_type| v1 |\n|exit_before_video_start |Boolean |Metric | Identifies when a viewer abandons the video because it is taking too long to load.| v1+ |\n|experiment_name |Text |Dim. | A/B Testing:  use this field to separate views into different experiments.| v1+ |\n|isp |Text |Dim. | Unused| v1+ |\n|latitude |Degrees |Dim. | Latitude of the viewer, truncated to 1 decimal place.| v1+ |\n|live_stream_id |Text |Dim. | If Mux Video is used, the Live Stream Id of the video.| v4+ |\n|live_stream_latency |Integer |Metric | Live Stream Latency measuring the average time from ingest to display for the view.| v4+ |\n|longitude |Degrees |Dim. | Longitude of the viewer, truncated to one decimal place.| v1+ |\n|max_downscale_percentage | Percentage | Metric | Maximum Downscale Percentage at any point in time during a video view.| v2+ |\n|max_downscale_percentage (view_max_downscale_percentage) | Percentage | Metric | Deprecated - see max_downscale_percentage| v1 |\n|max_upscale_percentage | Percentage | Metric |  Maximum Upscale Percentage at any point in time during a video view.| v2+ |\n|max_upscale_percentage (view_max_upscale_percentage) | Percentage | Metric | Deprecated - see max_upscale_percentage| v1 |\n|metro |Text |Dim. | Unused| v1+ |\n|mux_api_version | Text|Dim. | Ignore | v1+ |\n|mux_embed_version |Dim. |Dim. | Internal version of Mux Core SDK. Ignore| v1+ |\n|mux_viewer_id |Unique ID |Dim. | A Mux Internal ID representing the viewer who is watching the stream.| v1+ |\n|operating_system |Text |Dim. | Operating System (iOS, Windows, etc.).| v2+ |\n|operating_system (viewer_os_family) |Text |Dim. | Deprecated - see operating_system| v1 |\n|operating_system_version |Version |Dim. | Operating System version (e.g. 10.15).| v2 |\n|operating_system_version (viewer_os_version) |Version |Dim. | Deprecated - see operating_system_version| v1 |\n|page_load_time |Milliseconds |Metric | Measures the time from the initial user request for a page to the time when the video player is first initialized| v1+ |\n|page_type |Text |Dim. | Provides the context of the page for more specific analysis. Values include watchpage or iframe.| v1+ |\n|page_url |URL |Dim. | Page URL| v1+ |\n|platform_description |Text |Dim. | Unused| v1+ |\n|playback_id |Text |Dim. | If Mux Video is used, the Playback Id of the video.| v4+ |\n|playback_business_exception_error_type_id |Unique ID |Dim. | An ID value that is present when a playback business exception occurs | v9+ |\n|playback_failure_error_type_id |Unique ID |Dim. | An ID value that is present when a playback failure occurs | v9+ |\n|playback_success_score |Decimal |Dim. | Playback Success Score| v2+ |\n|player_autoplay |Boolean |Dim. | Indicates whether the player autoplayed the video or not| v1+ |\n|player_captions_enabled |Boolean |Dim. | Boolean indicating if the player used captions at any time during the view. | v13+ |\n|player_error_code |String |Dim. | An error code that represents a fatal error (one resulting in playback failure). Often an integer, but implementation-dependent.| v1+ |\n|player_error_context |Text |Dim. | Error instance-specific information such as stack trace or segment number.| v5+ |\n|player_error_message |Text |Dim. | Message sent by the player when an error has been fired up (associated with an error code)| v1+ |\n|player_height |Integer |Dim. | Height of the player as displayed in page, in pixels| v1+ |\n|player_instance_id |Unique ID |Dim. | Identifies the instance of the Player class that is created when a video is initialized| v1+ |\n|player_language |Text |Dim. | Player's text language| v1+ |\n|player_load_time |Milliseconds |Metric | Deprecated - see player_startup_time)| v1+ |\n|player_mux_plugin_name |Text |Dim. | Mux Integration Plugin name (e.g. mux-player)| v1+ |\n|player_mux_plugin_version |Version |Dim. | Mux Integration Plugin version (e.g. 2.2.0)| v2+ |\n|player_name |Text |Dim. | Identifies different configurations or types of players around your site or application (e.g. My Player)| v1+ |\n|player_pip_enabled |Boolean |Dim. | Boolean indicating if the player used Picture in Picture at any time during the view. | v13+ |\n|player_poster|URL| Dim. | The image shown as the pre-visualization before play | v1+ |\n|player_preload |Boolean |Dim. | Specifies if the player was configured to load the video when the page loads.| v1+ |\n|player_remote_played |Boolean |Dim. | Specify from the SDK if the video is remote played to AirPlay or Chromecast.| v2+ |\n|player_software |Text |Dim. | Player Software being used to play the Video (e.g. Video.js, JW Player, etc.)| v1+ |\n|player_software_version |Text |Dim. | Player Software Version (e.g. 2.45.5)| v1+ |\n|player_source_domain |Text |Dim. | Video Source Domain (e.g. myvideostreams.com)| v1+ |\n|player_source_duration |Milliseconds |Dim. | Video Source Duration| v1+ |\n|player_source_height |Integer |Dim. | Height of the source video being sent to the player, in pixels| v1+ |\n|player_source_stream_type |Text |Dim. | Unused| v1+ |\n|player_source_url |URL |Dim. | Video Source URL| v1+ |\n|player_source_width | Integer | Dim. | Width of the source video being as seen by the player | v1+ |\n|player_startup_time |Milliseconds |Metric | Measures the time from when the player is first initialized in the page to when it is ready to receive further instructions.| v1+ |\n|player_version |Text |Dim. | As you make changes to your player you can compare how new versions of your player perform. Set in combination with player_name (e.g. 1.2.0) | v1+ |\n|player_view_count |Integer |Dim. | View Count - equal to 1 in Full Exports (1 line = 1 video view)| v1+ |\n|player_width |Integer |Dim. | Width of the player as displayed in page, in pixels| v1+ |\n|property_id |Unique ID |Dim. | Mux Property ID, linked with a specific environment. Deprecated, please use environment_id. | v1+ |\n|rebuffer_count |Integer |Metric | Number of rebuffering events that happen during the video view. | v2+ |\n|rebuffer_count (buffering_count) |Integer |Metric | Deprecated - see rebuffer_count | v1 |\n|rebuffer_duration |Milliseconds |Metric | Amount of time in milliseconds that viewers wait for rebuffering per video view. | v2+ |\n|rebuffer_duration (buffering_duration) |Milliseconds |Metric | Deprecated - see rebuffer_duration | v1 |\n|rebuffer_frequency |Events per millisecond |Metric | Measures how often rebuffering events happen. | v2+ |\n|rebuffer_frequency (buffering_rate) |Events per millisecond |Metric | Deprecated - see rebuffer_frequency | v1 |\n|rebuffer_percentage |Percentage |Metric | Volume of rebuffering that is occurring across the view| v1+ |\n|region |Text |Dim. | Region of the viewer| v1+ |\n|session_id |Unique ID |Dim. | Mux Session ID tracking a viewer's session| v1+ |\n|smoothness_score |Decimal |Score | Smoothness Score| v2+ |\n|source_hostname |Text |Dim. | Video Hostname (e.g. media.myvideos.com).| v2+ |\n|source_hostname (player_source_host_name) |Text |Dim. | Deprecated - see source_hostname| v1 |\n|source_type |Text |Dim. | Format of the source, as determined by the player. E.g. application/dash+xml, x-application/mpegUrl, mp4, etc.| v2+ |\n|source_type (player_source_type) |Text |Dim. | Deprecated - see source_type| v1 |\n|startup_time_score |Decimal |Score | Startup Time Score| v2+ |\n|stream_type |Text |Dim. | Type of stream (e.g. live or on-demand).| v2+ |\n|stream_type (video_stream_type) |Text |Dim. | Deprecated - see stream_type| v1 |\n|sub_property_id |Text |Dim. | Sub Property Id| v2+ |\n|time_to_first_frame |Milliseconds | Metric | Deprecated - see video_startup_time| v1 |\n|used_fullscreen |Boolean |Dim. | Indicates whether the viewer used full screen to watch the video.| v1+ |\n|video_affiliate |Text |Dim. | Affiliate station that the viewer is watching or associated with the viewer. | v13+ |\n|video_brand |Text |Dim. | Brand associated with the video or the brand of the streaming platform the viewer is using to watch the video. | v13+ |\n|video_cdn_trace |Array |Dim. | Sequential values of the video delivery CDN over the course of the view | v14+ |\n|video_codec |Text |Dim. | The codec of the video that played during the view. | v13+ |\n|video_content_type |Text |Dim. | Content Type (e.g. short, movie, episode, clip, trailer, or event).| v1+ |\n|video_creator_id |Text |Dim. | A unique identifier for the creator of the video. Defaults to the Mux Creator ID if enabled for Assets and Livestreams hosted by Mux.| v13+ |\n|video_duration |Milliseconds |Dim. | The length of the video supplied to Mux via custom metadata| v1+ |\n|video_dynamic_range_type |Text |Dim. | The format or type of dynamic range available on the video during the view. | v13+ |\n|video_encoding_variant |Text |Dim. | An optional detail that allows you to compare different encoding settings.| v1+ |\n|video_id |Unique ID |Dim. | Your internal ID for the video| v1+ |\n|video_language |Text|Dim. | The audio language of the video, assuming it's unchangeable after playing.| v1+ |\n|video_producer |Text |Dim. | The producer of the video title| v1+ |\n|video_quality_score |Decimal |Score | Video Quality Score| v2+ |\n|video_startup_business_exception_error_type_id |Unique ID |Dim. | An ID value that is present when a video startup business exception occurs | v9+ |\n|video_series |Text |Dim. | Series name (e.g. The Girls)| v1+ |\n|video_startup_time |Milliseconds | Metric | (Video Startup Time on Mux Dashboards) Measures from when the player has been instructed to play the video, to when the first frame of video (either content or preroll ad) is showing and the playhead is progressing.| v2+ |\n|video_startup_failure |Boolean | Metric | Identifies when a viewer encounters an error before the first frame of the video begins playback.| v7+ |\n|video_title |Text |Dim. | Video Title| v1+ |\n|video_variant_id |Unique ID |Dim. | Your internal ID for a video variant| v1+ |\n|video_variant_name | Text |Dim. | An optional detail that allows you to monitor issues with the files of specific versions of the content, for example different audio translations or versions with hard-coded/burned-in subtitles.| v1+ |\n|view_cdn_edge_pop |Text |Dim. | Region where the CDN edge point of presence server is located or other origin server identification. | v13+ |\n|view_cdn_origin |Text |Dim. | Identifying name of the Content Origin or Region where the Origin server is located. | v13+ |\n|view_content_startup_time |Milliseconds |Metric | Measures from when the player has been instructed to play the video, to when the first frame of video content is showing and the playhead is progressing.| v10+ |\n|view_content_watch_time |Milliseconds |Metric | Total Content Watch Time across the view (includes Startup Time, Playing time, potential rebuffering).| v10+ |\n|view_downscaling_percentage |Percentage |Metric | Downscale Percentage| v2+ |\n|view_drm_level |Text |Dim. | Security level of the specific DRM type. Some DRM types do not have levels.  v13+ |\n|view_drm_type |Text |Dim. | The type of DRM used during playback (e.g. widevine or playready).| v5+ |\n|view_dropped |Boolean |Dim. | Boolean indicating whether the view was finalized without an explicit viewend event. | v11+ |\n|view_dropped_frame_count |Integer |Metric | The number of frames that were dropped by the player during playback| v5+ |\n|view_end |Time |Dim. | Date and Time at which the view ended, in UTC.| v1+ |\n|view_has_ad |Boolean |Metric | Identifies if an advertisement played or attempted to play during the video view.| v6+ |\n|view_id |Unique ID |Dim. | Unique View Identifier| v1+ |\n|view_max_playhead_position |Milliseconds |Dim. | The furthest the video was played, indicated by the maximum time value of the playhead during the view.| v3+ |\n|view_playing_time |Milliseconds |Metric | The amount of time the video spent playing during the view; this value does not include time spent joining, rebuffering, or seeking.| v3+ |\n|view_seek_count |Integer |Dim. | The number of times that the viewer attempted to seek to a new location within the view.| v1+ |\n|view_seek_duration |Milliseconds |Dim. | Total amount of time spent waiting for playback to resume after the viewer seeks to a new location. Seek Latency metric in the Dashboard is this value divided by view_seek_count.| v1+ |\n|view_session_id |Unique ID |Dim. | An id that can be used to correlate the view with platform services upstream such as CDN or origin logs.| v2+ |\n|view_start |Time |Dim. | Date and Time at which the view started, in UTC.| v1+ |\n|view_time_shift_enabled |Boolean |Dim. | Boolean indicating if this view had time_shift enabled. | v13+ |\n|view_total_content_playback_time |Milliseconds |Dim. | Internal metric used in calculating upscale and downscale percentages.| v1+ |\n|view_total_downscaling |Milliseconds |Dim. | Internal number used to calculate Downscale Percentage Metric. Downscale Percentage = view_total_downscaling / view_total_content_playback_time | v1+ |\n|view_total_upscaling |Milliseconds |Dim. | Internal number used to calculate Upscale Percentage Metric. Upscale Percentage = view_total_upscaling / view_total_content_playback_time| v1+ |\n|view_upscaling_percentage |Percentage |Metric | Upscale Percentage| v2+ |\n|viewer_application_engine |Text |Dim. | Web Browser Engine (Gecko, WebKit, etc.)| v1+ |\n|viewer_connection_type |Text |Dim. | The type of connection used by the player, as reported by the client when available: cellular, other, wifi, wired| v2+ |\n|viewer_device_category |Text |Dim. | The form factor of the device: camera, car browser, console, desktop, feature phone, peripheral, phone, portable media player, smart display, smart speaker, tablet, tv, wearable| v1+ |\n|viewer_device_manufacturer |Text |Dim. | Device Brand (e.g. Apple, Microsoft, etc.)| v1+ |\n|viewer_device_model |Text |Dim. | Device Model (e.g. iPhone11,2)| v4+ |\n|viewer_device_name |Text |Dim. | Device Name (e.g. iPhone 12)| v1+ |\n|viewer_experience_score |Decimal |Score | Overall Viewer Experience Score| v2+ |\n|viewer_os_architecture |Text |Dim. | No longer used. Ignore.| v1+ |\n|viewer_plan |Text |Dim. | Name of the viewer's customer-specific plan, product, or subscription. | v13+ |\n|viewer_plan_category |Text |Dim. | Category of the viewer's customer-specific subscription plan (e.g. bundle-type, subscription-campaign-id). | v13+ |\n|viewer_plan_status |Text |Dim. | Status pertaining to that viewer's subscription plan (e.g. subscriber, non-subscriber, SVOD, AVOD, free, standard, premium). | v13+ |\n|viewer_user_agent |Text |Dim. | User Agent (e.g. Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0))| v1+ |\n|viewer_user_id |Unique ID |Dim. | A Customer-defined ID representing the viewer who is watching the stream. Note: You should not use any value that is personally identifiable such as email address, username, etc. Instead, you should supply an anonymized viewer ID which you have stored within your own system.| v1+ |\n|watch_time |Milliseconds |Dim. | Total Watch Time across the view (includes Startup Time, Playing time, potential rebuffering).| v1+ |\n|watched |Boolean |Dim. | Ignore| v1+ |\n|weighted_average_bitrate |bits/sec |Metric | Weighted Average Bitrate, expressed in bps.| v2+ |\n\nAd Metrics and Dimensions\n\n| Mux API Value | Unit | Type | Definition | Versions |\n|---------------|------|------|------------|----------|\n|ad_attempt_count |Integer |Metric | The number of times that the player attempted to play an ad | v8+ |\n|ad_break_count |Integer |Metric | The number of times that the player entered an ad break| v8+ |\n|ad_break_error_count |Integer |Metric | The number of times that the viewer encountered an ad error during an ad break| v8+ |\n|ad_break_error_percentage |Percentage |Metric | Percentage of views that contain ads that encountered an ad break error| v8+ |\n|ad_error_count |Integer |Metric | The number of times that the player encountered an ad error| v8+ |\n|ad_error_percentage |Percentage |Metric | Percentage of views that contain ads that encountered an ad error| v8+ |\n|ad_impression_count |Integer |Metric | The number of times that the player began ad playback| v8+ |\n|ad_startup_error_count |Integer |Metric | The number of times that the player errored on ad startup| v8+ |\n|ad_startup_error_percentage |Percentage |Metric | Percentage of views that contain ads that encountered an ad startup error| v8+ |\n|ad_exit_before_start_count |Integer |Metric | The number of times that the viewer exited before the ad started playback| v8+ |\n|ad_exit_before_start_percentage |Percentage |Metric | Percentage of views that contain ads that encountered an ad exit before start| v8+ |\n|ad_playback_failure_error_type_id |Unique ID |Dim. | An ID value that is present when an ad playback failure occurs | v10+ |\n|ad_preroll_startup_time |Milliseconds |Metric | Measures from when the player has been instructed to play a preroll ad to when the first frame of the ad is showing and the playhead is progressing.| v10+ |\n|ad_watch_time |Milliseconds |Metric | Total Watch Time for ad playback across the view (includes Ad Preroll Startup Time, ad playing time, potential rebuffering). | v10+ |\n|preroll_ad_asset_hostname |Hostname |Dim. | Hostname of the Preroll Ad Asset.| v1+ |\n|preroll_ad_tag_hostname |Hostname |Dim. | Hostname of a Preroll Ad Tag.| v1+ |\n|preroll_played |Boolean |Dim. | Flag to identify video views for which a Preroll Ad has been successfully played.| v1+ |\n|preroll_requested |Boolean |Dim. | Flag to identify video views for which a Preroll Ad has been requested.| v1+ |\n|requests_for_first_preroll |Integer |Metric | Measures the number of ad requests that are made up to the point of preroll ad playback beginning.| v1+ |\n|video_startup_preroll_load_time |Milliseconds |Metric | Total amount of Video Startup Time that is spent loading the first preroll ad asset.| v1+ |\n|video_startup_preroll_request_time |Milliseconds |Metric | Total amount of Video Startup Time that is spent making preroll ad requests.| v1+ |\n\nRequest-level Metrics\n\n| Mux API Value | Unit | Type | Definition | Versions |\n|---------------|------|------|------------|----------|\n|max_request_latency |Milliseconds |Metric | Maximum time to first byte for a media request.| v2+ |\n|max_request_latency (view_max_request_latency) |Milliseconds |Metric | Deprecated - see max_request_latency| v1 |\n|request_latency |Milliseconds |Metric | Measures the average time to first byte for media requests.| v2+ |\n|request_latency (view_average_request_latency) |Milliseconds |Metric | Deprecated - see request_latency| v1 |\n|request_throughput |bits/sec |Metric | Measures the average throughput, in bits per second, for all media requests that were completed.| v2+ |\n|request_throughput (view_average_request_throughput) |bits/sec |Metric | Deprecated - see request_throughput| v1 |\n\nThe daily CSV export files are generated based on the specific version that is configured and include the fields specified in the section above.\n\nSample CSV export files are available to download, for reference:\n Version 2\n Version 3\n Version 4\n\nThe protobuf definition for Streaming Exports of video views is available in the mux-protobuf repository. Please subscribe to this repository for updates to the protobuf definition.\n\nThe JSON format streaming export contains identical fields as the protobuf-encoded format.\n\nBackward compatibility\n\nThe Streaming Export schema provided by Mux Data is backward compatible, meaning that each schema version guarantees that it will still work upon future upgrades. Customers do not need to worry about breaking changes.\n\nWhen to upgrade the schema?\n\nWhen Mux adds new fields into the Streaming Export, we will upgrade the schema version. Without taking any actions you will not be impacted by it: the fields that you used to get will keep working as normal, and the new fields introduced since your last upgrade will not be sent to you either. The benefit of designing it this way is that you will not be getting new fields without knowing.\n\nFor customers who want to get the new fields, read below to see the how-tos.\n\nHow to upgrade the schema?\n\nIf integrated with Google Pub/Sub\n\nIf your Google Pub/Sub topic is schematized, once a schema is associated with a topic, you can no longer change that schema. This means that customers using Google Pub/Sub for Streaming Export must take a couple of steps to move to a new topic that is associated with a new schema.\n\n Create a new topic in Google Pub/Sub with upgraded schema\n Point the Mux Data Streaming Export to that new topic\n Go to Mux Dashboard → Settings → Streaming Export → Click Upgrade.\n\nIf your Google Pub/Sub topic is schemaless, which it must be if you want to use JSON, you do not need to create new topics or reconfigure your streaming export, but to get the new fields released from Mux, customer needs to do the 3rd step as mentioned above.\n\nIf integrated with Amazon Kinesis\n\n If using protobuf message format, make sure you get the latest protobuf definition from Mux public repo. Subscribe to the mux-protobuf repository to receive updates.\n Go to Mux Dashboard → Settings → Streaming Export → Click Upgrade button."
  },
  {
    "id": "49-_guides/developer/extend-data-with-custom-metadata",
    "title": "Extend Data with custom metadata",
    "path": "_guides/developer/extend-data-with-custom-metadata.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/extend-data-with-custom-metadata",
    "content": "Limits\n\nThe number of custom dimensions you can track depends on your plan. See the pricing page for details.\n\nThere are many metadata dimensions that can be used to track information about video views such as Video Title, Video Series, or Encoding Variant. You can find the whole list on the guide to making your data actionable. Custom Dimensions allow you to define, submit, and report on metadata necessary to support your use case that are not in the pre-defined collection of metadata dimensions in Mux Data. Examples could include metadata such as the device firmware version or a subscription plan type.\n\nEach custom dimension can have a display name and an assigned category. They also have a pre-defined field name, such as custom_1, that is used to refer to the dimension in code when submitting a value to track as part of a view. You'll use these field names when sending these values via an SDK integration or accessing a dimension value using the Mux Data API.\n\nThe Custom Dimensions configuration is available from the Settings page and selecting the \"Custom Dimensions\" tab. You will see the list of the dimensions that are available for reporting.\n\nTo enable a dimension, click the switch next to the left of the dimension name. To disable a dimension, simply click the switch off. The custom dimension data will continue to be collected from the SDKs but it will not be available to users for reporting in the Mux Dashboard.\n\nTo edit a dimension, click the edit pencil to the right of the row. You can set the display name of the dimension to match your preferred definition and assign the most appropriate category. By default, Custom Dimensions are included in the Custom category but they can added to any existing dimension category.\n\nThe name and category of the dimension are used wherever dimensions are displayed, such as the Metrics Breakdown page, the View detail page, the Filter model, or the dimensions list on the Compare page.\n\nOnce configured to be visible, Custom Dimensions are available to report on in the same method as pre-defined dimensions. The dimensions are available for filtering, aggregation, and comparison from the Metrics Breakdown screen in the category that was assigned for each visible dimension.\n\nThe Custom Dimension values are also available in the export files using the pre-defined field name (i.e. custom_1).\n\nCustom Dimension data is configured in the Mux Data SDKs in a similar method to other view metadata.\n\nMetadata is submitted to the SDKs using the pre-defined field name assigned to the dimension you have configured. For example, if you configured the custom_1 dimension to have the display name \"Secondary User Id,\" you submit that secondary user id value using the custom_1 or CustomData1 metadata field, depending on the platform.\n\nMake sure you are using an up-to-date version of each Mux Data SDK to enable support for submitting Custom Dimensions.\n\nHTML5 Video Element and other web SDKs\n\nIn web-based SDKs, Custom Dimensions are set in the same data object as the other view metadata fields.\n\n\n```js\nmux.monitor('#test_video', {\n  data: {\n    // Set other view data\n    video_title: 'Big Buck Bunny',\n    player_init_time: playerInitTime,\n    env_key: 'YOUR_ENVIRONMENT_KEY_HERE',\n\n    // Set custom dimension data\n    custom_1: 'My Custom Dimension Value'    // Set the custom value here\n  }\n});\n```\n\n\nFor more guidance on using and configuring web-based SDKs, please refer to the guide on monitoring the HTML5 video element.\n\nVersion 4.1.0 or later of the HTML5 Video Element monitor is necessary to support Custom Dimensions.\n\nExoPlayer\n\nIn Android-based SDKs, Custom Dimensions are set in the CustomData object and attached to the CustomerData object that is used to initialize the Mux Data SDK.\n\n\n```java\n// Set other view data\nCustomerPlayerData customerPlayerData = new CustomerPlayerData();\ncustomerPlayerData.setEnvironmentKey(\"YOUR_ENVIRONMENT_KEY_HERE\");\nCustomerVideoData customerVideoData = new CustomerVideoData();\ncustomerVideoData.setVideoTitle(\"Big Buck Bunny\");\n\n// Set custom dimension data\nCustomData customData = new CustomData();\ncustomData.setCustomData1(\"MY_CUSTOM_DIMENSION_VALUE\");  // Set the custom value here\nCustomerData customerData = new CustomerData(customerPlayerData, customerVideoData, null);\ncustomerData.setCustomData(customData);\n\nmuxStats = new MuxStatsExoPlayer(this, player, \"demo-player\", customerData);\n```\n\n\nAn example integration that includes Custom Dimensions can be found in the demo application for muxinc/mux-stats-sdk-exoplayer which integrates Mux into an ExoPlayer demo application.\n\nFor more guidance on using and configuring Android SDKs, please refer to the guide on monitoring ExoPlayer.\n\nVersion 2.5.0 or later of the ExoPlayer monitor is necessary to support Custom Dimensions.\n\nAVPlayer\n\nIn iOS-based SDKs, Custom Dimensions are set in the MUXSDKCustomData object and attached to the MUXSDKCustomerData object that is used to initialize the Mux Data SDK.\n\n\n```swift\n// Set custom dimension data\nMUXSDKCustomData *customData = [[MUXSDKCustomData alloc] init];\n[customData setCustomData1:@\"my-custom-dimension-value\"];  // Set the custom value here\n\n// Set other view data\nMUXSDKCustomerPlayerData *playerData = [[MUXSDKCustomerPlayerData alloc] initWithPropertyKey:@\"YOUR_ENVIRONMENT_KEY_HERE\"];\nMUXSDKCustomerVideoData *videoData = [MUXSDKCustomerVideoData new];\nvideoData.videoTitle = @\"Big Buck Bunny\";\nMUXSDKCustomerViewData *viewData= [[MUXSDKCustomerViewData alloc] init];\n\nMUXSDKCustomerData *customerData = [[MUXSDKCustomerData alloc] initWithCustomerPlayerData:playerData videoData:videoData viewData:viewData customData: customData];\n_playerBinding = [MUXSDKStats monitorAVPlayerViewController:_avplayerController withPlayerName:@\"demo-player\" customerData:customerData];\n```\n\n\nAn example integration that includes Custom Dimensions can be found in the demo application for muxinc/mux-stats-sdk-avplayer which integrates Mux into a AVPlayer demo application.\n\nFor more guidance on using and configuring iOS SDKs, please refer to the guide on monitoring AVPlayer.\n\nVersion 2.5.0 or later of the AVPlayer monitor is necessary to support Custom Dimensions.\n\nRoku\n\nIn the Roku SDK, Custom Dimensions are set in the same muxConfig object as the other view metadata fields.\n\n\n```js\nm.mux = m.top.CreateNode(\"mux\")\nm.mux.setField(\"video\", m.video)\n\nmuxConfig = {\n  property_key: \"YOUR_ENVIRONMENT_KEY_HERE\",\n  ' Set the custom dimension data\n  custom_1: \"my-custom-dimension-value\"\n}\n\nm.mux.setField(\"config\", muxConfig)\nm.mux.control = \"RUN\"\n\n' Load the video into the Video node\n```\n\n\nFor more guidance on using and configuring the Roku SDK, please refer to the guide on monitoring Roku.\n\nVersion 1.1.0 or later of the Roku monitor is necessary to support Custom Dimensions."
  },
  {
    "id": "50-_guides/developer/filter-your-data",
    "title": "Filter your Data",
    "path": "_guides/developer/filter-your-data.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/filter-your-data",
    "content": "The filters[] parameter allows you to filter your data using flexible syntax that supports different types of operations depending on the dimension type.\n\nFilter Syntax Overview\n\nThe basic format for all filters is:\n\n  filters[]=&lt;operation&gt;&lt;dimension&gt;:&lt;value&gt;\n\n- &lt;operation&gt; is the optional prefix that defines the type of filter.\n  Examples:\n  - (none) → equals → country:US\n  - ! → not equals → !country:US\n  - + → set contains → +video_cdn_trace:fastly\n  - - → set omits → -video_cdn_trace:cloudflare\n\n- &lt;dimension&gt; is the field or metric you want to filter on.\n  Examples: country, operating_system, video_cdn_trace\n\n- : acts as the separator between the dimension and the value.\n\n- &lt;value&gt; is the value you're comparing against.\n  Examples:\n  - Scalar → US, windows\n  - Trace → [fastly,akamai]\n  - Empty trace → []\n\nSupported Operations\n\nScalar Operations\n\nScalar operations can be used with single-value dimensions or simple key-value pairs. Use these operations when you want to filter by an exact match or exclusion.\n\n| Syntax | Operation | Example | Description |\n| --- | --- | --- | --- |\n| dimension:value | Equals | filters[]=country:US | Field equals value |\n| !dimension:value | Not equals | filters[]=!operating_system:windows | Field does not equal value |\n\nSet Operations\n\nUse for trace dimensions that can have multiple values in an ordered list. Use these operations when you want to check if a single value appears in the trace dimension.\n\n| Syntax | Operation | Example | Description |\n| --- | --- | --- | --- |\n| +dimension:value | Has | filters[]=+video_cdn_trace:fastly | Set contains value |\n| -dimension:value | Omits | filters[]=-video_cdn_trace:cloudflare | Set does NOT contain value |\n\nPlease note that set operations cannot be used as a wildcard for substring searches. For example, filters[]=+video_cdn_trace:fas cannot be used to return views with CDN traces that contain fastly.\n\nTrace Operations\n\nUse for trace dimensions that can have multiple values in an ordered list. Use this operation when you want to filter for an exact, ordered match.\n\n| Syntax | Operation | Example | Description |\n| --- | --- | --- | --- |\n| dimension:[value1,value2] | Equals | filters[]=video_cdn_trace:[fastly,akamai] | Trace equals exactly [fastly, akamai] |\n\nPractical Examples\n\nScalar (Basic) Operations\n\nFilter for views from the US:\n\n\n```\nfilters[]=country:US\n```\n\n\nExclude mobile operating systems:\n\n\n```\nfilters[]=!operating_system:mobile\n```\n\n\nSet Operations\n\nFind views with 'fastly' as a CDN value in the video_cdn_trace dimension.\n\n\n```\nfilters[]=+video_cdn_trace:fastly\n```\n\n\nExclude views that went through cloudflare:\n\n\n```\nfilters[]=-video_cdn_trace:cloudflare\n```\n\n\nTrace Operations\n\nFind views that went through exactly fastly first, then akamai:\n\n\n```\nfilters[]=video_cdn_trace:[fastly,akamai]\n```\n\n\nFind views where no CDN value was set:\n\n\n```\nfilters[]=video_cdn_trace:[]\n```\n\n\nMultiple Filters\n\nYou can combine multiple filters.\n\nFilters with different dimensions\n\nWhen you are combining filters with different dimensions they are combined with AND.\n\n\n```\n# Views from US AND went through fastly\nfilters[]=country:US\nfilters[]=+video_cdn_trace:fastly\n```\n\n\nYou can also combine dimensions with the same dimension. These are combined with OR.\n\n\n```\n# Views from US OR Canada\nfilters[]=country:US\nfilters[]=country:CA\n```\n\n\nHowever, if you are combining filters with the same dimension value with a negated value, those are combined using AND.\n\n\n```\n# Views NOT from US AND NOT from Canada\nfilters[]=!country:US\nfilters[]=!country:CA\n```\n\n\nValue Formatting\n\n- Scalar (basic) values: Plain strings (country:US)\n- Trace values: Comma-separated values in brackets (video_cdn_trace:[a,b,c])\n- Empty traces: Use empty brackets (video_cdn_trace:[])\n\nCommon Errors\n\n❌ Don't use brackets with set operators:\n\n\n```\nfilters[]=+video_cdn_trace:[fastly]  # Invalid\n```\n\n\n✅ Correct:\n\n\n```\nfilters[]=+video_cdn_trace:fastly    # Valid\n```\n\n\n❌ Don't use scalar operator syntax with trace dimensions:\n\n\n```\nfilters[]=video_cdn_trace:fastly  # Invalid\n```\n\n\n✅ Use trace or set operator syntax with trace dimensions:\n\n\n```\nfilters[]=video_cdn_trace:[fastly]  # Exact match\nfilters[]=+video_cdn_trace:fastly   # Contains check\n```\n\n\nURL Encoding\n\nWhen using filters in URLs, remember to properly encode the parameters:\n\n\n```bash\n# Single filter\n/metrics?filters[]=country:US\n\n# Multiple filters\n/metrics?filters[]=country:US&filters[]=+tags:beta&filters[]=video_cdn_trace:[fastly,akamai]\n\n# URL encoded\n/metrics?filters%5B%5D=country%3AUS&filters%5B%5D=%2Btags%3Abeta&filters%5B%5D=video_cdn_trace%3A%5Bfastly%2Cakamai%5D\n```\n\nHere's an example of how you can URL encode the filter params using JavaScript:\n\n\n```javascript\n// Example filters\nconst filters = [\n  \"country:US\",\n  \"+tags:beta\",\n  \"video_cdn_trace:[fastly,akamai]\"\n];\n\n// Use URLSearchParams to build query string\nconst params = new URLSearchParams();\nfilters.forEach(f => params.append(\"filters[]\", f));\n\n// Full URL\nconst url = `/metrics?${params.toString()}`;\n\nconsole.log(url);\n// /metrics?filters%5B%5D=country%3AUS&filters%5B%5D=%2Btags%3Abeta&filters%5B%5D=video_cdn_trace%3A%5Bfastly%2Cakamai%5D\n```\n\n\nCommon Use Cases\n\nAnalytics and Debugging\n\nFind problematic CDN paths:\n\n\n```\n# Views that went through cloudflare but not fastly\nfilters[]=-video_cdn_trace:fastly\nfilters[]=+video_cdn_trace:cloudflare\n```\n\n\nDebug specific video delivery paths:\n\n\n```\n# Exact CDN sequence analysis\nfilters[]=video_cdn_trace:[fastly,akamai,cloudfront]\n```\n\n\nPerformance Analysis\n\nHigh-performance regions:\n\n\n```\n# Exclude slow CDN providers\nfilters[]=-video_cdn_trace:slow-cdn\nfilters[]=!operating_system:legacy\n```\n\n\nMobile vs Desktop comparison:\n\n\n```\n# Mobile traffic analysis\nfilters[]=operating_system:ios\nfilters[]=operating_system:android\n```\n\n\nContent Filtering\n\nLive vs VOD content:\n\n\n```\n# Exclude recorded content\nfilters[]=!content_type:recorded\nfilters[]=content_type:live\n```\n\n\nPlatform-specific analysis:\n\n\n```\n# Web platform only, excluding mobile apps\nfilters[]=platform:web\nfilters[]=!platform:ios\nfilters[]=!platform:android\n```\n\n\nError Handling\n\nThe API will return validation errors for:\n\n- Invalid dimension names\n- Incorrect operator usage for dimension type\n- Malformed values (e.g., mismatched brackets, quotes)\n- Invalid operator combinations (e.g., !+dimension:value)\n\nExample error response:\n\n\n```json\n{\n  \"error\": \"Sequence dimensions require bracket notation. Use video_cdn_trace:[value] instead of video_cdn_trace:value\"\n}\n```\n\n\nAdvanced Tips\n\nTesting Your Filters\n\nTo ensure your filters are working as expected, it can be helpful to limit the dataset you're working with. For that reason, you may wish to test your filters with a small date range first:\n\n\n```bash\n/metrics?timeframe[]=24:hours&filters[]=country:US&filters[]=+video_cdn_trace:akamai\n```"
  },
  {
    "id": "51-_guides/developer/get-images-from-a-video",
    "title": "Get thumbnails and images from a video",
    "path": "_guides/developer/get-images-from-a-video.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/get-images-from-a-video",
    "content": "To get an image from Mux, use a playback_id to make a request to image.mux.com in the following format:\n\n<CodeExample\n  lang=\"curl\"\n  code=\"https://image.mux.com/{PLAYBACK_ID}/thumbnail.{png|jpg|webp}\"\n/>\n\nImages can be served in either webp, png, or jpg format. Webp is an image format that uses lossy and lossless image compression methods to reduce image size while maintaining good quality. If your images are in the webp format, they will typically yield a smaller file size compared to using png or jpg images.\n\nYou can control how the image is created by including the following query string parameters with your request. If you don't include any, Mux will default to choosing an image from the middle of your video.\n\nThumbnail Query String Parameters\n\n| Parameter     | Type          | Description                                           |\n| :-------------|:--------------|:------------------------------------------------------|\n| time        | float       | The time (in seconds) of the video timeline where the image should be pulled. Defaults to the middle of the original video.|\n| width       | int32       | The width of the thumbnail (in pixels). Defaults to the width of the original video. |\n| height      | int32       | The height of the thumbnail (in pixels). Defaults to the height of the original video. |\n| rotate      | int32       | Rotate the image clockwise by the given number of degrees. Valid values are 90, 180, and 270. |\n| fit_mode    | string      | How to fit a thumbnail within width + height. Valid values are preserve, stretch, crop, smartcrop, and pad (see below). |\n| flip_v      | boolean     | Flip the image top-bottom after performing all other transformations. |\n| flip_h      | boolean     | Flip the image left-right after performing all other transformations. |\n| latest      | boolean     | When set to true, pulls the latest thumbnail from the playback ID of an ongoing live stream. Can only be used with live streams. More details. |\n\nThe fit_mode parameter can have the following values:\n- preserve : By default, Mux will preserve the aspect ratio of the video, while fitting the image within the requested width and height. For example if the thumbnail width is 100, the height is 100, and the video's aspect ratio is 16:9, the delivered image will be 100x56 (16:9).\n- stretch : The thumbnail will exactly fill the requested width and height, even if it distorts the image. Requires both width and height to be set. (Not very popular.)\n- crop : The video image will be scaled up or down until it fills the requested width and height box. Pixels then outside of the box will be cropped off. The crop is always centered on the image. Requires both width and height to be set.\n- smartcrop : An algorithm will attempt to find an area of interest in the image and center it within the crop, while fitting the requested width and height. Requires both width and height to be set.\n- pad : Similar to preserve but Mux will \"letterbox\" or \"pillar box\" (add black padding to) the image to make it fit the requested width and height exactly. This is less efficient than preserve but allows for maintaining the aspect ratio while always getting thumbnails of the same size. Requires both width and height to be set.\n\nExample with Query String Parameters\n\nHere is an example request for an image including query parameters which:\n- has a width of 400 and a height of 200\n- uses the smartcrop fit mode\n- is taken from the 35th second of the video\n- is a PNG\n\n<CodeExample\n  lang=\"curl\"\n  code=\"https://image.mux.com/{PLAYBACK_ID}/thumbnail.png?width=400&height=200&fit_mode=smartcrop&time=35\"\n/>\n\n  Note that there is a default limit of 1 thumbnail and 1 GIF for every 10 seconds of duration per asset. For assets under 100 seconds in duration, the limit is 10 thumbnails and 10 GIFs. For example, you can retrieve 30 thumbnails and 30 GIFs for a 5 minute asset or 10 thumbnails and 10 GIFs for a 30 second asset.\n\nTo get an animated gif or webp from Mux, use a playback_id associated with an asset or live stream to make a request to image.mux.com in the following format:\n\n<CodeExample\n  lang=\"curl\"\n  code=\"https://image.mux.com/{PLAYBACK_ID}/animated.{gif|webp}\"\n/>\n\nYou can control how the image is created by including the following query string parameters with your request.\n\nAnimated GIF Query String Parameters\n\n| Parameters    | Type          | Description   |\n| :------------ |:--------------|:--------------|\n| start       | float       | The time (in seconds) of the video timeline where the animated GIF should begin. Defaults to 0. |\n| end         | float       | The time (in seconds) of the video timeline where the GIF ends. Defaults to 5 seconds after the start. Maximum total duration of GIF is limited to 10 seconds; minimum total duration of GIF is 250ms. |\n| width       | int32       | The width in pixels of the animated GIF. Default is 320px, or if height is provided, the width is determined by preserving aspect ratio with the height. Max width is 640px. |\n| height      | int32       | The height in pixels of the animated GIF. The default height is determined by preserving aspect ratio with the width provided. Maximum height is 640px. |\n| fps         | int32       | The frame rate of the generated GIF. Defaults to 15 fps. Max 30 fps. |\n\nExample with Query String Parameters\n\nHere is an example request for a GIF including query parameters which:\n- set a width of 640\n- set a frame rate of 5fps\n\n<CodeExample\n  lang=\"curl\"\n  code=\"https://image.mux.com/{PLAYBACK_ID}/animated.gif?width=640&fps=5\"\n/>\n\nImages and GIFs can be used anywhere in your project, but here are some examples of common ways you can use images from Mux.\n\n  Avoid using images for storyboards (timeline hover previews). To learn more about storyboards, you can view this guide.\n\nAdd a poster image to your player\n\nMost video players will default to showing a black frame with a play icon and other video controls before a user presses play to start the video playback.\nYou can add a poster image to the majority of video players where you could feed an image URL from Mux. Here's an example using a HTML5 video element\nwith a poster image setup.\n\n\n```jsx\n<video id=\"my-video\" width=\"640\" height=\"360\" poster=\"https://image.mux.com/{PLAYBACK_ID}/thumbnail.jpg\" controls>\n```\n\n\nUse a GIF to show a preview\n\nWhen a user is picking a video from a catalogue, you could show a preview of the video using an animated GIF whilst they hover over a thumbnail of the video.\n\nYou could use pure CSS, some JavaScript, or another method which best fits with your application to achieve a similar result (the example above used CSS).\n\nMux videos have two types of playback policy, public or signed. If your playback_id is signed, you will need to also sign requests made for images and animated GIFs.\nYou can check out how to do that in our signed URLs guide.\n\nIf you run into any trouble signing image requests, please reach out and we'll be able to help.\n\nWhen a live stream is active, you can use the ?latest=true query string parameter to get the latest thumbnail from the live stream. This thumbnail is refreshed every 10 seconds.\n\nThis is useful for building moderation and classification workflows when working with user-generated live streams, but can also be used to show a discovery experience, showing the active live streams in your application.\n\nUsing the latest parameter on a VOD asset or non-live stream will return a 400 error.\n\nRead the blog post for more details end examples for this feature."
  },
  {
    "id": "52-_guides/developer/handle-live-stream-disconnects",
    "title": "Handle Live Stream Disconnects",
    "path": "_guides/developer/handle-live-stream-disconnects.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/handle-live-stream-disconnects",
    "content": "Before reading this guide, you created and set up a Live Stream by following these steps:\n\n- You have connected your encoder (for example OBS, Wirecast, your live streaming app) to an RTMP ingest server as covered in this guide: Configure Broadcast Software).\n- Mux sends the video.live_stream.connected event to your environment.\n- When the encoder starts sending media to the ingest server, the webhook events video.live_stream.recording and then video.live_stream.active are delivered to your environment.\n\nIf everything goes smoothly, the encoder will keep sending media and the server will keep processing it, creating video segments and\nupdating the HLS playlists with new pieces of video (to understand how this\nworks read Reduce live stream latency).  Since all of\nthis streaming is happening live, the ingest server needs to know what it should do when the encoder disconnects unexpectedly.\n\nWhat happens when the live stream disconnects either intentionally or due to a drop in the network? Mux sends the video.live_stream.disconnected\nevent for the live stream to your environment. This is where the reconnect_window comes into play.\n\nReconnect Window\n\nWhen you create the Live Stream or update the Live Stream, you can set the reconnect_window parameter in the Request JSON.\n\nThe Reconnect Window is the time in seconds that Mux should wait for the live stream broadcasting software to reconnect before considering the live stream finished\nand completing the recorded asset. As a default, Mux sets reconnect_window to 60 seconds for Standard Latency streams and zero seconds for Reduced and Low Latency streams, but this can be adjusted to any value between 0 to 1800 seconds.\n\nReconnect Window is supported for all latency modes of the live stream, including \"standard\", \"reduced\" and \"low\".\n\nReconnect Window and slates\n\nWhen you create the Live Stream or update the Live Stream,\nyou can set the reconnect_slate_url parameter with the URL of the slate image.\n\nSlate insertion can help output a live stream for viewers without interruptions. Below are some examples where Mux receives an imperfect stream and how Mux handles the output:\n\n- If the input contains only audio for the relevant time, the most recent video frame is duplicated\n- If the input contains only video for the relevant time, Mux will output silent audio\n- If a slate is inserted and the input has no audio or video (including because the encoder was disconnected) a slate period begins where Mux will output silent audio, and duplicate the most recent video frame. After 0.5 seconds, Mux will switch to the slate image and continue to send silent audio. If the encoder is still connected, Mux will disconnect the encoder after 5 minutes. Mux will then continue inserting slates for up to the duration of the reconnect_window in seconds. Viewers may experience a maximum slate duration of up to 5 minutes over the reconnect_window duration\n\nWhen Mux stops receiving the media, Mux adds the slate image as a video frame to the live stream. This event of not receiving media disconnects the encoder and starts the reconnect_window time interval.\nMux stops adding the slate image when Mux starts receiving media again or the reconnect window time interval expires.\n\nEnable slates for standard, reduced, and low latency mode live streams:\n - For standard latency live streams, set the use_slate_for_standard_latency parameter to true and make sure the reconnect_window parameter value is greater than 0s. Live streams, created before the slate image functionality was available, will not automatically start using slates until this parameter is set.\n - For reduced and low latency mode live streams, set the reconnect_window parameter value to greater than 0s.\n\nMux selects one of the following images as the default slate image depending on the live stream's video aspect ratio. The default slate image is used unless you\nset the reconnect_slate_url parameter. We recommended setting the slate image whose aspect ratio matches the live stream's video aspect ratio. You can modify\nthe reconnect_slate_url parameter using the update the Live Stream.\n\nMux downloads the slate image, hosted at the URL set as reconnect_slate_url parameter value, at the start of the live stream recording.\nSo, you must ensure the image is always downloadable from the URL. When Mux can not download the image, the default slate image (shown above) is used\nand the video.live_stream.warning for the live stream as well as the video.asset.warning webhook event for the asset is fired. Below is an example\nof the webhook event body:\n\n```json\n{\n    \"type\": \"video.live_stream.warning\", // or \"video.asset.warning\"\n    \"object\": {\n      \"type\": \"live\",\n      \"id\": \"CiinCsHA2EbsU00XwzherzjWAek3VmtUz8\"\n    },\n    \"id\": \"3a56ac3d-33da-4366-855b-f592d898409d\",\n    \"environment\": {\n      \"name\": \"Production\",\n      \"id\": \"j0863n\"\n    },\n    \"data\": {\n      \"warning\": {\n        \"type\": \"custom_slate_unavailable\",\n        \"message\": \"Unable to download custom reconnect slate image from URL 'http://example.com/bad_url.png' -- using black frames for slate if needed.\"\n      },\n      \"stream_key\": \"5203dc64-074a-5914-0dfc-ce007f5db53a\",\n      \"status\": \"idle\",  // or \"preparing\"\n      \"id\": \"CiinCsHA2EbsU00XwzherzjWAek3VmtUz8\",\n      \"active_asset_id\": \"0201p02fGKPE7MrbC269XRD7LpcHhrmbu0002\"\n    },\n    \"created_at\": \"2022-07-14T21:08:27.000000Z\",\n    \"accessor_source\": null,\n    \"accessor\": null,\n    \"request_id\": null\n  }\n```\n\n\nThe status parameter in the webhook event body (shown above) is idle for the live stream and preparing for the asset\nevent to match the corresponding status parameter values.\n\nWhen Mux is not receiving any media, the viewer experience depends on whether Mux starts receiving media before the reconnect window expires.\nWe strongly recommend updating the Live Stream to add a slate image.\nHowever, there are two possible scenarios when you do not want to add the slate image.\n\nIn scenario 1, the encoder re-connects\n\nThe ingest server will wait for the duration of the reconnect_window before it ends the live stream. While the encoder is disconnected, media is no longer being sent, so the HLS playlists are not getting new segments of video.\n\nStalled player during live stream\n\nA stalled player during a live stream happens when the live stream is still active, but the HLS manifest file is not getting new video segments appended to it.\n\nThe player will enter a stalled state if it runs out of buffer. To avoid this, consider adding extra buffer to your player.\n\nIf the encoder reconnects before the reconnect_window expires then the HLS playlist will resume appending new video segments to the live stream.\n\nIn scenario 2, the encoder disconnects\n\nIf the encoder does not reconnect before the reconnect_window expires, the following events will occur:\n\n1. Mux writes an EXT-X-ENDLIST tag to the HLS playlist. According to the HLS specification: EXT-X-ENDLIST: Indicates that no more media files will be added to the playlist file. This tells the player this stream is over and no more media is coming. Your player should emit an ended event, or something equivalent.\n2. The live stream will transition from active back to idle\n3.  Mux will create a new asset. The active_asset_id while the live stream was active will be finalized. If the same live stream goes live _again_ at a later time, then the live stream will get a new active_asset_id and a new asset will be created."
  },
  {
    "id": "53-_guides/developer/integrate-a-data-custom-domain",
    "title": "Integrate a Data custom domain",
    "path": "_guides/developer/integrate-a-data-custom-domain.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/integrate-a-data-custom-domain",
    "content": "In this guide you will learn how to configure a custom domain used for submitting Mux Data beacons from SDK clients. Video view data will be sent to the specified custom domain rather than the default Mux domain.\n\nYou might choose to do this for a couple of reasons, such as allowing analytics traffic to bypass school or other network firewall restrictions (via a known domain), zero-rating this traffic, or to aid tracking performance when ad blockers are in place.\n\nCustom Domains for Mux Data are available on select plans, such as Mux Data Media. Reach out if you have any questions.\n\nAfter selecting your desired custom domain, you will need to create CNAME records with your DNS provider to alias the custom domain to a Mux-controlled one and allow Mux to issue TLS certificates for your selected domain. After providing your Customer Success Manager with the desired subdomain, Mux will provide you with the specific required DNS records to enable custom domains (including the value for {KEY} below). The records will have the following basic format:\n\n\n```\nsubdomain.yourdomain.com 300 IN CNAME ${KEY}.customdomains.litix.io\n_acme-challenge.subdomain.yourdomain.com 300 IN CNAME ${KEY}.validations.customdomains.litix.io\n```\n\n\nNotify Mux after these records have been created so we can issue TLS certificates to terminate beacon traffic sent to your selected custom domain. You will be notified by Mux when the domain has been successfully provisioned.\n\nYou can verify whether the custom domain is operational by using curl to query your domain:\n\n\n```\n$ curl https://subdomain.yourdomain.com -s -w \"%{http_code}\"\n200%\n```\n\n\nMake sure that you have upgraded to the latest versions of each SDK to ensure Custom Domains function correctly.\n\nIt may take some time for DNS records to propagate before this request will work. After that is complete, configure your SDK integrations to specify your custom domain. Set the beaconCollectionDomain property to your custom domain.\n\nDepending on your SDK, you can set the value for beaconCollectionDomain in various ways."
  },
  {
    "id": "54-_guides/developer/intro-to-clips",
    "title": "Introduction to video clipping",
    "path": "_guides/developer/intro-to-clips.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/intro-to-clips",
    "content": "Clipping video with Mux\n\nMux provides two approaches for creating clips from your video content: Instant Clipping and Asset-Based Clipping. Each method is designed for different use cases, offering flexibility depending on your needs for speed, accuracy, and workflow.\n\nInstant Clipping\n\nInstant Clipping allows you to create clips instantly by specifying start and end times directly in the playback URL (using query parameters or JWT claims). This approach does not require re-encoding or creating a new asset, so clips are available immediately and at no extra encoding cost. Instant clipping operates at the segment level, so clips may start or end a few seconds outside your requested range, depending on the stream's segment duration.\n\nKey features:\n- No additional encoding or asset creation required\n- Clips are available instantly\n- No extra cost for encoding or storage\n- Segment-level accuracy (not frame-accurate)\n- Ideal for live streams and quick highlight creation\n\nLearn more: Create instant clips\n\nAsset-Based Clipping\n\nAsset-Based Clipping creates a new, standalone asset from a portion of an existing video or live stream recording. This method involves a re-encoding process, resulting in a new asset with its own playback ID, and supports frame-accurate clipping. Asset-based clips incur encoding and storage costs and may take some time to process before they are ready for playback.\n\nKey features:\n- Creates a new asset with its own playback ID\n- Frame-accurate clipping\n- Supports additional features like watermarks and text tracks\n- Incurs encoding and storage costs\n- Suitable for polished, distributable clips or downloadable MP4s\n\nLearn more: Create asset-based clips\n\nWhich clipping approach should you use?\n\nChoose Instant Clipping if:\n\n- You need clips to be available immediately\n- You want to avoid extra encoding costs\n- Segment-level accuracy is sufficient for your use case (e.g., live highlights, quick previews)\n- You want to limit playback to a specific range without creating a new asset\n\nChoose Asset-Based Clipping if:\n\n- You require frame-accurate clips\n- You need a new asset for distribution, download, or further processing\n- You want to add watermarks or preserve text tracks in the clip\n- You are willing to wait for processing and incur encoding/storage costs\n\n| Feature | Instant Clipping | Asset-Based Clipping |\n|---------|-----------------|---------------------|\n| Availability | ✅ Immediate | ⏳ Requires processing |\n| Frame Accuracy | ❌ Segment-level only | ✅ Frame-accurate |\n| Additional Encoding Cost | ❌ No | ✅ Yes |\n| Additional Storage Cost | ❌ No | ✅ Yes |\n| Watermark Support | ❌ No | ✅ Yes |\n| Text Track Support | ❌ No | ✅ Yes |\n| Downloadable MP4s | ❌ No | ✅ Yes |\n| Live Stream Support | ✅ Yes | ✅ Yes (recordings) |\n| Unique Playback ID | ❌ No | ✅ Yes |\n\nFor a deeper dive into each approach, see the individual guides:\n- Create instant clips\n- Create asset-based clips"
  },
  {
    "id": "55-_guides/developer/live-streaming-faqs",
    "title": "Live Streaming FAQs",
    "path": "_guides/developer/live-streaming-faqs.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/live-streaming-faqs",
    "content": "What is Mux’s latency for live streams?\nFor a standard live stream, latency is expected to be greater than 20 seconds and typically about 25 - 30 seconds. We offer a\nreduced latency mode which will reduce latency to about 12 - 20 seconds.\nA low-latency live stream can go as low as 5 seconds of glass-to-glass latency but the latency can vary depending on your viewer's geographical\nlocation and internet connectivity.\n\nDoes Mux support WebRTC for live streaming ingest?\nWe currently do not support direct WebRTC ingest to a Live Stream.\n\nWe have focused on RTMP and RTMPS for live streams from an encoder as they are the most universal ingest protocols.\n\nHow can I go live from a browser?\nTo go live directly from a browser, you need to convert the browser stream into a format that can be consumed by RTMP on our end.\n\nFor example, we’ve had customers use Zoom to provide the video from a browser, and use its RTMP-out feature to broadcast a stream with Mux for streaming to a larger conference-like audience.\n\nIs Mux Live Streaming API suitable for 2-way video communication applications?\n\nMux's Live Streaming API is not intended to provide 2-way video communication. For use cases that require 2-way video communication, we'd suggest looking at one of our partners, LiveKit.\n\nIs it possible to rewind live content while the live stream continues?\n\nDVR (Digital Video Recorder) mode is a live stream feature that lets it rewind. Mux supports DVR and non-DVR modes for live streams.\n\nnon-DVR mode is enabled by default for live streams and only has access to the most recent 30 seconds of the live stream.\n\nDVR mode is possible by utilizing the live stream's active_asset_id. When constructing the playback URL, the playback_id for the associated active_asset_id is used. When the live video ends, the Playback ID associated with the active_asset_id will automatically transition to an on-demand asset for playback instead.\n\nFor more information and caveats behind these two modes, refer to our Stream recordings of live streams guide.\n\nWhat is the maximum live stream duration?\nCurrently, we have a 12 hour limit for continuous streaming to our live endpoints. The live stream is disconnected after 12 hours.\n\nIf the encoder reconnects, Mux will transition to a new asset with its own playback ID.\n\nDo I need to create stream keys for every live event?\nNo, stream keys can be re-used as many time as you want. It's common for applications to assign one stream key to each user (broadcaster) in their system and allow that user to re-use the same stream key over time.\n\nIs there a limit to creating stream keys and live steams?\nThere is no limit on how many stream keys and live streams you can create.\n\nOnce created, stream keys are persistent and can be used for any number of live events.\n\nDo you charge for creating stream keys?\nWe don’t charge for creating stream keys, only when sending us an active RTMP feed.\n\nCan I live stream a pre-recorded video?\nMux does not support generating simulated live from on-demand assets. Such a service is also called a \"Playout service\".\n\nHowever, you can run a simulated live stream using a tool like OBS and Wirecast to send your on-demand asset to us as an RTMP stream. See how to configure your RTMP encoder on our Configuring Broadcast Software docs page.\n\nFor a more comprehensive guide and common options we recommend for work-arounds, see this guide of how to Stream simulated live.\n\nCan I restream/simulcast my live stream to social platforms like Facebook?\nYes. Mux Video live service supports up to six simultaneous restreams to third party platforms that support RTMP feed.\n\nRead more in this blog post: Help Your Users be in 5 Places at Once: Your Guide to Simulcasting.\n\nIs my content saved after the live broadcast is over?\nYes. Mux will automatically create an on-demand (VOD) asset after your live stream ends, which can be streamed again instantly after the live stream ends.\n\nCan I get access to my live event's recording?\nYes, you can enable downloading of the entire event recording using Master access feature.\n\nWith Master access enabled, you will receive a Webhook notification after the live stream ends, indicating that the master copy of the video asset is available to download.\n\nCan I generate thumbnails/GIFs while the live stream is active?\nYes. You can use our thumbnail and animated GIF API while the live event is active.\n\nMany customers use thumbnails or GIFs to show what content is currently playing or to as a way to promote the live stream.\n\nCan I test Mux live streaming for free?\nOn any paid plan, you can create free test live streams to help evaluate the Mux Video APIs without incurring any cost.\n\nWe give you access to create an unlimited number of test live streams. Test live streams are watermarked with the Mux logo, limited to 5 minutes, and disabled after 24 hours.\n\nCan I add multiple audio channels or tracks to my live stream?\n\nNo, we currently support only one audio track for live streams. On-demand video assets do support multiple alternative audio tracks\n\nYou may want your users to be able to select a language on the player and view a stream showing the same video content but play different audio. One workaround would be first, ingest multiple streams with one in each language. Then add logic to the player to switch between different playback URLs and the complete stream when the user changes the language.\n\nWhat happens if I live stream variable frame rate (VFR) content?\nWhile Mux does not output variable frame rate (VFR) content for live streams, we will accept variable frame rate (VFR) content for ingest. Having said that, we recommend using constant frame rate (CFR) content for live streams to ensure the best playback experience."
  },
  {
    "id": "56-_guides/developer/live-streaming-from-your-app",
    "title": "Live streaming from your app",
    "path": "_guides/developer/live-streaming-from-your-app.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/live-streaming-from-your-app",
    "content": "Live building blocks\n\nA recap from our Start live streaming guide:\n\nLive streaming from a native application requires software to capture the camera feed and stream it to the Mux live endpoint using the RTMP protocol. Fortunately for both iOS and Android you can find open source software to stream RTMP. The following open source applications can be used as a guide for building live streaming into your own app.\n\niOS & Android examples\n\n  Use the examples linked in this guide. They will contain the most current code and issue list. We may not provide support for outdated apps and dependencies.\n\n iOS Live Streaming Example\n Android Live Streaming Example\n\nOver time we'll build out more examples and SDKs for iOS and Android. If you have any feedback or requests please let us know.\n\nIf you're looking for a commercial solution, Streamaxia's OpenSDK and Larix Broadcaster are know to work well with Mux's RTMP ingest.\n\nWeb app live streaming\n\nThere are not any reliable open source solutions for building web-based encoders for streaming out over RTMP. Check the blog post for more information on going live from the browser."
  },
  {
    "id": "57-_guides/developer/make-your-data-actionable-with-metadata",
    "title": "Make your dimensions actionable with metadata",
    "path": "_guides/developer/make-your-data-actionable-with-metadata.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/make-your-data-actionable-with-metadata",
    "content": "One of Mux Data's core concepts are dimensions, which are the attributes of a video view that you can use to search, filter, and segment your video performance metrics.\n\nWhile some of these dimensions are populated automatically, Mux Data allows you to provide details about the video and environment that either can't be detected automatically, can't be accessed if the video fails to load, or should be overridden.\n\nEach dimension corresponds with a metadata key which can be used to set these values. While all metadata details except for env_key are optional, some may be necessary to calculate certain metrics and you'll see more helpful results as you include more.\n\nDimension Details\n\nLevel\n\nEach dimension is either considered basic or advanced. All dimensions are available for the standard retention period of 100 days. Long Term Metrics only support basic dimensions. If you are interested in Long Term Metrics, please reach out to Mux Support.\n\n  Long Term Metrics are available on Mux Data Custom Media plan. Long Term Metrics are available on Media Plans. Learn more about Mux Data Plans or contact support.\n\nScoping\n\nMany of Mux Data's dimensions are scoped to specific categories. Based on the category, they may have different behavior in terms of how these details are updated.\n\n Video details (prepended by video_) describe the current video that's playing and are all reset automatically when changing the video. This metadata might come from your internal CMS or video management system.\n Player details (prepended by player_) describe the player configuration that's being used and should be set whenever monitoring is started on a new player. They do not reset when the video is changed.\n All other details will persist until explicitly changed.\n\nType\n\nThere are three types of dimensions based on their availability.\n\nTracking: Enables tracking of additional metrics but are unavailable as dimensions.\n\nLimited: Appear as attributes of a view on the individual view page as well as in the API.\n\nFull: Can be used as filters and breakdowns in aggregate reports, in the video view page and in the API.\n\nHigh Priority Configurable Metadata\n\nThe following dimensions are the most important fields whose metadata keys you should populate in order to get the basic functionality from Mux Data.\n\n  For viewer_user_id you should not use any value that is personally identifiable on its own (such as email address, username, etc.). Instead, you should supply an anonymized viewer ID which you have stored within your own system.\n\n| Dimension Name | Key Name | Unit | Type | Level | Description |\n|:-|:-|:-|:-:|:-:|:-|\n| Environment | env_key | Unique ID | Required | N/A | Your env key from the Mux dashboard. This field ensures that your data goes into the correct environment. Note this was previously named property_key |\n| Video ID | video_id | Text | Full | basic | Your internal ID for the video. Defaults to the Mux External ID if enabled for Assets and Livestreams hosted by Mux. |\n| Video Title | video_title | Text | Full | basic | Title of the video being played (e.g.: Awesome Show: Pilot). Defaults to the Mux Video Title if enabled for Assets and Livestreams hosted by Mux. |\n| Viewer ID | viewer_user_id | Unique ID | Full | adv | An ID representing the viewer who is watching the stream. Use this to look up video views for an individual viewer. If no value is specified, a unique ID will be generated by the SDK. Note: You should not use any value that is personally identifiable on its own (such as email address, username, etc.). Instead, you should supply an anonymized viewer ID which you have stored within your own system. |\n\nOptional Configurable Metadata\n\nThe following dimensions can be set manually using the metadata key name and will be reported by Mux Data. The key name provided below is the snake_case used by Web SDKs. Keynames for iOS and Android SDK use camelCase and may differ in some cases. Review API documentation for API key names.\n\n| Dimension Name | SDK Key Name | Unit | Type | Level | Description |\n|:-|:-|:-|:-:|:-:|:-|\n| Audio Codec | video_audio_codec | Text | Full | adv | The codec of the audio that played during the view. |\n| CDN | video_cdn | Text | Full | basic | CDN delivering the video, either detected by Mux (via response X-CDN header) or specified in the view as video_cdn. Specifying a video_cdn value on the view does not override the detected value, if the X-CDN value is set on the segment response headers. |\n| CDN Edge PoP | view_cdn_edge_pop | Text | Full | adv | Region where the CDN edge point of presence server is located or other origin server identification. |\n| Content Type | video_content_type | Text | Full | basic | The type of content: e.g. short, movie, episode, clip, trailer, or event |\n| Client Application Name | view_client_application_name | Text | Full | adv | Name of the customer application that the viewer is using to watch the content. e.g 'OurBrand iOS App'|\n| Client Application Version | view_client_application_version | Text | Full | adv | Version of the customer application that the viewer is using to view the content. |\n| DRM Type | view_drm_type | Text | Full | adv | The DRM SDK or service that is used for the video playback, such as widevine or playready |\n| DRM Level | view_drm_level | Text | Full | adv | Security level of the specific DRM type. Some DRM types do not have levels. |\n| Duration | video_duration | Milliseconds | Limited | (none) | The length of the video in milliseconds |\n| Encoding Variant | video_encoding_variant | Text | Full | adv | Allows you to compare different encoders or encoding settings. This could designate the encoder used (e.g. x264, hevc, or av1), the preset used (e.g. av1-0, av1-4, or av1-8), or other properties of the encoding you want to track.  |\n| Experiment Name | experiment_name | Text | Full | adv | You can use this field to separate views into different experiments, if you would like to filter by this dimension later. |\n| Origin | view_cdn_origin | Text | Full | adv | Identifying name of the Content Origin or Region where the Origin server is located. |\n| Page Type | page_type | Text | Full | adv | Provide the context of the page for more specific analysis. Values include watchpage, iframe, or leave empty. watchpage — A web page that is dedicated to playing a specific video (for example youtube.com/watch/ID or hulu.com/watch/ID) iframe — An iframe specifically used to embed a player on different sites/pages |\n| Player Initialization Time | player_init_time | Milliseconds since Epoch | Tracking | N/A | If you are explicitly loading your player in page (perhaps as a response to a user interaction), include the timestamp (milliseconds since Jan 1 1970) when you initialize the player (or for HTML5 video, when right before you add the  element to the DOM) in order to accurately track page load time and player startup time. |\n| Player Name | player_name | Text | Full | basic | You can provide a name for the player (e.g. My Player) if you want to compare different configurations or types of players around your site or application. This is different from the player software (e.g. Video.js), which is tracked automatically by the SDK. |\n| Player Version | player_version | Text | Full | adv | As you make changes to your player you can compare how new versions of your player perform (e.g. 1.2.0). This is not the player software version (e.g. Video.js 5.0.0), which is tracked automatically by the SDK. |\n| Sub Property ID | sub_property_id | Text | Full | basic | A sub property is an optional way to group data within a property. For example, sub properties may be used by a video platform to group data by its own customers, or a media company might use them to distinguish between its many websites. |\n| Time Shift Enabled | view_time_shift_enabled | Boolean | Full | adv | Boolean indicating if this view had timeshift enabled. |\n| Used Captions | player_captions_enabled | Boolean | Full | adv | Boolean indicating if the player used captions at any time during the view. |\n| Used PiP | player_pip_enabled | Boolean | Full | adv | Boolean indicating if the player used Picture in Picture at any time during the view. |\n| Video Affiliate | video_affiliate | Text | Full | adv | Affiliate station that the viewer is watching or associated with the viewer. |\n| Video Brand | video_brand | Text | Full | adv | Brand associated with the video or the brand of the streaming platform the viewer is using to watch the video. |\n| Video Codec | video_codec | Text | Full | adv | The codec of the video that played during the view. |\n| Video Dynamic Range Type | video_dynamic_range_type | Text | Full | adv | The format or type of dynamic range available on the video during the view. |\n| Video Language | video_language_code | Text | Full | adv | The audio language of the video, assuming it's unchangeable after playing. |\n| Video Producer | video_producer | Text | Full | adv | The producer of the video title |\n| Video Series | video_series | Text | Full | basic | The series of the video (e.g.: Season 1) |\n| Video Stream Type | video_stream_type | Text | Full | basic | The type of video stream (e.g: live or on-demand) |\n| View Session ID | view_session_id | Unique ID | Full | adv | An ID that can be used to correlate the view with platform services upstream such as CDN or origin logs. |\n| Video Variant Name | video_variant_name | Text | Full | adv | Allows you to monitor issues with the files of specific versions of the content, for example different audio translations or versions with hard-coded/burned-in subtitles. |\n| Video Variant ID | video_variant_id | Text | Full | adv | Your internal ID for a video variant |\n| Viewer Plan | viewer_plan | Text | Full | adv | Name of the viewer's customer-specific plan, product, or subscription. |\n| Viewer Plan Status | viewer_plan_status | Text | Full | adv | Status pertaining to that viewer's subscription plan (e.g. subscriber, non-subscriber, SVOD, AVOD, free, standard, premium). |\n| Viewer Plan Category | viewer_plan_category | Text | Full | adv | Category of the viewer's customer-specific subscription plan (e.g. bundle-type, subscription-campaign-id). |\n| Custom Dimensions | custom_1 - 10 | Text | Full | adv | Customer-defined metadata |\n\nOverridable Metadata\n\nThe following dimensions are populated automatically where the data is supported by the SDK. This data can be overridden by the SDK client implementation using the metadata key name, if needed.\n\n| Dimension Name | Key Name | Unit | Type | Level | Description |\n|:-|:-|:-|:-:|:-:|:-|\n| Autoplay | player_autoplay_on | Boolean | Full | adv | Indicates whether the player was set to autoplay the video or not. This tracks whether the video has autoplay=true set; it is not always able to tell if the browser disregarded the setting, otherwise prevented the video from playing, or if the video play was triggered via a script. |\n| Browser | viewer_application_name | Text | Full | basic | Browser used for the video view (Safari, Chrome, etc.). On Android and iOS  applications this defaults to the bundle identifier. |\n| Browser Version | viewer_application_version | Version | Full | adv | Browser version (e.g. 66.0.3359.158). On Android and iOS applications this defaults to the bundle version. |\n| Connection Type | viewer_connection_type | Text | Full | adv | The type of connection used by the player, as reported by the client when available: cellular, other, wifi, wired |\n| Device Brand | viewer_device_manufacturer | Text | Full | basic | Device Manufacturer (e.g. Apple, Microsoft, etc.) |\n| Device Category | viewer_device_category | Text | Full | basic | The form factor of the device: camera, car browser, console, desktop, feature phone, peripheral, phone, portable media player, smart display, smart speaker, tablet, tv, wearable |\n| Device Model | viewer_device_model | Text | Full | adv | Device Model (e.g. iPhone11,2) |\n| Device Name | viewer_device_name | Text | Full | basic | Device Name (e.g. iPhone 12) |\n| Error Code | player_error_code | Text | Full | adv | Error code encountered by the player during playback. |\n| Operating System | viewer_os_family | Text | Full | basic | Operating System (iOS, Windows, etc.) |\n| Operating System Version | viewer_os_version | Version | Full | adv | Operating System version (e.g. 10.6) |\n| Page URL | page_url | URL | Limited | adv | Page URL |\n| Player Height | player_height | Integer | Limited | adv | Height of the player as displayed, in logical pixels |\n| Player Instance ID | player_instance_id | Unique ID | Limited | (none) | Identifies the instance of the Player class that is created when a video is initialized |\n| Player Language | player_language_code | Text | Full | adv | Player's text language |\n| Player Poster | player_poster | URL | Limited | (none) | The image shown as the pre-visualization before play |\n| Player Software | player_software_name | Text | Full | basic | Player Software being used to play the Video (e.g. Video.js, JW Player, etc.). Note this was previously named player_software |\n| Player Software Version | player_software_version | Text | Full | adv | Player Software Version (e.g. 2.45.5) |\n| Player Width | player_width | Integer | Limited | (none) | Width of the player as displayed, in logical pixels |\n| Preload | player_preload_on | Boolean | Full | adv | Specifies if the player was configured to load the video when the page loads. |\n| Remote Played | player_remote_played | Boolean | Full | adv | If the video is remote played to AirPlay as specified by the SDK. |\n| Source Height | player_source_height | Integer | Limited | adv | Height of the source video being sent to the player, in pixels |\n| Source Width | player_source_width | Integer | Limited | (none) | Width of the source video being as seen by the player |\n| Source Type | video_source_mime_type | Text | Full | basic | Format of the source, as determined by the player. E.g. application/dash+xml, x-application/mpegUrl, mp4, etc. |\n| Used Full Screen | player_is_fullscreen | Boolean | Limited | adv | Indicates whether the viewer used full screen to watch the video. |\n| Video Creator ID | video_creator_id | Text | Full | adv | A unique identifier for the creator of the video. Defaults to the Mux Creator ID if enabled for Assets and Livestreams hosted by Mux. |\n\nInternal Metadata\n\nThe following dimensions are populated automatically by the SDK, and cannot be overriden by the SDK client implementation.\n\n| Dimension Name | Unit | Type | Level | Description |\n|:-|:-|:-:|:-:|:-|\n| ASN | Boolean | Full | adv | The Autonomous System Number (ASN) representing the network provider of the viewer. |\n| Audio Codec Initial | Text | Full | adv | Initial codec of the audio that played. Derived from the first value of the audio_codec dimension. |\n| CDN Trace | Sequence | Full | adv | Populates all values of video_cdn field over the course of a view. |\n| Continent Code | Text | Full | basic | The continent from which the video was accessed, represented as a code. |\n| Country | Text | Full | adv | The country from which the video was accessed, represented as a country code. |\n| Exited Before Video Start | Boolean | Full | basic | Indicates whether the viewer exited before the video started playing. |\n| Mux Asset ID | Unique ID | Full | basic | A unique identifier for the video asset being played. |\n| Mux Live Stream ID | Unique ID | Full | basic | The unique identifier of the live stream being played. |\n| Mux Playback ID | Text | Full | basic | A unique identifier for the video view. |\n| Mux Plugin | Text | Full | adv | The name of the Mux plugin used by the video player. |\n| Mux Plugin Version | Text | Full | adv | The version of the Mux plugin used by the video player. |\n| Playback Business Exception | Boolean | Full | adv | Indicates whether a business rule-related issue caused playback failure. |\n| Playback Failure | Boolean | Full | adv | Indicates whether the playback failed for any reason. |\n| Region | Text | Full | adv | The specific region or state where the video was accessed. |\n| Source Bitrate | Integer | Limited | adv | Bitrate of the source video in bps. |\n| Source Bitrate Initial | Integer | Limited | adv | Initial bitrate of the source video in bps. Derived from the first value of the player_source_bitrate dimension. |\n| Source Framerate | Number | Limited | adv | Framerate of the source video. |\n| Source Framerate Initial | Number | Limited | adv | Initial framerate of the source video. Derived from the first value of the player_source_fps dimension. |\n| Source Height | Integer | Limited | adv | The height (in pixels) of the source currently loaded in the player, regardless of the size of the player. |\n| Source Height Initial | Integer | Limited | adv | Initial height (in pixels) of the source currently loaded in the player, regardless of the size of the player. Derived from the first value of the player_source_height dimension. |\n| Source Hostname | Text | Full | adv | The hostname of the video source, such as the CDN or media server. |\n| Source Width | Integer | Limited | adv | The width (in pixels) of the source currently loaded in the player, regardless of the size of the player. |\n| Source Width Initial | Integer | Limited | adv | Initial width (in pixels) of the source currently loaded in the player, regardless of the size of the player. Derived from the first value of the player_source_width dimension. |\n| Video Codec Initial | Text | Full | adv | Initial codec of the video that played. Derived from the first value of the video_codec dimension. |\n| Video Dynamic Range Type Initial | Text | Full | adv | Initial format or type of dynamic range available on the video that played. Derived from the first value of the video_dynamic_range_type dimension. |\n| Video Startup Failure | Boolean | Full | basic | Indicates whether the video failed to start due to an error. |\n| Video Startup Business Exception | Boolean | Full | adv | Indicates whether a business rule-related issue caused a video startup failure. |\n| View Dropped | Boolean | Full | adv | Boolean indicating whether the view was finalized without an explicit viewend event. |\n| View Has Ad | Boolean | Full | basic | Indicates whether the video view included an ad. |\n\nSet Metadata with Session Data\n\nMetadata is normally set using code in the SDK configuration. However, some video metadata can also be set using Session Data key/value pairs in the HLS manifest. This method makes it easier to communicate values to the Mux player SDK without having to side-channel information to the client or change client-side code in order to configure metadata for a view.\n\nSome common use cases where this is helpful are, for example, setting a view session id that comes from a backend system which can be used to associate a playback view with the requests that were made to a CDN or being able to easily capture which experiments a viewer is participating in without having to communicate that to the player.\n\nHLS Session Data, which is represented in an HLS master playlist using the EXT-X-SESSION-DATA tag, is a key/value pair that can be read by the player. When the master playlist is loaded into a video player integrated with a Mux Data SDK that supports extracting Session Data, the Session Data keys that use the io.litix.data prefix will be included in the Mux Data view as dimension metadata the same as if you had configured the value from the SDK configuration code.\n\n  This feature is intended for developers using their own custom video delivery pipeline. HLS Session Data is set by Mux Video when videos are viewed; injecting your own HLS Session Data into Mux Video content is not currently supported.\n\nThe Session Data tags are interpreted as follows from the master playlist:\n\n```text\nTag: #EXT-X-SESSION-DATA\nKey: DATA-ID=\"io.litix.data.[dimension_name]\"\nValue: VALUE=\"dimension value\"\n```\n\n\nThe dimension names available to be set from the master playlist:\n video_\n custom_\n experiment_name\n view_session_id\n viewer_user_id\n\nThe following is an example of Session Data tags in a master playlist:\n\n```text\n#EXTM3U\n#EXT-X-VERSION:7\n#EXT-X-INDEPENDENT-SEGMENTS\n\n#EXT-X-SESSION-DATA:DATA-ID=\"io.litix.data.experiment_name\",VALUE=\"abr_test:true\"\n#EXT-X-SESSION-DATA:DATA-ID=\"io.litix.data.view_session_id\",VALUE=\"12345ABCD\"\n\n#EXT-X-STREAM-INF:BANDWIDTH=2516370,AVERAGE-BANDWIDTH=2516370,CODECS=\"mp4a.40.2,avc1.640020\",RESOLUTION=1280x720\n...\n```\n\nThe Session Data tags contained in a master playlist would result in the Experiment Name dimension set to abr_test:true and View Session ID dimension set to 12345ABCD.\n\n  We're aware of a crash that may occur in AVPlayer Data SDK versions 2.12.0 - 3.5.0 when processing HLS Session Data that is prefixed with io.litix.data. AVPlayer Data SDK integrations that process HLS Session Data not prefixed with io.litix.data are not affected. Custom integrations that use the Objective-C MuxCore SDK and do not depend on the AVPlayer Data SDK are not affected.\n\niOS/Android Metadata\n\nIn iOS and Android SDKs, names are converted to lowerCamelCase setters and getters. For example, to set the Video Stream Type field in iOS or Android, use videoStreamType instead of video_stream_type.\n\nIn the Objective-C SDKs, options are provided via the MUXSDKCustomerPlayerData, MUXSDKCustomerVideoData, MUXSDKCustomerViewData, and MUXSDKCustomData objects. See the header directories in MuxCore.xcframework from the latest release for a complete list of names.\n\nIn the Java SDK, options are provided via the CustomerPlayerData, CustomerVideoData, and CustomData objects. Use your IDE to inspect these objects' API."
  },
  {
    "id": "58-_guides/developer/manage-stream-keys",
    "title": "Manage stream keys",
    "path": "_guides/developer/manage-stream-keys.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/manage-stream-keys",
    "content": "When live streaming, a stream key is used by a broadcaster to receive a live stream for a Mux account. Stream keys, by nature, are private and should be handled with care. This means that access to the stream key should be reserved for the broadcaster and hidden from end users.\n\n1. Use case - Single stream\n\nSingle live stream configurations are great for when only one stream will ever be active at a time, or for disposable, single-use live streams.\n\nFor example, if you are hosting a conference where the agenda is a back-to-back track of speakers, a single live stream is used in this scenario.\n\n2. Use case - Multiple streams\n\nCreating multiple live stream configurations are implemented in situations where multiple live streams are expected. Some reasons you might choose this live stream configuration would include—\n\n- Multiple concurrent streams that overlap in when they go live\n- User generated content where going live can happen at any time and there is no established schedule\n\nConcurrent live streams\n\nWhen working with multiple streams that can overlap in realtime, use multiple live stream configurations. Each live stream configuration can be tied to each live stream event.\n\nFor example, if you are hosting different concurrent events, each event would need an individual live stream configuration created.\n\nIf you want to control the ability to accept a live stream, you can use the enable live stream and disable live stream API endpoints. These endpoints can be called based on your business logic from your CMS/backend to control your content creator's ability to go live.\n\nUser generated content\n\nIf your solution allows your users to go live at any time, a live stream configuration for each potential content creator will need to be created. As you will see in the following, the Mux live stream configuration id will be tied to each content creator using your service.\n\nWhen provisioning your user as a content creator, create a live stream configuration that will be used solely by _this_ content creator. The data.id response value needs to be stored within your CMS so that it can be used to deliver the live stream to end users when the content creator goes live. A live stream configuration created for a content creator can be reused by that content creator over their life span.\n\nThe data.stream_key value _could_ also be stored in the CMS in case the content creator wants to recall the stream key at a later time.\n\nAnother option is to pass through the stream key to the content creator at provision time without storing the stream key. A common use-case that we support is for the ability to reset the stream key for a given live stream configuration. To do this, Mux offers a reset stream key API.\n\nAdvanced options\n\nReset stream key\n\nIf a stream key needs to be reset for a live stream configuration because it was lost or compromised, the reset stream key can be used to regenerate the stream key.\n\nComplete live stream\n\nTypically, when a content creator has end their live stream session by stopping a stream, Mux will wait for the duration configured for the live stream's reconnect_window before making it available as an on-demand asset.\n\nTo make a live stream available immediately, you can signal live stream complete to immediately make the live stream available as an on-demand asset.\n\n  Mux does not close the encoder connection immediately. Encoders are often\n  configured to re-establish connections immediately which would result in a new\n  recorded asset. For this reason, Mux waits for 60s before closing the\n  connection with the encoder. This 60s timeframe is meant to give encoder\n  operators a chance to disconnect from their end.\n\nEnable live stream\n\nTo enable a live stream configuration so that it is able to receive an RTMP session, call the enable live stream API endpoint.\n\n  By default, all newly created live stream configurations are enabled.\n\nDisable live stream\n\nShould you want to disable a live stream configuration so that it no longer accepts RTMP sessions, the disable live stream is used to achieve this use case.\n\n  Unlike signal live stream complete, Mux closes the encoder connection immediately with this API. Any attempt\n  from the encoder to re-establish the connection will fail until the live\n  stream is re-enabled."
  },
  {
    "id": "59-_guides/developer/minimize-processing-time",
    "title": "Minimize processing time",
    "path": "_guides/developer/minimize-processing-time.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/minimize-processing-time",
    "content": "Mux Video accepts most modern video formats and codecs. However, certain types of inputs need to be standardized in order for Mux to do further operations on them, and this can add time before the video is ready to be streamed. If you want to standardize your content before sending it to Mux, and potentially improve performance, this guide will show what you need to do.\n\nStandard input specs\n\nTo be considered standard input, the input video file must meet the following requirements:\n\n H.264 or HEVC video codecs. H.264 is the dominant video codec in use today and almost every device supports H.264. HEVC is a more modern codec that's increasingly popular, though not as universally supported. While Mux accepts other codecs as input, other codecs are considered non-standard and will be standardized automatically to H.264.\n Closed GOP (group-of-pictures). (Warning: video jargon ahead. You can likely ignore this) In video files encoded with a closed-GOP, all B frames reference other frames in the same GOP. Closed GOPs always begins with an IDR (Instantaneous Decoder Refresh) frame. This means that every GOP can be played independently, without reference to another GOP. Standard inputs must be encoded with a closed-GOP.\n 8-bit 4:2:0, or 10-bit 4:2:0 if HEVC. This refers to the color depth and chroma subsampling. If you don't know what this is, you can probably ignore this, since most streaming video is 8-bit 4:2:0. HDR usually uses 10-bit 4:2:0, which is only supported as standard when using the HEVC video codec. However, SDR is preferred as Mux does not provide full HDR support.\n Simple Edit Decision Lists. Edit Decision Lists (EDLs) are typically added during post-production and define how certain segments are used to build a track timeline for playback. A good example of a Simple Edit Decision List is to fix out of order frames in the video. Input files with more complex uses of EDLs are considered non-standard.\n AAC audio codec. AAC is the dominant audio codec in use today and almost every device supports this audio codec. While Mux accepts files that use other audio codecs, Mux only delivers AAC audio and non-AAC audio inputs are considered non-standard.\n\nAdditional requirements for assets with a max_resolution_tier of 1080p\n\nAssets ingested up to 1080p are subject to the following standard input requirements.\n\n 1080p/2K or smaller. Files with a resolution of up to 2048x2048 are considered standard. Files with a larger than this are considered non-standard, unless ingested with a higher max_resolution_tier.\n Max 20-second keyframe interval (10 seconds for HEVC). To stream well using HTTP-based streaming methods like HLS, Mux requires all keyframes intervals to be less than 20 seconds, or less than 10 seconds if encoded with HEVC.\n 8Mbps or below. While Mux accepts higher bitrate inputs, average bitrates higher than 8Mbps are generally challenging for most viewers' connections and are considered non-standard. The bitrate should not exceed 16Mbps for any single GOP.\n Frame rate between 5 and 120. Inputs with average frames per second (fps) less than 5 or greater than 120 is considered non-standard. Frame rates within this range will be preserved (e.g. 60 fps will remain 60 fps). Inputs with less than 5 fps or greater than 120 fps will be automatically standardized to 30 fps.\n\nAdditional requirements for assets with a max_resolution_tier of 2160p (4K)\n\nAssets ingested at 2K and 4K resolutions are subject to the following standard input requirements.\n\n 2160p or smaller. The input file must not have any dimension (width, height, or both) that exceeds 4096 pixels.\n Max 10-second keyframe interval (6 seconds for HEVC). To stream 4k video well, a 10 second keyframe interval is required. If using the HEVC video CODEC, this is further limited to 6 seconds.\n 20Mbps or below. While Mux accepts higher bitrate inputs, bitrates higher than 20Mbps are generally challenging for most viewers' connections.\n Frame rate between 5 and 60. For 4k videos, a frame rate above 60fps is considered non-standard.\n\nHow to create standard input (ffmpeg)\n\nAs a starting point, here is a sample ffmpeg command for creating video that complies with Mux standard input. Feel free to modify this by using things like 2-pass encoding, different presets, or different bitrates (as long as the total bitrate ends up below than 8Mbps).\n\n\n```shell\nffmpeg -i input.mp4 -c:a copy -vf \"scale=w=min(iw\\,1920):h=-2\" -c:v libx264 \\\n-profile high -b:v 7000k -g 239 -pix_fmt yuv420p -maxrate 16000k -bufsize 24000k out.mp4\n```\n\n\nStandard input for 4K\n\nIf you are creating a 4K video, the resolution and bitrate limits are higher. Here is a sample ffmpeg command for creating video that complies with Mux standard input for 4K.\n\n\n```shell\nffmpeg -i input.mp4 -c:a copy -vf \"scale=w=min(iw\\,4096):h=-2\" -c:v libx264 \\\n-profile high -b:v 18000k -g 239 -pix_fmt yuv420p -maxrate 36000k -bufsize 54000k out.mp4\n```\n\n\nHow to create standard input on mobile devices\n\n  Mux's iOS and Android upload SDKs are optimised to pre-process video files created on mobile devices to create standard input video files before uploading to Mux.\n\nMany mobile devices capture H.264 8-bit 4:2:0 video by default. More recent mobile devices increasing use HEVC 4:2:0 by default (either 8-bit with HDR disabled, or 10-bit with HDR enabled). Here are the main things to watch out for:\n\n Ensure that the total file bitrate is below 8 mbps.\n Prefer recording video in SDR (standard dynamic range). Some newer devices capture video in HDR (High Dynamic Range), which requires 10-bit 4:2:0 color. This is also acceptable, but may be more likely to exceed the limited bitrate to be considered standard input. If you have the choice, you should record SDR.\n Ensure the output file is smaller than 1080p (1920x1080) or 2K (2048x1152). Some cameras shoot 4K video, which by default is converted down to 1080p when using Mux Video. If you want to use 4K video, ensure you're enabling that in your API calls to Mux.\n* If possible, choose a keyframe interval of 5s or so, but certainly between 1 and 10 seconds, and enable closed-GOP encoding. (If you don't see these options in your app or camera, it's probably the default already.)\n\nNon-standard input\n\nMux Video works fine with video outside of the standard input specs. But because other videos cannot be easily streamed to many modern devices, Mux Video must perform an initial encoding operation on non-standard input to create a mezzanine file. This means that non-standard input will be slower to ingest.\n\nAs soon as Mux Video detects that the input file is non-standard, it emits the video.asset.non_standard_input_detected. This lets you know right away that your video will need additional processing time, along with the specific reasons why it's considered non-standard.\n\n\n```json\n{\n  \"type\": \"video.asset.non_standard_input_detected\",\n  \"data\": {\n    \"id\": \"{ASSET_ID}\",\n    \"status\": \"preparing\",\n    \"non_standard_input_reasons\": {\n      \"video_gop_size\": \"high\"\n    }\n    // ... other asset fields\n  }\n}\n```\n\n\n_Note that non_standard_input_reasons may not be finalized as additional reasons maybe found later and will be included on the asset after ingest completion._\n\nMux Video also exposes this information in all subsequent asset webhooks, including the video.asset.ready event. This information is also returned in the asset object when retrieved using the Get Asset API.\n\nUnderstanding the transcoding progress of a non-standard input\n\nWhen an asset needs additional processing, you can use the progress field from the Get Asset API response, which returns the current state of and, the completion percentage of a transocode.\n\n\n```json\n// GET /video/v1/assets/{ASSET_ID}\n{\n  \"id\": \"{ASSET_ID}\",\n  \"status\": \"preparing\",\n  \"non_standard_input_reasons\": {\n    \"video_gop_size\": \"high\"\n  },\n  \"progress\": {\n    \"state\": \"transcoding\",\n    \"progress\": 23.02\n  }\n  // ... other asset fields\n}\n```\n\n\nThis field tells you both the current processing state and an estimated completion percentage from 0 to 100, allowing you to keep your users informed with accurate progress indicators.\n\nThe progress field can have the following states:\n\n- transcoding: Asset is undergoing non-standard transcoding. progress will be between 0 and 100.\n- ingesting: Asset is being ingested (initial processing before or after transcoding). Progress will be 0.\n- errored: Asset has encountered an error (status is errored). Progress will be -1.\n- completed: Asset processing is complete (status is ready).  Progress will be 100.\n- live: Asset is a live stream currently in progress.  Progress will be -1.\n\nGeneral limits\n\nThe max duration for any single asset is 12 hours."
  },
  {
    "id": "60-_guides/developer/modify-playback-behavior",
    "title": "Modify playback behavior",
    "path": "_guides/developer/modify-playback-behavior.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/modify-playback-behavior",
    "content": "Playback modifiers are optional parameters added to the video playback URL. These modifiers allow you to change the behavior of the stream you receive from Mux.\n\nMux Video supports 2 different types of playback policies: public and signed. Playback modifiers are supported for both types of playback policies. However, the method to add them differs.\n\nQuery String with public playback URL\n\n```text\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?{MODIFIER_NAME}={MODIFIER_VALUE}\n```\n\nReplace PLAYBACK_ID with your asset's public policy playback ID. Replace MODIFIER_NAME and MODIFIER_VALUE with any of the supported modifiers listed below in this document.\n\nJWT Claim with signed playback URL\n\n\n```text\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?token={TOKEN}\n```\n\nReplace PLAYBACK_ID with your asset's signed policy playback ID and TOKEN with the signature generated. Add modifiers to your claims body in the JWT payload. View the guide for Secure video playback for details about adding query parameters to signed tokens.\n\nAvailiable playback modifiers\n\n| Modifier | Availiable Values | Default Value | Description |\n| :-- | :-- | :-- | :-- |\n| redundant_streams | true, false | false | Includes HLS redundant in the stream's manifest. See the Play your videos guide. |\n| roku_trick_play | true, false | false | Adds support for timeline hover previews on Roku devices. See the Create timeline hover previews guide.\n| default_subtitles_lang | A BCP47 compliant language code | none | Sets which subtitles/captions language should be set as the default. See the Subtitles guide guide.\n| max_resolution| 270p, 360p, 480p, 540p, 720p, 1080p, 1440p, 2160p | none | Sets the maximum resolution of renditions included in the manifest. See the Control playback resolution guide.|\n| min_resolution| 270p, 360p, 480p, 540p, 720p, 1080p, 1440p, 2160p | none | Sets the minimum resolution of renditions included in the manifest. See the Control playback resolution guide. |\n| rendition_order| desc | Automatically ordered by Mux's internal logic. | Sets the logic to order renditions by in the HLS manifest. See the blog post.|\n| program_start_time | An epoch timestamp | none | Sets the start time of the asset created from a live stream or live stream when using the instant clipping feature. |\n| program_end_time | An epoch timestamp | none | Sets the end time of the asset created from a live stream or live stream when using the instant clipping feature. |\n| asset_start_time | Time (in seconds) | none | Sets the relative start time of the asset when using the instant clipping feature. |\n| asset_end_time | Time (in seconds) | none | Sets the relative end time of the asset when using the instant clipping feature. |"
  },
  {
    "id": "61-_guides/developer/monitor-agnoplay-player",
    "title": "Monitor Agnoplay player service",
    "path": "_guides/developer/monitor-agnoplay-player.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-agnoplay-player",
    "content": "This integration is managed and operated by Agnoplay.\n  Feedback should be made through your Agnoplay representative https://agnoplay.com or info@agnoplay.com.\n\nEnvironment key\n\nContact Agnoplay\n\nContact your Agnoplay representative through https://agnoplay.com or info@agnoplay.com, and provide them with your environment key.\n\nWait for the magic\n\nThe Agnoplay support team will add your environment key to the configuration of Agnoplay instance, after which your Mux Data environment will be populated with data within minutes. That's all to it."
  },
  {
    "id": "62-_guides/developer/monitor-akamai-media-player",
    "title": "Monitor Akamai media player",
    "path": "_guides/developer/monitor-akamai-media-player.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-akamai-media-player",
    "content": "<CodeExamples\n  examples={{\n    npm: npm install --save @mux/mux-data-akamai,\n    yarn: yarn add @mux/mux-data-akamai,\n    cdn: `,\n  }}\n  exampleOrder=\"npm,yarn,cdn\"\n/>\n\nRegister the mux plugin with the akamai object.\n\nThe only required field in the data key that you pass into plugins.mux is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data on initialization.\n\n\n```js\nakamai.amp.AMP.create(\"#my-player\", {\n  // ... other player configuration\n  plugins: {\n    mux: {\n      resources: [\n        {src: \"http://src.litix.io/akamai/3/akamai-mux.js\", type: \"text/javascript\"},\n      ],\n      debug: false,\n      data: {\n        env_key: 'ENV_KEY', // required\n        // Site Metadata\n        viewer_user_id: '', // ex: '12345'\n        experiment_name: '', // ex: 'player_test_A'\n        sub_property_id: '', // ex: 'cus-1'\n        // Player Metadata\n        player_name: '', // ex: 'My Main Player'\n        player_version: '', // ex: '1.0.0'\n        // Video Metadata\n        video_id: '', // ex: 'abcd123'\n        video_title: '', // ex: 'My Great Video'\n        video_series: '', // ex: 'Weekly Great Videos'\n        video_duration: '', // in milliseconds, ex: 120000\n        video_stream_type: '', // 'live' or 'on-demand'\n        video_cdn: '' // ex: 'Fastly', 'Akamai'\n      }\n    }\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nNew source\n\n\n```js\n// player is the instance returned by the `akamai.amp.AMP.create` function\nplayer.mux.emit('videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\n// player is the instance returned by the `akamai.amp.AMP.create` function\nplayer.mux.emit('programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\nakamai.amp.AMP.create(\"#my-player\", {\n  // ... other player configuration\n  plugins: {\n    mux: {\n      resources: [\n        {src: \"http://src.litix.io/akamai/3/akamai-mux.js\", type: \"text/javascript\"},\n      ],\n      debug: false,\n      disableCookies: true,\n      data: {\n        env_key: 'ENV_KEY', // required\n        // Metadata\n        player_name: '', // ex: 'My Main Player'\n        // ... and other metadata\n      }\n    }\n  }\n});\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\nakamai.amp.AMP.create(\"#my-player\", {\n  // ... other player configuration\n  plugins: {\n    mux: {\n      resources: [\n        {src: \"http://src.litix.io/akamai/3/akamai-mux.js\", type: \"text/javascript\"},\n      ],\n      debug: false,\n      respectDoNotTrack: true,\n      data: {\n        env_key: 'ENV_KEY', // required\n        // Metadata\n        player_name: '', // ex: 'My Main Player'\n        // ... and other metadata\n      }\n    }\n  }\n});\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, @mux/mux-data-akamai will track errors emitted from the video element as fatal errors.\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n  };\n}\n\nakamai.amp.AMP.create(\"#my-player\", {\n  // ... other player configuration\n  plugins: {\n    mux: {\n      resources: [\n        {src: \"http://src.litix.io/akamai/3/akamai-mux.js\", type: \"text/javascript\"},\n      ],\n      debug: false,\n      respectDoNotTrack: true,\n      errorTranslator,\n      data: {\n        env_key: 'ENV_KEY', // required\n        // Metadata\n        player_name: '', // ex: 'My Main Player'\n        // ... and other metadata\n      }\n    }\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\nakamai.amp.AMP.create(\"#my-player\", {\n  // ... other player configuration\n  plugins: {\n    mux: {\n      resources: [\n        {src: \"http://src.litix.io/akamai/3/akamai-mux.js\", type: \"text/javascript\"},\n      ],\n      debug: false,\n      respectDoNotTrack: true,\n      automaticErrorTracking: false,\n      data: {\n        env_key: 'ENV_KEY', // required\n        // Metadata\n        player_name: '', // ex: 'My Main Player'\n        // ... and other metadata\n      }\n    }\n  }\n});\n```\n\n\nAds tracking with @mux/mux-data-akamai\n\nAd events are tracked automatically if your player is configured for ads. No additional configuration is needed.\n\nCustomize beacon collection domain\n\n\n```js\nakamai.amp.AMP.create(\"#my-player\", {\n  // ... other player configuration\n  plugins: {\n    mux: {\n      resources: [\n        {src: \"http://src.litix.io/akamai/3/akamai-mux.js\", type: \"text/javascript\"},\n      ],\n      // ... various configuration options\n      beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n      data: {\n        env_key: 'ENV_KEY', // required\n        // Metadata\n        player_name: '', // ex: 'My Main Player'\n        player_init_time: playerInitTime // ex: 1451606400000\n        // ... and other metadata\n      }\n    }\n  }\n});\n```\n\n\nCurrent release\n\nv3.11.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv3.11.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv3.11.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv3.11.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv3.11.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv3.11.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv3.11.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv3.11.7\n\n- Update mux-embed to v5.9.0\n\nv3.11.6\n\n- Update mux-embed to v5.8.3\n\nv3.11.5\n\n- Update mux-embed to v5.8.2\n\nv3.11.4\n\n- Update mux-embed to v5.8.1\n\nv3.11.3\n\n- Update mux-embed to v5.8.0\n\nv3.11.2\n\n- Update mux-embed to v5.7.0\n\nv3.11.1\n\n- Update mux-embed to v5.6.0\n\nv3.11.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv3.10.10\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv3.10.9\n\n- Update mux-embed to v5.4.2\n\nv3.10.8\n\n- Update mux-embed to v5.4.1\n\nv3.10.7\n\n- Update mux-embed to v5.4.0\n\nv3.10.6\n\n- Update mux-embed to v5.3.3\n\nv3.10.5\n\n- Update mux-embed to v5.3.2\n\nv3.10.4\n\n- Update mux-embed to v5.3.1\n\nv3.10.3\n\n- Update mux-embed to v5.3.0\n\nv3.10.2\n\n- Update mux-embed to v5.2.1\n\nv3.10.1\n\n- Update mux-embed to v5.2.0\n\nv3.10.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv3.9.0\n\n- Minor refactors to have strict typing and type inferences available.\n\n- Update mux-embed to v5.0.0\n\nv3.8.4\n\n- Update mux-embed to v4.30.0\n\nv3.8.3\n\n- Update mux-embed to v4.29.0\n\nv3.8.2\n\n- Update mux-embed to v4.28.1\n\nv3.8.1\n\n- Update mux-embed to v4.28.0\n\nv3.8.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv3.7.3\n\n- Update mux-embed to v4.26.0\n\nv3.7.2\n\n- Update mux-embed to v4.25.1\n\nv3.7.1\n\n- Update mux-embed to v4.25.0\n\nv3.7.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv3.6.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv3.5.5\n\n- Update mux-embed to v4.22.0\n\nv3.5.4\n\n- Update mux-embed to v4.21.0\n\nv3.5.3\n\n- Update mux-embed to v4.20.0\n\nv3.5.2\n\n- Update mux-embed to v4.19.0\n\nv3.5.1\n\n- Update mux-embed to v4.18.0\n\nv3.5.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv3.4.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv3.3.6\n\n- Update mux-embed to v4.15.0\n\nv3.3.5\n\n- Update mux-embed to v4.14.0\n\nv3.3.4\n\n- Update mux-embed to v4.13.4\n\nv3.3.3\n\n- Update mux-embed to v4.13.3\n\nv3.3.2\n\n- Update mux-embed to v4.13.2\n\nv3.3.1\n\n- Fixes an issue with accessing the global object\n- Update mux-embed to v4.13.1\n\nv3.3.0\n\n- Upgraded internal webpack version\n- Export a function to register the mux plugin with Akamai\n\n- Update mux-embed to v4.13.0\n\nv3.2.14\n\n- Publish package to NPM\n\nv3.2.13\n\n- Update mux-embed to v4.12.1\n\nv3.2.12\n\n- Update mux-embed to v4.12.0\n\nv3.2.11\n\n- Update mux-embed to v4.11.0\n\nv3.2.10\n\n- Update mux-embed to v4.10.0\n\nv3.2.9\n\n- Update mux-embed to v4.9.4\n\nv3.2.8\n\n- Update mux-embed to v4.9.3\n\nv3.2.7\n\n- Update mux-embed to v4.9.2\n\nv3.2.6\n\n- Update mux-embed to v4.9.1\n\nv3.2.5\n\n- Update mux-embed to v4.9.0\n\nv3.2.4\n\n- Fix an issue with removing player_error_code and player_error_message when the error code is 1.\n  Also stops emitting MEDIA_ERR_ABORTED as errors.\n- Update mux-embed to v4.8.0\n\nv3.2.3\n\n- Update mux-embed to v4.7.0\n\nv3.2.2\n\n- Update mux-embed to v4.6.2\n\nv3.2.1\n\n- Update mux-embed to v4.6.1\n\nv3.2.0\n\n- Bump mux-embed to 4.6.0\n\nv3.1.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv3.0.0\n\n- Update mux-embed to v4.1.1\n- Fix an issue where player_remote_played` would not be reported correctly"
  },
  {
    "id": "63-_guides/developer/monitor-android-media-player",
    "title": "Monitor Android MediaPlayer",
    "path": "_guides/developer/monitor-android-media-player.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-android-media-player",
    "content": "This documents integration instructions for Android's MediaPlayer class. This integration supports Android 4.2 (API level 17) and newer, though older versions of Android have spotty support for streaming protocols such as HLS and Dash.\n\nThe Mux integration with MediaPlayer is built on top of Mux's core Java SDK, and the full code can be seen here: muxinc/mux-stats-sdk-mediaplayer.\n\nThe easiest way to get the AAR is to download the latest version from: muxinc/mux-stats-sdk-mediaplayer releases.\n\nIf you would prefer to build it yourself, first clone the repo. Then, you can do one of the following:\n\n1. Open the project in Android Studio and build the release variant of the MuxMediaPlayer module. You can then Find the AAR in mux-stats-sdk-mediaplayer/MuxMediaPlayer/build/outputs/aar/MuxMediaPlayer-release.aar\n2. Build the AAR directly:\n\n\n```sh\n./gradlew :MuxMediaPlayer:assembleRelease\n```\n\n\nWe recommend using Android Studio's new module tool which can be accessed via File > New > New Module.... Select the Import .JAR/.AAR Package and then select the mux.aar that you downloaded or built. This should correctly configure the IDE as well as modify your build configuration (Gradle/Maven).\n\nFor an example integration, you can see the demo application within this repo which integrates Mux into the MediaPlayer demo application.\n\nFirst, create the CustomerPlayerData and CustomerVideoData objects as appropriate for your current playback, and be sure to set your ENV_KEY.\n\n\n```java\nimport com.mux.stats.core.models.CustomerPlayerData;\nimport com.mux.stats.core.models.CustomerVideoData;\n// ...\nCustomerPlayerData customerPlayerData = new CustomerPlayerData();\ncustomerPlayerData.setEnvironmentKey(\"ENV_KEY\");\nCustomerVideoData customerVideoData = new CustomerVideoData();\ncustomerVideoData.setVideoTitle(\"My great video\");\n```\n\n\nNext, Create the MuxStatsMediaPlayer object by passing your Android Context (typically your Activity), the MediaPlayer instance, a player name, and the customer data objects.\n\n\n```java\nimport com.mux.stats.sdk.muxstats.mediaplayer.MuxStatsMediaPlayer;\n...\nmuxStatsMediaPlayer = new MuxStatsMediaPlayer(this, player, \"demo-player\", customerPlayerData, customerVideoData);\n```\n\n\nIn order to correctly monitor if the player is full-screen, provide the screen size to the MuxStatsMediaPlayer instance.\n\n\n```java\nPoint size = new Point();\ngetWindowManager().getDefaultDisplay().getSize(size);\nmuxStatsMediaPlayer.setScreenSize(size.x, size.y);\n```\n\n\nIn order to determine a number of viewer context values as well as track the size of the video player, set the player view.\n\n\n```java\nmuxStatsMediaPlayer.setPlayerView(playerView);\n```\n\n\nTo allow MuxStatsMediaPlayer to listen for various MediaPlayer events, add it as a listener. MediaPlayer only allows single listeners, so if your activity or application also needs to listen to these events, use the helper methods to wrap your listener implementation with MuxStatsMediaPlayer's listener implementation.\n\n\n```java\nplayer.setOnCompletionListener(muxStatsMediaPlayer.getOnCompletionListener(myCompletionListener));\nplayer.setOnErrorListener(muxStatsMediaPlayer.getOnErrorListener(myErrorListener));\nplayer.setOnPreparedListener(muxStatsMediaPlayer.getOnPreparedListener(this));\nplayer.setOnInfoListener(muxStatsMediaPlayer.getOnInfoListener(null));  // No wrapped listener.\nplayer.setOnSeekCompleteListener(muxStatsMediaPlayer.getOnSeekCompleteListener(null));  // No wrapped listener.\nplayer.setOnVideoSizeChangedListener(muxStatsMediaPlayer.getOnVideoSizeChangedListener(myVideoSizeChangedListener));\n```\n\n\nFinally, when you are destroying the player, call the MuxStatsMediaPlayer.release() method.\n\n\n```java\nmuxStatsMediaPlayer.release()\n```\n\n\nMediaPlayer does not provide listener callbacks for all necessary events, so you must add explicit calls into MuxStatsMediaPlayer at the same time that certain MediaPlayer methods are invoked:\n\n start: view docs\n pause: view docs\n seekTo: view docs\n\nFor example, in the demo, a MediaController view is used to control the MediaPlayer instance, and the appropriate MuxStatsMediaPlayer methods are invoked in the\nMediaPlayerControl implementation used to link the two instances.\n\n\n```java\nprivate class MediaPlayerControl implements MediaController.MediaPlayerControl,\n        MediaPlayer.OnBufferingUpdateListener {\n    @Override\n    public void start() {\n        if (player != null) {\n            player.start();\n            muxStats.play();\n        }\n    }\n\n    @Override\n    public void pause() {\n        if (player != null) {\n            player.pause();\n            muxStats.pause();\n        }\n    }\n\n    @Override\n    public void seekTo(int pos) {\n        if (player != null) {\n            player.seekTo(pos);\n            muxStats.seeking();\n        }\n    }\n}\n```\n\n\nAfter you've integrated, start playing a video in your player. A few minutes after you stop watching, you'll see the results in your Mux data dashboard. Login to the dashboard and find the environment that corresponds to your env_key and look for video views.\n\nIn the MediaPlayer SDK, options are provided via the CustomerPlayerData and CustomerVideoData objects.\n\nAll metadata details except for envKey are optional, however you'll be able to compare and see more interesting results as you include more details. This gives you more metrics and metadata about video streaming, and allows you to search and filter on important fields like the player version, CDN, and video title.\n\nFor more information, see the Metadata Guide.\n\nChanging the video\n\nThere are two cases where the underlying tracking of the video view need to be reset. First, when you load a new source URL into an existing player, and second when the program within a singular stream changes (such as a program within a live stream).\n\nNote: You do not need to change the video info when changing to a different source of the same video content (e.g. different resolution or video format).\n\nNew Source\nWhen you change to a new video (in the same player) you need to update the information that Mux knows about the current video. Examples of when this is needed are:\n\n The player advances to the next video in a playlist\n* The user selects a different video to play\n\nThis is done by calling muxStatsMediaPlayer.videoChange(CustomerVideoData) which will remove all previous video data and reset all metrics for the video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nIt's best to change the video info immediately after telling the player which new source to play.\n\nNew Program (in single stream)\nIn some cases, you may have the program change within a stream, and you may want to track each program as a view on its own. An example of this is a live stream that streams multiple programs back to back, with no interruptions.\n\nIn this case, call muxStatsMediaPlayer.programChange(CustomerVideoData). This will remove all previous video data and reset all metrics for the video view, creating a new video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nError tracking\n\nBy default, Mux's integration with MediaPlayer automatically tracks fatal errors as thrown by MediaPlayer. In some applications, however, you may want to disable this and track errors on your own, especially if you have retry logic in your application to try to recover from errors that MediaPlayer encounters.\n\nIn this case, there are two things that you need to do:\n\n1. Turn off the automatic error tracking. To do this, call muxStatsExoPlayer.setAutomaticErrorTracking(false)\n2. When your application encounters a fatal error that you cannot recover from, call muxStatsExoPlayer.error(MuxErrorException e), including a message and a code.\n\nThe following is an example of firing a custom error.\n\n\n```java\n// Error code: integer value for the generic type of error that\n// occurred.\n// Error message: String providing more information on the error\n// that occurred.\n// For an example, the HTML5 video element uses the\n// following: https://developer.mozilla.org/en-US/docs/Web/API/MediaError\n// for codes and messages. Feel free to use your own codes and messages\nint errorCode = 1;\nString errorMessage = \"A fatal error was encountered during playback\";\nMuxErrorException error = new MuxErrorException(errorCode, errorMessage);\nmuxStatsMediaPlayer.error(error);\n```\n\n\nIt is important that you only trigger an error when the playback has to be abandoned or aborted in an unexpected manner, as Mux tracks fatal playback errors only.\n\nCurrent release\n\nv0.1.0\n - Initial integration with MediaPlayer"
  },
  {
    "id": "64-_guides/developer/monitor-androidx-media3",
    "title": "Monitor AndroidX Media3",
    "path": "_guides/developer/monitor-androidx-media3.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-androidx-media3",
    "content": "The Mux Data SDK for Media3 integrates Mux Data with Google's AndroidX Media3 SDK in order to integrate your video app with Mux Data. Our SDK consists of a set of open-source libraries capable of observing Media3 for events and data related to your customers' playback experience.\n\nThis guide will walk you through a basic integration with Mux Data and your Media3 app. You will add the Mux Data SDK to your project, integrate the SDK with your Media3 Player and if necessary, learn to customize our SDK's functionality based on your specific needs\n\nMost of this guide assumes you are using ExoPlayer, specifically, as opposed to a MediaController or a custom implementation of Player. Our SDK does offer support for players other than ExoPlayer, but this support is limited by the interface of Player and Player.Listener. You may supplement the data we are able to collect using your Player's specific APIs by overriding BaseMedia3Binding and supplying that object when you create your MuxStatsSdkMedia3<> for your custom player.\n\nAdd our repository to your Gradle project\n\nAdd Mux's maven repository to your gradle files. Newer projects require declaring this in settings.gradle, and older projects require it to be set in the project-level build.gradle.\n\nAdd a dependency for Mux Data\n\nAdd our library to the dependencies block for your app. Replace the string [Current Version] with the current version of the SDK from the releases page.\n\n<CodeExamples\n  examples={{\n    gradle_kts:\nimplementation(\"com.mux.stats.sdk.muxstats:data-media3:[Current Version]\")\n    ,\n    gradle_groovy:\nimplementation \"com.mux.stats.sdk.muxstats:data-media3:[Current Version]\"\n    ,\n  }}\n  exampleOrder=\"gradle_kts,gradle_groovy\"\n/>\n\nStay on a version of Media3\n\nBy default, we try to support the latest minor release of media3 with our SDK. That is, 1.0, 1.1, etc. When media3 updates, we update our data-media3 library to support the newest version. If you need an update to the Mux Data SDK, but can't update your media3 integration, you can use one of our -atX_Y variants. These variants of our Mux Data SDK receive all the same updates as the default version, but offer support for a specific version of media3.\n\nTo stay on a specific version of media3, add the appropriate version to the end of our artifactId. For example, to always use Media3 1.0.x, use the library at com.mux.stats.sdk.muxstats:data-media3-at_1_0:[Current Version]\n\n<CodeExamples\n  examples={{\n    gradle_kts:\n// Stay on media3 1.0 while getting the most-recent mux data\nimplementation(\"com.mux.stats.sdk.muxstats:data-media3-at_1_0:[Current Version]\")\n    ,\n    gradle_groovy:\n// Stay on media3 1.0 while getting the most-recent mux data\nimplementation \"com.mux.stats.sdk.muxstats:data-media3-at_1_0:[Current Version]\"\n    ,\n  }}\n  exampleOrder=\"gradle_kts,gradle_groovy\"\n/>\n\nOfficially Supported Media3 Versions\n\nWe try to support all production versions of media3. Currently, we support the following versions:\n\n 1.6.x\n 1.5.x\n 1.4.x\n 1.3.x\n 1.2.x\n 1.1.x\n 1.0.x\n\nTo monitor a Player, monitor it using monitorWithMuxData(). You must initialize your Mux Data integration with a valid Environment Key.\n\nIf your player is newly-created, it's best to do this at around the same time that you call prepare() or play(). Ideally, you should do it synchronously, either right before calling or right after you start preparing/playing.\n\nReusing Player instances\n\nIf your Player's state was IDLE before calling monitorWithMuxData() or enable(), you should follow the same advice as if you were working with a new Player instance: start monitoring either immediately before or right after calling prepare() and play(). When you start monitoring again, a new View will be created in Mux Data.\n\nThe easiest way to get your player into the IDLE state is to call stop(), though you'll have to call prepare() and play() again to start playing.\n\nIf you want to start monitoring a Player instance that was already created and prepared, you should start start monitoring via monitorWithMuxData() or enable() immediately after you start the player again or set a new MediaItem. When you attach a monitor to the Player in this case, a new View will be created in Mux Data. In this case, this order is important; you must monitor the player after setting a new MediaItem in order to properly count any buffering the player may do.\n\nYou can make your data more informative and actionable by supplementing it with data of your own. To supply this data, you can use the CustomerData object you created in Step 2.\n\nThose examples contain only a few of the fields available. For more information, see the Metadata Guide.\n\nAll metadata details are optional, however you'll be able to compare and see more interesting results as you include more details. This gives you more metrics and metadata about video streaming, and allows you to search and filter on important fields like the player version, CDN, and video title.\n\nCertain metadata can be collected automatically, such as the media title, source URL, and poster art.\n\nChanging the video\n\nThere are two cases where the underlying tracking of the video view needs to be reset: first, when you load a new source URL into an existing player, and second, when the program within a single media stream changes (such as a program within a live stream, described more below).\n\nNote: You do not need to change the video info when changing to a different source of the same video content (e.g. different resolution or video format).\n\nNew source\n\nWhen you change to a new video (in the same player) you need to update the information that Mux knows about the current video. Examples of when this is needed are:\n\n The player advances to the next video in a playlist\n The user selects a different video to play\n\nThis is done by calling muxStatsExoPlayer.videoChange(CustomerVideoData) which will remove all previous video data and reset all metrics for the video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nIt's best to change the video info immediately after telling the player which new source to play.\n\nNew program (in single stream)\n\nIn some cases, you may have the program change within a stream, and you may want to track each program as a view on its own. An example of this is a live stream that streams multiple programs back to back, with no interruptions.\n\nIn this case, call muxStatsExoPlayer.programChange(CustomerVideoData). This will remove all previous video data and reset all metrics for the video view, creating a new video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nManually set when a video is being played full-screen\n\nFor most use cases, the SDK is capable of detecting whether or not a video is being played full-screen. Specifically, it can do so in the case where the player view is the same size as the device display (excepting ActionBars and other framework window decoration).\n\nFor other uses cases (non-overlaid controls, window decoration via plain Views, etc) you may need to tell the SDK when the user switches to full-screen.\n\nIf you are using SimplePlayerView or a similar ExoPlayer UI component, you can set the full-screen flag from the OnFullScreenModeChangedListener.\n\n\n```kotlin\n  override fun onCreate(savedInstanceState: Bundle?) {\n    super.onCreate(savedInstanceState)\n\n    // If you are using SimplePlayerView, StyledPlayerView, etc\n    playerView = findViewById(R.id.my_player_view)\n\n    playerView.setFullscreenButtonClickListener { isFullScreen ->\n      // Set presentation based on which mode is requested\n      if(isFullScreen) {\n        muxStats.presentationChange(MuxSDKViewPresentation.FULLSCREEN)\n      } else {\n        muxStats.presentationChange(MuxSDKViewPresentation.NORMAL)\n      }\n      // Handle moving to fullscreen playback with your code\n    }\n  }\n```\n\n\nError tracking\n\nBy default, Mux's integration with ExoPlayer automatically tracks fatal errors as thrown by ExoPlayer. If a fatal error happens outside the context of ExoPlayer and you want to track it with Mux, you can call muxStats.error(MuxErrorException) like this:\n\n\n```kotlin\n// Error code: integer value for the generic type of error that\n// occurred.\n// Error message: String providing more information on the error\n// that occurred.\n// For an example, the HTML5 video element uses the\n// following: https://developer.mozilla.org/en-US/docs/Web/API/MediaError\n// for codes and messages. Feel free to use your own codes and messages\nval errorCode = 1\nval errorMessage = \"A fatal error was encountered during playback\"\nval errorContext = \"Additional information about the error such as a stack trace\"\nval error = MuxErrorException(errorCode, errorMessage, errorContext)\nmuxStats.error(error)\n```\n\nNote that error(MuxErrorException e) can be used with or without automatic error tracking. If your application has retry logic that attempts to recover from ExoPlayer errors then you may want to disable automatic error tracking like this:\n\n\n```kotlin\nmuxStats.setAutomaticErrorTracking(false)\n```\n\n\nIt is important that you only trigger an error when the playback has to be abandoned or aborted in an unexpected manner, as Mux tracks fatal playback errors only.\n\nUsage with Google Interactive Media Ads (IMA)\n\nThe Mux Data SDK for Media3 can observe events that occur during Ad playback. To enable this functionality, you need to attach an instance of MuxStatsSdkMedia3 to your ImaAdsLoader.\n\nThe Mux Data SDK must take over the AdErrorListener and AdEventListener of your loader, but you can supply your own listeners, as shown in the example.\n\nFist, add Mux's Media3 IMA Extension to your build:\n\n<CodeExamples\n  examples={{\n    gradle_kts:\n// in your app's dependencies\nimplementation(\"com.mux.stats.sdk.muxstats:data-media3-ima:0.7.1\")\n    ,\n    gradle_groovy:\n// in your app's dependencies\nimplementation \"com.mux.stats.sdk.muxstats:data-media3-ima:0.7.1\"\n    ,\n  }}\n  exampleOrder=\"gradle_kts,gradle_groovy\"\n/>\n\nThen, use the extension to monitor your IMA integration.\n\n<CodeExamples\n  examples={{\n    kotlin:\nval newPlayer = ExoPlayer.Builder(this)\n  .setMediaSourceFactory(DefaultMediaSourceFactory(DefaultDataSource.Factory(this))\n  .setLocalAdInsertionComponents({ adsLoader }, view.playerView))\n  // ... rest of builder calls\n  .build()\nval customerData = CustomerData()\n// optionally, set properties on CustomerData\n\nmuxStats = newPlayer.monitorWithMuxData(context, DATA_ENV_KEY, customerData)\nadsLoader = ImaAdsLoader.Builder(this)\n  // ... rest of builder calls\n  .monitorWith(\n    muxStats = muxStats!!,\n    customerAdErrorListener = ,\n    customerAdEventListener = ,\n  )\n  .build()\nadsLoader.setPlayer(newPlayer)\n    ,\n    java:\nExoPlayer player = new ExoPlayer.Builder(this)\n    // ... Add IMA components\n    .build();\n\nMuxStatsSdkMedia3 muxStats =\n    new MuxStatsSdkMedia3<>(\n        / context = / this,\n        / envKey = / \"YOUR MUX DATA ENV KEY HERE\",\n        / customerData = / myCustomerData, // Populated as in Step 2 of the guide\n        / player = / player,\n        / playerView = / playerView,\n        / playerBinding = / new ExoPlayerBinding()\n    );\n\nMuxImaAdsListener muxAdsListener = MuxImaAdsListener.newListener(\n    muxStats,\n    adEvent -> {}, // If you have handling logic for AdEvents, put it here\n    adError -> {} // If you have handling logic for Ad Errors, put it here\n);\nadsLoader = new ImaAdsLoader.Builder(this)\n    .setAdErrorListener(muxAdsListener)\n    .setAdEventListener(muxAdsListener)\n    // Set up rest of AdsLoader\n    .build();\nadsLoader.setPlayer(player);\n    ,\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nManually set the screen orientation\n\nThe Mux SDK supports sending an event when the playback orientation changes. You can trigger this by calling muxStatsExoPlayer.orientationChange(MuxSDKViewOrientation orientation), passing either MuxSDKViewOrientation.LANDSCAPE or MuxSDKViewOrientation.PORTRAIT depending on the current orientation of the player.\n\nIf you are updating from our ExoPlayer SDK, you have to do a short migration. The migration steps below should get you building again:\n\n1. Change your Mux Data SDK dependency to implementation \"com.mux.stats.sdk.muxstats:data-media3:1.0.0\"\n1. Change all mentions of MuxStatsExoPlayer to MuxStatsSdkMedia3\n1. If you are using java, add new ExoPlayerBinding() to the end of the parameters you set when creating your muxStats.\n1. If you are using the IMA Ads SDK: You will need to rewrite your integration as explained in Step 4 of this guide.\n\nCurrent release\n\nv1.10.0\nUpdates:\n Add (incubating) playbackModeChange API methods to MuxStatsSdkMedia3.\n Add cumulative ad playing time and total content time metric tracking. The metrics track the \"wall-clock\" time spent with video playing during a view, excluding buffering, seeking, and startup time.\n library-ima: Detect the type of ad being played (preroll, midroll, or postroll)\n\nInternal lib updates:\n Update stats.muxcore to 8.6.0\n Update stats.android to 1.5.0\n\nPrevious releases\n\nv1.9.0\nImprovements:\n Update Kotlin version from 1.9 to 2.2.10. This should be a backward-compatible change, but please reach out if you see issues\n\nInternal Lib Updates:\n Update stats.muxcore to v8.5.2\n\nv1.8.1\nUpdates:\n Add support for media3 v1.8\n\nFixes:\n Un-deprecate CustomerVideoData.videoCdn\n\nInternal lib updates:\n Update stats.muxcore to v8.5.1\n\nv1.8.0\n\nUpdates:\n Add automatic CDN-change detection, assuming your CDN is sending x-cdn response headers\n Improved Request Metrics tracking\n\nInternal lib updates:\n Update stats.muxcore to v8.5.0\n\nv1.7.4\nImprovements:\n fix: AbstractMethodError in some apps\n\nv1.7.3\nImprovements:\n fix: viewerClientApplicationName and viewerClientApplicationVersion not reported\n\nInternal lib updates:\n Update sdk.android to v1.4.10\n Update muxstats.java to v8.4.1\n This update also makes sdk:android and muxstats.java peers of each other. Previously, sdk.android depended on muxstats.java. This should be an internal-only change, but it's noted here in case you are tracking transitive dependencies in your build workflows\n\nv1.7.2\nImprovements:\n Add support for media3 v1.6.0\n\nFixes:\n fix: when showing multiple Players simultaneously, each should be counted as a separate view\n\nInternal Lib Updates:\n Update muxstats:android to v1.4.9\n\nv1.7.1\nUpdates\n Add CustomerVideoData::videoCreatorId\n\nInternal lib updates:\n update muxstats.java to v8.4.0\n Update sdk:android to v1.4.8\n\nv1.7.0\nUpdates\n Add more Standard Dimensions\n\nInternal lib updates:\n Update stats.muxcore to v8.3.0\n Update muxstats.android to v1.4.7\n\nv1.6.3\nImprovements:\n Adds 10 more custom dimension slots for media customers\nInternal lib updates:\n Update stats.android to v1.4.6 and stats.muxcore to v8.2.0\n\nv1.6.2\nImprovements:\n update: add support for media3 1.5.x\n fix: content renditionchanges during ad breaks must be deferred until after the ad break\n\nInternal lib updates:\n update android to v1.4.5\n update muxstats.core to v8.4.1\n\nv1.6.1\nImprovements:\n fix: suppress some ad events when outside of an ad break\n fix: dropped frames not tracked\n\nInternal Library Updates:\n Update muxstats-android to v1.4.4\n\nv1.6.0\nUpdates:\n Better tracking of ad events. If you are using a VideoPlayerAdCallback supply it to ImaAdsLoader.monitorWith\n\nFixes:\n fix rebuffering not ended when seeking starts\n fix verbose logging causing bad views in some cases\n\nInternal lib updates:\n Update stats.java to 8.1.2\n Update muxstats.android to 1.4.2\n\nv1.5.2\nFixes:\n fix: media3 version reported as, eg, 1.2.x instead of the real version\n\nImprovements:\n Add support for media3 v1.4\n Handle nonfatal codec exceptions on API 21+\n\nInternal lib updates:\n Update android lib 1.4.0\n Update stats.java lib to 8.1.0\n Remove kt-utils from the dependencies. It is no longer required\n\nv1.5.1\nImprovements:\n fix: incorrect startup time after enable, disable, and videoChange\n\nv1.5.0\nImprovements:\n Update Android Core to 1.3.0\n misc. local build updates\n\nv1.4.0\nNew:\n Expose parameter to control logging level when initializing monitoring\n\nv1.3.2\n fix: incorrect screen resolution reported in some cases\n Update to Mux Android Core 1.2.2\n Update to Mux Java Core 8.0.2\n\nv1.3.1\nUpdates:\n update: Add support for media3 1.3.0\n\nFixes:\n fix: reported app hang due to event handling during beacon dispatch\n fix: crash when exoplayer HLS module not used\n\nImprovements:\n Update Android Core to v1.2.1\n Update Java Core to v8.0.1\n\nv1.3.0\nNew:\n MuxErrorException now allows you to report non-fatal and business-related errors\n\nImprovements:\n update: Updated MuxCore to version 8.0.0\n update: Updated Android Core to version 1.2.0\n\nFixes:\n fix: renditionchange sent in situations where rendition was only reset\n fix: Capture IMA CSAI media failures with LOG events\n fix: rebuffering percentage inflated if client ads fail to load\n\nv1.2.2\n\nFixes:\n fix: populate ad data even for non-preroll ads\n fix: seeking time included in time-to-first frame if user seeks before play starts\n\nImprovements:\n remove extraneous androidx deps from the exoplayer lib (they are still required if using IMA)\n\nv1.2.1\n\nUpdates:\n add support for media3 v1.2.x\n\nv1.2.0\n\nUpdates:\n add support for media3 v1.2.x\n\nv1.1.0\n\nUpdates:\n Expose IDevice and INetworkRequest for injection, as with the other player sdks\n\nv1.0.3\n\nUpdates:\n update: Update compileSdkVersion and targetSdkVersion to 34.\n\nv1.0.2\n\nFixes:\n fix: SSAI Ad events not properly reported\n\nv1.0.1\n\nFixes:\n fix: setting playWhenReady to true while READY sends play but not playing\n\nImprovements:\n Update to Core 1.0.1 - Fixes handling of leaving ads by seeking out of them\n\nv1.0.0\nNew:\n Update this SDK to v1.0.0 (🎉)\n\nFixes:\n fix: Custom Domain implementation POSTs to wrong URL\n fix: viewstart may not be sent if monitor attached while idle && playWhenReady == true\n\nv0.8.0\nImprovements:\n feat: Detect Title, Source URL, and Poster Art"
  },
  {
    "id": "65-_guides/developer/monitor-avplayer",
    "title": "Monitor AVPlayer",
    "path": "_guides/developer/monitor-avplayer.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-avplayer",
    "content": "Mux Data integration for AVPlayer supports applications running on iOS 12.0 or newer, tvOS 12.0 or newer, and Mac Catalyst that use AVPlayerViewController, AVPlayerLayer, or a standalone AVPlayer playing audio or if presented with a fixed size. Applications running on visionOS 1.0 and higher are also supported if they use AVPlayerViewController or a standalone AVPlayer playing audio or if presented with a fixed size.\n\nThis integration uses Mux's core Objective-C SDK and the full source can be seen here: muxinc/mux-stats-sdk-avplayer. This SDK is packaged as an xcframework.\n\nInstallation\n\nInstalling in Xcode with Swift Package Manager\n\n1. In Xcode click \"File\" > \"Swift Packages\" > \"Add Package Dependency...\"\n2. The package repository URL is https://github.com/muxinc/mux-stats-sdk-avplayer.git\n\n\n```\nhttps://github.com/muxinc/mux-stats-sdk-avplayer.git\n```\n\n\n3. Click Next.\n4. Since the MUXSDKStats follows SemVer, we recommend setting the \"Rules\" to install the latest version and choosing the option \"Up to Next Major\". Here's an overview of the different SPM Dependency Rules and their semantics.\n\nInstalling in Package.swift\n\nOpen your Package.swift file, add the following to dependencies:\n\n\n```swift\n    .package(\n      url: \"https://github.com/muxinc/mux-stats-sdk-avplayer\",\n      .upToNextMajor(from: \"4.0.0\")\n    ),\n```\n\n\nNote that MUXSDKStats has a dependency on MuxCore, so you will see that MuxCore gets installed as well.\n\n> As of Xcode 14.3.1 integrating the Mux SDKs as part of a shared framework using Swift Package Manager library targets is now supported. An example for setting this up is available here.\n\nInstalling with CocoaPods\n\nTo install with CocoaPods, modify your Podfile to use frameworks by including use_frameworks! and then add the following pods to your Podfile:\n\n\n```\npod 'Mux-Stats-AVPlayer', '~>4.0'\n```\n\n\nThis will install Mux-Stats-AVPlayer and the latest current release of our core Objective-C Library.\n\nNext, add correct import statement into your application.\n\nInstalling static library SDK package\n\nTo install the SDK using a static library package:\n\n1. Download the static SDK package MUXSDKStats-static.xcframework.zip attached to the version you'd like to install from the releases here.\n2. Download MuxCore-static.xcframework.zip whose version matches the package from step 1 from the releases here. Use the chart below to find the matching version.\n3. Unzip both MUXSDKStats-static.xcframework.zip and MuxCore-static.xcframework.zip, then drag and drop both MUXSDKStats.xcframework and MuxCore.xcframework to your Xcode project.\n4. Add MUXSDKStats and MuxCore to the application or framework target that will depend on them.\n5. Make sure that both MUXSDKStats and MuxCore are listed in your targets Frameworks, Libraries, and Embedded Content section in the General panel. Both need to include Embed & Sign under the Embed column.\n6. In that same targets Build Phases panel make sure both MUXSDKStats and MuxCore are present and include Required under the Status column.\n\nPackage versions\n\n| MUXSDKStats  | MuxCore |\n| ------------ | ------- |\n| v4.3.0       | v5.2.0  |\n| v4.2.0       | v5.1.2  |\n| v4.1.2       | v5.1.2  |\n| v4.1.1       | v5.1.1  |\n| v4.1.0       | v5.1.0  |\n| v4.0.0       | v5.0.1  |\n| v3.6.2       | v4.7.1  |\n| v3.6.1       | v4.7.1  |\n| v3.6.0       | v4.7.0  |\n\nThe example below uses monitorAVPlayerViewController. If you are using AVPlayerLayer, use monitorAVPlayerLayer instead.\n\nThe playerName parameter is a string that identifies this instance of your player. When calling destroyPlayer or videoChangeForPlayer later on, you will need this string. Each instance of a player that runs simultaneously in your application should have a different playerName.\n\nIf you are using SwiftUI, attach the monitor in the onAppear action for your view. This ensures that the Mux Data SDK is able to get the dimensions of the view which is used to calculate video quality metrics.\n\nFor more complete examples check the 3 demo apps in the repo. There is one demo app for iOS objective-c, one for iOS swift and another one for tvOS.\n\nAfter you've integrated, start playing a video in your player. A few minutes after you stop watching, you'll see the results in your Mux data dashboard. Login to the dashboard and find the environment that corresponds to your env_key and look for video views.\n\nThe only required field is env_key. But without some more metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nMetadata fields are provided via the MUXSDKCustomerPlayerData and MUXSDKCustomerVideoData objects.\n\nFor the full list of properties view the header files for this interfaces:\n\n- MUXSDKCustomerPlayerData.h\n- MUXSDKCustomerVideoData.h\n\nFor more details about each property, view the Make your data actionable guide.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call monitorAVPlayer. Then, once you have the metadata, you can update the metadata with either the setCustomerPlayerData or updateCustomerDataForPlayer methods.\n\nChanging the Video\n\nThere are two cases where the underlying tracking of the video view need to be reset. First, when you load a new source URL into an existing player, and second when the program within a singular stream changes (such as a program within a live stream).\n\nNote: You do not need to change the video info when changing to a different source of the same video content (e.g. different resolution or video format).\n\nNew source\nWhen you change to a new video (in the same player) you need to update the information that Mux knows about the current video. Examples of when this is needed are:\n\n The player advances to the next video in a playlist\n The user selects a different video to play\n\nThis is done by calling videoChangeForPlayer: which will remove all previous video data and reset all metrics for the video view. You can include any metadata when changing the video but you should only need to update the values that start with video_.\n\nIt is required to call videoChangeForPlayer: immediately before telling the player which new source to play. This recommendation changed in v1.2.0.\n\nIt is also required to call player.play after replacing the current item.\n\nIf you have new player data you instead call videoChangeForPlayer.\n\n\n```swift\n// Example of changing the AVPlayerItem\n\nlet videoData = MUXSDKCustomerVideoData()\nvideoData.videoId = \"abcd123\"\nvideoData.videoTitle = \"My Great Video\"\nvideoData.videoSeries = \"Weekly Great Videos\"\nvideoData.videoDuration = 120000 // in milliseconds\nvideoData.videoIsLive = false\nvideoData.videoCdn = \"cdn\"\nMUXSDKStats.videoChange(forPlayer: \"AVPlayer\", with: videoData)\n\nplayer.replaceCurrentItem(with: AVPlayerItem(url: url!))\n// calling `play()` here is necessary\nplayer.play()\n```\n\n\nNew program (in single stream)\nIn some cases, you may have the program change within a stream, and you may want to track each program as a view on its own. An example of this is a live stream that streams multiple programs back to back, with no interruptions.\n\nIn this case, call programChangeForPlayer:withCustomerData:. This will remove all previous video data and reset all metrics for the video view, creating a new video view. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nUsage with Google Interactive Media Ads (IMA)\n\nIf you are using Google Interactive Media Ads, and specifically either the iOS SDK GoogleAds-IMA-iOS-SDK or the tvOS SDK GoogleAds-IMA-tvOS-SDK then we have another\nplugin library that integrates tracking of ad playback events. You should have a fully functioning Google Ads IMA integration working in your iOS or tvOS application first.\n\nThe v0.14.0 and higher releases of the Mux Google Ads IMA plugin expose a new API. If you've already integrated an earlier version documentation is available to migrate to the new API.\n\nInstallation\n\nSwift Package Manager\n\nInstalling in Xcode with Swift Package Manager\n\n1. In Xcode click \"File\" > \"Swift Packages\" > \"Add Package Dependency...\"\n2. The package repository URL is https://github.com/muxinc/mux-stats-google-ima.git\n\nInstalling as a dependency in Package.swift manifest\n\nIn order to install in your iOS application open your Package.swift file, add the following to dependencies:\n\n\n```swift\n.package(\n  url: \"https://github.com/muxinc/mux-stats-google-ima\",\n  .upToNextMajor(from: \"0.14.0\")\n)\n```\n\n\nCocoapods\n\nThe Mux Google IMA plugin is available through CocoaPods. To install it, add the following line to your Podfile:\n\n\n```ruby\npod 'Mux-Stats-Google-IMA'\n```\n\n\nSteps for new IMA integrations\n\n1. Import the SDK: import MuxStatsGoogleIMAPlugin in Swift  import  in Objective-C\n2. After initializing the Mux monitor with monitorAVPlayerViewController or monitorAVPlayerLayer, save this value to a variable (below it's called playerBinding)\n3. Create an adListener instance using the playerBinding you created above and your applications IMA ads loader by calling MUXSDKIMAAdListener(playerBinding: playerBinding!, monitoringAdsLoader: yourAdsLoader).\n4. Add IMAAdsManager monitoring by calling adListener.monitorAdsManager(yourIMAAdsManager)\n5. Notify adListener when you send your ad request\n   For client-side ads, the most common case, use imaListener.clientAdRequest(yourIMAAdsRequest) to forward each IMAAdsRequest you initiate\n   For server-side ads using Dynamic Ad Insertion, use imaListener.daiAdRequest(yourIMAStreamRequest) to forward each IMAAdsRequest you initiate\n6. MUXSDKIMAAdListener will automatically intercept IMAAdsLoader and IMAAdsManager delegate calls\n\nSteps to migrate existing IMA integration to new API\n\n1. Replace calls to MuxImaLister with MUXSDKIMAAdListener. MuxImaListener supports the same new API so this step is optional, the remaining steps are applicable to MuxImaListener. As of v0.14.0MuxImaLister is deprecated and will be removed in a future release.\n2. Supply an IMAAdsLoader when calling the MUXSDKIMAAdListener initializer. Make sure your IMAAdsLoader delegate is configured before this step.\n3. MUXSDKIMAAdListener will forward IMAAdsLoaderDelegate calls to your delegate.\n4. When you've created a new IMAAdsManager, like you've done with IMAAdsLoader, configure your own  IMAAdsManagerDelegate first and then call monitorAdsManager.\n5. MUXSDKIMAAdListener will forward IMAAdsManagerDelegate calls to your delegate.\n6. Remove calls to dispatchEvent, dispatchError, and onContentPauseOrResume from your integration.\n\nIf you have enabled Picture in Picture support and are using the IMAPictureInPictureProxy, you will need an additional step in order to track ad related metrics correctly.\n\nFor a complete example project written in Swift with UIKit, check out the Example/DemoApp folder of muxinc/mux-stats-google-ima\n\nYou can find more examples in the \"/Examples\" directory of muxinc/mux-stats-sdk-avplayer on GitHub. All of these apps have examples with Google IMA ads. video-demo is an iOS app written in Swift and TVDemoApp is a TVOS app written in objective-c\n\nTrack orientation change events\n\nAs of 1.3.0 Mux-Stats-AVPlayer can optionally track orientationchange events. To use this functionality, call the orientationChangeForPlayer method.\n\nThese events will show up on the events log on the view views page.\n\nUsage with AVQueuePlayer\n\nTo use with AVQueuePlayer  you will need to follow these steps:\n\n1. Listen for AVPlayerItemDidPlayToEndTime in your application\n2. When that notification fires, call videoChangeForPlayer:withVideoData\n\nHere is an example that sets up a AVQueuePlayer with two items, and listener after the first item finishes playing and passes in new videoData.\n\n\n```swift\nlet playName = \"iOS AVPlayer\"\n\noverride func viewDidLoad() {\n    super.viewDidLoad()\n\n    let item1 = AVPlayerItem(url: URL(string: \"https://stream.mux.com/jY02nK1sxQKmJiQ7ltXY01w9LZQWdtNetE.m3u8\")!)\n    let item2 = AVPlayerItem(url: URL(string: \"https://bitdash-a.akamaihd.net/content/sintel/hls/playlist.m3u8\")!)\n    NotificationCenter.default.addObserver(\n        self,\n        selector: #selector(self.playerItemDidReachEnd),\n        name: NSNotification.Name.AVPlayerItemDidPlayToEndTime,\n        object: item1\n    )\n    player = AVQueuePlayer(items: [item1, item2])\n\n    let playerData = MUXSDKCustomerPlayerData(environmentKey: \"ENV_KEY\");\n    playerData?.playerName = \"AVPlayer\"\n    let videoData = MUXSDKCustomerVideoData();\n    videoData.videoIsLive = false;\n    videoData.videoTitle = \"Title1\"\n    MUXSDKStats.monitorAVPlayerViewController(self, withPlayerName: playName, playerData: playerData!, videoData: videoData);\n    player!.play()\n}\n\n@objc func playerItemDidReachEnd (notification: NSNotification) {\n    let videoData = MUXSDKCustomerVideoData();\n    videoData.videoTitle = \"Title2\"\n    videoData.videoId = \"applekeynote2010-2\"\n    MUXSDKStats.videoChange(forPlayer: playName, with: videoData)\n}\n```\n\n\nOverriding device metadata\n\nBy default, the Mux Data SDK for iOS collects data about your users' device to report on the dashboard. If you wish to provide your own device metadata, you can use CustomerViewerData to override the detected values.\n\nHandling errors manually\n\nBy default, automaticErrorTracking is enabled which means the Mux SDK will catch errors that the player throws and track an error event. Error tracking is meant for fatal errors. When an error is thrown it will mark the view as having encountered an error in the Mux dashboard and the view will no longer be monitored.\n\nIf you want to disable automatic and track errors manually you can do by passing in automaticErrorTracking: false to the monitor method that you are using.\n\nWhether automatic error tracking is enabled or disabled, you can dispatch errors manually with dispatchError.\n\nError Categorization\n\nSet custom error metadata to distinguish between fatal errors or warnings and classify errors as playback failures or business exceptions. Errors categorized as warnings or as business exceptions are not considered playback failures, meaning these errors are excluded from alerting, giving a more accurate picture of the health of your system with less noise from alerts. You can find more general information on Error Categorization here.\n\nThis is an example of how to categorize an error event to be a warning.\n\nThis is an example of how to categorize an error event as a business exception.\n\n\n```objc\n// Call this method from the source of the business exception with parameters appropriate to your integration.\n- (void)dispatchBusinessExceptionWithPlayerName:(NSString *)playerName\n                                  playerErrorSeverity:(MUXSDKErrorSeverity)errorSeverity\n                                  playerErrorCode:(NSString *)playerErrorCode\n                                  playerErrorMessage:(NSString *)playerErrorMessage\n                                  playerErrorContext:(NSString *)playerErrorContext {\n  [MUXSDKStats dispatchError: playerErrorCode,\n                 withMessage: playerErrorMessage,\n                    severity: MUXSDKErrorSeverityWarning,\n         isBusinessException: YES,\n                errorContext: playerErrorContext,\n                   forPlayer: playerName];\n}\n```\n\n\nInstalling manually with Carthage (not recommended)\n\nThe recommended way to install the Mux SDKs is with CocoaPods. However, if you want to install manually via Carthage that is supported only for version 1.x of Mux-Stats-AVPlayer.\n\nIf you are installing Mux-Stats-AVPlayer your Cartfile will also need to specify the mux-core library. Like this:\n\n\n```\nbinary \"https://raw.githubusercontent.com/muxinc/mux-stats-sdk-avplayer/master/MUXSDKStats.json\"\nbinary \"https://raw.githubusercontent.com/muxinc/stats-sdk-objc/master/MUXCore.json\"\n```\n\n\nAfter running carthage update --platform iOS follow the usual instructions for linking the frameworks. The Carthage README on GitHub walks through that and this guide is a good walk-through.\n\n---\n\nIf you are using the Google IMA integration there are a few extra steps. Your Cartfile will have these dependencies:\n\n\n```\nbinary \"https://raw.githubusercontent.com/muxinc/mux-stats-sdk-avplayer/master/MUXSDKStats.json\"\nbinary \"https://raw.githubusercontent.com/muxinc/stats-sdk-objc/master/MUXCore.json\"\ngithub \"muxinc/mux-stats-google-ima\" ~> 0.16.0\n```\n\n\nIn addition to specifying these dependencies in the Cartfile and linking them up, you will also need to follow Google's documentation for \"Manually, using the SDK download\".\n\n---\n\nApp Store warning: ITMS-90809: Deprecated API Usage\n\nIt has come up a few times that users of our iOS library get this warning from Apple.\n\n> Apple will stop accepting submissions of apps that use UIWebView APIs . See https://developer.apple.com/documentation/uikit/uiwebview for more information.\n\nIf you run grep -r \"UIWebView\" . in your project you will see a match coming from the dSYM/ directory in Mux-Core. At first glance, we too thought our SDK was triggering this warning.\n\nHowever, after looking into this with several different applications we found that the warning was not being triggered by our SDK. In every case it was coming from another 3rd party.\n\nNote that none of the Mux iOS libraries (including Mux-Core and Mux-Stats-AVPlayer) use UIWebView. If you are getting this warning you must have another SDK that is using UIWebView.\n\nThe reason there is some confusion around this and the reason you get a match in the dSYM/ directory in Mux-Core is because our SDK links to UIKit and targets a version of iOS that _may include_ UIWebView.  The dSYM files are used for debugging purposes and they do not contain any functional code. You may see that this same confusion came up in other SDKs like Mapbox and Stripe (listed below).\n\nResources:\n\n Mux issue 32\n Mux issue 53\n Mapbox issue 373\n Stripe issue 82\n\nCurrent release\n\nv4.10.0\nUpdates:\n Add (incubating) playbackModeChange API\n Add cumulative ad playing time and total content time metric tracking. The metrics track the \"wall-clock\" time spent with video playing during a view, excluding buffering, seeking, and startup time.\n\nPrevious releases\n\nv4.9.0\nImprovements:\n Move calls to AVPlayerItem.currentDate()) and AVPlayerItem.accessLog()) off the main thread.\n\nv4.8.2\nFixes:\n Disable Text-Based API (.tbd) generation for framework builds. CocoaPods fails to strip these, and this can lead to App Store upload errors.\n\nv4.8.1\n\nFixes:\n Fix crash Invalid parameter not satisfying: tag != nil introduced in v4.8.0\n\nv4.8.0\n\nImprovements:\n Use AVMetrics to generate bandwidth metric events for HLS streams (iOS 18+, tvOS 18+, visionOS 2+). This also enables automatic CDN change tracking via the X-CDN header for these OS versions.\n\nv4.7.0\n\nImprovements:\n Fix crash when AVPlayer is used off the main thread\n Moves some calls to AVAsset to the background to avoid blocking the main thread\n Fixes mismatched bitrate/size reporting in rendition change events\n\nv4.6.0\n\nImprovements:\n Builds from source for both Swift Package Manager and CocoaPods for more flexible integration in your projects\n Various tidying-up of public header files\n\nFixes:\n Fixes an issue where some customer viewer data fields were not being sent\n\nv4.4.0\n\nImprovements:\n Updates the MuxCore dependency to 5.3.x\n preserve debugging symbols from framework build\n\nFixes:\n update package spec with missing macCatalyst platform\n\nv4.3.0\n\nImprovements:\n Update MuxCore to v5.2.0\n\nv4.2.0\n\nFixes:\n Send ended when an AVPlayerItem finishes playing to completion\n\nv4.1.2\n\nImprovements:\n Update MuxCore to v5.1.2\n\nv4.1.1\n\nImprovements:\n Update MuxCore to v5.1.1\n\nv4.1.0\n\nImprovements:\n Automatically dispatch a viewend when a new AVPlayerItem becomes the player currentItem.\n\nFixes:\n No longer dispatch viewinit if the player currentItem is replaced with nil.\n\nv4.0.0\nNew:\n Error events can be categorized with warning or fatal severity levels.\n Error events can be categorized as business exceptions.\n\nImprovements:\n Player error details (same as listed above) are no longer deduplicated and are explicitly included with each error event sent to Mux.\n\nAPI Changes:\n The minimum deployment targets for the SDK are now iOS 12 and tvOS 12.\n Removes deprecated MUXSDKStats APIs.\n\nv3.6.2\nFixes:\n A crash that occurred when monitoring playback using AirPlay.\n\nv3.6.1\nImprovements:\n Include privacy manifest file\n\nv3.6.0\nImprovements:\n Applications running on visionOS can monitor metrics for AVPlayerViewController or AVPlayer with a fixed player size. We recommend testing your visionOS application's AVPlayer monitoring integration on both the simulator and a physical device prior to deploying to the App Store.\n\nFixes:\n A memory leak has been fixed that occurred when tearing down monitoring of a standalone AVPlayer with a fixed player size.\n\nKnown Issues:\n Installation using Cocoapods on visionOS applications is not currently supported. Installation on iOS and tvOS using Cocoapods is not affected.\n Monitoring AVPlayerLayer playback on visionOS applications is not supported at this time.\n Views from playback on visionOS will always indicate Used Fullscreen to be false.\n\nv3.5.1\nFixes:\n Add referential safety checks when dispatching session data\n\nv3.5.0\nAPI Changes:\n Expose reporting an error context parameter alongside customer errors\n\nKnown Issues:\n Including a SESSION-DATA tag in the manifest of a monitored HLS stream may cause a crash in v3.5.0 or earlier of MUXSDKStats. To resolve the issue limit SESSION-DATA tags only to applications that use MUXSDKStats v3.5.1 or higher.\n\nv3.4.2\nFixes:\n Pin MuxCore to specific version consistent across Cocoapods and Swift Package Manager\n\nv3.4.1\nFixes:\n Add state check when dispatching viewend event\n\nImprovements:\n Update MuxCore dependency\n\nv3.4.0\nAPI Changes:\n Monitor AVPlayer with a fixed player size\n Set custom player software name and version values when initializing a new binding\n\nImprovements\n Documentation revisions\n Audio-only monitoring example\n\nv3.3.3\nFixes:\n Set the player width and height dimensions to the entire area of the screen where the player is present. Before this change, player width and height were set to the width and height of the video drawn on screen. Letterboxed or pillarboxed areas of the player were previously excluded as a result.\n\nPlayer width and height dimensions are now equal to the AVPlayerLayer bounds or AVPlayerViewController view bounds, depending on which is used. Previously AVPlayerViewController videoBounds or AVPlayerLayer videoRect were used to set the player width and height.\n\nUpscale Percentage or Downscale Percentage calculations are not affected if the player draws the video with the same aspect ratio as the video resolution.\n\nv3.3.2\nFixes:\n Crash when removing a time observer from the wrong AVPlayer instance during monitoring teardown\nImprovements:\n Add Swift Package Manager example application\n\nv3.3.1\nImprovements:\n Update MuxCore with backfilled header nullability annotations to remove build warnings\n\nv3.3.0\nUpdates:\n Add drmType to MUXSDKCustomerViewData so you can track this field if you wish\n\nImprovements:\n System reliability updates during large events\n\nv3.2.1\nFixes:\n Fix ad metadata not being reported\n\nv3.2.0\nFixes:\n Fix wrong viewer time when finishing seek after an ad break\n\nv3.1.0\nUpdates:\n Add Frame Drop Metrics (172)\n Add 5 more Custom Dimensions (6 through 10) to MUXSDKCustomData\n\nv3.0.0\nUpdates:\n Add fields to CustomerViewerData allowing them to override detected device metadata values\n Add Request ID metadata property to BandwidthMetricData\n Add Customer overrides for Device Metadata\n\nBreaking:\n Due to Xcode 14, support for iOS and tvOS versions 9 and 10 have been removed. This may result in a warning for client applications with deployment versions below iOS/tvOS 11. For more information see the last 'Deprecations' block in the release notes.\n\nImprovements:\n Update to MuxCore 4.0.0, Xcode 14\n* Improve HLS/DASH segment request metrics (165)\n\nv2.13.2\n- Fix an issue with certain error conditions not being properly recognized on the data dashboard\n\nv2.13.1\n- Relax muxcore pod dependency version, can now update any to 3.x version, 3.12 or higher\n- Start a new View if a View receives events after 1 hour of inactivity\n\nv2.12.1\n\n- Fix: Crash in AVMetadataItem inspection when dispatching session data\n- Fix: State check for isPaused\n\nv2.12.0\n\n- Fix: Register seek events when state is buffering\n- Capture HLS session data and send event to core\n\nv2.11.0\n\n- Set Xcode build setting APPLICATION_EXTENSION_API_ONLY = YES\n- Fix: Update rendition change logic to fire events after playback has started\n\nv2.10.0\n\n- Fix: Missing programmatic seek events for iOS 15.0\n- Add picture in picture ads compatibility with mux-stats-google-ima 0.7.0\n\nv2.9.0\n\n- Fix: Missing programmatic seek latency metric and sequencing bugs\n- Fix: Clear customer metadata stored under playerName when destroyPlayer is called\n- Add Carthage binary project specification\n- Add internal device detection properties\n\nv2.8.0\n\n- Fixes a bug that caused missing seek events when seeking programmatically\n\nv2.7.0\n\n- Add player_live_edge_program_time\n- Add player_program_time\n\nv2.6.0\n\n- Allow overriding of viewer information (application name)\n- Tests for AVQueuePlayer\n- Custom beacon collection domains\n- Adds programChangeForPlayer:withCustomerData:\n\nv2.5.0\n\n- Consolidates  MUXSDKCustomerViewData, MUXSDKCustomerVideoData, and MUXSDKCustomerPlayerData into MUXSDKCustomerData and deprecates methods that treat these as separate arguments\n- Adds support for custom dimensions\n\nv2.4.2\n\n- Replaces identifierForVendor with alternative UUID\n- Fixes race condition when checking viewer connection type\n\nv2.4.1\n\n- Fixes a bug when disabling automatic video change that could sometimes result in views not being split apart and/or having a high seek latency.\n\nv2.4.0\n\n- Automatically build statically linked frameworks\n- Removes use of categories\n- Updates documentation\n\nv2.3.2\n\n- Adds a new method to disable built in videochange calls when using AVQueuePlayer. This method can be called as:\n\n```\n[MUXSDKStats setAutomaticVideoChange:PLAYER_NAME enabled:false];\n```\n\n\nv2.2.2\n\n- Fixes a code signing is missing error for Mac Catalyst\n- Fixes a crash from a KVO observer being removed incorrectly\n- Fixes bugs in seeking tracking for tvOS\n\nv2.2.1\n\n- Fixes a bug where AirPlay rebuffering was incorrectly reported as paused\n\nv2.2.0\n\n- Add Swift PM support\n\nv2.1.0\n\n- Submits viewer_device_model field\n- Updates our implementation of the Google IMA SDK in demo apps to work with the latest version\n- Automated UI test for ads\n\nv2.0.0\n\nThis release moves the build process to use XCFramework bundle type. For iOS, there are no changes required to your application code.\n\nIf you are using this SDK with TVOS the name of the module has changed (the Tv suffix is no longer needed):\n\nTVOS before 2.0:\n\n\n```objc\n@import MuxCoreTv;\n@import MUXSDKStatsTv;\n```\n\n\nTVOS after 2.0:\n\n\n```objc\n@import MuxCore;\n@import MUXSDKStats;\n```\n\n\nv1.7.0\n\n- Adds support for view_session_id.\n- Adds support for player_remote_played - this will be true when a video is shown over AirPlay.\n\nv1.6.0\n\n- Add viewer_connection_type for iOS (either wifi or cellular). Detecting viewer_connection type is done off the main thread to make sure this doesn't interfere with the performance of your application. Note that viewer_connection_type is omitted from TVOS because in versions before TVOS 12 there is no reliable way to detect wifi vs. ethernet.\n\nv1.4.1\n\n- (bugfix) monitorAVPlayerLayer with optional argument automaticErrorTracking was misnamed to withAutomaticErrorTracking. This has been changed to the correct name which is consistent with the corresponding monitorAVPlayerViewController method (thanks @hlung in 58)\n- (bugfix) nullability warnings for MUXSDKStats (thanks @hlung in 58)\n\nv1.4.0\n- add option to disable automatic error tracking when calling either monitorAVPlayerViewController or monitorAVPlayerLayer\n- add MUXSDKStats.dispatchError method to manually dispatch an error\n\nYou probably will not need to use these features, but if your player is throwing noisy non-fatal errors or you want to catch the player errors yourself and take precise control over the error code and error message then you now have that ability.\n\nDispatching an error should only be used for fatal errors. When the player goes into the error state then it is no longer being tracked and the view will show up as having encountered an error in the Mux dashboard.\n\nv1.3.8\n - Performance updates that optimize main thread usage.\n\nv1.3.7\n - Bug fix: Update our framework build process to be compatible with carthage 0.35.0. See the GitHub issue for more details. The gist of it is that Carthage no longer ignores dSYM files, so those need to be packaged up correctly with the framework.\n\nv1.3.6\n - Bug fix: Rebuild frameworks without importing UIKit (we don't use it). This came to our attention when it was reported that our SDK was triggering this warning from Apple “The App Store will no longer accept new apps using UIWebView as of April 2020 and app updates using UIWebView as of December 2020.”\n\nv1.3.5\n - Bug fix for usage with AVQueuePlayer. Unlike other methods of changing the playerItem on an AVPlayer instance, when AVQueuePlayer progresses from one item to the next the rate observer does not fire so we have to handle it in a special case. See instructions above for usage with AVQueuePlayer.\n\nv1.3.4\n - Update scaling logic to report upscaling based on logical resolution, not physical resolution. This will result in lower upscaling percentages, but correlates more closely with perceived visual quality\n\nv1.3.3\n - Fix a bug to make sure all needed header files are included in the tvOS framework\n\nv1.3.2\n - Fix a bug in request metrics tracking, request metric event timestamps should always be sent in Unix millisecond timestamps, not seconds.\n\nv1.3.1\n - Fix an issue where multiple AVPlayer instances that are tracked simultaneously report the same throughput metrics.\n\nv1.3.0\n- Add support for orientationchange events. This can be dispatched with MUXSDKStats orientationChangeForPlayer: withOrientation:\n- Add support for automatically tracking renditionchange events. You can see this new event in the events list for a view.\n- Improve implementation for bandwidth metrics calculation. Instead of polling for changes on the access log, use AVPlayerItemNewAccessLogEntryNotification\n- Fix bug in programChange so that it works consistently now\n- Dispatch viewend when destoryPlayer is called. Previously this was not called which didn't affect metrics, but resulted in a viewdropped event in the events list.\n\nv1.2.1\n- Fix bug that prevents request metrics tracking from working. AVPlayer gives us requestStart and requestResponseEnd, so with those data points we can track throughput. This bug fix requires Mux-Stats-Core v2.1.3 or greater. Run pod update Mux-Stats-AVPlayer  and pod update Mux-Stats-Core to get the latest versions.\n\nv1.2.0\n- Fix bug in Mux-Stats-AVPlayer that prevents videoChangeForPlayer from working\n- Fix bug in AVPlayer SDK where it misses initial play event at times if SDK is initialized too late. This could cause some iOS views to not be displayed in the monitoring dashboard, and to potentially have incomplete metrics such as Video Startup Time.\n- Add ability to optionally pass in new player data when calling videoChangeForPlayer: videoChangeForPlayer:withPlayerData:withVideoData\n\nv1.1.3\n- Fix a bug to prevent an edge-case scenario where crashes can happen after calling destroyPlayer when observers have not yet bet set up on the player instance.\n\nv1.1.2\n- bump dependency version of Mux-Stats-Core to 2.1\n\nv1.1.1\n- bugfix - report the correct Mux Plugin Version. This SDK was erroneously reporting the incorrect 'Mux Plugin Version' attribute for views\n\nv1.1.0\n- Added new static method to MUXSDKStats updateCustomerDataForPlayer:withPlayerData:withVideoData`. This allows a developer to update customerPlayerData and/or customerVideoData after the SDK has been initialized. Not all metadata can be changed if it was previously set, but all metadata that was not set initially can be updated to the intended values.\n\nv1.0.2\n - Fix a bug that caused slowness when loading AVPlayer due to checking currentItem.asset.duration before the duration was loaded\n\nv1.0.1\n - Fix a bug with incorrect source video duration\n\nv1.0.0\n - Extract GoogleAds-IMA-iOS-SDK into a separate library (Mux-Stats-Google-IMA). The reason for this change was to remove the hard dependency on GoogleAds-IMA-iOS-SDK\n - In order to implement ad events tracking, please follow the instructions to use this library (Mux-Stats-AVPlayer) in conjunction with Mux-Stats-Google-IMA and GoogleAds-IMA-iOS-SDK\n\n0.1.5\n- add support for tracking ad playback with GoogleAds-IMA-iOS-SDK\n\n0.1.1\n- add support for AVPlayer monitoring"
  },
  {
    "id": "66-_guides/developer/monitor-azure-media-player",
    "title": "Monitor Azure media player",
    "path": "_guides/developer/monitor-azure-media-player.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-azure-media-player",
    "content": "Azure Media Services has been deprecated by the Azure team. If you still utilize Azure Media Player and need to integrate this with Mux, please reach out to us."
  },
  {
    "id": "67-_guides/developer/monitor-bitmovin-android",
    "title": "Monitor Bitmovin Player Android",
    "path": "_guides/developer/monitor-bitmovin-android.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-bitmovin-android",
    "content": "This documents integration instructions for Bitmovin's Bitmovin Player library, version 3.x and 2.x.\n\nThe Mux integration with Bitmovin Player is built on top of Mux's core Java SDK, and the full code can be seen here: muxinc/mux-stats-sdk-bitmovin-android.\n\nAdd the Mux SDK to your project using one of the following approaches:\n\nAdd Gradle dependency on the Mux Bitmovin Player SDK\nAdd the Mux Maven repository to your Gradle file:\n\n```text\nrepositories {\n    maven {\n        url \"https://muxinc.jfrog.io/artifactory/default-maven-release-local\"\n    }\n}\n```\n\n\nNext, add a dependency on the Mux Data Bitmovin Player SDK. We support both minapi16 and minapi21 as separate artifacts.\n\nThe current version is v0.5.1. Additional releases can be found on our releases page.\n\nBitmovin Player support\nWe support version 3.11.1 of Bitmovin Player. Support for additional versions is planned\n\n\n```groovy\nimplementation 'com.mux.stats.sdk.muxstats:muxstatssdkbitmovinplayer_r3_11_1:[CurrentVersion]'\n```\n\n\nFirst, create the CustomerPlayerData and CustomerVideoData objects as appropriate for your current playback, and be sure to set your ENV_KEY.\n\n\n```java\nimport com.mux.stats.sdk.core.model.CustomerPlayerData;\nimport com.mux.stats.sdk.core.model.CustomerVideoData;\nimport com.mux.stats.sdk.core.model.CustomerViewData\nimport com.mux.stats.sdk.core.model.CustomData;\nimport com.mux.stats.sdk.core.model.CustomerData;\n\nCustomerPlayerData customerPlayerData = new CustomerPlayerData();\ncustomerPlayerData.setEnvironmentKey(\"YOUR_ENVIRONMENT_KEY_HERE\");\n\nCustomerVideoData customerVideoData = new CustomerVideoData();\ncustomerVideoData.setVideoTitle(intent.getStringExtra(\"YOUR_VIDEO_TITLE\"));\n\nCustomerViewData customerViewData = new CustomerViewData();\ncustomerViewData.setViewSessionId(\"A26C4C2F-3C8A-46FB-885A-8D973F99A998\");\n\nCustomData customData = new CustomData();\ncustomData.setCustomData1(\"YOUR_CUSTOM_STRING_HERE\");\n\nCustomerData customerData = new CustomerData(customerPlayerData, customerVideoData, customerViewData);\ncustomerData.setCustomData(customData);\n```\n\n\nNext, create the MuxStatsSDKBitmovinPlayer object by passing your Android Context (typically your Activity), a Bitmovin PlayerView instance, a player name, and the customer data objects.\n\n\n```java\nimport com.mux.stats.sdk.muxstats.MuxStatsSDKBitmovinPlayer;\n...\n// Make sure to monitor the player before calling `prepare` on the Bitmovin Player instance\nmuxStatsBitmovinPlayer = new MuxStatsSDKBitmovinPlayer(\n  this, player, \"demo-player\", customerData);\n```\n\n\nIn order to correctly monitor if the player is full-screen, provide the screen size to the MuxStatsSDKBitmovinPlayer instance.\n\n\n```java\nPoint size = new Point();\ngetWindowManager().getDefaultDisplay().getSize(size);\nmuxStatsBitmovinPlayer.setScreenSize(size.x, size.y);\n```\n\n\nIn order to determine a number of viewer context values as well as track the size of the video player, set the player view.\n\n\n```java\nmuxStatsBitmovinPlayer.setPlayerView(playerView);\n```\n\n\nFinally, when you are destroying the player, call the MuxStatsSDKBitmovinPlayer.release() function.\n\n\n```java\nmuxStatsBitmovinPlayer.release()\n```\n\n\nAfter you've integrated, start playing a video in your player. A few minutes after you stop watching, you'll see the results in your Mux data dashboard. Login to the dashboard and find the environment that corresponds to your env_key and look for video views.\n\nIn the Java SDK, options are provided via the objects within the CustomerData object.\n\nAll metadata details except for envKey are optional, however you'll be able to compare and see more interesting results as you include more details. This gives you more metrics and metadata about video streaming, and allows you to search and filter on important fields like the player version, CDN, and video title.\n\nFor more information, see the Metadata Guide.\n\nChanging the video\n\nThere are two cases where the underlying tracking of the video view need to be reset. First, when you load a new source URL into an existing player, and second when the program within a singular stream changes (such as a program within a live stream).\n\nNote: You do not need to change the video info when changing to a different source of the same video content (e.g. different resolution or video format).\n\nNew source\n\nWhen you change to a new video (in the same player) you need to update the information that Mux knows about the current video. Examples of when this is needed are:\n\n The player advances to the next video in a playlist\n The user selects a different video to play\n\nThis is done by calling muxStatsBitmovinPlayer.videoChange(CustomerVideoData) which will remove all previous video data and reset all metrics for the video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nIt's best to change the video info immediately after telling the player which new source to play.\n\nNew program (in single stream)\n\nIn some cases, you may have the program change within a stream, and you may want to track each program as a view on its own. An example of this is a live stream that streams multiple programs back to back, with no interruptions.\n\nIn this case, call muxStatsBitmovinPlayer.programChange(CustomerVideoData). This will remove all previous video data and reset all metrics for the video view, creating a new video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nError tracking\n\nBy default, Mux's integration with Bitmovin Player automatically tracks fatal errors as thrown by Bitmovin Player. If a fatal error happens outside the context of Bitmovin Player and you want to track it with Mux, you can call muxStatsBitmovinPlayer.error like this:\n\n\n```java\n// Error code: integer value for the generic type of error that\n// occurred.\n// Error message: String providing more information on the error\n// that occurred.\n// For an example, the HTML5 video element uses the\n// following: https://developer.mozilla.org/en-US/docs/Web/API/MediaError\n// for codes and messages. Feel free to use your own codes and messages\nint errorCode = 1;\nString errorMessage = \"A fatal error was encountered during playback\";\nMuxErrorException error = new MuxErrorException(errorCode, errorMessage);\nmuxStatsBitmovinPlayer.error(error);\n```\n\nNote that muxStatsBitmovinPlayer.error(MuxErrorException e) can be used with or without automatic error tracking. If your application has retry logic that attempts to recover from Bitmovin Player errors then you may want to disable automatic error tracking like this:\n\n\n```java\nmuxStatsBitmovinPlayer.setAutomaticErrorTracking(false)\n```\n\n\nIt is important that you only trigger an error when the playback has to be abandoned or aborted in an unexpected manner, as Mux tracks fatal playback errors only.\n\nCurrent release\n\nv0.5.2\nFixes:\n Fix ANRs during Position Checks (9)\n\nPrevious releases\nv0.5.1\nImprovements:\n Detect Fullscreen Bitmovin's size listeners instead of guessing from view & screen sizes (5)\n\nv0.5.0\n* Initial release"
  },
  {
    "id": "68-_guides/developer/monitor-bitmovin-player",
    "title": "Monitor Bitmovin player",
    "path": "_guides/developer/monitor-bitmovin-player.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-bitmovin-player",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video.\n\n<CodeExamples\n  examples={{\n    npm: npm install --save @mux/mux-data-bitmovin,\n    yarn: yarn add @mux/mux-data-bitmovin,\n    cdn:\n\n  }}\n/>\n\nCall bitmovin.player.Player like you normally would. Call initBitmovinMux with the player reference and the SDK options.\n\nThe only required field in the options that you pass into @mux/mux-data-bitmovin is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data on initialization.\n\n\n```js\ninitBitmovinMux(player, {\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000, can use `initBitmovinMux.utils.now()`\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call initBitmovinMux. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\n// player is the instance returned by the `bitmovin.player.Player` function\nplayer.mux.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\n\n```js\n// player is the instance returned by the `bitmovin.player.Player` function\nplayer.mux.emit('videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\n// player is the instance returned by the `bitmovin.player.Player` function\nplayer.mux.emit('programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\ninitBitmovinMux(player, {\n  debug: false,\n  disableCookies: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n});\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\ninitBitmovinMux(player, {\n  debug: false,\n  respectDoNotTrack: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, @mux/mux-data-bitmovin will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\n// player is the instance returned by the `bitmovin.player.Player` function\nplayer.mux.emit('error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n  };\n}\n\ninitBitmovinMux(player, {\n  debug: false,\n  errorTranslator,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\ninitBitmovinMux(player, {\n  debug: false,\n  automaticErrorTracking: false,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nAds tracking with @mux/mux-data-bitmovin\n\nMux supports Bitmovin's VAST advertising client for pre-, mid-, and post-roll ads. Simply configure these plugins as you would normally, and Mux will track ads automatically. No additional configuration is needed.\n\nThe metrics for preroll request and response times, as well as number of requests, are pending an update to Bitmovin's API. Everything else will operate normally, but those metrics may be missing.\n\nCustomize beacon collection domain\n\n\n```js\ninitBitmovinMux(player, {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nCurrent release\n\nv6.4.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv6.4.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv6.4.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv6.4.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv6.4.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv6.4.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv6.4.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv6.4.7\n\n- Update mux-embed to v5.9.0\n\nv6.4.6\n\n- Update mux-embed to v5.8.3\n\nv6.4.5\n\n- Update mux-embed to v5.8.2\n\nv6.4.4\n\n- Update mux-embed to v5.8.1\n\nv6.4.3\n\n- Update mux-embed to v5.8.0\n\nv6.4.2\n\n- Update mux-embed to v5.7.0\n\nv6.4.1\n\n- Update mux-embed to v5.6.0\n\nv6.4.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv6.3.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv6.3.2\n\n- Update mux-embed to v5.4.2\n\nv6.3.1\n\n- Update mux-embed to v5.4.1\n\nv6.3.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv6.2.6\n\n- Update mux-embed to v5.3.3\n\nv6.2.5\n\n- Update mux-embed to v5.3.2\n\nv6.2.4\n\n- Update mux-embed to v5.3.1\n\nv6.2.3\n\n- Update mux-embed to v5.3.0\n\nv6.2.2\n\n- Update mux-embed to v5.2.1\n\nv6.2.1\n\n- Update mux-embed to v5.2.0\n\nv6.2.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv6.1.0\n\n- Refactors for stricter data types (e.g. string vs. number) based on TypeScript types.\n\n- Update mux-embed to v5.0.0\n\nv6.0.3\n\n- Update mux-embed to v4.30.0\n\nv6.0.2\n\n- Update mux-embed to v4.29.0\n\nv6.0.1\n\n- Update mux-embed to v4.28.1\n\nv6.0.0\n\n- fix an issue when using modular v8 imports for Bitmovin player\n\n- Update mux-embed to v4.28.0\n\nv5.12.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv5.11.3\n\n- Update mux-embed to v4.26.0\n\nv5.11.2\n\n- Update mux-embed to v4.25.1\n\nv5.11.1\n\n- Update mux-embed to v4.25.0\n\nv5.11.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv5.10.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv5.9.4\n\n- Update mux-embed to v4.22.0\n\nv5.9.3\n\n- Update mux-embed to v4.21.0\n\nv5.9.2\n\n- Update mux-embed to v4.20.0\n\nv5.9.1\n\n- Update mux-embed to v4.19.0\n\nv5.9.0\n\n- Set Mux Error Context with additional error information from Bitmovin player\n\nv5.8.1\n\n- Update mux-embed to v4.18.0\n\nv5.8.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv5.7.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv5.6.0\n\n- Expose utils on SDK initialization function to expose utils.now() for player_init_time\n\n- Update mux-embed to v4.15.0\n\nv5.5.5\n\n- Update mux-embed to v4.14.0\n\nv5.5.4\n\n- Update mux-embed to v4.13.4\n\nv5.5.3\n\n- Update mux-embed to v4.13.3\n\nv5.5.2\n\n- Update mux-embed to v4.13.2\n\nv5.5.1\n\n- Fixes an issue with accessing the global object\n- Update mux-embed to v4.13.1\n\nv5.5.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv5.4.8\n\n- Publish package to NPM\n\nv5.4.7\n\n- Update mux-embed to v4.12.1\n\nv5.4.6\n\n- Update mux-embed to v4.12.0\n\nv5.4.5\n\n- Provide a more friendly error message if the Bitmovin instance is not available\n- Update mux-embed to v4.11.0\n\nv5.4.4\n\n- Update mux-embed to v4.10.0\n\nv5.4.3\n\n- Update mux-embed to v4.9.4\n\nv5.4.2\n\n- Use common function for generating short IDs\n- Update mux-embed to v4.9.3\n\nv5.4.1\n\n- Update mux-embed to v4.9.2\n\nv5.4.0\n\n- Support Bitmovin module-based player\n\nv5.3.6\n\n- Update mux-embed to v4.9.1\n\nv5.3.5\n\n- Update mux-embed to v4.9.0\n\nv5.3.4\n\n- Update mux-embed to v4.8.0\n\nv5.3.3\n\n- Update mux-embed to v4.7.0\n\nv5.3.2\n\n- Update mux-embed to v4.6.2\n\nv5.3.1\n\n- Update mux-embed to v4.6.1\n\nv5.3.0\n\n- Bump mux-embed to 4.6.0\n\nv5.2.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv5.1.0\n\n- Update mux-embed to v4.1.1\n- Fix an issue where player_remote_played would not be reported correctly\n\nv5.0.0\n\n- Update mux-embed to v4.0.0\n- Support server-side device detection\n\nv4.0.0\n\n- remove support for version 5 of the Bitdash player\n- allow passing of global bitmovin object, rather than requiring it be on window\n\nv3.1.1\n\n- fix an issue where manifests with EXT-X-PROGRAM-DATE-TIME could cause issues with video startup time\n\nv3.1.0\n\n- bugfix for aderror tracking\n\nv3.0.1\n\n- fix ad tracking on latest releases of the Bitmovin v7 and v8 players\n- improve ad tracking for Bitmovin v8\n\nv3.0.0\n\n- bump mux-embed dependency to 3.0.0"
  },
  {
    "id": "69-_guides/developer/monitor-brightcove-android",
    "title": "Brightcove (Android)",
    "path": "_guides/developer/monitor-brightcove-android.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-brightcove-android",
    "content": "Brightcove's native SDK for Android has support for both the native MediaPlayer as well as ExoPlayer. In the case that you utilize ExoPlayer (via a class such as BrightcoveExoPlayerVideoView), monitoring basic video playback is relatively simple.\n\nRequirements\n - Brightcove SDK for Android 6.x\n - ExoPlayer-based Brightcove Player (e.g. BrightcoveExoPlayerVideoView)\n\nIntegration Instructions\n\nBrightcove's SDK for Android encapsulates an underlying SimpleExoPlayer instance. In order to integrate, you need to create an instance of MuxStats for each new video loaded into the player. This is best done by listening for the didSetVideo event that the EventEmitter emits.\n\nBrightcove's current Android SDK (6.2.x) uses ExoPlayer r2.7.x, so you should include the appropriate AAR file from our releases page and in our Monitor ExoPlayer guide.\n\nNote: didSetVideo is used in order to get the updated Video in the case that a playlist of Video objects, so that you can retrieve the updated metadata.\n\n\n```java\n// MainFragment.java (or MainActivity.java, wherever\n// you have access to your `BrightcoveExoPlayerVideoView`\n\nimport com.mux.stats.sdk.core.model.CustomerPlayerData;\nimport com.mux.stats.sdk.core.model.CustomerVideoData;\nimport com.mux.stats.sdk.muxstats.MuxStatsExoPlayer;\n\npublic class MainFragment extends BrightcovePlayerFragment implements EventListener {\n\n  public static final String TAG = MainFragment.class.getSimpleName();\n  private MuxStatsExoPlayer muxStatsExoPlayer;\n\n  @Override\n  public View onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) {\n    View result = inflater.inflate(R.layout.fragment_main, container, false);\n    baseVideoView = (BrightcoveExoPlayerVideoView) result.findViewById(R.id.brightcove_video_view);\n    super.onCreateView(inflater, container, savedInstanceState);\n    baseVideoView.getEventEmitter().on(\"didSetVideo\", this);\n\n    // Set up your videos for playback here\n    Video video = Video.createVideo(\"https://path/to/video.mp4\", DeliveryType.HLS);\n\n    baseVideoView.add(video);\n    baseVideoView.start();\n    return result;\n  }\n\n  @Override\n  public void processEvent(Event event) {\n    ExoPlayerVideoDisplayComponent videoDisplayComponent = (ExoPlayerVideoDisplayComponent) baseVideoView.getVideoDisplay();\n    Video video = baseVideoView.getCurrentVideo();\n    ExoPlayer exoPlayer = videoDisplayComponent.getExoPlayer();\n\n    CustomerPlayerData customerPlayerData = new CustomerPlayerData();\n    CustomerVideoData customerVideoData = new CustomerVideoData();\n    customerVideoData.setVideoTitle(video.getId());\n    CustomerData customerData = new CustomerData(customerPlayerData, customerVideoData, null)\n\n    if (muxStatsExoPlayer != null) {\n      muxStatsExoPlayer.release();\n      muxStatsExoPlayer = null;\n    }\n\n    muxStatsExoPlayer = new MuxStatsExoPlayer(this, \"YOUR_ENV_KEY_HERE\", exoPlayer, baseVideoView, customerData);\n  }\n}\n```"
  },
  {
    "id": "70-_guides/developer/monitor-brightcove-ios",
    "title": "Monitor Brightcove (iOS)",
    "path": "_guides/developer/monitor-brightcove-ios.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-brightcove-ios",
    "content": "Brightcove's native SDK for iOS is based on AVPlayerLayer. You will need to be using Brightcove's iOS player version 6.x.\n\n\n```\npod 'Mux-Stats-AVPlayer', '~>3.0'\n```\n\n\nThis will install Mux-Stats-AVPlayer and the latest current release of our core Objective-C Library. There will be no breaking updates in major versions, so you can safely run pod update for future versions.\n\nNext, add correct import statement into your application.\n\nIn your application, you will need to hook into Brightcove's SDK lifecycle events in order to access the underlying AVPlayerLayer instance.\n\n\n```objc\n@import BrightcovePlayerSDK;\n@import MUXSDKStats;\n\n@property (nonatomic, copy) NSString *trackedPlayerName;\n\n- (void)playbackController:(id<BCOVPlaybackController>)controller didAdvanceToPlaybackSession:(id<BCOVPlaybackSession>)session\n{\n    // Destroy previous MUXSDKStats if this signifies the other view ended\n    // Note: you may want to handle this in another lifecycle event, if you\n    // have one that signifies when the video playback has ended/exited.\n    if (self.trackedPlayerName != nil) {\n        [MUXSDKStats destroyPlayer:self.trackedPlayerName];\n    }\n\n    MUXSDKCustomerPlayerData *playerData = [[MUXSDKCustomerPlayerData alloc] initWithEnvironmentKey:@\"ENV_KEY\"];\n    [playerData setPlayerName: @\"Brightcove SDK w/ Mux\"];\n    // set additional player metadata here\n    MUXSDKCustomerVideoData *videoData = [MUXSDKCustomerVideoData new];\n    [videoData setVideoId:@\"EXAMPLE ID\"];\n    // set additional video metadata here\n    self.trackedPlayerName = @\"example_player_name\";\n    [MUXSDKStats monitorAVPlayerLayer:session.playerLayer withPlayerName:self.trackedPlayerName playerData:playerData videoData:videoData];\n}\n```\n\n\nRefer to the detailed guide for AVPlayer to finish setup.\n\n  <GuideCard\n    title=\"Detailed AVPlayer guide\"\n    description=\"After getting a reference to your AVPlayerLayer instance, finish configuring it.\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/monitor-avplayer\"},\n    ]}\n  />"
  },
  {
    "id": "71-_guides/developer/monitor-brightcove-web",
    "title": "Monitor Brightcove (Web)",
    "path": "_guides/developer/monitor-brightcove-web.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-brightcove-web",
    "content": "Either include the Mux JavaScript SDK for video.js (videojs-mux) either via the Brightcove Studio by adding the script https://src.litix.io/videojs/4/videojs-mux.js as a new JavaScript line in your Plugins configuration or load videojs-mux from the CDN on your web pages.\n\n<CodeExamples\n  examples={{\n    npm: npm install --save videojs-mux,\n    yarn: yarn add videojs-mux,\n    cdn: `\n  }}\n  exampleOrder=\"npm,yarn,cdn\"\n/>\n\nInitialize the videojs player like you normally would and get a reference to the player. Call player.mux with the Mux plugin options to initialize monitoring.\n\n\n```html\n<video\n  id=\"my-player\"\n  data-video-id=\"...\"\n  data-account=\"...\"\n  data-player=\"...\"\n  data-embed=\"default\"\n  data-application-id\n  class=\"video-js\"\n  controls>\n>\n</video>\n\n<script>\n  const playerInitTime = Date.now();\n  // Get a reference to your player, and pass it to the init function\n  const player = videojs(\"my-player\");\n  player.mux({\n    debug: false,\n    data: {\n      env_key: 'ENV_KEY', // required\n      // Metadata\n      player_name: '', // ex: 'My Main Player'\n      player_init_time: playerInitTime // ex: 1451606400000\n      // ... and other metadata\n    }\n  });\n</script>\n```\n\n\nThe only required field in the options that you pass into the data options in the player.mux function is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data on initialization.\n\n\n```js\n// player is the instance returned by the `videojs` function\nplayer.mux({\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\n\n```js\n// player is the instance returned by the `videojs` function\nplayer.mux.emit('videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\n// player is the instance returned by the `videojs` function\nplayer.mux.emit('programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\n// player is the instance returned by the `videojs` function\nplayer.mux({\n  debug: false,\n  disableCookies: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\n// player is the instance returned by the `videojs` function\nplayer.mux({\n  debug: false,\n  disableCookies: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, videojs-mux` will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\n// player is the instance returned by the `videojs` function\nplayer.mux.emit('error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\n// player is the return value from the `videojs` function\nplayer.mux({\n  debug: false,\n  errorTranslator,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\n// player is the return value from the `videojs` function\nplayer.mux({\n  debug: false,\n  automaticErrorTracking: false,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nCustomize beacon collection domain\n\n\n```js\n// player is the return value from the `videojs` function\nplayer.mux({\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```"
  },
  {
    "id": "72-_guides/developer/monitor-castlabs-prestoplay-android",
    "title": "Monitor castLabs Player (Android)",
    "path": "_guides/developer/monitor-castlabs-prestoplay-android.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-castlabs-prestoplay-android",
    "content": "This integration is managed and operated by castLabs.\n  Feedback should be made by using the contact form or creating a ticket in the General Helpdesk.\n\nMux Environment Key\n\nIntegration Guide\n\nCastLabs maintains an online version of the official documentation which you can check out here."
  },
  {
    "id": "73-_guides/developer/monitor-castlabs-prestoplay-web",
    "title": "Monitor castLabs Player (Web)",
    "path": "_guides/developer/monitor-castlabs-prestoplay-web.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-castlabs-prestoplay-web",
    "content": "This integration is managed and operated by castLabs.\n  Feedback should be made by using the contact form or creating a ticket in the General Helpdesk.\n\nMux Environment Key\n\nIntegration Guide\n\nCastLabs maintains an online version of the official documentation which you can check out here."
  },
  {
    "id": "74-_guides/developer/monitor-chromecast",
    "title": "Monitor Chromecast",
    "path": "_guides/developer/monitor-chromecast.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-chromecast",
    "content": "Mux Data is the best way to monitor video streaming performance.\n\nIntegration is easy - just initialize the Mux SDK, pass in some metadata, and you're up and running in minutes.\n\nThis documents integration instructions for Chromecast. For other players, see the additional Integration Guides.\n\nMux supports Chromecast applications that are built on top of the Cast Application Framework CAF Receiver SDK. The CAF Receiver SDK supports the following streaming protocols.\n\nA Chromecast application contains two main components: a sender and a receiver. The Mux Data SDK is integrated at the receiver side; include the chromecast-mux.js JavaScript file within your custom receiver application. You can use the Mux-hosted version of the script to receive automatic updates. (The API will not change within major versions, as in chromecast/MAJOR_VERSION/chromecast-mux.js).\n\n<CodeExamples\n  examples={{\n    npm: npm install --save @mux/mux-data-chromecast,\n    yarn: yarn add @mux/mux-data-chromecast,\n    cdn: `,\n  }}\n  exampleOrder=\"npm,yarn,cdn\"\n/>\n\nTo monitor video playback within your Chromecast application, pass the PlayerManager instance to initChromecastMux along with SDK options and metadata.\n\nYou can initialize within a message interceptor for the LOAD event, or immediately on app load as before. This suggestion changed in version 4.0.0 and newer.\n\n\n```js\nimport initChromecastMux from '@mux/mux-data-chromecast';\n\nvar app = {\n  init: function () {\n    const context = cast.framework.CastReceiverContext.getInstance();\n    const playerManager = context.getPlayerManager();\n    let firstPlay = true;\n    let playerInitTime = initChromecastMux.utils.now();\n\n    playerManager.setMessageInterceptor(cast.framework.messages.MessageType.LOAD, loadRequestData => {\n      if (firstPlay) {\n        initChromecastMux(playerManager, {\n          debug: false,\n          data : {\n            env_key: 'ENV_KEY', // required\n\n            // Metadata\n            player_name: 'Custom Player', // ex: 'My Main Player'\n            player_init_time: playerInitTime,\n\n            // ... additional metadata\n          }\n        });\n      }\n\n      return loadRequestData;\n    });\n\n    context.start();\n  }\n};\n\n$(document).ready(function () {\n  app.init();\n});\n```\n\n\nAfter you've finished integration, the quickest way to see that the SDK is loaded is to pass debug: true in the options passed to the SDK. With this flag enabled, you can open the debug console, and you should start seeing debug statements from [mux] when you click play on the video.\n\nAfter playing a video, a few minutes after you stop watching, you'll see the results in your Mux account. We'll also email you when your first video view has been recorded. Log in to the dashboard and find the environment that corresponds to your env_key and look for video views.\n\nNote that it may take a few minutes for views to show up in the Mux Data dashboard.\n\nDetailed Documentation\n\nOptions are provided via the data object passed in the call to initChromecastMux.\n\nAll metadata details except for env_key are optional, however you'll be able to compare and see more interesting results as you include more details. This gives you more metrics and metadata about video streaming, and allows you to search and filter on important fields like the player version, CDN, and video title.\n\nFor more information, see the Metadata Guide.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call initChromecastMux. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\nplayerManager.mux.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\nThe source change should be done by intercepting the cast.framework.messages.MessageType.LOAD message and doing the following:\n\n\n```js\nplayerManager.setMessageInterceptor(cast.framework.messages.MessageType.LOAD, loadRequestData => {\n  // It's important to only call this on subsequent videos being loaded, not\n  // the first playback (where you call `initChromecastMux`).\n  if (!firstVideo) {\n    playerManager.mux.emit('videochange', { ... });\n  }\n\n  return loadRequestData;\n});\n```\n\n\nNew program\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, @mux/mux-data-chromecast will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\nplayerManager.mux.emit('error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\ninitChromecastMux(playerManager, {\n  debug: false,\n  errorTranslator: errorTranslator,\n  data : {\n    env_key: 'ENV_KEY', // required\n    // Metadata\n    player_name: 'Custom Player', // ex: 'My Main Player'\n    // ... additional metadata\n  }\n});\n\n```\n\n\nDisable automatic error tracking\n\n\n```js\ninitChromecastMux(playerManager, {\n  debug: false,\n  automaticErrorTracking: false,\n  data : {\n    env_key: 'ENV_KEY', // required\n    // Metadata\n    player_name: 'Custom Player', // ex: 'My Main Player'\n    // ... additional metadata\n  }\n});\n```\n\n\nCustomize beacon collection domain\n\n\n```js\ninitChromecastMux(playerManager, {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nDestroying the Monitor\n\nThere are certain use cases where you want to stop monitoring playback within a player (for instance if the player is no longer being used, you are recycling players, or you are shutting down the application). In this case, you should make sure to destroy the monitor. This can be done by simply calling playerManager.mux.destroy().\n\nCurrent release\n\nv4.16.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv4.16.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv4.16.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv4.16.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv4.16.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv4.16.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv4.16.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv4.16.7\n\n- Update mux-embed to v5.9.0\n\nv4.16.6\n\n- Update mux-embed to v5.8.3\n\nv4.16.5\n\n- Update mux-embed to v5.8.2\n\nv4.16.4\n\n- Update mux-embed to v5.8.1\n\nv4.16.3\n\n- Update mux-embed to v5.8.0\n\nv4.16.2\n\n- Update mux-embed to v5.7.0\n\nv4.16.1\n\n- Update mux-embed to v5.6.0\n\nv4.16.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv4.15.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv4.15.2\n\n- Update mux-embed to v5.4.2\n\nv4.15.1\n\n- Update mux-embed to v5.4.1\n\nv4.15.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv4.14.6\n\n- Update mux-embed to v5.3.3\n\nv4.14.5\n\n- Update mux-embed to v5.3.2\n\nv4.14.4\n\n- Update mux-embed to v5.3.1\n\nv4.14.3\n\n- Update mux-embed to v5.3.0\n\nv4.14.2\n\n- Update mux-embed to v5.2.1\n\nv4.14.1\n\n- Update mux-embed to v5.2.0\n\nv4.14.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv4.13.0\n\n- TypeScript type changes only.\n\n- Update mux-embed to v5.0.0\n\nv4.12.4\n\n- Update mux-embed to v4.30.0\n\nv4.12.3\n\n- Update mux-embed to v4.29.0\n\nv4.12.2\n\n- Update mux-embed to v4.28.1\n\nv4.12.1\n\n- Update mux-embed to v4.28.0\n\nv4.12.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv4.11.5\n\n- Update mux-embed to v4.26.0\n\nv4.11.4\n\n- Update mux-embed to v4.25.1\n\nv4.11.3\n\n- [advanced-use] Add option to turn off automatic ad tracking for Chromecast applications\n\nv4.11.2\n\n- Update mux-embed to v4.25.0\n\nv4.11.1\n\n- Fix an issue where certain ad providers may result in javascript errors\n\nv4.11.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv4.10.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv4.9.0\n\n- fix an issue where retrieving ad information on chromecast can throw an exception\n\n- Update mux-embed to v4.22.0\n\nv4.8.0\n\n- Include Ad metadata in ad events\n\n- Update mux-embed to v4.21.0\n\nv4.7.0\n\n- - Added capturing player dimensions with device pixel ratio considered\n  - Added capturing dropped frames\n\n- Update mux-embed to v4.20.0\n\nv4.6.2\n\n- Update mux-embed to v4.19.0\n\nv4.6.1\n\n- Update mux-embed to v4.18.0\n\nv4.6.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv4.5.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv4.4.0\n\n- Expose utils on SDK initialization function to expose utils.now() for player_init_time\n\n- Update mux-embed to v4.15.0\n\nv4.3.5\n\n- Update mux-embed to v4.14.0\n\nv4.3.4\n\n- Update mux-embed to v4.13.4\n\nv4.3.3\n\n- Update mux-embed to v4.13.3\n\nv4.3.2\n\n- Update mux-embed to v4.13.2\n\nv4.3.1\n\n- Fixes an issue with accessing the global object\n- Update mux-embed to v4.13.1\n\nv4.3.0\n\n- Upgraded internal webpack version\n\n- Improve Chromecast rebuffering metrics\n- Update mux-embed to v4.13.0\n\nv4.2.15\n\n- Publish package to NPM\n\nv4.2.14\n\n- Update mux-embed to v4.12.1\n\nv4.2.13\n\n- Update mux-embed to v4.12.0\n\nv4.2.12\n\n- Update mux-embed to v4.11.0\n\nv4.2.11\n\n- Listen for Chromecast BITRATE_CHANGED event, update the video source width and height, then call Mux renditionchange with the new bitrate\n\nv4.2.10\n\n- Update mux-embed to v4.10.0\n\nv4.2.9\n\n- Update mux-embed to v4.9.4\n\nv4.2.8\n\n- Use common function for generating short IDs\n- Update mux-embed to v4.9.3\n\nv4.2.7\n\n- Update mux-embed to v4.9.2\n\nv4.2.6\n\n- Update mux-embed to v4.9.1\n\nv4.2.5\n\n- Update mux-embed to v4.9.0\n\nv4.2.4\n\n- Update mux-embed to v4.8.0\n\nv4.2.3\n\n- Update mux-embed to v4.7.0\n\nv4.2.2\n\n- Update mux-embed to v4.6.2\n\nv4.2.1\n\n- Update mux-embed to v4.6.1\n\nv4.2.0\n\n- Bump mux-embed to 4.6.0\n\nv4.1.1\n\n- Fix an issue where player.mux.destroy() would raise an exception if called without any parameters.\n\nv4.1.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv4.0.0\n\n- Remove automatic video change tracking. You must now emit videochange events to signal a change. This should be done inside an interceptor for the LOAD event.\n- Fix an issue where ended events were sent at the wrong time.\n- Ensure that tracking is paused on the Chromecast STOPPED event.\n\nv3.1.0\n\n- Update mux-embed to v4.1.1\n- Add support for custom dimensions\n- Fix an issue where player_remote_played was not functioning. This value defaults to true if not set\n\nv3.0.0\n\n- Update mux-embed to v4.0.0\n- Update device model appropriately for various Chromecast devices\n- Support server-side device detection\n\nv2.0.1\n\n- Bug fix: Ensure the video_source_url is detected\n\nv2.0.0\n\n- Support ad event tracking\n- Default videochange detection to false - this can still be enabled if required\n- Clean up error tracking to report only fatal errors\n- Minor optimisations and bug fixes\n\nv1.0.0\n\n- Support customizing error handling (via configuring automaticErrorTracking and errorTranslator).\n- Do not shut down on REQUEST_STOP.\n- Expose playerManager.mux.destroy()` to stop monitoring the player instance.\n- Clean up better and minor bug fix around destroying monitor.\n\nv0.1.0\n\n- Initial SDK created."
  },
  {
    "id": "75-_guides/developer/monitor-cts-pdk",
    "title": "Monitor CTS PDK",
    "path": "_guides/developer/monitor-cts-pdk.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-cts-pdk",
    "content": "If installing from the MPX Console, load ctx-mux from the CDN:\n\n\n```curl\nhttps://src.litix.io/cts/3/cts-mux.js\n```\n\n\nIf installing in the player embed, follow the example below\n\n\n```html\n<div class=\"tpPlayer\"\n     id=\"player\"\n     // ... other configuration options\n     tp:muxPlugin = \"priority=1|URL=https://src.litix.io/cts/3/cts-mux.js|env_key=ENV_KEY|debug=false\">\n</div>\n<script>\n  // Creates the Player object that builds the component.\n  const player = new Player(\"player\");\n  player.bind(\"player\");\n</script>\n```\n\n\nThe only required field in the SDK options is env_key. Mux will automatically pull some metadata fields like video_id, video_title, and video_duration from the player itself. You can optionally override these values in the plugin parameters. Providing useful metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata fields separated by | with the plugin parameters.\n\n\n```html\n<div class=\"tpPlayer\"\n     id=\"player\"\n     // ... other configuration options\n     tp:muxPlugin = \"priority=1|URL=https://src.litix.io/cts/3/cts-mux.js|env_key=ENV_KEY|debug=false|player_name='EXAMPLE_PLAYER_NAME'|player_version=1.0.0\">\n</div>\n<script>\n  // Creates the Player object that builds the component.\n  const player = new Player(\"player\");\n  player.bind(\"player\");\n</script>\n```\n\n\nThe only required field in the options that you pass into the data options in the player.mux function is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nFor more information, view Make your data actionable.\n\nChanging the video\n\nIf the underlying source changes of the video within the same player, cts-mux will track this change automatically. No extra configuration is needed.\n\nDisable cookies\n\nBy default, cts-mux uses a cookie to track playback across subsequent page views. This cookie includes information about the tracking of the viewer, such as an anonymized viewer ID that Mux generates for each user. None of this information is personally-identifiable, but you can disable the use of this cookie if desired. For instance, if your site or application is targeted towards children under 13, you should disable the use of cookies.\n\nThis is done by setting disableCookies=true in the options passed to the Mux plugin.\n\n\n```html\n<div class=\"tpPlayer\"\n     id=\"player\"\n     // ... other configuration options\n     tp:muxPlugin = \"priority=1|URL=https://src.litix.io/cts/3/cts-mux.js|env_key=ENV_KEY|debug=false|player_name='EXAMPLE_PLAYER_NAME'|disableCookies=true>\n</div>\n<script>\n  // Creates the Player object that builds the component.\n  const player = new Player(\"player\");\n  player.bind(\"player\");\n</script>\n```\n\n\nOver-ride 'do not track' behavior\n\nBy default, cts-mux does not respect Do Not Track when set within browsers. This can be enabled in the options passed to Mux, via a setting named respectDoNotTrack. The default for this is false. If you would like to change this behavior, pass respectDoNotTrack=true.\n\n\n```html\n<div class=\"tpPlayer\"\n     id=\"player\"\n     // ... other configuration options\n     tp:muxPlugin = \"priority=1|URL=https://src.litix.io/cts/3/cts-mux.js|env_key=ENV_KEY|debug=false|player_name='EXAMPLE_PLAYER_NAME'|respectDoNotTrack=true>\n</div>\n<script>\n  // Creates the Player object that builds the component.\n  const player = new Player(\"player\");\n  player.bind(\"player\");\n</script>\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nThere is currently no way to change the default error tracking behavior. If this is something you need in your CTS PDK integration, please reach out.\n\nAds tracking with cts-mux\n\nMux has been tested with CTS's VAST plugin for ad support. Configure the VAST plugin as you would with your PDK player normally, and Mux will track ads automatically. No additional configuration is needed.\n\nCurrent release\n\nv3.13.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv3.13.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv3.13.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv3.13.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv3.13.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv3.13.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv3.13.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv3.13.7\n\n- Update mux-embed to v5.9.0\n\nv3.13.6\n\n- Update mux-embed to v5.8.3\n\nv3.13.5\n\n- Update mux-embed to v5.8.2\n\nv3.13.4\n\n- Update mux-embed to v5.8.1\n\nv3.13.3\n\n- Update mux-embed to v5.8.0\n\nv3.13.2\n\n- Update mux-embed to v5.7.0\n\nv3.13.1\n\n- Update mux-embed to v5.6.0\n\nv3.13.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv3.12.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv3.12.2\n\n- Update mux-embed to v5.4.2\n\nv3.12.1\n\n- Update mux-embed to v5.4.1\n\nv3.12.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv3.11.6\n\n- Update mux-embed to v5.3.3\n\nv3.11.5\n\n- Update mux-embed to v5.3.2\n\nv3.11.4\n\n- Update mux-embed to v5.3.1\n\nv3.11.3\n\n- Update mux-embed to v5.3.0\n\nv3.11.2\n\n- Update mux-embed to v5.2.1\n\nv3.11.1\n\n- Update mux-embed to v5.2.0\n\nv3.11.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv3.10.0\n\n- Refactors to properly enforce new TypeScript types and account for non-standard constructor usage by CTS.\n\n- Update mux-embed to v5.0.0\n\nv3.9.4\n\n- Update mux-embed to v4.30.0\n\nv3.9.3\n\n- Update mux-embed to v4.29.0\n\nv3.9.2\n\n- Update mux-embed to v4.28.1\n\nv3.9.1\n\n- Update mux-embed to v4.28.0\n\nv3.9.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv3.8.3\n\n- Update mux-embed to v4.26.0\n\nv3.8.2\n\n- Update mux-embed to v4.25.1\n\nv3.8.1\n\n- Update mux-embed to v4.25.0\n\nv3.8.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv3.7.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv3.6.5\n\n- Update mux-embed to v4.22.0\n\nv3.6.4\n\n- Update mux-embed to v4.21.0\n\nv3.6.3\n\n- Update mux-embed to v4.20.0\n\nv3.6.2\n\n- Update mux-embed to v4.19.0\n\nv3.6.1\n\n- Update mux-embed to v4.18.0\n\nv3.6.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv3.5.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv3.4.6\n\n- Update mux-embed to v4.15.0\n\nv3.4.5\n\n- Update mux-embed to v4.14.0\n\nv3.4.4\n\n- Update mux-embed to v4.13.4\n\nv3.4.3\n\n- Update mux-embed to v4.13.3\n\nv3.4.2\n\n- Update mux-embed to v4.13.2\n\nv3.4.1\n\n- Update mux-embed to v4.13.1\n\nv3.4.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv3.3.14\n\n- Publish package to NPM\n\nv3.3.13\n\n- Update mux-embed to v4.12.1\n\nv3.3.12\n\n- Update mux-embed to v4.12.0\n\nv3.3.11\n\n- Update mux-embed to v4.11.0\n\nv3.3.10\n\n- Update mux-embed to v4.10.0\n\nv3.3.9\n\n- Update mux-embed to v4.9.4\n\nv3.3.8\n\n- Use common function for generating short IDs\n- Update mux-embed to v4.9.3\n\nv3.3.7\n\n- Update mux-embed to v4.9.2\n\nv3.3.6\n\n- Update mux-embed to v4.9.1\n\nv3.3.5\n\n- Update mux-embed to v4.9.0\n\nv3.3.4\n\n- Update mux-embed to v4.8.0\n\nv3.3.3\n\n- Update mux-embed to v4.7.0\n\nv3.3.2\n\n- Update mux-embed to v4.6.2\n\nv3.3.1\n\n- Update mux-embed to v4.6.1\n\nv3.3.0\n\n- Bump mux-embed to 4.6.0\n\nv3.2.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv3.1.0\n\n- Update mux-embed to v4.1.1\n- Fix an issue where player_remote_played would not be reported correctly\n\nv3.0.0\n\n- Update mux-embed to v4.0.0\n- Support server-side device detection"
  },
  {
    "id": "76-_guides/developer/monitor-dash-js",
    "title": "Monitor dash.js",
    "path": "_guides/developer/monitor-dash-js.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-dash-js",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video. You can use the Mux-hosted version of the script or install via npm. mux-embed follows semantic versioning and the API will not change between major releases.\n\nCall mux.monitor and pass in a valid CSS selector or the video element itself. Followed by the SDK options and metadata. If you use a CSS selector that matches multiple elements, the first matching element in the document will be used.\n\nIn the SDK options, be sure to pass in the dashjs player instance.\n\nAlternatively, if your player does not immediately have access to the dash.js player instance, you can start monitoring dash.js at any time in the future. In order to do this, you can call either of the following:\n\n\n```js\nmux.addDashJS(\"#my-player\", options)\n// or\nmyVideoEl.mux.addDashJS(options)\n```\n\n\nLog in to the Mux dashboard and find the environment that corresponds to your env_key and look for video views. It takes about a minute or two from tracking a view for it to show up on the Metrics tab.\n\nIf you aren't seeing data, check to see if you have an ad blocker, tracking blocker or some kind of network firewall that prevents your player from sending requests to Mux Data servers.\n\nThe only required field in the options that you pass into mux-embed is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data key when calling mux.monitor.\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  dashjs: dashjsPlayer,\n  data: {\n    env_key: 'ENV_KEY', // required\n\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000\n\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call monitor. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\nmux.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\n\n```js\nmux.emit('#my-player', 'videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\nmux.emit('#my-player', 'programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  disableCookies: true,\n  dashjs: dashjsPlayer,\n  data: {\n    env_key: 'ENV_KEY',\n    // ... rest of metadata\n  }\n}\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  dashjs: dashjsPlayer,\n  respectDoNotTrack: true, // Disable tracking of browsers where Do Not Track is enabled\n  data: {\n    env_key: 'EXAMPLE_ENV_KEY',\n    // ... rest of metadata\n  }\n}\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, mux-embed will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\nmux.emit('#my-player', 'error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\nmux.monitor('#my-player', {\n  debug: false,\n  errorTranslator: errorTranslator,\n  dashjs: dashjsPlayer,\n  data: {\n    env_key: 'ENV_KEY', // required\n\n    // ... additional metadata\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  automaticErrorTracking: false,\n  dashjs: dashjsPlayer,\n  data: {\n    env_key: 'EXAMPLE_ENV_KEY', // required\n\n    // ... additional metadata\n  }\n```\n\n\nUse TypeScript with mux-embed\n\nmux-embed now provides TypeScript type definitions with the published package! If you want to opt in, you can check out how here.\n\nCustomize beacon collection domain\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  dashjs: dashjsPlayer,\n  data: {\n    env_key: 'EXAMPLE_ENV_KEY', // required\n    // ... additional metadata\n  }\n});\n```"
  },
  {
    "id": "77-_guides/developer/monitor-exoplayer",
    "title": "Monitor ExoPlayer",
    "path": "_guides/developer/monitor-exoplayer.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-exoplayer",
    "content": "This documents integration instructions for Google's ExoPlayer library, version 2.x. ExoPlayer versions before 2.0 are not supported. As of version 3.0.0 of Mux's integration with ExoPlayer, only versions of ExoPlayer greater than or equal to 2.10.x are supported.\n\nThe Mux integration with ExoPlayer is built on top of Mux's core Java SDK, and the full code can be seen here: muxinc/mux-stats-sdk-exoplayer.\n\nAdd Gradle dependency on the Mux ExoPlayer SDK\nAdd the Mux Maven repository to your Gradle file:\n\n```gradle\nrepositories {\n    maven {\n        url \"https://muxinc.jfrog.io/artifactory/default-maven-release-local\"\n    }\n}\n```\n\n\nNext, add a dependency on the Mux Data ExoPlayer SDK. Supported versions of ExoPlayer are:\n - r2.10.6\n - r2.11.1\n - r2.12.1\n - r2.13.1\n - r2.14.1\n - r2.15.1\n - r2.16.1\n - r2.17.1\n - r2.18.1\n - r2.19.1\n - amznPort (see below)\n\nThere is typically API compatibility within an ExoPlayer major-minor version, so you should be able to pair one of the versions listed above with any player sharing the same major-minor version (e.g., the ExoPlayer r2.12.1 version of the Mux ExoPlayer SDK works with ExoPlayer r2.12.0 and r2.12.2 equally well).\n\nAdd a dependency to your Gradle file using the Mux SDK version and an ExoPlayer version listed above in the following format:\n\n```gradle\napi 'com.mux.stats.sdk.muxstats:MuxExoPlayer_(ExoPlayer SDK version with underscores):(Mux SDK version)'\n```\n\n\nExample using Mux ExoPlayer SDK 2.7.2 and ExoPlayer version r2.16.1:\n\n```gradle\napi 'com.mux.stats.sdk.muxstats:MuxExoPlayer_r2_16_1:2.7.2'\n```\n\n\nConfigure ProGuard/R8\n\nIf you're using ProGuard or R8, you'll need to add the following line to your app's proguard rules file (eg, proguard-rules.pro). This won't change anything about your app binary, it just suppresses a known warning\n\n\n```\n-dontwarn com.google.ads.interactivemedia.v3.api.**\n```\n\n\nAmazon ExoPlayer Port\nIn addition to the versions above, the Mux Data ExoPlayer SDK also supports Amazon's official ExoPlayer port for Amazon Devices. If you are monitoring ExoPlayer on an Amazon device, you can get that version with the following line:\n\n```gradle\napi 'com.mux.stats.sdk.muxstats:MuxExoPlayer_amznPort:(Mux SDK version)'\n```\n\n\nFor an example integration, you can see the demo application within muxinc/mux-stats-sdk-exoplayer which integrates Mux into the ExoPlayer demo application.\n\nFirst, create the CustomerPlayerData and CustomerVideoData objects as appropriate for your current playback\n\n\n```kotlin\nval customerData = CustomerData().apply {\n        customerVideoData = CustomerVideoData().apply {\n          // Data about this video\n          // Add or change properties here to customize video metadata such as title,\n          //   language, etc\n          videoTitle = \"Mux ExoPlayer Android Example\"\n          // ExoPlayer doesn't provide an API to obtain this, so it must be set manually\n          videoSourceUrl = videoUrl\n        }\n        customerViewData = CustomerViewData().apply {\n          // Data about this viewing session\n          viewSessionId = UUID.randomUUID().toString()\n        }\n        customerViewerData = CustomerViewerData().apply {\n          // Data about the Viewer and the device they are using\n          muxViewerDeviceCategory = \"kiosk\"\n          muxViewerDeviceManufacturer = \"Example Display Systems\"\n          muxViewerOsVersion = \"1.2.3-dev\"\n        }\n        customData = CustomData().apply {\n          // Add values for your Custom Dimensions.\n          // Up to 5 strings can be set to track your own data\n          customData1 = \"Hello\"\n          customData2 = \"World\"\n          customData3 = \"From\"\n          customData4 = \"Mux\"\n          customData5 = \"Data\"\n        }\n```\n\n\nNext, create the MuxStatsExoPlayer object by passing your Context (typically your Activity), your ENV_KEY, the ExoPlayer instance, and the customer data object you just created.\n\n\n```kotlin\nmuxStatsExoPlayer = exoPlayer.monitorWithMuxData(\n      context = requireContext(),\n      envKey = \"YOUR_ENV_KEY_HERE\",\n      playerView = playerView,\n      customerData = customerData\n    )\n```\n\n\nIf you haven't set your playerView already, do so now. We recommend this in order to determine a number of viewer context values as well as track the size of the video player.\n\n\n```java\nmuxStatsExoPlayer.setPlayerView(simpleExoPlayerView.getVideoSurfaceView());\n```\n\n\nFinally, when you are destroying the player, call the MuxStatsExoPlayer.release() function.\n\n\n```java\nmuxStatsExoPlayer.release()\n```\n\n\nAfter you've integrated, start playing a video in your player. A few minutes after you stop watching, you'll see the results in your Mux data dashboard. Login to the dashboard and find the environment that corresponds to your env_key and look for video views.\n\nNote For ExoPlayer v2.15 and below\n\nOn older supported versions of ExoPlayer, Mux prefers that you pass an instance of SimpleExoPlayer specifically, instead of any ExoPlayer. In the latter case, however, some metrics and errors may not be available, such as upscaling metrics. Updating to ExoPlayer r2.16.0 or higher will remove this limitation\n\n\n```kotlin\nmuxStatsExoPlayer = exoPlayer.monitorWithMuxData(\n      context = requireContext(),\n      envKey = \"YOUR_ENV_KEY_HERE\",\n      playerView = playerView,\n      customerData = customerData\n    )\n\n```\n\nor in java:\n\n```java\n// Make sure to monitor the player before calling `prepare` on the ExoPlayer instance\nmuxStatsExoPlayer = new MuxStatsExoPlayer(this, \"YOUR_ENV_KEY_HERE\", player, playerView, customerData);\n```\n\n\nOptions are provided to this SDK via the objects within the CustomerData object.\n\nAll metadata details are optional, however you'll be able to compare and see more interesting results as you include more details. This gives you more metrics and metadata about video streaming, and allows you to search and filter on important fields like the player version, CDN, and video title.\n\nThere is one caveat with ExoPlayer; ExoPlayer does not provide an API to retrieve the current source URL from the player. Due to this, CustomerVideoData has a method allowing you to set via CustomerVideoData.setVideoSourceUrl(String url). Setting this value will allow you to see the source URL as well as the dimension Source Hostname within the dashboard.\n\nFor more information, see the Metadata Guide.\n\nChanging the video\n\nThere are two cases where the underlying tracking of the video view need to be reset. First, when you load a new source URL into an existing player, and second when the program within a singular stream changes (such as a program within a live stream).\n\nNote: You do not need to change the video info when changing to a different source of the same video content (e.g. different resolution or video format).\n\nNew source\n\nWhen you change to a new video (in the same player) you need to update the information that Mux knows about the current video. Examples of when this is needed are:\n\n The player advances to the next video in a playlist\n The user selects a different video to play\n\nThis is done by calling muxStatsExoPlayer.videoChange(CustomerVideoData) which will remove all previous video data and reset all metrics for the video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nIt's best to change the video info immediately after telling the player which new source to play.\n\nNew program (in single stream)\n\nIn some cases, you may have the program change within a stream, and you may want to track each program as a view on its own. An example of this is a live stream that streams multiple programs back to back, with no interruptions.\n\nIn this case, call muxStatsExoPlayer.programChange(CustomerVideoData). This will remove all previous video data and reset all metrics for the video view, creating a new video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nManually set when a video is being played full-screen\n\nFor most use cases, the SDK is capable of detecting whether or not a video is being played full-screen. Specifically, it can do so in the case where the player view is the same size as the device display (excepting ActionBars and other framework window decoration).\n\nFor other uses cases (non-overlaid controls, window decoration via plain Views, etc) you may need to tell the SDK when the user switches to full-screen.\n\nIf you are using SimplePlayerView or a similar ExoPlayer UI component, you can set the full-screen flag from the OnFullScreenModeChangedListener.\n\n\n```kotlin\n  override fun onCreate(savedInstanceState: Bundle?) {\n    super.onCreate(savedInstanceState)\n\n    // If you are using SimplePlayerView, StyledPlayerView, etc\n    playerView = findViewById(R.id.my_player_view)\n\n    playerView.setFullscreenButtonClickListener { isFullScreen ->\n      // Set presentation based on which mode is requested\n      if(isFullScreen) {\n        muxStats.presentationChange(MuxSDKViewPresentation.FULLSCREEN)\n      } else {\n        muxStats.presentationChange(MuxSDKViewPresentation.NORMAL)\n      }\n      // Handle moving to fullscreen playback with your code\n    }\n  }\n```\n\n\nError tracking\n\nBy default, Mux's integration with ExoPlayer automatically tracks fatal errors as thrown by ExoPlayer. If a fatal error happens outside the context of ExoPlayer and you want to track it with Mux, you can call muxStatsExoPlayer.error like this:\n\n\n```kotlin\n// Error code: integer value for the generic type of error that\n// occurred.\n// Error message: String providing more information on the error\n// that occurred.\n// For an example, the HTML5 video element uses the\n// following: https://developer.mozilla.org/en-US/docs/Web/API/MediaError\n// for codes and messages. Feel free to use your own codes and messages\nval errorCode = 1\nval errorMessage = \"A fatal error was encountered during playback\"\nval errorContext = \"Additional information about the error such as a stack trace\"\nval error = MuxErrorException(errorCode, errorMessage, errorContext)\nmuxStatsExoPlayer.error(error)\n```\n\nNote that muxStatsExoPlayer.error(MuxErrorException e) can be used with or without automatic error tracking. If your application has retry logic that attempts to recover from ExoPlayer errors then you may want to disable automatic error tracking like this:\n\n\n```kotlin\nmuxStatsExoPlayer.setAutomaticErrorTracking(false)\n```\n\n\nIt is important that you only trigger an error when the playback has to be abandoned or aborted in an unexpected manner, as Mux tracks fatal playback errors only.\n\nUsage with Google Interactive Media Ads (IMA)\n\nIf you are using Google's IMA SDK to play back ads within your Android application, you can configure Mux to monitor the ad performance by passing your instance of AdsLoader to muxStatsExoPlayer.monitorImaAdsLoader(adsLoader).\n\nExoPlayer r2.12.x and Up\n\n\n```kotlin\n// For example, within the r2.12.x demo application\n// PlayerActivity.getAdsLoader\nadsLoader = ImaAdsLoader.Builder(context = this)\n    /*\n     * This replaces `monitorImaAdsLoader` method because in r2.12.x ImaAdsLoader\n     * will create google.v3.AdsLoader on adRequest, which means that monitorImaAdsLoader\n     * Will always receive null pointer and will be unable to recieve add events.\n     */\n    .setAdErrorListener(muxStats.getAdErrorEventListener())\n    .setAdEventListener(muxStats.getAdEventListener())\n    .build()\n```\n\n\nExoPlayer pre-r2.12.x\n\n\n```kotlin\n// Within setting up the AdsMediaSource\nsdkFactory = ImaSdkFactory.getInstance()\nadsLoader = sdkFactory.createAdsLoader(this)\nmuxStatsExoPlayer.monitorImaAdsLoader(adsLoader)\n```\n\n\nAs of version 1.3.0 and later, the Mux SDK for ExoPlayer supports firing an event when the playback orientation changes. You can trigger this by calling muxStatsExoPlayer.orientationChange(MuxSDKViewOrientation orientation), passing either MuxSDKViewOrientation.LANDSCAPE or MuxSDKViewOrientation.PORTRAIT depending on the current orientation of the player.\n\nJava and Android Gradle Plugin Build Compatibility\nStarting with version 2.6.0, the Mux SDK for ExoPlayer requires JDK 11 and version 7.0 or greater of the Android Gradle Plugin. This is only a requirement for build compatibility. The Mux SDK for ExoPlayer will remain bytecode-compatible with Java 1.8.\n\nIf you are updating from version 2.5.9 or lower, you may need to:\n  - Update Android Studio to version 2020.x or greater\n  - Update your dependency on the Android Build Tools plugin to 7.0.0 or greater\n  - Update Gradle in gradle-wrapper.properties to 7.0.2 or greater\n  - Ensure your Android Studio is using JDK 11:\n    - Go to Android Studio Settings\n    - Go Build, Execution and Deployment -> BuildTools -> Gradle\n    - If the Gradle JDK option is not set to a Java 11 JDK, click the dropdown and select a Java 11 JDK. It should be the default on Studio 2020.x\n\nCurrent release\n\nv3.5.2\n\nFixes:\n fix rebuffering not ended when seeking starts\n fix extra-verbose logging causing crashes in some cases\n\nInternal library updates\n Update MuxCore to v8.1.2\n\nPrevious releases\n\nv3.5.1\n\nFixes:\n allow media3 and exoplayer Data SDKs to coexist in the same app build\n\nv3.5.0\nNew:\n MuxErrorException now allows you to report non-fatal and business-related errors\n\nImprovements:\n Updated MuxCore to version 8.0.0\n Updated Android Core to version 1.2.0\n\nFixes:\n fix: Capture IMA CSAI media failures with LOG events\n\nv3.4.7\nFixes:\n fix: ad metadata not collected for mid and postrolls\n fix: time-to-first-frame incorrect if user seeks before play starts\n\nv3.4.6\nFixes:\n fix: seeking not properly tracked on ExoPlayer 2.18 and 2.19\n\nv3.4.5\nImprovements:\n Add support for ExoPlayer 2.19\n\nv3.4.4\nFixes:\n fix issue where beaconCollectionDomain wouldn't work correctly\n\nv3.4.3\nImprovements:\n chore: Cut support for ExoPlayer v2.10.x - v2.13.x\n fix: starting an ad break while rebuffering doesn't end rebuffering\n\nv3.4.2\nImprovements:\n collect segment response headers beginning with x-litix\n\nv3.4.1\nImprovements:\n Include ad playback time in total playback time\n\nv3.4.0\nUpdated:\n Added viewDrmType to CustomerViewData so customers can provide their own value\nImprovements:\n Under-the-hood reliability improvements during large events\n\nv3.3.4\nImprovements:\n Simplify some internal HTTP error handling. This change should not affect the majority of users\n\nv3.3.3\nImprovements:\n Update to MuxCore v7.8.0, adds longBeaconDispatch to CustomOptions. This feature should only be used in a small number of use cases, and your setting may be overridden by mux's backend servers\n\nv3.3.2\nImprovements:\n Update beacon batch interval from 5s to 10s (277)\n\nv3.3.1\nImprovements:\n Update to Mux Core 7.7.2, Fixes bug in ad-metadata reporting\n\nv3.3.0\nNew:\n Add ad-related metadata to ad events\nImprovements:\n Update to Gradle 7.3 + Wrapper 7.4.0 + Simplify Demo Variant Names\n\nv3.2.0\nUpdates:\n Improve Error Code Variety on ExoPlayer 2.15+\n Add Error Context and DRM Type for views\n Add API Total dropped frames\n\nImprovements:\n Added extra values for Rendition lists.\n\nv3.1.1\nFixes:\n Fix ArrayIndexOutOfBounds Exception after clearing the media item\n\nv3.1.0\nUpdates:\n Override metadata about your users' device with CustomerViewerData\n\nFixes:\n Allow overriding Device Category metadata\n Exoplayer 2.11: Fix renditonchange sent on non-video track changes\n Fix beacon dispatcher crashing when verbose logging is enabled\n\nImprovements:\n Update to MuxCore 7.4.0 (improvements/fixes have been noted in the release notes)\n\nv3.0.2\nImprovements:\n Collect Request IDs for HLS segments for Error Tracking\n\nv3.0.1\nFixes:\n Fix the Kotlin extension for MuxStatsExoPlayer to require envKey\n\nv3.0.0\nAPI Improvements:\n Automatic Screen Size Detection: You no longer have to manually input your device's screen size to see fullscreen/screen size metrics. Just pass in your Activity and PlayerView when you make your MuxStatsExoPlayer\n Supply your player view via constructor parameter\n Kotlin extension for monitoring ExoPlayer\n ENV_KEY is now a required parameter to create a MuxStatsExoPlayer. It's required, so it's been made mandatory. The existing (non-env-key) constructors are now deprecated\n\nPlease refer to the new usage guide for more details\n\nAPIs Removed:\n Removed deprecated constructors of MuxExoPlayer. Use CustomerData instead\n Removed MuxExoPlayer.setStreamType() as it was no longer used\n Removed several methods, such as getPlayerData(), getCurrentPosition(), etc that are not meant for public use\n\nThe full list of removed methods is long, but the change is unlikely to impact you if you are using the SDK as documented. You can review the complete list of removed APIs on our Release page on GitHub\n\nCommit Changelog:\nBreaking:\n Remove Support for ExoPlayer 2.9.6\n Remove deprecated constructors (see above)\n\nUpdates:\n API Update: Add Environment Key via Constructor\n\nImprovements:\n Convert to Kotlin, Refactor ExoPlayer interaction for maintainability, remove deprecations\n Remove non-ads demos, as the difference is not significant. This reduces CI time\n Remove Release Variants for test and demo apps. They are not required, and this reduces build/CI time\n Add GitHub Actions for Basic CI and Release Automation\n\nv2.10.0\nFixes:\n Fix setPlayerSize to treat input as physical pixels, as documented. If you are using setPlayerSize(), you may have to update your code\n\nv2.9.1\nImprovements:\n Support for ExoPlayer v2.18.1\n Fix crashes in rare cases where the player is released asynchronously\n Update MuxCore to v7.3.1\n\nMuxCore Changes:\n Split views with long periods of inactivity into multiple views\n\nv2.9.0\nImprovements:\n Add ability to override OS data values (incubating)\n Update to MuxCore 7.3.0\n\nMuxCore Changes:\n Support for overriding OS data values\n\nv2.8.0\nImprovements:\n Add support for Custom Data Domains\n Add support for manually tracking if a view was played automatically\n Update to MuxCore v7.2.0\n\nFixes:\n Fix Issue with HLS/DASH CDN tracking\n\nMuxCore Changes:\n Custom Beacon Collection Domains\n Add Autoplay flag on CustomerPlayerData\n Fix serialization strategy for complex objects in beacons\n\n2.7.2\nFixes:\n Fix Build/Crash Issues When Used With Minimal/Custom ExoPlayers\n\nv2.7.1\nFixes:\n Fix an issue where our core library wasn't being packaged properly\n\nv2.7.0\nImprovements:\n Add support for Experiment Tracking via manifest tags (HLS only)\n Add support for Amazon ExoPlayer Port\n Add support for ExoPlayer v2.17.x\n\nFixes:\n HLS/DASH: Fix CDN tracking when playlist and chunks are coming from different CDNs\n Rate-limit requestcompleted events to prevent ingestion errors when the DataSource enters a retry loop\n\nMuxCore Changes\n Add support for Experiment Tracking\n\nv2.6.1\nMuxCore 7.0.10 Fixes:\n  - Fix event-handling issues that can cause events to be dropped in rare cases\n\nv2.6.0\nImprovements:\n  - Add support for ExoPlayer r2.16.1\n  - Update to AGP 7.0\n  - Add additional logging for Event dispatching errors\n  - Add ability to override device name\n\nFixes\n  - Fix an issue with screen dimensions while in fullscreen\n\nMuxCore 7.0.7 and 7.0.8 Changes:\n  - Fix potential packaging errors when used with androidX\n  - Fix bug related to the manual fullscreen API\n\nv2.5.9\nImprovements:\n - Add support for measuring live stream glass-to-glass latency (181)\n\nMuxCore 7.0.6 Changes\n - Added support for Live Latency\n\nMuxCore 7.0.7 Changes\n - Final API for Live latency\n\nv2.5.8\nImprovements:\n - Add API to indicate whether video is shown fullscreen\n - MuxCore:\n     - Add support for latency metrics\n     - Add a Fullscreen enum and API\n     - Remove Sentry\n\nFixes:\n - Fix for usage of legacy support libraries\n - Added -donotwarn for ExoPlayer classes\n - MuxCore:\n     - Fix upscale percentages by clamping player size\n\nv2.5.7\nImprovements:\n - Add support for ExoPlayer r2.15\n\nFixes:\n - Updating to MuxCore 7.0.4 to fix ConcurrentModificationException when calling updateCustomerData.\n\nv2.5.6\nFixes:\n - Fix reference to packageVersionName in Gradle deployVariant task. Includes a change to the Gradle package layout, see example in docs.\n\nv2.5.5\nFixes:\n - Problem with ExoPlayer default implementation of methods on interfaces.\n\nv2.5.4\nFixes:\n - Reverts audio test improvements introduced in v2.5.3.\n\nv2.5.3\nImprovements:\n - Upgrade Docker base image used for builds to JDK 8u302\n - Audio test improvements\n\nFixes:\n - Retain code obfuscation and mapping files\n - Added pause event to be dispatched when player-stop is called\n\nv2.5.2\n - Updating to MuxCore 7.0.2 with fixes to code obfuscation\n\nv2.5.1\n - Fix packaging of ExoPlayer SDK AAR with MuxCore\n\nv2.5.0\nImprovements:\n - Releasing process involving Artifactory\n - MuxCore pulled from Maven instead of in bundled jar\n - Support for overriding the beacon domain\n - Javadoc coverage for public API\n - For API version 30+ use context.getDisplay instead of WindowManager.\n\nFixes:\n - Removed VideoComponent listener and now capturing firstFrameRendered\n - Added conversion from physical px to dpx on setScreen size\n -  MuxCore:\n     - Fix customer data null pointer exception\n     - Fixed key name in setMuxEmbed function\n     - Handle case where player size is larger than physical screen, treat as full-screen\n\nv2.4.15\n - Reduced the amount of messages sent each second to main thread.\n - Additional logging for bandwidth metrics tests.\n\nv2.4.14\n - Support ExoPlayer 2.14\n\nv2.4.13\n - Add CustomerData class to ProGuard\n\nv2.4.12\n - Add checkstyle task to Gradle\n - Replaced FrameRendererListener with VideoListener.\n - Custom data update: deprecate MuxExoPlayer constructors that take a CustomerData argument separately, add custom-dimensions example to demo app\n\nv2.4.11\n - Run automated tests on real devices\n - Fix MIME-type detection for HLS & DASH stream by allowing the server to make that determination.\n - Upgrade MuxCore to 6.6.0, which includes:\n   - Add support for custom dimensions in view metadata\n   - Fix propagation of bandwidth metrics data by sending even when unchanged\n\nv2.4.10\n - Fix an issue where a null pointer exception may be raised when playing back DASH content (only present in v2.4.9)\n\nv2.4.9 (deprecated)\n - Added support for CDN header tracking, including mid-stream CDN switching\n - Fix a null-pointer crash in the ads listener\n - Updated the Mux Core library, added support for bandwidth metrics\n\nv2.4.8\n - Reset internal state when calling videochange, fixing an issue where rebuffering may be reported incorrectly after calling videochange\n\nv2.4.7\n - Fix an issue where metrics weren't tracked correctly sometimes when playback starts with a seek event\n - Upgrade MuxCore to 6.3.0, which includes:\n   - Reset error-tracking state when loading a new video.\n - [Internal] Fix automated tests for r2.13.1\n\nv2.4.5\n - Add support for ExoPlayer r2.13.x\n\nv2.4.4\n - Removed all content from res directory under MuxExoPlayer, ensuring smaller build size\n - [Internal] Added test for playback end events and view end event\n - [Maintenance] Reformat code with Google Java style\n - Upgrade MuxCore to 6.2.0, which includes:\n   - Added viewEnd event on player release.\n\nv2.4.3\n - Fix an issue where customerViewData was not propagated correctly through all constructors\n\nv2.4.2\n - Fix an issue where customerViewData was not propagated correctly through constructors\n\nv2.4.1\n - Fix an issue where detection of rebuffering after seeking was not working at times\n - Use a random UUID stored in shared preferences for mux_viewer_id\n - Fix an issue where view_session_id wasn't sent correctly\n\nv2.4.0\n - Fix an issue where additional icons and image files were included\n - Fix an issue where the application would crash on Android 11\n - Expose additional fatal playback errors\n\nv2.3.1\n - Fix an issue where AAR file size was too large due to inadvertent inclusion of a video file\n\nv2.3.0\n - Fix an issue where logical resolution was calculated incorrectly\n - Report wired instead of ethernet for certain connection types\n - [internal] Integrate automated integration tests\n\nv2.2.0\n - Upgrade to Android Studio 4.1\n - Upgrade to Gradle 6.1.1\n - Update Dockerfile and build script for new tooling\n - Support back to minAPI 16 via multidexing support\n\nv2.1.0\n - Support ExoPlayer r2.12.x flavors\n - Expose CustomerViewData through ProGuard\n - Ensure packages are scoped to com.mux.stats.sdk in ProGuard\n - Update version reported by the plugin (v2.0.0 reported v1.5.0 unintentionally, now will report v2.1.0)\n - Fix an issue where accessing ad integration could cause a crash\n - Bump to MuxCore v6.0.0\n - Fix invalid rebuffering reported for audio-only and playback\n - Ensure that events are sent in a more timely manner (some events are held after a PauseEvent until\nthe next active event)\n\nv2.0.0\n - Bump to v5.0.0 of MuxCore\n   - Update ad handling logic to ensure that ad metrics and dimensions are tracked correctly\n   - Retry sending failed beacons, rather than letting them drop\n   - Fix issue where we were incorrectly calculating scaling metrics when screen or video resolution was negative\n   - Fix an issue where watch time is incorrectly increasing after certain events\n   - Make sure that time to first frame is not tracked for views that result from programchange\n   - Add support for viewer_connection_type, which is a breaking change for IDevice, as it adds another method that must be implemented\n   - Add support for view_session_id, which includes an additional CustomerViewData class. This changes the constructor for creating a MuxStats instance\n - Drop support for ExoPlayer r2.7.x and r2.8.x\n - Implement SeekingEvent directly in MuxStatsExoPlayer\n - Fix issue where source type could be null and cause a crash\n - Fix an issue where ad events are sent out of order in some cases\n - Add connection type detection\n - Report logical sizes for player size, rather than physical size\n - Fix an issue where time to first frame was incorrectly measured in some cases, such as mid- or post-roll ad playback without a pre-roll\n - Add support for CustomerViewData, including setViewSessionId\n\nv1.5.0\n - Fix an issue where if you were using muxStatsExoPlayer.setPlayerSize(width, height) those values were not used correctly. Note: If you call this, you must update the player size whenever that changes, as the SDK will no longer pull those values automatically.\n\nv1.4.0\n - Move MuxSDKViewOrientation to com.mux.stats.sdk.core.MuxSDKViewOrientation and expose it publicly\n\nv1.3.0\n - Add support for RenditionChangeEvent, which is tracked automatically\n - Add support for OrientationChangeEvent, which can be triggered by calling muxStatsExoPlayer.orientationChange(MuxSDKViewOrientation orientation). Supported orientations are MuxSDKViewOrientation.LANDSCAPE and MuxSDKViewOrientation.PORTRAIT.\n - Fix an issue where full screen tracking was not working correctly\n\nv1.2.0\n - Add support for ExoPlayer 2.11.x\n - Note: there is a known issue right now with ExoPlayer r2.11.x where ads are not tracked correctly. This is under development.\n\nv1.1.0\n - Add support for additional debug logging. See muxStatsExoPlayer.enableMuxCoreDebug(Boolean enable, Boolean verbose)\n - Add the ability to update customerVideoData and customerPlayerData mid-stream, in cases that certain metadata may not be available at the beginning of playback. See muxStatsExoPlayer.updateCustomerData(CustomerPlayerData customerPlayerData, CustomerVideoData customerVideoData)\n - Fix an issue where if MuxStatsExoPlayer is initialized too late, the stream is not tracked correctly\n - Fix an issue where Mux Plugin Version is reported incorrectly\n - Fix an issue where the EndedEvent is not sent to the backend\n - Fix an issue where tracking playback is not correct when playWhenReady is set to false (i.e. non-autoplay playback)\n - Fix an issue where events could be sent after playback completes, forcing the view to be active for longer than it actually was\n - Utilize more accurate client timestamps for event timing\n\nv1.0.0\n - Add support for ExoPlayer 2.9.x\n - Add support for ExoPlayer 2.10.x\n - Fix issue where ExoPlayer versions 2.9.x and greater would log messages about accessing the player on the wrong thread\n - breaking change Removed support for ExoPlayer 2.6.x and older (due to changes in build pipeline and Gradle configurations)\n - Support Gradle 3.5.2\n\nv0.5.1\n - Clean up demo application\n - Allow disabling of Sentry reporting for exceptions.\n\nv0.5.0\n - Deprecated method muxStatsExoPlayer.getImaSDKListener in favor of muxStatsExoPlayer.monitorImaAdsLoader(adsLoader). The previous method will still work, but you should migrate to the new method as the deprecated method will be removed with the next major version.\n - Fix an issue where Google IMA SDK was a hard requirement unintentionally.\n\nv0.4.5\n - Introduce support for tracking ads with Google's IMA SDK.\n\nv0.4.3\n - Fix an issue where a NullPointerException may occur during playback of a video while tracking bandwidth metrics.\n\nv0.4.2\n - Added API method programChange(CustomerVideoData customerVideoData), for use when inside of a single stream the program changes. For instance, in a long-running live stream, you may have metadata indicating program changes which should be tracked as separate views within Mux. Previously, videoChange might have been used for this case, but this would not work correctly, and you would not necessarily have seen the subsequent views show up.\n - Fixed a bug where under poor network conditions, an exception raised as a result of a network request could result in not tracking the view correctly subsequently (such as missing rebuffer tracking after this point).\n\nv0.4.1\n- Remove the listeners on the ExoPlayer object when release is called.\n  - This fixes and issue where the application may crash after calling release\n    if the ExoPlayer instance is removed while the SDK is still listening to\n    it.\n\nv0.4.0\n- [feature] Support bandwidth throughput metrics on video segment download\n  for HLS and Dash streaming.\n- breaking change The signature for getAdaptiveMediaSourceEventListener\n  and getExtractorMediaSourceEventListener has been changed. These methods\n  are used to enable throughput metrics tracking for ExoPlayer versions\n  _before_ r2.8.0, and now require that the streaming protocol type is\n  passed as the first parameter. The type is the same as is returned from\n  this ExoPlayer API call.\n\nv0.3.0\n- breaking change The signature for the MuxStatsExoPlayer constructor\n  has changed, and now requires an additional parameter (the first) to be\n  and Android Context reference.\n- abstract more core logic into mux-stats-sdk-java\n- [build] rename and copy build artifacts\n\nv0.2.2\n- add back in previously missing methods to MuxStatsExoPlayer:\n  - videoChange\n  - setPlayerSize\n  - error\n  - setAutomaticErrorTracking\n\nv0.2.1\n- add support for ExoPlayer r2.7.x\n- add support for ExoPlayer r2.8.x\n- update to v2.1.0 of mux-stats-sdk-java"
  },
  {
    "id": "78-_guides/developer/monitor-flowplayer",
    "title": "Monitor Flowplayer",
    "path": "_guides/developer/monitor-flowplayer.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-flowplayer",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video.\n\n<CodeExamples\n  examples={{\n    npm: npm install --save @mux/mux-data-flowplayer,\n    yarn: yarn add @mux/mux-data-flowplayer,\n    cdn:\n\n  }}\n  exampleOrder=\"npm,yarn,cdn\"\n/>\n\nCall flowplayer like you normally would and save a reference to the player. Call initFlowplayerMux with the player reference.\n\nPassing in flowplayer global\n\nYou'll see the 3rd argument to initFlowplayerMux is flowplayer. This is the global flowplayer object. If you are using a bundler and importing flowplayer with require or import then you'll need to pass in the flowplayer object.\n\nIf no flowplayer object is passed in, then initFlowplayerMux will look for flowplayer on then global window object.\n\nThe only required field in the options that you pass into @mux/mux-data-flowplayer is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data on initialization.\n\n\n```js\ninitFlowplayerMux(player, container, {\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000, can use `initFlowplayerMux.utils.now()`\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call initFlowplayerMux. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\n// player is the instance that gets returned from the `flowplayer` function\nplayer.mux.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\n\n```js\n// player is the instance that gets returned from the `flowplayer` function\nplayer.mux.emit('videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\n// player is the instance that gets returned from the `flowplayer` function\nplayer.mux.emit('programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\n// player is the instance that gets returned from the `flowplayer` function\ninitFlowplayerMux(player, container, {\n  debug: false,\n  disableCookies: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n});\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\n// player is the instance that gets returned from the `flowplayer` function\ninitFlowplayerMux(player, {\n  debug: false,\n  respectDoNotTrack: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n});\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, @mux/mux-data-flowplayer will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\n// player is the instance that gets returned from the `flowplayer` function\nplayer.mux.emit('error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\n// player is the instance that gets returned from the `flowplayer` function\ninitFlowplayerMux(player, {\n  debug: false,\n  errorTranslator,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\ninitFlowplayerMux(player, {\n  debug: false,\n  automaticErrorTracking: false,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nAds tracking with @mux/mux-data-flowplayer\n\nMux has been tested with and support Flowplayer's IMA and VAST plugins for ad support. No addition configuration is needed, Mux will track ads automatically.\n\nCustomize beacon collection domain\n\n\n```js\ninitFlowplayerMux(player, {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nCurrent release\n\nv3.14.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv3.14.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv3.14.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv3.14.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv3.14.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv3.14.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv3.14.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv3.14.7\n\n- Update mux-embed to v5.9.0\n\nv3.14.6\n\n- Update mux-embed to v5.8.3\n\nv3.14.5\n\n- Update mux-embed to v5.8.2\n\nv3.14.4\n\n- Update mux-embed to v5.8.1\n\nv3.14.3\n\n- Update mux-embed to v5.8.0\n\nv3.14.2\n\n- Update mux-embed to v5.7.0\n\nv3.14.1\n\n- Update mux-embed to v5.6.0\n\nv3.14.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv3.13.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv3.13.2\n\n- Update mux-embed to v5.4.2\n\nv3.13.1\n\n- Update mux-embed to v5.4.1\n\nv3.13.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv3.12.6\n\n- Update mux-embed to v5.3.3\n\nv3.12.5\n\n- Update mux-embed to v5.3.2\n\nv3.12.4\n\n- Update mux-embed to v5.3.1\n\nv3.12.3\n\n- Update mux-embed to v5.3.0\n\nv3.12.2\n\n- Update mux-embed to v5.2.1\n\nv3.12.1\n\n- Update mux-embed to v5.2.0\n\nv3.12.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv3.11.5\n\n- Update mux-embed to v5.0.0\n\nv3.11.4\n\n- Update mux-embed to v4.30.0\n\nv3.11.3\n\n- Update mux-embed to v4.29.0\n\nv3.11.2\n\n- Update mux-embed to v4.28.1\n\nv3.11.1\n\n- Update mux-embed to v4.28.0\n\nv3.11.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv3.10.3\n\n- Update mux-embed to v4.26.0\n\nv3.10.2\n\n- Update mux-embed to v4.25.1\n\nv3.10.1\n\n- Update mux-embed to v4.25.0\n\nv3.10.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv3.9.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv3.8.5\n\n- Update mux-embed to v4.22.0\n\nv3.8.4\n\n- Update mux-embed to v4.21.0\n\nv3.8.3\n\n- Update mux-embed to v4.20.0\n\nv3.8.2\n\n- Update mux-embed to v4.19.0\n\nv3.8.1\n\n- Update mux-embed to v4.18.0\n\nv3.8.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv3.7.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv3.6.0\n\n- Expose utils on SDK initialization function to expose utils.now() for player_init_time\n\n- Update mux-embed to v4.15.0\n\nv3.5.5\n\n- Update mux-embed to v4.14.0\n\nv3.5.4\n\n- Update mux-embed to v4.13.4\n\nv3.5.3\n\n- Update mux-embed to v4.13.3\n\nv3.5.2\n\n- Update mux-embed to v4.13.2\n\nv3.5.1\n\n- Fixes an issue with accessing the global object\n- Update mux-embed to v4.13.1\n\nv3.5.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv3.4.3\n\n- Publish package to NPM\n\nv3.4.2\n\n- Update mux-embed to v4.12.1\n\nv3.4.1\n\n- Update mux-embed to v4.12.0\n\nv3.4.0\n\n- Add ability to pass in the Flowplayer instance to initFlowplayerMux function\n\n- Update mux-embed to v4.11.0\n\nv3.3.10\n\n- Update mux-embed to v4.10.0\n\nv3.3.9\n\n- Update mux-embed to v4.9.4\n\nv3.3.8\n\n- Use common function for generating short IDs\n- Update mux-embed to v4.9.3\n\nv3.3.7\n\n- Update mux-embed to v4.9.2\n\nv3.3.6\n\n- Update mux-embed to v4.9.1\n\nv3.3.5\n\n- Update mux-embed to v4.9.0\n\nv3.3.4\n\n- Update mux-embed to v4.8.0\n\nv3.3.3\n\n- Update mux-embed to v4.7.0\n\nv3.3.2\n\n- Update mux-embed to v4.6.2\n\nv3.3.1\n\n- Update mux-embed to v4.6.1\n\nv3.3.0\n\n- Bump mux-embed to 4.6.0\n\nv3.2.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv3.1.0\n\n- Update mux-embed to v4.1.1\n- Fix an issue where player_remote_played would not be reported correctly\n\nv3.0.0\n\n- Update mux-embed to v4.0.0\n- Support server-side device detection\n\nv2.0.2\n\n- Improve error handling/reporting\n\nv2.0.1\n\n- Detect the correct video_source_url\n\nv2.0.0\n\n- Bump mux-embed to 3.0.0"
  },
  {
    "id": "79-_guides/developer/monitor-hls-js",
    "title": "Monitor HLS.js",
    "path": "_guides/developer/monitor-hls-js.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-hls-js",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video. You can use the Mux-hosted version of the script or install via npm. mux-embed follows semantic versioning and the API will not change between major releases.\n\nCall mux.monitor and pass in a valid CSS selector or the video element itself. Followed by the SDK options and metadata. If you use a CSS selector that matches multiple elements, the first matching element in the document will be used.\n\nIn the SDK options, be sure to pass in the hlsjs instance and the Hls constructor. If the Hls constructor is available on the global window object then it can be omitted from the SDK options.\n\nAlternatively, if your player does not immediately have access to the HLS.js player instance, you can start monitoring HLS.js at any time in the future. In order to do this, you can call either of the following:\n\n\n```js\nmux.addHLSJS(\"#my-player\", options)\n// or\nmyVideoEl.mux.addHLSJS(options)\n```\n\n\nLog in to the Mux dashboard and find the environment that corresponds to your env_key and look for video views. It takes about a minute or two from tracking a view for it to show up on the Metrics tab.\n\nIf you aren't seeing data, check to see if you have an ad blocker, tracking blocker or some kind of network firewall that prevents your player from sending requests to Mux Data servers.\n\nThe only required field in the options that you pass into mux-embed is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data key when calling mux.monitor.\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  hlsjs: hls,\n  Hls,\n  data: {\n    env_key: 'ENV_KEY', // required\n\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000\n\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call monitor. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\nmux.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\n\n```js\nmux.emit('#my-player', 'videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  ...\n});\n```\n\n\nNew program\n\n\n```js\nmux.emit('#my-player', 'programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  disableCookies: true,\n  hlsjs: hls,\n  Hls,\n  data: {\n    env_key: 'ENV_KEY',\n    // ... rest of metadata\n  }\n}\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  hlsjs: hls,\n  Hls,\n  respectDoNotTrack: true, // Disable tracking of browsers where Do Not Track is enabled\n  data: {\n    env_key: 'ENV_KEY',\n    // ... rest of metadata\n  }\n}\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, mux-embed will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\nmux.emit('#my-player', 'error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\nmux.monitor('#my-player', {\n  debug: false,\n  errorTranslator,\n  hlsjs: hls,\n  Hls,\n  data: {\n    env_key: 'ENV_KEY', // required\n\n    // ... additional metadata\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  automaticErrorTracking: false,\n  hlsjs: hls,\n  Hls,\n  data: {\n    env_key: 'ENV_KEY', // required\n\n    // ... additional metadata\n  }\n```\n\n\nUse TypeScript with mux-embed\n\nmux-embed now provides TypeScript type definitions with the published package! If you want to opt in, you can check out how here.\n\nCustomize beacon collection domain\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  hlsjs: hls,\n  Hls,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // ... additional metadata\n  }\n});\n```"
  },
  {
    "id": "80-_guides/developer/monitor-html5-video-element",
    "title": "Monitor HTML5 video element",
    "path": "_guides/developer/monitor-html5-video-element.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-html5-video-element",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video. You can use the Mux-hosted version of the script or install via npm. mux-embed follows semantic versioning and the API will not change between major releases.\n\nIf possible, use the SDK for your particular player (e.g. Video.js, JW Player, etc.). While the HTML5 SDK works with any modern HTML5 video player, the player-specific Mux SDK is preferable because it offers a deeper integration and in most cases collects more pieces of data. If you don't see your player listed then use mux-embed and let us know so we can prioritize creating an SDK for the player that you are using.\n\nCall mux.monitor and pass in a valid CSS selector or the video element itself. Followed by the SDK options and metadata. If you use a CSS selector that matches multiple elements, the first matching element in the document will be used.\n\nLog in to the Mux dashboard and find the environment that corresponds to your env_key and look for video views. It takes about a minute or two from tracking a view for it to show up on the Metrics tab.\n\nIf you aren't seeing data, check to see if you have an ad blocker, tracking blocker or some kind of network firewall that prevents your player from sending requests to Mux Data servers.\n\nThe only required field in the options that you pass into mux-embed is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data key when calling mux.monitor.\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000\n\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call monitor. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\nmux.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\n\n```js\nconst myPlayer = document.querySelector('#my-player');\nmyPlayer.src = 'https://muxed.s3.amazonaws.com/leds.mp4';\n\nmux.emit('#my-player', 'videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\nmux.emit('#my-player', 'programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  disableCookies: true,\n  data: {\n    env_key: 'ENV_KEY',\n    // ... rest of metadata\n  }\n}\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  respectDoNotTrack: true, // Disable tracking of browsers where Do Not Track is enabled\n  data: {\n    env_key: 'EXAMPLE_ENV_KEY',\n    // ... rest of metadata\n  }\n}\n```\n\n\nCustomize error tracking behavior\n\nBy default, mux-embed will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\nmux.emit('#my-player', 'error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\nmux.monitor('#my-player', {\n  debug: false,\n  errorTranslator: errorTranslator,\n  data: {\n    env_key: 'ENV_KEY', // required\n\n    // ... additional metadata\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  automaticErrorTracking: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n\n    // ... additional metadata\n  }\n```\n\n\nUse TypeScript with mux-embed\n\nTypeScript support for mux-embed is currently in beta, so you'll need to take a couple extra steps in order to use it.\n\nUse TypeScript's triple slash ` directive. At the top of your .ts or .tsx` file where you want to use the types, add a line that looks like this:\n\n\n```ts\n/// <reference path=\"../../node_modules/mux-embed/dist/types/mux-embed.d.ts\"/>\n```\n\n\nNote that the triple slash directive requires passing in the relevant path from your .ts or tsx file to the source d.ts file in node_modules/.\n\nAlso, you may have a linting rule that prevents you from using the triple slash directive, you can disable that with and eslint-disable line:\n\n\n```ts\n// eslint-disable-next-line @typescript-eslint/triple-slash-reference\n```\n\n\nHere's an example directory structure and component file:\n\n\n```sh filename=\"Directory Structure\"\n├── node_modules/\n│   └── mux-embed/\n│       └── dist/\n│           └── types/\n│               └── mux-embed.d.ts\n└── src/\n    └── video-component/\n        └── video-component.ts\n```\n\n\n\n```ts filename=\"video-component.ts\"\n// NOTE: You may also need to disable linter rules, such as this example for @typescript-eslint\n// eslint-disable-next-line @typescript-eslint/triple-slash-reference\n/// <reference path=\"../../node_modules/mux-embed/dist/types/mux-embed.d.ts\"/>\nimport mux from 'mux-embed';\n\n// ...\n\nlet videoEl?: HTMLVideoElement;\n\n// This should now be type valid, too!\nvideoEl?.mux.destroy();\n```\n\n\nThis opt-in approach is temporary while we're in beta with TypeScript support. If you run into any issues with the types, please let us know so we can improve them.\n\nCustomize beacon collection domain\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  data: {\n    env_key: 'ENV_KEY', // required\n    // ... additional metadata\n  }\n});\n```"
  },
  {
    "id": "81-_guides/developer/monitor-jw-player-ios",
    "title": "Monitor JW Player (iOS)",
    "path": "_guides/developer/monitor-jw-player-ios.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-jw-player-ios",
    "content": "In order to integrate Mux Data tracking for your JW Player, you will need to be using JW Player 3.x or later. You will need to already have a JW Player license key and an iOS app with a working implementation of JWPlayer-SDK.\n\n\n```\npod 'Mux-Stats-JWPlayer', '~> 0.3'\n```\n\n\nThis will install Mux-Stats-JWPlayer and the latest current release of our core Objective-C library.\n\nNext, import MUXSDKStatsJWPlayer into your application and call MUXSDKStatsJWPlayer.monitorJWPlayerController, passing in your JW player instance and metadata.\n\n\n```swift\nimport MUXSDKStatsJWPlayer;\n\nclass VideoPlayerController: UIViewController {\n   var player: JWPlayerController?\n\n  override func viewDidLoad ()\n      super.viewDidLoad()\n    let config = JWConfig()\n    config.file = \"http://example.com/hls.m3u8\"\n    player = JWPlayerController(config: config)\n  }\n\n  override func viewDidAppear(_ animated: Bool) {\n      super.viewDidAppear(animated)\n        player!.view!.frame = self.view.bounds\n      view.addSubview(player!.view)\n\n      let playName = \"iOS JW player\"\n      let playerData = MUXSDKCustomerPlayerData(environmentKey: \"ENV_KEY\");\n      // insert player metadata\n      let videoData = MUXSDKCustomerVideoData();\n      // insert video metada\n      MUXSDKStatsJWPlayer.monitorJWPlayerController(player!, name: playName, delegate: nil, playerData: playerData!, videoData: videoData)\n            player!.play()\n  }\n}\n```\n\n\nRegister a delegate (optional)\n\nIf your own ViewController implements ` and you want to use it, then pass that in as the delegate argument to monitorJWPlayerController. See the example below:\n\n\n```swift\noverride func viewDidAppear(_ animated: Bool) {\n    super.viewDidAppear(animated)\n    player!.view!.frame = self.view.bounds\n    view.addSubview(player!.view)\n\n    let playName = \"iOS JW player\"\n    let playerData = MUXSDKCustomerPlayerData(environmentKey: \"ENV_KEY\");\n    // insert player metadata\n    let videoData = MUXSDKCustomerVideoData();\n    // insert video metada\n    // pass in `self` as the delegate\n    MUXSDKStatsJWPlayer.monitorJWPlayerController(player!, name: playName, delegate: self, playerData: playerData!, videoData: videoData)\n    player!.play()\n}\n\n// example of implementing a delegate method\nfunc onReady(_ event: JWEvent & JWReadyEvent) {\n  // this will get called when JWPlayer triggers onPlay\n}\n```\n\n\nThe only required field is env_key. But without some more metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nMetadata fields are provided via the MUXSDKCustomerPlayerData and MUXSDKCustomerVideoData` objects.\n\nFor the full list of properties view the header files for this interfaces:\n\n- MUXSDKCustomerPlayerData.h\n- MUXSDKCustomerVideoData.h\n\nFor more details about each property, view the Make your data actionable guide.\n\n\n```swift\nlet playName = \"iOS AVPlayer\"\nlet playerData = MUXSDKCustomerPlayerData(environmentKey: \"ENV_KEY\");\nplayerData.viewerUserId = \"1234\"\nplayerData.experimentName = \"player_test_A\"\n// note that the 'playerName' field here is unrelated to the 'playName' variable above\nplayerData.playerName = \"My Main Player\"\nplayerData.playerVersion = \"1.0.0\"\n\nlet videoData = MUXSDKCustomerVideoData();\nvideoData.videoId = \"abcd123\"\nvideoData.videoTitle = \"My Great Video\"\nvideoData.videoSeries = \"Weekly Great Videos\"\nvideoData.videoDuration = 120000 // in milliseconds\nvideoData.videoIsLive = false\nvideoData.videoCdn = \"cdn\"\n\nMUXSDKStatsJWPlayer.monitorJWPlayerController(player!, name: playName, delegate: self, playerData: playerData!, videoData: videoData)\n```"
  },
  {
    "id": "82-_guides/developer/monitor-jw-player-web",
    "title": "Monitor JW Player",
    "path": "_guides/developer/monitor-jw-player-web.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-jw-player-web",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video.\n\n<CodeExamples\n  examples={{\n    npm: npm install --save @mux/mux-data-jwplayer,\n    yarn: yarn add @mux/mux-data-jwplayer,\n    cdn:\n\n<!--  Note that the KEY in the example should be replaced with the key\nprovided by JW Player for your account. -->\n\n  }}\n  exampleOrder=\"npm,yarn,cdn\"\n/>\n\nBe sure to call initJWPlayerMux immediately after initializing JW Player so that Mux can attach as soon as possible.\n\nThe only required field in the options that you pass into @mux/mux-data-jwplayer is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data on initialization.\n\n\n```js\ninitJWPlayerMux(player, {\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000, you can use `initJWPlayerMux.utils.now()`\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call initJWPlayerMux. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\n// player is the instance returned by the `jwplayer` function\nplayer.mux.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\n\n```js\n// player is the instance returned by the `jwplayer` function\nplayer.mux.emit('videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\n// player is the instance returned by the `jwplayer` function\nplayer.mux.emit('programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\ninitJWPlayerMux(player, {\n  debug: false,\n  disableCookies: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\ninitJWPlayerMux(player, {\n  debug: false,\n  respectDoNotTrack: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, @mux/mux-data-jwplayer will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\n// player is the instance returned by the `jwplayer` function\nplayer.mux.emit('error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\ninitJWPlayerMux(player, {\n  debug: false,\n  errorTranslator,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\ninitJWPlayerMux(player, {\n  debug: false,\n  automaticErrorTracking: false,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nAds tracking with @mux/mux-data-jwplayer\n\nMux supports JW Player's VAST integration for pre-, mid-, and post-roll ads. Simply configure these plugins as you would normally, and Mux will track ads automatically. No additional configuration is needed.\n\nOther JW Player ad integrations, such as Google IMA and FreeWheel have not been tested, but may work out of the box. Please contact us with any questions.\n\nLatency metrics with @mux/mux-data-jwplayer\n\nMux supports latency metrics by parsing the incoming HLS manifest. JW Player allows us to intercept the manifest response using an onXhrOpen hook.\nThis is not available in Safari browsers where HLS is played natively.\n\n\n```js\nvar player = jwplayer('my-player').setup({\n  playlist: [{\n    sources: [{\n      file: 'video.m3u8',\n      onXhrOpen: function(xhr, url) {\n        player.mux && player.mux.onXhrOpen(xhr, url);\n      }\n    }]\n  }]\n});\n\n// Initialize Mux Data monitoring\ninitJWPlayerMux(player, {\n  // ...\n});\n```\n\n\nCustomize beacon collection domain\n\n\n```js\ninitJWPlayerMux(player, {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nCurrent release\n\nv4.20.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv4.20.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv4.20.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv4.20.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv4.20.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv4.20.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv4.20.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv4.20.7\n\n- Update mux-embed to v5.9.0\n\nv4.20.6\n\n- Update mux-embed to v5.8.3\n\nv4.20.5\n\n- Update mux-embed to v5.8.2\n\nv4.20.4\n\n- Update mux-embed to v5.8.1\n\nv4.20.3\n\n- Update mux-embed to v5.8.0\n\nv4.20.2\n\n- Update mux-embed to v5.7.0\n\nv4.20.1\n\n- Update mux-embed to v5.6.0\n\nv4.20.0\n\n- Add error details from sourceError to error context\n\nv4.19.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv4.18.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv4.18.2\n\n- Update mux-embed to v5.4.2\n\nv4.18.1\n\n- Update mux-embed to v5.4.1\n\nv4.18.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv4.17.7\n\n- Update mux-embed to v5.3.3\n\nv4.17.6\n\n- add support for dropped frame count\n\nv4.17.5\n\n- Update mux-embed to v5.3.2\n\nv4.17.4\n\n- Update mux-embed to v5.3.1\n\nv4.17.3\n\n- Update mux-embed to v5.3.0\n\nv4.17.2\n\n- Update mux-embed to v5.2.1\n\nv4.17.1\n\n- Update mux-embed to v5.2.0\n\nv4.17.0\n\n- Collect additional data on rendition change: height, width, rendition namet\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv4.16.0\n\n- Add opt-in TypeScript Types to Mux Embed and use + refactor for other dependent data SDKs.\n\n- Update mux-embed to v5.0.0\n\nv4.15.4\n\n- Update mux-embed to v4.30.0\n\nv4.15.3\n\n- Update mux-embed to v4.29.0\n\nv4.15.2\n\n- Update mux-embed to v4.28.1\n\nv4.15.1\n\n- Update mux-embed to v4.28.0\n\nv4.15.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv4.14.3\n\n- Update mux-embed to v4.26.0\n\nv4.14.2\n\n- Update mux-embed to v4.25.1\n\nv4.14.1\n\n- Update mux-embed to v4.25.0\n\nv4.14.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv4.13.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv4.12.0\n\n- Emit requestfailed events and include more detailed information from JW Player in the Mux Error Context\n\n- Update mux-embed to v4.22.0\n\nv4.11.4\n\n- Update mux-embed to v4.21.0\n\nv4.11.3\n\n- Update mux-embed to v4.20.0\n\nv4.11.2\n\n- Update mux-embed to v4.19.0\n\nv4.11.1\n\n- Update mux-embed to v4.18.0\n\nv4.11.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv4.10.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv4.9.0\n\n- Expose utils on SDK initialization function to expose utils.now() for player_init_time\n\n- Record request_url and request_id with network events\n- Update mux-embed to v4.15.0\n\nv4.8.5\n\n- Update mux-embed to v4.14.0\n\nv4.8.4\n\n- Update mux-embed to v4.13.4\n\nv4.8.3\n\n- Update mux-embed to v4.13.3\n\nv4.8.2\n\n- Update mux-embed to v4.13.2\n\nv4.8.1\n\n- Update mux-embed to v4.13.1\n\nv4.8.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv4.7.12\n\n- Publish package to NPM\n\nv4.7.11\n\n- Display an error message if the JW player is removed but the Mux monitor is not destroyed\n- Update mux-embed to v4.12.1\n\nv4.7.10\n\n- Update mux-embed to v4.12.0\n\nv4.7.9\n\n- Update mux-embed to v4.11.0\n\nv4.7.8\n\n- Update mux-embed to v4.10.0\n\nv4.7.7\n\n- Update mux-embed to v4.9.4\n\nv4.7.6\n\n- Update mux-embed to v4.9.3\n\nv4.7.5\n\n- Update mux-embed to v4.9.2\n\nv4.7.4\n\n- Update mux-embed to v4.9.1\n\nv4.7.3\n\n- Update mux-embed to v4.9.0\n\nv4.7.2\n\n- Update mux-embed to v4.8.0\n\nv4.7.1\n\n- Update mux-embed to v4.7.0\n\nv4.7.0\n\n- Introducing HLS Session Data Support\n\n- Update mux-embed to v4.6.2\n\nv4.6.1\n\n- Update mux-embed to v4.6.1\n\nv4.6.0\n\n- Bump mux-embed to 4.6.0\n\nv4.5.0\n\n- Update mux-embed to v4.4.2\n- Use JW error codes for player_error_code on errors\n\nv4.4.0\n\n- Add support for latency metrics\n\nv4.3.1\n\n- Remove unneeded debug logging\n\nv4.3.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv4.2.0\n\n- Update mux-embed to v4.1.1\n- Fix an issue where player_remote_played would not be reported correctly\n\nv4.1.0\n\n- Improve metrics by sending the playing and adplaying events at more appropriate times\n\nv4.0.0\n\n- Update mux-embed to v4.0.0\n- Support server-side device detection\n\nv3.1.0\n\n- add rendition change event for getting bitrate metrics\n\nv3.0.0\n\n- bump mux-embed dependency to 3.0.0"
  },
  {
    "id": "83-_guides/developer/monitor-kaltura-android",
    "title": "Monitor Kaltura Player (Android)",
    "path": "_guides/developer/monitor-kaltura-android.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-kaltura-android",
    "content": "This documents integration instructions for Kaltura PlayKit and TVPlayer for Android version v4.16.0 or higher.\n\nThe Mux integration with Kaltura is built on top of Mux's core Java SDK, and the full code can be seen here: muxinc/mux-stats-sdk-kaltura-android.\n\nFeatures\n\n1. Install the Mux Data SDK\n\nAdd the Mux Maven repository to your Gradle file:\n\n```text\nrepositories {\n    maven {\n        url \"https://muxinc.jfrog.io/artifactory/default-maven-release-local\"\n    }\n}\n```\n\n\nNext, add a dependency to your Gradle file using the Mux SDK version in the following format:\n\n```text\napi 'com.mux.stats.sdk.muxstats:MuxKalturaSDK:(Mux SDK version)'\n```\n\n\nExample using Mux Kaltura SDK 0.1.0:\n\n```text\napi 'com.mux.stats.sdk.muxstats:MuxKalturaSDK:0.1.0'\n```\n\n\n2. Initialize the monitor with your Kaltura player instance\n\nOur SDK supports Kaltura PlayKit and TVPlayer v4.16.0 or higher.\n\nFirst, create the CustomerPlayerData and CustomerVideoData objects as appropriate for your current playback, and be sure to set your ENV_KEY.\n\n```java\nimport com.mux.stats.core.model.CustomerData;\nimport com.mux.stats.core.model.CustomerPlayerData;\nimport com.mux.stats.core.model.CustomerVideoData;\nimport com.mux.stats.core.model.CustomerViewData;\n// ...\nCustomerPlayerData customerPlayerData = new CustomerPlayerData();\ncustomerPlayerData.setEnvironmentKey(\"ENV_KEY\");\nCustomerVideoData customerVideoData = new CustomerVideoData();\ncustomerVideoData.setVideoTitle(\"The most epic video ever\");\nCustomerViewData customerViewData = new CustomerViewData();\ncustomerViewData.setViewSessionId(\"A26C4C2F-3C8A-46FB-885A-8D973F99A998\");\nCustomerData customerData = new CustomerData(customerPlayerData, customerVideoData, customerViewData);\n```\n\n\nNext, create the MuxStatsKaltura object by passing your Android Context (typically your Activity), the player instance, a player name, and the customer data object. The following example shows how to instantiate the SDK using the TVPlayer \"KalturaPlayer\" (represented by the variable player). For a PlayKit-only player just pass in your raw com.kaltura.playkit.Player reference in place of the KalturaPlayer.\n\n\n```java\nMuxNetworkRequests network = new MuxNetworkRequests();\nmuxStats = new MuxStatsKaltura(this, player, \"my-player-name\", customerData, new CustomOptions().setSentryEnabled(false), network);\n```\n\n\nIn order to correctly monitor if the player is full-screen, provide the screen size to the MuxStatsKaltura instance.\n\n```java\nPoint size = new Point();\ngetWindowManager().getDefaultDisplay().getSize(size);\nmuxStats.setScreenSize(size.x, size.y);\nmuxStats.enableMuxCoreDebug(true, false);\n```\n\n\nFinally, when you are destroying the player, call the MuxStatsKaltura.release() method.\n\n\n```java\nmuxStats.release()\n```\n\n\nAfter you've integrated, start playing a video in your player. A few minutes after you stop watching, you'll see the results in your Mux data dashboard. Login to the dashboard and find the environment that corresponds to your env_key and look for video views.\n\n3. Add Metadata\n\nIn the Java SDK, options are provided via the CustomerPlayerData, CustomerVideoData, and CustomerViewData objects.\n\nAll metadata details except for envKey are optional, however you'll be able to compare and see more interesting results as you include more details. This gives you more metrics and metadata about video streaming, and allows you to search and filter on important fields like the player version, CDN, and video title.\n\nFor more information, see the Metadata Guide.\n\n4. Advanced\n\nChanging the video\n\nThere are two cases where the underlying tracking of the video view must be reset. First, when you load a new source URL into an existing player, and second when the program within a singular stream changes (such as a program within a live stream).\n\nNote: You do not need to change the video info when changing to a different source of the same video content (e.g. different resolution or video format).\n\nNew source\n\nWhen you change to a new video (in the same player) you need to update the information that Mux knows about the current video. Examples of when this is needed are:\n\n The player advances to the next video in a playlist\n The user selects a different video to play\n\nThis is done by calling MuxStatsKaltura.videoChange(CustomerVideoData) which will remove all previous video data and reset all metrics for the video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nIt's best to change the video info immediately after telling the player which new source to play.\n\nNew program (in single stream)\n\nIn some cases, you may have the program change within a stream, and you may want to track each program as a view on its own. An example of this is a live stream that streams multiple programs back to back, with no interruptions.\n\nIn this case, call MuxStatsKaltura.programChange(CustomerVideoData). This will remove all previous video data and reset all metrics for the video view, creating a new video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nError tracking\n\nBy default, Mux's integration with Kaltura automatically tracks fatal errors as thrown by the Kaltura player. If a fatal error happens outside the context of Kaltura player and you want to track it with Mux, you can call MuxStatsKaltura.error like this:\n\n\n```java\n// Error code: integer value for the generic type of error that\n// occurred.\n// Error message: String providing more information on the error\n// that occurred.\n// For an example, the HTML5 video element uses the\n// following: https://developer.mozilla.org/en-US/docs/Web/API/MediaError\n// for codes and messages. Feel free to use your own codes and messages\nint errorCode = 1;\nString errorMessage = \"A fatal error was encountered during playback\";\nMuxErrorException error = new MuxErrorException(errorCode, errorMessage);\nmuxStats.error(error);\n```\n\nNote that MuxStatsKaltura.error(MuxErrorException e) can be used with or without automatic error tracking. If your application has retry logic that attempts to recover from Kaltura player errors then you may want to disable automatic error tracking like this:\n\n\n```java\nmuxStats.setAutomaticErrorTracking(false)\n```\n\n\nIt is important that you only trigger an error when the playback has to be abandoned or aborted in an unexpected manner, as Mux tracks fatal playback errors only.\n\nSentry\n\nIn order to improve our SDKs, Mux utilizes Sentry to track exceptions that our SDK may throw. No personal data is captured by Mux's SDK in these error reports, but if you want to disable this functionality, you can. This should be managed through the CustomOptions object passed to the constructor.\n\n\n```java\nmuxStats = new MuxStatsKaltura(this, player, \"my-player-name\", customerData, new CustomOptions().setSentryEnabled(false), network);\n```\n\n\nRelease notes\n\nCurrent release\n\nv0.2.0\nImprovements:\n* Update to MuxCore 7.8, adds CustomerViewerData to CustomerData\n\nPrevious releases\n\nv0.1.0\nFeature:\n - First beta release of the Kaltura SDK for Android"
  },
  {
    "id": "84-_guides/developer/monitor-kaltura-ios",
    "title": "Monitor Kaltura Player (iOS and tvOS)",
    "path": "_guides/developer/monitor-kaltura-ios.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-kaltura-ios",
    "content": "Mux Data Mux-Stats-Kaltura supports iOS 13.0 or newer and tvOS 13.0 or newer. The Mux integration with Kaltura is built on top of Mux's core Objective-C SDK, and the full code can be seen here: muxinc/mux-stats-sdk-kaltura-ios.\n\nThis SDK is built with XCFramework bundle type and supports Mac Catalyst.\n\nInstalling with SwiftPM\n\n1. In Xcode click \"File\" > \"Swift Packages\" > \"Add Package Dependency...\"\n1. The package repository URL is https://github.com/muxinc/mux-stats-sdk-kaltura-ios.git\n1. Click next.\n1. Select dependency resolution options. We recommend setting the \"Rules\" to install the latest version and choosing the option \"Up to Next Major\".\n\nNote that MUXSDKStatsKaltura has a dependency on MuxCore, so you will see that MuxCore gets installed as well.\n\n> As of Xcode 14.3.1 integrating the Mux SDKs as part of a shared framework using Swift Package Manager is now supported.\n\nInstalling with CocoaPods\n\nTo install with CocoaPods, modify your Podfile to use frameworks by including use_frameworks! and then add the following pods to your Podfile:\n\n\n```\npod 'Mux-Stats-Kaltura', '~>3.0'\n```\n\n\nThis will install Mux-Stats-Kaltura and the latest current release of our core Objective-C Library. There will be no breaking updates in major versions, so you can safely run pod update for future versions.\n\nNext, add correct import statement into your application.\n\n\n```swift\nimport MUXSDKKaltura\n```\n\n\nThe example below uses monitorPlayer:player:playerName:customerData:.\n\nThe playerName parameter is a string that identifies this instance of your player. When calling destroyPlayer later on, you will need this string. Each instance of a player that runs simultaneously in your application should have a different playerName.\n\nFor more complete examples check the demo apps in the repo.\n\nAfter you've integrated, start playing a video in your player. A few minutes after you stop watching, you'll see the results in your Mux data dashboard. Login to the dashboard and find the environment that corresponds to your env_key and look for video views.\n\nThe only required field is env_key. But without some more metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nMetadata fields are provided via the MUXSDKCustomerPlayerData and MUXSDKCustomerVideoData objects.\n\nFor the full list of properties view the header files for this interfaces:\n\n- MUXSDKCustomerPlayerData.h\n- MUXSDKCustomerVideoData.h\n\nFor more details about each property, view the Make your data actionable guide.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call  monitorPlayer. Then, once you have the metadata, you can update the metadata with the  setCustomerDataForPlayer  method.\n\nChanging the Video\n​\nThere are two cases where the underlying tracking of the video view need to be reset. First, when you load a new source URL into an existing player, and second when the program within a singular stream changes (such as a program within a live stream).\n\nNote: You do not need to change the video info when changing to a different source of the same video content (e.g. different resolution or video format).\n​\nNew source\n​\nWhen you change to a new video (in the same player) you need to update the information that Mux knows about the current video. Examples of when this is needed are:\n​\n-   The player advances to the next video in a playlist\n-   The user selects a different video to play\n​\nThis is done by calling  videoChangeForPlayer  which will remove all previous video data and reset all metrics for the video view. You can include any metadata when changing the video but you should only need to update the values that start with  video_.\n​\nIt is required to call  videoChangeForPlayer  immediately before telling the player which new source to play.\n​\n\n​\nNew program (in single stream)\n​\nIn some cases, you may have the program change within a stream, and you may want to track each program as a view on its own. An example of this is a live stream that streams multiple programs back to back, with no interruptions.\n​\nIn this case, call  programChangeForPlayer:name:customerData. This will remove all previous video data and reset all metrics for the video view, creating a new video view. You can include any metadata when changing the video but you should only need to update the values that start with  video.\n\nUsage with Google Interactive Media Ads (IMA)\n\nIf you are using Google Interactive Media Ads and the PlayKit_IMA SDK, you can track ad playback events by installing the mux-stats-google-ima-kaltura-ios companion package.\n\nPlease note: A fully functioning PlayKit_IMA integration is required for ad playback tracking in your iOS or tvOS application.\n\nAdd the following to your Podfile and run pod install\n\n```\n'Mux-Stats-Google-IMA-Kaltura' ~> '2.0.0'\n```\n\n\nInitialize the Mux monitor with MUXSDKStats.monitorPlayer. Create an listener instance by calling MUXSDKImaKalturaListener(playerBinding: playerBinding, player: player).\nStart dispatching the events by calling start on the listener instance.\n\n\n```swift\nimport MUXSDKStatsKaltura\n\n// Follow the instructions from pod 'PlayKit_IMA' to set up\n// your IMA plugin configuration in the loadPlayer method\n//\n// When you call `monitorPlayer:withPlayer:playerName:customerData:`\n// from your ViewController, you will get back a MUXSDKPlayerBinding object\nlet playerBinding = MUXSDKStats.monitorPlayer(\n  player: player,\n  playerName: self.playerName,\n  customerData: data\n)\n\n// Use the MUXSDKPlayerBinding object and the Player instance to initialize the MUXSDKImaKalturaListener class\n// and call start on the listener object\nlet listener = MUXSDKImaKalturaListener(playerBinding: playerBinding, player: player)\nlistener.start()\n```\n\n\nYou can find a complete example here.\n\nTrack orientation change events\n\nYou can optionally track  orientationchange  events. To use this functionality, call the  orientationChangeForPlayer  method.\n​\nThese events will show up on the events log on the view views page.\n\nHandling errors manually\n\nBy default,  automaticErrorTracking  is enabled which means the Mux SDK will catch errors that the player throws and track an  error  event. Error tracking is meant for fatal errors. When an error is thrown it will mark the view as having encountered an error in the Mux dashboard and the view will no longer be monitored.\n​\nIf you want to disable automatic and track errors manually you can do by passing in  automaticErrorTracking: false  to the  monitorPlayer  method that you are using.\n​\nWhether automatic error tracking is enabled or disabled, you can dispatch errors manually with  dispatchError.\n\nCurrent release\n\nv4.0.0\n\nImprovements:\n- Include privacy manifest file to satisfy upcoming privacy requirements for App Store submissions\n- Update Mux Core and Kaltura player dependencies\n\nPrevious releases\n\nv3.0.0\n\nImprovements:\n- Repackage SDK as source distribution\n- Add Swift Package Manager support\n- Raise minimum deployment targets to iOS 13 and tvOS 13\n\nBreaking:\n- Rename module name from Mux_Stats_Google_IMA_Kaltura to MUXSDKStatsKaltura\n\nKnown Issues:\n- Cocoapod pod spec linting fails on Xcode 14.3 and above due to Cocoapods/Cocoapods issue 11839. As a workaround use xcode-select to switch to Xcode 14.2 before linting.\n\nv2.0.1\nFixes:\n Fix build issues in react-native projects\n\nv2.0.0\nFixes:\nUpdate MuxCore dependency and rebuild with recent tools. Some linkage changes have been necessary, but you shouldn't see any issues. You may require Xcode 14 to use this version of the Data SDK for Kaltura\n\nv1.1.1\n- Fix: Change minimum deployment target to iOS 9.0 and tvOS 9.0\n\nv1.1.0\n- Test: Unit test for destroy player\n- Feature: Support for Google IMA SDK Listener\n\nv1.0.0\n- Fix: Missing play event\n- Fix: Improve rendition change detection\n- Fix: Missing rebuffering metrics\n- Test: Unit test infrastructure\n- Test: Add test coverage\n\nv0.3.0\n- Third beta release of the Kaltura SDK for iOS\n- Adds tvOS support\n- Adds tvOS target to DemoApp and updates example project\n\nv0.2.0\n-   Second beta release of the Kaltura SDK for iOS\n-   Adds  setCustomerDataForPlayer to update metadata after monitor call\n-   Adds  videoChangeForPlayer to update metadata when a video change occurs\n-   Adds  programChangeForPlayer:name:customerData: to update metadata when a program change within a stream\n-   Adds  orientationChangeForPlayer to track orientation changes\n-   Adds  manual error tracking with dispatchError\n\n v0.1.0\n - First beta release of the Kaltura SDK for iOS"
  },
  {
    "id": "85-_guides/developer/monitor-kaltura-web",
    "title": "Monitor Kaltura Web",
    "path": "_guides/developer/monitor-kaltura-web.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-kaltura-web",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video.\n\n<CodeExamples\n  examples={{\n    npm: \"npm install --save @mux/mux-data-kaltura\",\n    yarn: \"yarn add @mux/mux-data-kaltura\",\n    cdn: `,\n  }}\n  exampleOrder=\"npm,yarn,cdn\"\n/>\n\nUnder the Kaltura plugins option, pass in the mux configuration with key mux.\n\nLog in to the Mux dashboard and find the environment that corresponds to your env_key and look for video views. It takes about a minute or two from tracking a view for it to show up on the Metrics tab.\n\nIf you aren't seeing data, check to see if you have an ad blocker, tracking blocker or some kind of network firewall that prevents your player from sending requests to Mux Data servers.\n\nThe only required field in the options that you pass into @mux/mux-data-kaltura is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data key, in the mux plugin configuration.\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first initialize the Mux SDK. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\n// player is the instance returned by the `KalturaPlayer.setup` function\nplayer.mux.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\n\n```js\n// player is the instance returned by the `KalturaPlayer.setup` function\nplayer.mux.emit('videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\n// player is the instance returned by the `KalturaPlayer.setup` function\nplayer.mux.emit('programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\nvar kalturaPlayer = KalturaPlayer.setup({\n  // ...\n  plugins: {\n    mux: {\n      debug: false,\n      disableCookies: true,\n      data: {\n        env_key: \"ENV_KEY\",\n        // ...\n      }\n    }\n  }\n});\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\nvar kalturaPlayer = KalturaPlayer.setup({\n  // ...\n  plugins: {\n    mux: {\n      respectDoNotTrack: true,\n      data: {\n        env_key: \"ENV_KEY\",\n        // ...\n      }\n    }\n  }\n});\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, @mux/mux-data-kaltura will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\n// player is the instance returned by the `KalturaPlayer.setup` function\nplayer.mux.emit('error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\nvar kalturaPlayer = KalturaPlayer.setup({\n  // ...\n  plugins: {\n    mux: {\n      errorTranslator,\n      data: {\n        env_key: \"ENV_KEY\",\n        // ...\n      }\n    }\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\nvar kalturaPlayer = KalturaPlayer.setup({\n  // ...\n  plugins: {\n    mux: {\n      automaticErrorTracking: false,\n      data: {\n        env_key: \"ENV_KEY\",\n        // ...\n      }\n    }\n  }\n});\n```\n\n\nAds tracking with @mux/mux-data-kaltura\n\nMux supports Kaltura's playkit-js-ima plugin for pre-, mid-, and post-roll ads. Simply configure these plugins as you would normally, and Mux will track ads automatically. No additional configuration is needed.\n\nOther Kaltura ad integrations have not been tested, but may work out of the box. Please contact us with any questions.\n\nCustomize beacon collection domain\n\n\n```js\nvar kalturaPlayer = KalturaPlayer.setup({\n  // ...\n  plugins: {\n    mux: {\n      beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n      data: {\n        env_key: \"ENV_KEY\",\n        // ...\n      }\n    }\n  }\n});\n```\n\n\nCurrent release\n\nv1.9.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv1.9.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv1.9.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv1.9.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv1.9.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv1.9.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv1.9.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv1.9.7\n\n- Update mux-embed to v5.9.0\n\nv1.9.6\n\n- Update mux-embed to v5.8.3\n\nv1.9.5\n\n- Update mux-embed to v5.8.2\n\nv1.9.4\n\n- Update mux-embed to v5.8.1\n\nv1.9.3\n\n- Update mux-embed to v5.8.0\n\nv1.9.2\n\n- Update mux-embed to v5.7.0\n\nv1.9.1\n\n- Update mux-embed to v5.6.0\n\nv1.9.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv1.8.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv1.8.2\n\n- Update mux-embed to v5.4.2\n\nv1.8.1\n\n- Update mux-embed to v5.4.1\n\nv1.8.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv1.7.6\n\n- Update mux-embed to v5.3.3\n\nv1.7.5\n\n- Update mux-embed to v5.3.2\n\nv1.7.4\n\n- Update mux-embed to v5.3.1\n\nv1.7.3\n\n- Update mux-embed to v5.3.0\n\nv1.7.2\n\n- Update mux-embed to v5.2.1\n\nv1.7.1\n\n- Update mux-embed to v5.2.0\n\nv1.7.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv1.6.5\n\n- Update mux-embed to v5.0.0\n\nv1.6.4\n\n- Update mux-embed to v4.30.0\n\nv1.6.3\n\n- Update mux-embed to v4.29.0\n\nv1.6.2\n\n- Update mux-embed to v4.28.1\n\nv1.6.1\n\n- Update mux-embed to v4.28.0\n\nv1.6.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv1.5.3\n\n- Update mux-embed to v4.26.0\n\nv1.5.2\n\n- Update mux-embed to v4.25.1\n\nv1.5.1\n\n- Update mux-embed to v4.25.0\n\nv1.5.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv1.4.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv1.3.5\n\n- Update mux-embed to v4.22.0\n\nv1.3.4\n\n- Update mux-embed to v4.21.0\n\nv1.3.3\n\n- Update mux-embed to v4.20.0\n\nv1.3.2\n\n- Update mux-embed to v4.19.0\n\nv1.3.1\n\n- Update mux-embed to v4.18.0\n\nv1.3.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv1.2.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv1.1.6\n\n- Record request_url and request_id with network events\n- Update mux-embed to v4.15.0\n\nv1.1.5\n\n- Update mux-embed to v4.14.0\n\nv1.1.4\n\n- Update mux-embed to v4.13.4\n\nv1.1.3\n\n- Update mux-embed to v4.13.3\n\nv1.1.2\n\n- Update mux-embed to v4.13.2\n\nv1.1.1\n\n- Update mux-embed to v4.13.1\n\nv1.1.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv1.0.14\n\n- Publish package to NPM\n\nv1.0.13\n\n- Update mux-embed to v4.12.1\n\nv1.0.12\n\n- Update mux-embed to v4.12.0\n\nv1.0.11\n\n- Update mux-embed to v4.11.0\n\nv1.0.10\n\n- Update mux-embed to v4.10.0\n\nv1.0.9\n\n- Update mux-embed to v4.9.4\n\nv1.0.8\n\n- Update mux-embed to v4.9.3\n\nv1.0.7\n\n- Update mux-embed to v4.9.2\n\nv1.0.6\n\n- Update mux-embed to v4.9.1\n\nv1.0.5\n\n- Update mux-embed to v4.9.0\n\nv1.0.4\n\n- Update mux-embed to v4.8.0\n\nv1.0.3\n\n- Update mux-embed to v4.7.0\n\nv1.0.2\n\n- Update mux-embed to v4.6.2\n\nv1.0.1\n\n- Update mux-embed` to v4.6.1\n\nv1.0.0\n\n- Bump mux-embed to 4.6.0\n\nv1.0.0-beta.1\n\n- Update mux-embed to v4.4.2 to support latency metrics\n\nv1.0.0-beta.0\n\n- First beta release of the Kaltura SDK for web"
  },
  {
    "id": "86-_guides/developer/monitor-lg",
    "title": "Monitor LG",
    "path": "_guides/developer/monitor-lg.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-lg",
    "content": "LG Smart TV applications are built on top of the HTML5 video technology. To support video streaming, these applications can be integrated with player SDKs such as the HLS.js and Dash.js.\n\nDue to the HTML5 nature of LG Smart TV applications, the Mux Data integration with LG televisions uses one of the HTML5 integrations, such as the ones listed above. When setting up your application, you should check which video player engine that is used, and depending on that, utilize the appropriate integration point within mux-embed.\n\nCheck these 3 web integration guides for more details:\n\n HTML5 video element\n HLS.js\n* Dash.js\n\n\n```js\n// main.js\nplay: function() {\n  var data = {\n    env_key: 'ENV_KEY', // required\n    player_name: 'My Custom Player',\n    player_init_time: mux.utils.now(),\n    // ... additional metadata\n  };\n\n  switch (this.playerEngine) {\n    case this.PLAYENGINE_HLSJS:\n      if (Hls.isSupported()) {\n        const hls = new Hls();\n        hls.loadSource('<your source file>');\n        hls.attachMedia(this.player);\n        hls.on(Hls.Events.MANIFEST_PARSED,function(e,d) {\n          app.player.play();\n        });\n        mux.monitor('#my-player', {\n          debug: true,\n          hlsjs: hls,\n          Hls: Hls,\n          data: data\n        });\n        this.hls = hls;\n      }\n      break;\n    case this.PLAYENGINE_DASHJS:\n      const dashjsPlayer = dashjs.MediaPlayer().create();\n      dashjsPlayer.getDebug().setLogToBrowserConsole(false);\n      mux.monitor('#my-player', {\n        debug: true,\n        dashjs: dashjsPlayer,\n        data: data\n      });\n      dashjsPlayer.initialize(this.player, 'http://dash.edgesuite.net/envivio/EnvivioDash3/manifest.mpd', true);\n      this.dashjsPlayer = dashjsPlayer;\n      break;\n  }\n}\n```\n\n\nAfter you've finished integration, the quickest way to see that the SDK is loaded is to pass debug: true in the options passed to the SDK. With this flag enabled, you can open the debug console, and you should start seeing debug statements from [mux] when you click play on the video.\n\nAfter playing a video, a few minutes after you stop watching, you'll see the results in your Mux account. We'll also email you when your first video view has been recorded. Log in to the dashboard and find the environment that corresponds to your env_key and look for video views.\n\nNote that it may take a few minutes for views to show up in the Mux Data dashboard.\n\nOptions are provided via the data object passed in the call to mux.monitor.\n\nAll metadata details except for env_key are optional, however you'll be able to compare and see more interesting results as you include more details. This gives you more metrics and metadata about video streaming, and allows you to search and filter on important fields like the player version, CDN, and video title.\n\n\n```js\nmux.monitor('#my-player', {\n  debug: false,\n  hlsjs: hls,\n  Hls,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, see the Metadata Guide.\n\nCustomize beacon collection domain\n\n```js\nmux.monitor('my-player', {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  hlsjs: hls,\n  Hls,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // ... additional metadata\n  }\n});"
  },
  {
    "id": "87-_guides/developer/monitor-nexplayer",
    "title": "Monitor NexPlayer",
    "path": "_guides/developer/monitor-nexplayer.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-nexplayer",
    "content": "Third-party integration\n  This integration is managed and operated by NexPlayer.\n  Feedback should be made on the GitHub repo's Issues page or by contacting NexPlayer support by email.\n\nAdd the NexPlayer_HTML5_Mux plugin to your project by cloning the GitHub repo or installing using yarn/npm.\n\nAdd NexPlayer as you normally would to your solution including recommended CSS styling. In addition, you will need to import the Mux SDK and NexMuxHandShake.js into the ` and set the window.muxPlayerInitTime to the current date/time.\n\n  NexPlayer minimum version\n  Be sure to use the NexPlayer SDK v5.5.3.1 as it contains necessary functionality to integrate with Mux.\n\n\n```html\n<head>\n  <style type=\"text/css\">\n    #player_container {\n      position: relative;\n      padding-top: 28%;\n      padding-bottom: 28%;\n      left: 28%;\n    }\n\n    #player {\n      background-color: #191828;\n      position: absolute;\n      top: 0%;\n      width: 50%;\n      height: 50%;\n    }\n  </style>\n  <script type=\"text/javascript\" src=\"https://src.litix.io/core/4/mux.js\"></script>\n  <script type=\"text/javascript\" src=\"https://nexplayer.nexplayersdk.com/5.5.3.1/nexplayer.js\"></script>\n  <script type=\"text/javascript\" src=\"../node_modules/NexPlayer_HTML5_Mux/app/NexMuxHandShake.js\"></script>\n  <script type=\"text/javascript\">window.muxPlayerInitTime = Date.now();</script>\n</head>\n```\n\n\nInitialize your instance of NexPlayer with a configuration that includes the NexPlayer_HTML5_Mux plugin that activates Mux Data. Be sure to replace the ENV_KEY and NEXPLAYER_KEY with respective values.\n\nThe only required field in the options that you pass into the NexPlayer_HTML5_Mux plugin is ENV_KEY. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the muxConfiguration` on initialization.\n\n\n```js\nvar muxConfiguration = {\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n    // Player Metadata\n    player_name: 'NexPlayer', // ex: 'My Main Player'\n    player_version:  '', // ex: '1.0.0'\n    player_init_time: window.muxPlayerInitTime, // ex: 1451606400000\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  },\n};\n```\n\n\nFor more information, view Make your data actionable.\n\nNew source\n\n\n```js\n// nexMux is the instance returned by the\n// `new NexMuxHandShake()` in the above example\nnexMux.videoChange({\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\n// nexMux is the instance returned by the\n// `new NexMuxHandShake()` in the above example\nnexMux.programChange({\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\nvar muxConfiguration = {\n  debug: false,\n  disableCookies: true,\n  data: {\n    env_key: 'ENV_KEY', // required\n    ...\n  },\n};\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\nvar muxConfiguration = {\n  debug: false,\n  respectDoNotTrack: true,\n  data: {\n    env_key: 'ENV_KEY', // required\n    ...\n  },\n};\n```\n\n\nDisable automatic error tracking\n\n\n```js\nvar muxConfiguration = {\n  debug: false,\n  automaticErrorTracking: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n    ...\n  },\n};\n```\n\n\nCustomize beacon collection domain\n\n\n```js\nvar muxConfiguration = {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  data: {\n    env_key: 'ENV_KEY', // required\n    ...\n  },\n};\n```"
  },
  {
    "id": "88-_guides/developer/monitor-ooyala-player",
    "title": "Monitor Ooyala player",
    "path": "_guides/developer/monitor-ooyala-player.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-ooyala-player",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video.\n\n\n```html\n<!-- Include ooyala-mux after the core Ooyala javascript files -->\n<script src=\"https://player.ooyala.com/static/v4/stable/latest/core.min.js\"></script>\n<!-- Insert other Ooyala plugin files here -->\n<script src=\"https://src.litix.io/ooyala/4/ooyala-mux.js\"></script>\n```\n\n\nCall OO.player.create like you normally would. Call initOoyalaMux with the player reference in the onCreate callback.\n\n\n```html\n<div id=\"my-player\"></div>\n<script>\n  let playerInitTime;\n\n  // Use a callback for when the player is created to register Mux Data\n  function onPlayerCreated (player) {\n    initOoyalaMux(player, {\n      debug: false,\n      data: {\n        env_key: 'ENV_KEY', // required\n        // Metadata\n        player_name: '', // ex: 'My Main Player'\n        player_init_time: playerInitTime // ex: 1451606400000\n        // ... and other metadata\n      }\n    }\n  });\n\n  const asset = {\n    // Insert Ooyala asset configuration here\n  };\n\n  const playerConfig = {\n    onCreate: onPlayerCreated,\n    // Insert other Ooyala player configuration (e.g. autoplay etc) here\n  };\n\n  // Create the player with the Mux callback\n  OO.ready(function() {\n    playerInitTime = initOoyalaMux.utils.now();\n    OO.player.create('playerdiv', asset, playerConfig)\n  });\n</script>\n```\n\n\nThe only required field in the options that you pass into ooyala-mux is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data on initialization.\n\n\n```js\ninitOoyalaMux(player, {\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nNew source\n\n\n```js\n// player is the instance received in the `onCreate` callback\nplayer.mux.emit('videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\n// player is the instance received in the `onCreate` callback\nplayer.mux.emit('programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\ninitOoyalaMux(player, {\n  debug: false,\n  disableCookies: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n});\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\ninitOoyalaMux(player, {\n  debug: false,\n  respectDoNotTrack: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n});\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, ooyala-mux will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\n// player is the instance received in the `onCreate` callback\nplayer.mux.emit('error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: 'Additional context for the error'\n  };\n}\n\ninitOoyalaMux(player, {\n  debug: false,\n  errorTranslator,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\ninitOoyalaMux(player, {\n  debug: false,\n  automaticErrorTracking: false,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nAds tracking with ooyala-mux\n\nMux has been tested with and supports Ooyala's google-ima-ads-manager. Configure these plugins as you would normally, and Mux will track ads automatically. No additional configuration is needed.\n\nOther Ooyala ad integrations, such as FreeWheel and VAST/VPAID may work out of the box. Please contact us with any questions.\n\nCustomize beacon collection domain\n\n\n```js\ninitOoyalaMux(player, {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nCurrent release\n\nv4.12.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv4.12.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv4.12.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv4.12.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv4.12.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv4.12.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv4.12.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv4.12.7\n\n- Update mux-embed to v5.9.0\n\nv4.12.6\n\n- Update mux-embed to v5.8.3\n\nv4.12.5\n\n- Update mux-embed to v5.8.2\n\nv4.12.4\n\n- Update mux-embed to v5.8.1\n\nv4.12.3\n\n- Update mux-embed to v5.8.0\n\nv4.12.2\n\n- Update mux-embed to v5.7.0\n\nv4.12.1\n\n- Update mux-embed to v5.6.0\n\nv4.12.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv4.11.10\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv4.11.9\n\n- Update mux-embed to v5.4.2\n\nv4.11.8\n\n- Update mux-embed to v5.4.1\n\nv4.11.7\n\n- Update mux-embed to v5.4.0\n\nv4.11.6\n\n- Update mux-embed to v5.3.3\n\nv4.11.5\n\n- Update mux-embed to v5.3.2\n\nv4.11.4\n\n- Update mux-embed to v5.3.1\n\nv4.11.3\n\n- Update mux-embed to v5.3.0\n\nv4.11.2\n\n- Update mux-embed to v5.2.1\n\nv4.11.1\n\n- Update mux-embed to v5.2.0\n\nv4.11.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv4.10.5\n\n- Update mux-embed to v5.0.0\n\nv4.10.4\n\n- Update mux-embed to v4.30.0\n\nv4.10.3\n\n- Update mux-embed to v4.29.0\n\nv4.10.2\n\n- Update mux-embed to v4.28.1\n\nv4.10.1\n\n- Update mux-embed to v4.28.0\n\nv4.10.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv4.9.3\n\n- Update mux-embed to v4.26.0\n\nv4.9.2\n\n- Update mux-embed to v4.25.1\n\nv4.9.1\n\n- Update mux-embed to v4.25.0\n\nv4.9.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv4.8.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv4.7.5\n\n- Update mux-embed to v4.22.0\n\nv4.7.4\n\n- Update mux-embed to v4.21.0\n\nv4.7.3\n\n- Update mux-embed to v4.20.0\n\nv4.7.2\n\n- Update mux-embed to v4.19.0\n\nv4.7.1\n\n- Update mux-embed to v4.18.0\n\nv4.7.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv4.6.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv4.5.0\n\n- Expose utils on SDK initialization function to expose utils.now() for player_init_time\n\n- Update mux-embed to v4.15.0\n\nv4.4.5\n\n- Update mux-embed to v4.14.0\n\nv4.4.4\n\n- Update mux-embed to v4.13.4\n\nv4.4.3\n\n- Update mux-embed to v4.13.3\n\nv4.4.2\n\n- Update mux-embed to v4.13.2\n\nv4.4.1\n\n- Fixes an issue with accessing the global object\n- Update mux-embed to v4.13.1\n\nv4.4.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv4.3.14\n\n- Publish package to NPM\n\nv4.3.13\n\n- Update mux-embed to v4.12.1\n\nv4.3.12\n\n- Update mux-embed to v4.12.0\n\nv4.3.11\n\n- Update mux-embed to v4.11.0\n\nv4.3.10\n\n- Update mux-embed to v4.10.0\n\nv4.3.9\n\n- Update mux-embed to v4.9.4\n\nv4.3.8\n\n- Update mux-embed to v4.9.3\n\nv4.3.7\n\n- Update mux-embed to v4.9.2\n\nv4.3.6\n\n- Update mux-embed to v4.9.1\n\nv4.3.5\n\n- Update mux-embed to v4.9.0\n\nv4.3.4\n\n- Update mux-embed to v4.8.0\n\nv4.3.3\n\n- Update mux-embed to v4.7.0\n\nv4.3.2\n\n- Update mux-embed to v4.6.2\n\nv4.3.1\n\n- Update mux-embed to v4.6.1\n\nv4.3.0\n\n- Bump mux-embed to 4.6.0\n\nv4.2.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv4.1.0\n\n- Update mux-embed to v4.1.1\n- Fix an issue where player_remote_played would not be reported correctly\n\nv4.0.0\n\n- Update mux-embed to v4.0.0\n- Support server-side device detection\n\nv3.0.0\n\n- bump mux-embed to 3.0.0"
  },
  {
    "id": "89-_guides/developer/monitor-react-native-video",
    "title": "Monitor React native video",
    "path": "_guides/developer/monitor-react-native-video.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-react-native-video",
    "content": "This SDK is currently beta.\nSee the Known Issues and Caveats in the README on GitHub.\n\nInclude the Mux JavaScript SDK on every page of your web app that includes video.\n\n<CodeExamples\n  examples={{\n    npm: \"npm install --save @mux/mux-data-react-native-video\",\n    yarn: \"yarn add @mux/mux-data-react-native-video\",\n  }}\n  exampleOrder=\"npm,yarn,cdn\"\n/>\n\nWrap your Video component with the muxReactNativeVideo higher-order-component.\n\n\n```jsx\nimport app from './package.json' // this is your application's package.json\nimport Video from 'react-native-video'; // import Video from react-native-video like your normally would\nimport muxReactNativeVideo from '@mux/mux-data-react-native-video';\n\n// wrap the `Video` component with Mux functionality\nconst MuxVideo = muxReactNativeVideo(Video);\n\n// Pass the same props to `MuxVideo` that you would pass to the\n// `Video` element. All of these props will be passed through to your underlying react-native-video component\n// Include a new prop for `muxOptions`\n<MuxVideo\n  style={styles.video}\n  source={{\n    uri:\n      'https://bitdash-a.akamaihd.net/content/sintel/hls/playlist.m3u8',\n  }}\n  controls\n  muted\n  muxOptions={{\n    application_name: app.name,            // (required) the name of your application\n    application_version: app.version,      // the version of your application (optional, but encouraged)\n    data: {\n      env_key: 'YOUR_ENVIRONMENT_KEY',     // (required)\n      video_id: 'My Video Id',             // (required)\n      video_title: 'My awesome video',\n      player_software_version: '5.0.2',     // (optional, but encouraged) the version of react-native-video that you are using\n      player_name: 'React Native Player',  // See metadata docs for available metadata fields /docs/web-integration-guide#section-5-add-metadata\n    },\n  }}\n/>\n```\n\n\nThe required fields in the muxOptions that you pass into the MuxVideo component are application_name, data.env_key and data.video_id. However, without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data on initialization.\n\n\n```js\n  muxOptions={{\n    application_name: app.name,            // (required) the name of your application\n    application_version: app.version,      // the version of your application (optional, but encouraged)\n    data: {\n      env_key: 'ENV_KEY',\n      // Site Metadata\n      viewer_user_id: '', // ex: '12345'\n      experiment_name: '', // ex: 'player_test_A'\n      sub_property_id: '', // ex: 'cus-1'\n      // Player Metadata\n      player_name: '', // ex: 'My Main Player'\n      player_version: '', // ex: '1.0.0'\n      player_init_time: '', // ex: 1451606400000\n      // Video Metadata\n      video_id: '', // ex: 'abcd123'\n      video_title: '', // ex: 'My Great Video'\n      video_series: '', // ex: 'Weekly Great Videos'\n      video_duration: '', // in milliseconds, ex: 120000\n      video_stream_type: '', // 'live' or 'on-demand'\n      video_cdn: '' // ex: 'Fastly', 'Akamai'\n    },\n  }}\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first initialize the Mux SDK. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\nMuxVideo.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nCustomize beacon collection domain\n\n\n```js\n  muxOptions={{\n    application_name: app.name,              // (required) the name of your application\n    application_version: app.version,        // the version of your application (optional, but encouraged)\n    beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n    data: {\n      env_key: 'ENV_KEY',\n      // Site Metadata\n      viewer_user_id: '', // ex: '12345'\n      experiment_name: '', // ex: 'player_test_A'\n      sub_property_id: '', // ex: 'cus-1'\n      // Player Metadata\n      player_name: '', // ex: 'My Main Player'\n      player_version: '', // ex: '1.0.0'\n      player_init_time: '', // ex: 1451606400000\n      // Video Metadata\n      video_id: '', // ex: 'abcd123'\n      video_title: '', // ex: 'My Great Video'\n      video_series: '', // ex: 'Weekly Great Videos'\n      video_duration: '', // in milliseconds, ex: 120000\n      video_stream_type: '', // 'live' or 'on-demand'\n      video_cdn: '' // ex: 'Fastly', 'Akamai'\n    },\n  }}\n});\n```\n\n\nCurrent release\n\nv0.19.6\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv0.19.5\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv0.19.4\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv0.19.3\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv0.19.2\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv0.19.1\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv0.19.0\n\n- React Native custom onProgress handling\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv0.18.3\n\n- Fix for race condition between rebuffering and pause events\n\nv0.18.2\n\n- Update mux-embed to v5.9.0\n\nv0.18.1\n\n- fix issue where updateData wasn't exposed, and issues with player_is_paused reporting\n\nv0.18.0\n\n- expose updateData method on MuxVideo element\n\nv0.17.6\n\n- Update mux-embed to v5.8.3\n\nv0.17.5\n\n- Update mux-embed to v5.8.2\n\nv0.17.4\n\n- Update mux-embed to v5.8.1\n\nv0.17.3\n\n- Update react-native-video version and Add the Mux, Inc Apple team to the demo app\n- Update mux-embed to v5.8.0\n\nv0.17.2\n\n- Update mux-embed to v5.7.0\n\nv0.17.1\n\n- Update mux-embed to v5.6.0\n\nv0.17.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv0.16.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv0.16.2\n\n- Update mux-embed to v5.4.2\n\nv0.16.1\n\n- Update mux-embed to v5.4.1\n\nv0.16.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv0.15.6\n\n- Update mux-embed to v5.3.3\n\nv0.15.5\n\n- Update mux-embed to v5.3.2\n\nv0.15.4\n\n- Update mux-embed to v5.3.1\n\nv0.15.3\n\n- Update mux-embed to v5.3.0\n\nv0.15.2\n\n- Update mux-embed to v5.2.1\n\nv0.15.1\n\n- Update mux-embed to v5.2.0\n\nv0.15.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv0.14.4\n\n- Update mux-embed to v5.0.0\n\nv0.14.3\n\n- Update mux-embed to v4.30.0\n\nv0.14.2\n\n- Update mux-embed to v4.29.0\n\nv0.14.1\n\n- Update mux-embed to v4.28.1\n\nv0.14.0\n\n- Add renditionchange events for Android\n- Introduces error tracking\n\n- Bug fix for rebuffering metrics\n- Update mux-embed to v4.28.0\n\nv0.13.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv0.12.3\n\n- Update mux-embed to v4.26.0\n\nv0.12.2\n\n- Update mux-embed to v4.25.1\n\nv0.12.1\n\n- Update mux-embed to v4.25.0\n\nv0.12.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv0.11.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv0.10.3\n\n- Update mux-embed to v4.22.0\n\nv0.10.2\n\n- Update mux-embed to v4.21.0\n\nv0.10.1\n\n- Update mux-embed to v4.20.0\n\nv0.10.0\n\n- Improve accuracy of react-native-video rebuffer tracking\n\n- Update mux-embed to v4.19.0\n\nv0.9.0\n\n- Allow for timeupdates less than 250ms\n\nv0.8.1\n\n- Update mux-embed to v4.18.0\n\nv0.8.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv0.7.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv0.6.6\n\n- Update mux-embed to v4.15.0\n\nv0.6.5\n\n- Update mux-embed to v4.14.0\n\nv0.6.4\n\n- Update mux-embed to v4.13.4\n\nv0.6.3\n\n- Update mux-embed to v4.13.3\n\nv0.6.2\n\n- Update mux-embed to v4.13.2\n\nv0.6.1\n\n- Update mux-embed to v4.13.1\n\nv0.6.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv0.5.8\n\n- Publish package to NPM\n\nv0.5.7\n\n- Update mux-embed to v4.12.1\n\nv0.5.6\n\n- Update mux-embed to v4.12.0\n\nv0.5.5\n\n- Update mux-embed to v4.11.0\n\nv0.5.4\n\n- Update mux-embed to v4.10.0\n\nv0.5.3\n\n- Update mux-embed to v4.9.4\n\nv0.5.2\n\n- Use common function for generating short IDs\n- Update mux-embed to v4.9.3\n\nv0.5.1\n\n- Update mux-embed to v4.9.2\n\nv0.5.0\n\n- We now expose the emit function the SDK uses which allows developers to manually invoke an event emission.\n\nv0.4.6\n\n- Update mux-embed to v4.9.1\n\nv0.4.5\n\n- Update mux-embed to v4.9.0\n\nv0.4.4\n\n- Update mux-embed to v4.8.0\n\nv0.4.3\n\n- Update mux-embed to v4.7.0\n\nv0.4.2\n\n- Update mux-embed to v4.6.2\n\nv0.4.1\n\n- Update mux-embed to v4.6.1\n\nv0.4.0\n\n- Bump mux-embed to 4.6.0\n\nv0.3.0\n\n- Fix an issue where playerID is null when wrapping the component with react-native-video-controls.\n\nv0.2.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv0.1.0\n\n- Initial release"
  },
  {
    "id": "90-_guides/developer/monitor-roku",
    "title": "Monitor Roku",
    "path": "_guides/developer/monitor-roku.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-roku",
    "content": "Mux's Roku integration supports Roku SceneGraph applications, in conjunction with standard Video nodes. Mux runs as a Task alongside the Video node, and supports instances where the Video nodes are reused with additional content as well as when the Video nodes are reset between content.\n\nPlace the SDK file in your libs folder. The latest version of the SDK can be found here:\n\n\n```sh\nhttps://src.litix.io/roku/2/mux-analytics.brs\n```\n\n\nCreate a new Task XML named MuxTask.xml inside your components folder and give it the following interface. This is used to link the mux-analytics.brs file into your application.\n\n\n```html\n<component name=\"MuxTask\" extends=\"Task\">\n  <interface>\n    <field id=\"video\" type=\"node\" alwaysNotify=\"true\"/>\n    <field id=\"config\" type=\"assocarray\" alwaysNotify=\"true\"/>\n    <field id=\"rafEvent\" type=\"assocarray\" alwaysNotify=\"true\"/>\n    <field id=\"error\" type=\"assocarray\" alwaysNotify=\"true\"/>\n    <field id=\"view\" type=\"String\" alwaysNotify=\"true\"/>\n    <field id=\"exit\" type=\"Boolean\" alwaysNotify=\"true\"/>\n    <field id=\"exitType\" type=\"String\" alwaysNotify=\"true\" value=\"hard\" />\n    <field id=\"useRenderStitchedStream\" type=\"Boolean\" alwaysNotify=\"true\" value=\"false\"/>\n    <field id=\"useSSAI\" type=\"Boolean\" alwaysNotify=\"true\" value=\"false\"/>\n    <field id=\"disableAutomaticErrorTracking\" type=\"Boolean\" alwaysNotify=\"true\" value=\"false\"/>\n    <field id=\"randomMuxViewerId\" type=\"Boolean\" value=\"false\"/>\n  </interface>\n  <script type=\"text/brightscript\" uri=\"pkg:/libs/mux-analytics.brs\"/>\n</component>\n```\n\n\nWithin your main application, create the Mux Task node, and pass the Video node that you are tracking to it. This should be done before the content is set into the Video node so that Mux can track the load process.\n\n\n```js\nm.mux = m.top.CreateNode(\"mux\")\nm.mux.setField(\"video\", m.video)\n\nmuxConfig = {\n  env_key: \"ENV_KEY\",\n}\n\nm.mux.setField(\"config\", muxConfig)\nm.mux.control = \"RUN\"\n\n' Load the video into the Video node\n```\n\n\nAfter you've integrated, start playing a video in the player you've integrated with. A few minutes after you stop watching, you'll see the results in your Mux account. We'll also email you when your first video view has been recorded.\n\nYou can also test that Mux is receiving data in the Mux Data dashboard. Login to the dashboard and find the environment that corresponds to your ENV_KEY and look for video views.\n\nNote that it may take a few minutes for views to show up in the Mux Data dashboard.\n\nTo help you with the integration process and ensure you have successfully incorporated the SDK within your player, we have provided a number of optional manifest attributes. These attributes can help you better understand how the MUX SDK event tracking works as well as show you the actual data being collected. Some of the benefits of using some of the debugging attributes (mentioned below) are that you will be able to see the SDK events and data collected as it occurs.\n\nNOTE: The outputs illustrated below are printed on a single line within the terminal to reduce clutter.\n\nmux_debug_events\n\nValues\nfull, partial or none\n\nDescription\nOutputs the event at the time it occurs. Default value is none\n\nExample output\n\nProperty set to partial:\n\n\n```sh\n[mux-analytics] EVENT playerready\n```\n\n\nProperty set to full:\n\n\n```sh\n[mux-analytics] EVENT playing\n{\n  viewer_application_name:Roku,\n  mux_api_version:2.1,\n  view_seek_duration:0,\n  viewer_application_version:9.20,\n  player_name:Reset Player,\n  viewer_time:1582317809984,\n  view_start:1582317808627,\n  player_model_number:4660X,\n  video_source_mime_type:mp4,\n  event:playing,\n  ...\n```\n\n\n---\n\nmux_debug_beacons\n\nValues\nfull, partial or none\n\nDescription\nOutputs the data (full) or event(s) (partial) that is being sent (at the time of sending). Default value is none.\n\nExample output\n\nProperty set to partial:\n\n\n```sh\n[mux-analytics] BEACON (2) [  playerready viewstart ]\n```\n\n\nProperty set to full:\n\n\n```sh\n[mux-analytics] BEACON (2)\n[\n  {\n    viewer_application_name:Roku,\n    mux_api_version:2.1,\n    view_seek_duration:0,\n    viewer_application_version:9.20,\n    player_name:Reset Player,\n    viewer_time:1582317809984,\n    view_start:1582317808627,\n    player_model_number:4660X,\n    video_source_mime_type:mp4,\n    event:playerready,\n    ...\n  }, {\n    viewer_application_name:Roku,\n    mux_api_version:2.1,\n    view_seek_duration:0,\n    viewer_application_version:9.20,\n    player_name:Reset Player,\n    viewer_time:1582317809984,\n    view_start:1582317808627,\n    player_model_number:4660X,\n    video_source_mime_type:mp4,\n    event:viewstart,\n    ...\n  }\n]\n```\n\n\n----\nmux_base_url\n\nValues\nProtocol + domain name. Eg. https://img.litix.io\n\nDescription\nControls to which domain the data should be sent. Useful for environmental builds of your project\n\nThe Roku SDK supports adding metadata via two different mechanisms.\n\nThe majority of the metadata should be passed inside the muxConfig object that is passed to the Mux Task. You can read detailed information about the fields that are supported in Metadata. To update any field, update this within muxConfig and then call m.mux.setField(\"config\", muxConfig).\n\nSome other underlying information is mapped from standard Roku content metadata, most of which you probably already set when creating your video. In particular, the metadata fields that you should set (if you do not already) are:\n - ContentType\n - URL\n - Live\n - StreamFormat\n - Length\n\nIf advertising is to be used, you must send the appropriate events to the Mux Task, as shown below.\n\n\n```js\nfunction setUpRokuAdFramework\n  adIface.SetTrackingCallback(adTrackingCallback, adIface)\nend function\n\nfunction adTrackingCallback(obj = Invalid as Dynamic, eventType = Invalid as Dynamic, ctx = Invalid as Dynamic)\n  m.mux = GetGlobalAA().global.findNode(\"mux\")\n  adUrl = Invalid\n  if obj <> Invalid\n    adUrl = obj.getAdUrl()\n  end if\n  m.mux.setField(\"rafEvent\", {obj: { adurl: adUrl }, eventType:eventType, ctx:ctx})\nend function\n```\n\n\nIf you are utilizing RAF's renderStitchedStream method to stitch ads and content together client-side, then you must tell the Mux SDK that this is in use. This is set via useRenderStitchedStream on the Mux Task, set to true, such as:\n\n\n```js\nmux.setField(\"useRenderStitchedStream\", true)\n```\n\n\nIf you are _not_ utilizing renderStitchedStream but instead controlling ad and content playback directly, then you need to set useRenderStitchedStream to false.\n\nIf you are utilizing server-side ad insertion (SSAI), you should signal that to the SDK by setting useSSAI to true:\n\n\n```js\nmux.setField(\"useSSAI\", true)\n```\n\n\nControlling View Start and End Directly\n\nIn some situations, it is necessary to directly signal the beginning or ending of a view to Mux. This is necessary when the Video Node is recycled (i.e. more pieces of content are loaded into the same Node), or when using advertising, as the ads run outside of the lifecycle of the Video.\n\nNote: A view is defined as the user watching a single piece of _content_, which includes any advertising.\n\n\n```js\nmux = GetGlobalAA().global.findNode(\"mux\")\n\n' To signal the start of a view:\nmux.setField(\"view\", \"start\")\n\n' To signal the end of a view:\nmux.setField(\"view\", \"end\")\n```\n\n\nThe exitType setting controls the behavior of the task when a request to exit/terminate the thread is invoked (via mux.exit=true). The default value of exitType is hard.\n\nIf the value is set to hard then the thread terminates immediately and any data that has not propagated already to the MUX servers is lost.\n\nIf the value is set to soft then the thread sends all the remaining data to the MUX servers and terminates afterward.\n\nTo change value to soft call m.mux.setField(\"exitType\", \"soft\")\n\nNOTE: This means that there might be a time difference between you calling mux.exit=true and the task thread actually terminating. Please ensure you have a single MUX Task running at any given time.\n\nDisabling Automatic Error Tracking\n\nThe Mux SDK for Roku tracks error events from the Video node automatically, and reports them as fatal playback errors. If you would like to disable this automatic error tracking, you can set the following in your MuxTask.xml:\n\n\n```js\n<field id=\"disableAutomaticErrorTracking\" type=\"Boolean\" alwaysNotify=\"true\" value=\"true\"/>\n```\n\n\nWhile it is not advised to control this at runtime, you can also set this by calling\n\n\n```js\nmux.setField(\"disableAutomaticErrorTracking\", true)\n```\n\n\nIn order to emit events, you will need to trigger any errors directly, by calling\n\n\n```js\nmux.setField(\"error\", {\n  player_error_code: errorCode,\n  player_error_message: errorMessage,\n  player_error_context: errorContext,\n  player_error_severity: errorSeverity,\n  player_error_business_exception: isBusinessException\n})\n```\n\n\nThe error code and message should always be provided, and you can set the other fields if desired. The possible values or errorSeverity are \"warning\" or \"fatal\". Read more about Error Classification for more details.\n\nCDN Tracking\n\nThe Mux SDK for Roku can listen to CDN change events. In order to emit events, you will need to trigger any CDN changes directly, by calling\n\n\n```js\n' The \"new_cdn\" string should be the new CDN name\nmux.setField(\"cdn\", \"new_cdn\")\n```\n\n\nRebuffer Controls\n\nMux does not suggest disabling the automatic rebuffer tracking. The following is for advanced usage only.\n\nThe Mux SDK for Roku tracks error events from the Video node automatically. If you would like to disable this automatic rebuffer tracking, you can set the following in your MuxTask.xml:\n\n\n```js\n<field id=\"disablePlayheadRebufferTracking\" type=\"Boolean\" alwaysNotify=\"true\" value=\"true\"/>\n```\n\n\nWhile it is not advised to control this at runtime, you can also set this by calling\n\n\n```js\nmux.setField(\"disablePlayheadRebufferTracking\", true)\n```\n\n\nRebuffer start and end events can be emitted by calling the following\n\n\n```js\nmux.setField(\"rebufferstart\", true)\n```\n\n\n\n```js\nmux.setField(\"rebufferend\", true)\n```\n\n\nPlayback Mode\n\nA playback mode event can be emitted by calling the following\n\n\n```js\nmux.setField(\"playback_mode\", {\n  player_playback_mode: mode,\n  player_playback_mode_data: data\n})\n```\n\n\nThe mode should always be provided, suggested values are: inline, fullscreen, mini and pip.\nThe data is optional, if provided it should be a parse-able JSON string.\n\nA playbackmodechange event will be emitted containing the following fields:\n\n- player_playback_mode (containing the mode set)\n- player_playback_mode_data (containing the data set)\n- ad_playing_time_ms_cumulative (containing ad watch time)\n- view_playing_time_ms_cumulative (containing the total content watch time plus ad watch time)\n\nNetwork custom request event\n\nCustom request events can be emitted with custom data for network requests by calling the following\n\n\n```js\nmux.setField(\"request\", manifestRequest)\n```\n\n\nThe manifestRequest must be a parse-able JSON string.\n\nThe following fields can be included in manifestRequest. All fields should be numeric values, not strings, except where noted:\n\n- type (required, string) - The status of the request: completed, failed, or canceled\n- request_start (numeric) - Timestamp in milliseconds since the Unix epoch when the request was initiated\n- request_response_start (numeric) - Timestamp in milliseconds since the Unix epoch when the first byte of the response was received\n- request_response_end (numeric) - Timestamp in milliseconds since the Unix epoch when the last byte of the response was received\n- request_bytes_loaded (numeric) - The total number of bytes loaded as part of this request\n- request_hostname (string) - The hostname portion of the URL that was requested\n- request_type (string) - The type of content being requested. One of: manifest, video, audio, video_init, audio_init, media, subtitle, or encryption\n- request_id (string) - A unique identifier for the request\n- request_url (string) - The URL that was requested\n- request_labeled_bitrate (numeric) - Labeled bitrate in bps of the video, audio, or media segment that was downloaded\n- request_response_headers (object) - A map of response headers and their values\n- request_media_duration (numeric) - The duration of the media loaded, in seconds. Should not be included for manifest requests\n- request_video_width (numeric) - For events with media or video request_type, the width of the video included in the segment/fragment\n- request_video_height (numeric) - For events with media or video request_type, the height of the video included in the segment/fragment\n- request_error (string) - The name of the error event that occurred (e.g., FragLoadError)\n- request_error_code (numeric) - The response code of the request that spawned the error (e.g., 401, 400, 500)\n- request_error_text (string) - The message returned with the failed status code\n\nDepending on the type value, a corresponding event will be emitted: requestcompleted (for type: \"completed\"), requestfailed (for type: \"failed\"), or requestcanceled (for type: \"canceled\").\n\nFor more information about these fields, see Network Request Data.\n\nLatency and Throughput Calculation\n\nIf you set request_start, request_response_start, request_response_end, and request_bytes_loaded, latency and throughput will be automatically calculated and sent in each event.\n\n- Latency is calculated as the time between request_start and request_response_start.\n- Throughput is calculated as request_bytes_loaded divided by the time between request_response_start and request_response_end.\n\nRequest Duration Calculation\n\nIf the request is completed (type is \"completed\"), the request_type is \"api\" or \"encryption\", and both request_start and request_response_end are present as valid numeric values, the total request duration (request_duration) will be calculated as request_response_end - request_start and included in the event. Requests of type \"api\" or \"encryption\" are limited to a maximum of 5 per view; if this limit is exceeded, the event is discarded and not sent to Mux.\n\nCurrent release\n\nv2.4.1\n- fix: max function doesn't exist\n\nPrevious releases\n\nv2.4.0\n- add network request field\n- add network change events: Network change events are now sent when a network transition is detected (for example, from Wi-Fi to Ethernet).\n\nv2.3.2\n- fix issue where invalid playhead time would crash\n\nv2.3.1\n- Improve performance by reducing thread rendevous\n- fix: player_playback_mode not appearing in Dashboard\n- fix: send codec in video_source_codec to have it show up in renditionchange events\n\nv2.3.0\n\n- add calculations for ad watch time, now sending analytics properties ad_playing_time_ms_cumulative as total ad watch time and view_playing_time_ms_cumulative as content watch time plus ad watch time\n- add support for playback_mode user event, which triggers a playbackmodechange event, containing the playback mode and data\n- playbackmodechange event sent before every viewstart event, containing standard playback mode\n\nv2.2.2\n\n- fix issue where watch time was calculated incorrectly, a guard was added for big jumps on content playback time calculations\n\nv2.2.1\n\n- fix for MAX_VIDEO_POSITION_JUMP not being properly declared, which could cause app crashes\n\nv2.2.0\n- fix viewing data irregularities where watch time values could be near maxint values\n- add support for disabling automatic rebuffer tracking and allow for rebuffer events to be emitted directly\n- video_codec and video_audio_codec fields are now sent in renditionchange events\n\nv2.1.0\n- fix error code inconsistencies on error event handling\n- viewer_connection_type is set to invalid if unable to be determined, set to other if connection not Wired or Wireless\n- viewer_connection_type is now rechecked and updated every 10 seconds\n- add support for cdn user event, which triggers a cdnchange analytics event, containing the current and previous CDN\n\nv2.0.1\n- fix an issue where client_application_name and other newer metadata fields could not be set\n- fix an issue where disableAutomaticErrorTracking was not settable at runtime\n\nv2.0.0\n- BREAKING: disableAutomaticErrorTracking, useRenderStitchedStream, and useSSAI have had their types changed to Boolean, so you will need to make sure to update your MuxTask.xml files to the right types, and anywhere you might set those values dynamically.\n- add support for disableAutomaticErrorTracking\n- add support for useRandomMuxViewerId\n- fix issue where ended event was sent when it should not have been\n- support severity and business exception in manual error handler\n\nv1.8.0\n- Fix an issue where beacon requests were not delayed upon retry\n- Fix a couple if internal typos\n- Various performance improvements to reduce the number of rendezvous\n\nv1.7.1\n- Fix issue where a crash may occur due to the Content node having an invalid URL\n\nv1.7.0\n- Fix issue where renditionchange was triggered too often when demuxed audio/video are used\n- Fix issue where a memory leak was possible with some configurations with ads involved\n- Add support for useSSAI to track ad breaks correctly when SSAI integrations are used\n\nv1.6.0\n- Add support for automatically detecting video changes and metadata when using a playlist within a single Content Node\n- Add support for 8k devices\n- Add support for Video Quality Metrics\n- Add support for tracking individual network requests, throughput, and network errors\n\nv1.5.1\n- Remove unintended logging\n\nv1.5.0\n- Fix an issue where views were not tracked correctly when playing with advertisements via renderStitchedStream\n- Fix an issue where player_init_time was expected as a string but would not work correctly\n- Performance improvements\n- Update sample app to have option for renderStitchedStream\n\nv1.4.3\n- Add support for collecting dropped frame counts automatically where possible\n\nv1.4.2\n- Add support for beaconCollectionDomain\n- Add support for setting env_key instead of property_key\n\nv1.4.1\n- Fix a syntax issue causing compilation problems\n\nv1.4.0\n- Fix a misnamed ad event (adpause was incorrectly sent as adpaused)\n- Add support for a few more ad events\n- Fix an issue where ad play count was attributed at ad completion, rather than ads beginning to play\n\nv1.3.3\n- Fix an issue where certain env keys were not handled correctly\n\nv1.3.2\n- Fix an issue where hostname extraction did not work correctly for hostnames with -s\n\nv1.3.1\n- Fixes an issue where certain Roku devices would not correctly expose the model number\n\nv1.3.0\nUpdates:\n- Add drmType property to the Mux node. This value is automatically reported from the player if available (44)\n- Add droppedFrames property to the Mux node. This value is must be reported from your player. (44)\n- Add errorContext field to Error Events. This value is automatically reported from the player if available (44)\n\nv1.2.1\n - Fixes an issue that could cause incorrect playback reporting when seeking occurs during a view and updated the SDK testing infrastructure.\n\nv1.2.0\n - Remove auto-generated video_id value; applications should pass their own video_id in the metadata.\n\nv1.1.1\n - Fix an issue where an invalid value provided for player_init_time could cause the application to crash.\n\nv1.1.0\n - Add support for custom dimensions\n\nv1.0.3\n - Fix an issue where properties from the Roku application (such as Director) that are not string types crash the application\n - Fix an issue with the sample application running ads\n\nv1.0.2\n - Fix an issue where viewer_device_model was not populated correctly.\n\nv1.0.1\n - Fix an issue where the player playhead position was not reported. This has no impact on collected metrics, but fixes a display issue within the dashboard when viewing individual views.\n\nv1.0.0\n - Fix an issue where viewer_user_id was overwritten unintentionally.\n - Fix an issue where player_mux_plugin_name and device type were set incorrectly.\n - Fix an issue where the seeked event was incorrectly named.\n - Provide updated device information to match the intended uses for each field.\n - Fix an issue where certain metrics (large numbers) were sent in scientific notation, causing incorrect values to be stored.\n - Fix an issue where error code and message were incorrectly sent with aderror events.\n\nv0.2.0\n - Remove the debug option of mux_minification. If you set this, it will have no action. Instead, all events and beacons will be logged in an un-minified version, while everything will be sent to the Mux backend minified.\n - Update such that player_instance_id (controlled by the Mux SDK) is sent as a GUID rather than a different format of ID.\n\nv0.1.0\n - Add exitType configuration option\n - Fix an issue where source duration is reported incorrectly\n - Fix an issue where, on certain devices, the rebuffer percentage could be reported incorrectly (e.g. extremely high)\n - Fix an issue where watch_time may have been calculated incorrectly in certain situations\n - Fix an issue to allow correctly tracking exits before video start"
  },
  {
    "id": "91-_guides/developer/monitor-samsung-tizen",
    "title": "Samsung-Tizen",
    "path": "_guides/developer/monitor-samsung-tizen.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-samsung-tizen",
    "content": "Mux Data is the best way to monitor video streaming performance.\n\nIntegration is easy - just initialize the Mux SDK, pass in some metadata, and you're up and running in minutes.\n\nThis documents integration instructions for Samsung Tizen TVs. For other players, see the additional Integration Guides.\n\nMux Data supports applications built for Samsung Tizen TVs using JavaScript and Tizen's AVPlay API. The Samsung Tizen Smart TV SDK supports C++, JavaScript, and Microsoft .NET; this SDK is only compatible with JavaScript applications using AVPlay.\n\nInclude the Mux Data SDK by including the tizen-mux.js JavaScript file within your index.html file defining your application. You can use the Mux-hosted version of the script to receive automatic updates. (The API will not change within major versions, as in tizen/MAJOR_VERSION/tizen-mux.js.)\n\n\n```html\n<!-- place within the <head> of your index.html -->\n<script src=\"//src.litix.io/tizen/2/tizen-mux.js\"></script>\n```\n\n\nTo monitor video playback within your Tizen application, pass the AVPlay player instance to monitorTizenPlayer along with SDK options and metadata.\n\n\n```js\n// Place in your application initialization code, around\n// where you call `prepare`\n\nvar player = $('#my-player').get(0);\nplayer.url = this.url;\nvar playerInitTime = monitorTizenPlayer.utils.now();\nthis.prepare();\nmonitorTizenPlayer(player, {\n  debug: true,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // Metadata\n    player_name: 'Custom Player', // ex: 'My Main Player'\n    player_init_time: playerInitTime,\n    // ... additional metadata\n  },\n  // Optional passthrough listener\n  playbackListener: playbackListener\n});\n```\n\n\nTizen's AVPlay API does not allow multiple AVPlayPlaybackCallback listeners to be registered to a player. If you require your own listener to be registered, you must pass this in as playbackListener as shown above. Mux's SDK will proxy the calls to your listener. (Note: the location of this changed with v1.0.0)\n\nTo stop monitoring your player (e.g. when playback is complete), call player.mux.stopMonitor().\n\nLog in to the Mux dashboard and find the environment that corresponds to your env_key and look for video views. It takes about a minute or two from tracking a view for it to show up on the Metrics tab.\n\nIf you aren't seeing data, check to see if you have an ad blocker, tracking blocker or some kind of network firewall that prevents your player from sending requests to Mux Data servers.\n\nDetailed Documentation\n\nOptions are provided via the data object passed in the call to monitorTizenPlayer.\n\nAll metadata details except for env_key are optional, however you'll be able to compare and see more interesting results as you include more details. This gives you more metrics and metadata about video streaming, and allows you to search and filter on important fields like the player version, CDN, and video title.\n\n\n```js\nmonitorTizenPlayer(player, {\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, see the Metadata Guide.\n\nCustomize beacon collection domain\n\n\n```js\nmonitorTizenPlayer(player, {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', //ex: 'foo.bar.com'\n  data: {\n    env_key: 'ENV_KEY', // required\n    // ,,,\n  }\n});\n```\n\n\nCurrent release\n\nv2.15.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv2.15.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv2.15.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv2.15.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv2.15.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv2.15.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv2.15.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv2.15.7\n\n- Update mux-embed to v5.9.0\n\nv2.15.6\n\n- Update mux-embed to v5.8.3\n\nv2.15.5\n\n- Update mux-embed to v5.8.2\n\nv2.15.4\n\n- Update mux-embed to v5.8.1\n\nv2.15.3\n\n- Update mux-embed to v5.8.0\n\nv2.15.2\n\n- Update mux-embed to v5.7.0\n\nv2.15.1\n\n- Update mux-embed to v5.6.0\n\nv2.15.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv2.14.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv2.14.2\n\n- Update mux-embed to v5.4.2\n\nv2.14.1\n\n- Update mux-embed to v5.4.1\n\nv2.14.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv2.13.6\n\n- Update mux-embed to v5.3.3\n\nv2.13.5\n\n- Update mux-embed to v5.3.2\n\nv2.13.4\n\n- Update mux-embed to v5.3.1\n\nv2.13.3\n\n- Update mux-embed to v5.3.0\n\nv2.13.2\n\n- Update mux-embed to v5.2.1\n\nv2.13.1\n\n- Update mux-embed to v5.2.0\n\nv2.13.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv2.12.5\n\n- Update mux-embed to v5.0.0\n\nv2.12.4\n\n- Update mux-embed to v4.30.0\n\nv2.12.3\n\n- Update mux-embed to v4.29.0\n\nv2.12.2\n\n- Update mux-embed to v4.28.1\n\nv2.12.1\n\n- Update mux-embed to v4.28.0\n\nv2.12.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv2.11.3\n\n- Update mux-embed to v4.26.0\n\nv2.11.2\n\n- Update mux-embed to v4.25.1\n\nv2.11.1\n\n- Update mux-embed to v4.25.0\n\nv2.11.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv2.10.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv2.9.5\n\n- Update mux-embed to v4.22.0\n\nv2.9.4\n\n- Update mux-embed to v4.21.0\n\nv2.9.3\n\n- Update mux-embed to v4.20.0\n\nv2.9.2\n\n- Update mux-embed to v4.19.0\n\nv2.9.1\n\n- Update mux-embed to v4.18.0\n\nv2.9.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv2.8.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv2.7.0\n\n- Expose utils on SDK initialization function to expose utils.now() for player_init_time\n\n- Update mux-embed to v4.15.0\n\nv2.6.5\n\n- Update mux-embed to v4.14.0\n\nv2.6.4\n\n- Update mux-embed to v4.13.4\n\nv2.6.3\n\n- Update mux-embed to v4.13.3\n\nv2.6.2\n\n- Update mux-embed to v4.13.2\n\nv2.6.1\n\n- Fixes an issue with accessing the global object\n- Update mux-embed to v4.13.1\n\nv2.6.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv2.5.8\n\n- Publish package to NPM\n\nv2.5.7\n\n- Update mux-embed to v4.12.1\n\nv2.5.6\n\n- Update mux-embed to v4.12.0\n\nv2.5.5\n\n- Update mux-embed to v4.11.0\n\nv2.5.4\n\n- Update mux-embed to v4.10.0\n\nv2.5.3\n\n- Update mux-embed to v4.9.4\n\nv2.5.2\n\n- Use common function for generating short IDs\n- Update mux-embed to v4.9.3\n\nv2.5.1\n\n- Update mux-embed to v4.9.2\n\nv2.5.0\n\n- Improve rebuffering metrics by using Tizen buffering events instead of playhead tracking\n\nv2.4.6\n\n- Update mux-embed to v4.9.1\n\nv2.4.5\n\n- Update mux-embed to v4.9.0\n\nv2.4.4\n\n- Update mux-embed to v4.8.0\n\nv2.4.3\n\n- Update mux-embed to v4.7.0\n\nv2.4.2\n\n- Update mux-embed to v4.6.2\n\nv2.4.1\n\n- Update mux-embed to v4.6.1\n\nv2.4.0\n\n- Bump mux-embed to 4.6.0\n\nv2.2.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv2.1.0\n\n- Update mux-embed to v4.1.1\n\nv2.0.0\n\n- Update mux-embed to v4.0.0\n- Support server-side device detection\n\nv1.0.0\n\n- Update to mux-embed v3.1.0\n- The mechanism for registering your own AVPlayPlaybackCallback listener changed. Previously, you set this on the player itself, but in v1.0.0 and newer, simply pass it in when you call monitorTizenPlayer, alongside the debug and data options, as playbackListener\n\nv0.3.0\n\n- Support programchange\n- Update to mux-embed v2.8.0\n- Fix an issue where play event may not have been sent appropriately\n\nv0.1.0\n\n- Initial SDK released."
  },
  {
    "id": "92-_guides/developer/monitor-shaka-player",
    "title": "Monitor Shaka player",
    "path": "_guides/developer/monitor-shaka-player.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-shaka-player",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video.\n\n<CodeExamples\n  examples={{\n    npm: npm install --save @mux/mux-data-shakaplayer,\n    yarn: yarn add @mux/mux-data-shakaplayer,\n    cdn: '',\n  }}\n  exampleOrder=\"npm,yarn,cdn\"\n/>\n\nCall new shaka.Player like you normally would and get the return value (a reference to the player). Call initShakaPlayerMux with the player reference and the SDK options.\n\nPassing in shaka global\n\nYou'll see the 3rd argument to initShakaPlayerMux is shaka. This is the global shaka object. If you are using a bundler and importing shaka with require or import then you'll need to pass in the shaka object.\n\nIf no shaka object is passed in, then initShakaPlayerMux will look for shaka on then global window object.\n\nThe only required field in the options that you pass into @mux/mux-data-shakaplayer is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data on initialization.\n\n\n```js\ninitShakaPlayerMux(player, {\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY',\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call initShakaPlayerMux. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\n// player is the instance returned by `new shaka.Player`\nplayer.mux.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\n\n```js\n// player is the instance returned by `new shaka.Player`\nplayer.mux.emit('videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\n// player is the instance returned by `new shaka.Player`\nplayer.mux.emit('programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\n// player is the instance returned by `new shaka.Player`\ninitShakaPlayerMux(player, {\n  debug: false,\n  disableCookies: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n});\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\n// player is the instance returned by `new shaka.Player`\ninitShakaPlayerMux(player, {\n  debug: false,\n  respectDoNotTrack: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n});\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, @mux/mux-data-shakaplayer will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\n// player is the instance returned by `new shaka.Player`\nplayer.mux.emit('error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\n// player is the instance returned by `new shaka.Player`\ninitShakaPlayerMux(player, {\n  debug: false,\n  errorTranslator,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\n// player is the instance returned by `new shaka.Player`\ninitShakaPlayerMux(player, {\n  debug: false,\n  automaticErrorTracking: false,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nTrack Ad playback with a custom integration\n\nOur integration for Shaka player does not have a built-in integration for tracking ad playback. If you would like to track ads played within Shaka player, you will need to build a custom integration, which is detailed here: Build a Custom Integration.\n\nCustomize beacon collection domain\n\n\n```js\n// player is the instance returned by `new shaka.Player`\ninitShakaPlayerMux(player, {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nCurrent release\n\nv5.14.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv5.14.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv5.14.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv5.14.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv5.14.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv5.14.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv5.14.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv5.14.7\n\n- Update mux-embed to v5.9.0\n\nv5.14.6\n\n- Update mux-embed to v5.8.3\n\nv5.14.5\n\n- Update mux-embed to v5.8.2\n\nv5.14.4\n\n- Update mux-embed to v5.8.1\n\nv5.14.3\n\n- Update mux-embed to v5.8.0\n\nv5.14.2\n\n- Update mux-embed to v5.7.0\n\nv5.14.1\n\n- Update mux-embed to v5.6.0\n\nv5.14.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv5.13.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv5.13.2\n\n- Update mux-embed to v5.4.2\n\nv5.13.1\n\n- Update mux-embed to v5.4.1\n\nv5.13.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv5.12.8\n\n- Update mux-embed to v5.3.3\n\nv5.12.7\n\n- Update mux-embed to v5.3.2\n\nv5.12.6\n\n- Update mux-embed to v5.3.1\n\nv5.12.5\n\n- Update mux-embed to v5.3.0\n\nv5.12.4\n\n- fix an issue where [Object object] would be returned in error_context at times\n\nv5.12.3\n\n- Update mux-embed to v5.2.1\n\nv5.12.2\n\n- Update mux-embed to v5.2.0\n\nv5.12.1\n\n- Resolve Shaka crash if response.data is not present\n\nv5.12.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv5.11.0\n\n- tsignore added due to new TypeScript types (types not fully applied yet)\n\n- Update mux-embed to v5.0.0\n\nv5.10.5\n\n- Update mux-embed to v4.30.0\n\nv5.10.4\n\n- Update mux-embed to v4.29.0\n\nv5.10.3\n\n- Only submit requestcompleted events for the manifest, media, and encryption requests\n\nv5.10.2\n\n- Update mux-embed to v4.28.1\n\nv5.10.1\n\n- Update mux-embed to v4.28.0\n\nv5.10.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv5.9.3\n\n- Update mux-embed to v4.26.0\n\nv5.9.2\n\n- Update mux-embed to v4.25.1\n\nv5.9.1\n\n- Update mux-embed to v4.25.0\n\nv5.9.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv5.8.6\n\n- Update mux-embed to v4.23.0\n\nv5.8.5\n\n- Update mux-embed to v4.22.0\n\nv5.8.4\n\n- Update mux-embed to v4.21.0\n\nv5.8.3\n\n- Update mux-embed to v4.20.0\n\nv5.8.2\n\n- Update mux-embed to v4.19.0\n\nv5.8.1\n\n- Load error codes on-demand\n\nv5.8.0\n\n- Collect Shaka contextual error information\n\n- Update mux-embed to v4.18.0\n\nv5.7.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv5.6.0\n\n- Add new renditionchange fields to Shaka SDK\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n- Add frame drops to Shaka SDK\n\n- Update mux-embed to v4.16.0\n\nv5.5.0\n\n- Expose utils on SDK initialization function to expose utils.now() for player_init_time\n\n- Record request_url and request_id with network events\n- Update mux-embed to v4.15.0\n\nv5.4.5\n\n- Update mux-embed to v4.14.0\n\nv5.4.4\n\n- Update mux-embed to v4.13.4\n\nv5.4.3\n\n- Update mux-embed to v4.13.3\n\nv5.4.2\n\n- Update mux-embed to v4.13.2\n\nv5.4.1\n\n- Fixes an issue with accessing the global object\n- Update mux-embed to v4.13.1\n\nv5.4.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv5.3.14\n\n- Publish package to NPM\n\nv5.3.13\n\n- Update mux-embed to v4.12.1\n\nv5.3.12\n\n- Update mux-embed to v4.12.0\n\nv5.3.11\n\n- Update mux-embed to v4.11.0\n\nv5.3.10\n\n- Update mux-embed to v4.10.0\n\nv5.3.9\n\n- Update mux-embed to v4.9.4\n\nv5.3.8\n\n- Use common function for generating short IDs\n- Update mux-embed to v4.9.3\n\nv5.3.7\n\n- Update mux-embed to v4.9.2\n\nv5.3.6\n\n- Update mux-embed to v4.9.1\n\nv5.3.5\n\n- Update mux-embed to v4.9.0\n\nv5.3.4\n\n- Update mux-embed to v4.8.0\n\nv5.3.3\n\n- Update mux-embed to v4.7.0\n\nv5.3.2\n\n- Update mux-embed to v4.6.2\n\nv5.3.1\n\n- Update mux-embed to v4.6.1\n\nv5.3.0\n\n- Bump mux-embed to 4.6.0\n\nv5.2.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv5.1.0\n\n- Update mux-embed to v4.1.1\n- Fix an issue where player_remote_played would not be reported correctly\n\nv5.0.0\n\n- Update mux-embed to v4.0.0\n- Support server-side device detection\n\nv4.0.1\n\n- remove mime type detection, Mux will now detect this server-side based on the source\n- HLS mime type changed from application/vnd.apple.mpegurl to application/x-mpegurl. This is part of a larger effort to standardize mime type detection across different players\n\nv4.0.0\n\n- Only send 'critical' errors to Mux. Previously, any error (including non-fatal errors) could be sent to Mux. See: https://shaka-player-demo.appspot.com/docs/api/shaka.util.Error.html.Severity"
  },
  {
    "id": "93-_guides/developer/monitor-theoplayer-android",
    "title": "Monitor THEOplayer",
    "path": "_guides/developer/monitor-theoplayer-android.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-theoplayer-android",
    "content": "This documents integration instructions for THEO Technologies' THEOplayer library\n\nThe Mux integration with THEOplayer is built on top of Mux's core Java SDK, and the full code can be seen here: muxinc/mux-stats-sdk-theoplayer-android.\n\nAdd the Mux SDK to your project using one of the following approaches:\n\nAdd Gradle dependency on the Mux THEOplayer SDK (preferred)\nAdd the Mux Maven repository to your Gradle file:\n\n```text\nrepositories {\n    maven {\n        url \"https://muxinc.jfrog.io/artifactory/default-maven-release-local\"\n    }\n}\n```\n\n\nNext, add a dependency on the Mux Data THEOplayer SDK.\n\nThe latest version of our SDK can be found here\n\n\n```groovy\nimplementation 'com.mux.stats.sdk.muxstats:muxstatssdktheoplayer:[CurrentVersion]'\n```\n\n\nFirst, create the CustomerPlayerData and CustomerVideoData objects as appropriate for your current playback, and be sure to set your ENV_KEY.\n\n\n```java\nimport com.mux.stats.sdk.core.model.CustomerPlayerData;\nimport com.mux.stats.sdk.core.model.CustomerVideoData;\nimport com.mux.stats.sdk.core.model.CustomerViewData\nimport com.mux.stats.sdk.core.model.CustomData;\nimport com.mux.stats.sdk.core.model.CustomerData;\n\nCustomerPlayerData customerPlayerData = new CustomerPlayerData();\ncustomerPlayerData.setEnvironmentKey(\"YOUR_ENVIRONMENT_KEY_HERE\");\n\nCustomerVideoData customerVideoData = new CustomerVideoData();\ncustomerVideoData.setVideoTitle(intent.getStringExtra(\"YOUR_VIDEO_TITLE\"));\n\nCustomerViewData customerViewData = new CustomerViewData();\ncustomerViewData.setViewSessionId(\"A26C4C2F-3C8A-46FB-885A-8D973F99A998\");\n\nCustomData customData = new CustomData();\ncustomData.setCustomData1(\"YOUR_CUSTOM_STRING_HERE\");\n\nCustomerData customerData = new CustomerData(customerPlayerData, customerVideoData, customerViewData);\ncustomerData.setCustomData(customData);\n```\n\n\nNext, create the MuxStatsSDKTHEOPlayer object by passing your Android Context (typically your Activity), a THEOplayerView instance, a player name, and the customer data objects.\n\n\n```java\nimport com.mux.stats.sdk.muxstats.MuxStatsSDKTHEOPlayer;\n...\n// Make sure to monitor the player before calling `prepare` on the THEOplayer instance\nmuxStatsTHEOplayer = new MuxStatsSDKTHEOPlayer(\n  this, player, \"demo-player\", customerData);\n```\n\n\nIn order to correctly monitor if the player is full-screen, provide the screen size to the MuxStatsSDKTHEOPlayer instance.\n\n\n```java\nPoint size = new Point();\ngetWindowManager().getDefaultDisplay().getSize(size);\nmuxStatsTHEOPlayer.setScreenSize(size.x, size.y);\n```\n\n\nIn order to determine a number of viewer context values as well as track the size of the video player, set the player view.\n\n\n```java\nmuxStatsTHEOplayer.setPlayerView(theoPlayerView);\n```\n\n\nFinally, when you are destroying the player, call the MuxStatsSDKTHEOPlayer.release() function.\n\n\n```\nmuxStatsTHEOplayer.release()\n```\n\n\nAfter you've integrated, start playing a video in your player. A few minutes after you stop watching, you'll see the results in your Mux data dashboard. Login to the dashboard and find the environment that corresponds to your env_key and look for video views.\n\nIn the Java SDK, options are provided via the objects within the CustomerData object.\n\nAll metadata details except for envKey are optional, however you'll be able to compare and see more interesting results as you include more details. This gives you more metrics and metadata about video streaming, and allows you to search and filter on important fields like the player version, CDN, and video title.\n\nFor more information, see the Metadata Guide.\n\nChanging the video\n\nThere are two cases where the underlying tracking of the video view need to be reset. First, when you load a new source URL into an existing player, and second when the program within a singular stream changes (such as a program within a live stream).\n\nNote: You do not need to change the video info when changing to a different source of the same video content (e.g. different resolution or video format).\n\nNew source\n\nWhen you change to a new video (in the same player) you need to update the information that Mux knows about the current video. Examples of when this is needed are:\n\n The player advances to the next video in a playlist\n The user selects a different video to play\n\nThis is done by calling muxStatsTHEOplayer.videoChange(CustomerVideoData) which will remove all previous video data and reset all metrics for the video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nIt's best to change the video info immediately after telling the player which new source to play.\n\nNew program (in single stream)\n\nIn some cases, you may have the program change within a stream, and you may want to track each program as a view on its own. An example of this is a live stream that streams multiple programs back to back, with no interruptions.\n\nIn this case, call muxStatsTHEOplayer.programChange(CustomerVideoData). This will remove all previous video data and reset all metrics for the video view, creating a new video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nDetect when a video is being played full-screen\n\nFor most use cases, the SDK is capable of detecting whether or not a video is being played full-screen. Specifically, it can do so in the case where the player view is the same size as the device display (excepting ActionBars and other framework window decoration).\n\nFor other uses cases (non-overlaid controls, window decoration via plain Views, etc) you may need to tell the SDK when the user switches to full-screen.\n\n\n```java\n  @Override\n  public void onCreate(@Nullable Bundle savedInstanceState) {\n    super.onCreate(savedInstanceState)\n\n    // If you are using SimplePlayerView, StyledPlayerView, etc\n    theoPlayerView = findViewById(R.id.my_player_view);\n\n    theoPlayerView.getFullscreenManager().addFullscreenChangeListener(new FullscreenChangeListener() {\n      @Override\n      public void onEnterFullscreen() {\n        muxStatsTHEOplayer.presentationChange(MuxSDKViewPresentation.FULLSCREEN);\n      }\n      @Override\n      public void onExitFullscreen() {\n        muxStatsTHEOPlayer.presentationChange(MuxSDKViewPresentation.PORTRAIT);\n      }\n    });\n  }\n```\n\n\nError tracking\n\nBy default, Mux's integration with THEOplayer automatically tracks fatal errors as thrown by THEOplayer. If a fatal error happens outside the context of THEOplayer and you want to track it with Mux, you can call muxStatsTHEOplayer.error like this:\n\n\n```java\n// Error code: integer value for the generic type of error that\n// occurred.\n// Error message: String providing more information on the error\n// that occurred.\n// For an example, the HTML5 video element uses the\n// following: https://developer.mozilla.org/en-US/docs/Web/API/MediaError\n// for codes and messages. Feel free to use your own codes and messages\nint errorCode = 1;\nString errorMessage = \"A fatal error was encountered during playback\";\nMuxErrorException error = new MuxErrorException(errorCode, errorMessage);\nmuxStatsTHEOplayer.error(error);\n```\n\nNote that muxStatsTHEOplayer.error(MuxErrorException e) can be used with or without automatic error tracking. If your application has retry logic that attempts to recover from THEOplayer errors then you may want to disable automatic error tracking like this:\n\n\n```java\nmuxStatsTHEOplayer.setAutomaticErrorTracking(false)\n```\n\n\nIt is important that you only trigger an error when the playback has to be abandoned or aborted in an unexpected manner, as Mux tracks fatal playback errors only.\n\nCurrent release\n\nv0.4.2\nUpdates:\n update: rename library artifact to muxstatssdktheoplayer\n\nPrevious releases\n\nv0.4.1\nImprovements:\n Use \"Android TV\" osFamily on tv devices\n\nv0.4.0\nImprovements:\n Update to Core 8.1.0\n\nv0.3.0\nImprovements:\n Add support for THEOplayer v7\nFixes:\n fix: NullPointerException with getPlayerData() inside MuxStats  (29)\n\nv0.2.0\nUpdates:\n Support THEOPlayer v5 and higher\n\nv0.1.3\nFixes:\n Update THEOplayer to 2.92.0 (18)\n\nv0.1.2\nImprovements:\n Update to MuxCore 7.0.10\nMuxCore Fixes:\n Fix event-handling errors in rare cases\n\nv0.1.1\n Initial release"
  },
  {
    "id": "94-_guides/developer/monitor-theoplayer-ios",
    "title": "Monitor THEOplayer (iOS)",
    "path": "_guides/developer/monitor-theoplayer-ios.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-theoplayer-ios",
    "content": "Requirements:\n\n THEOplayer.xcframework SDK for iOS (> 5.9)\n A working implementation of THEOplayer in your iOS app\n\nBefore integrating Mux-Stats-THEOplayer into your player, first make sure your THEOplayer implementation is working as expected.\n\nAdd Mux-Stats-THEOplayer to your podfile\n\n\n```\npod 'Mux-Stats-THEOplayer', '~> 0.8'\n```\n\n\nRun pod install then import MuxCore and MUXSDKStatsTHEOplayer modules into your application. Call monitorTHEOplayer and pass in a reference to your THEOplayer instance.\n\nBelow is an example configuration for a simple THEOplayer implementation. The key part to pay attention to is monitorTHEOplayer. This example is using ads with THEOplayer, which will also be tracked with Mux Data.\n\n\n```swift\nimport MuxCore\nimport MUXSDKStatsTHEOplayer\nimport THEOplayerSDK\nimport UIKit\n\nclass ViewController: UIViewController {\n    let playerName = \"demoplayer\"\n    var player: THEOplayer!\n\n    override func viewDidAppear(_ animated: Bool) {\n        super.viewDidAppear(animated)\n        self.player = THEOplayer(configuration: THEOplayerConfiguration(chromeless: false))\n        self.player.frame = view.bounds\n        self.player.addAsSubview(of: view)\n\n        let typedSource = TypedSource(\n            src: \"https://stream.mux.com/tqe4KzdxU6GLc8oowshXgm019ibzhEX3k.m3u8\",\n            type: \"application/vnd.apple.mpegurl\")\n\n        let ad = THEOAdDescription(src: \"https://pubads.g.doubleclick.net/gampad/ads?sz=640x480&iu=/124319096/external/ad_rule_samples&ciu_szs=300x250&ad_rule=1&impl=s&gdfp_req=1&env=vp&output=vmap&unviewed_position_start=1&cust_params=deployment%3Ddevsite%26sample_ar%3Dpremidpostpod&cmsid=496&vid=short_onecue&correlator=\")\n\n        let source = SourceDescription(source: typedSource, ads: [ad], textTracks: nil, poster: nil, analytics: nil, metadata: nil)\n        self.player.source = source\n\n        // TODO: Add your env key\n        let playerData = MUXSDKCustomerPlayerData(environmentKey: \"ENV_KEY\")!\n\n        let videoData = MUXSDKCustomerVideoData()\n        videoData.videoTitle = \"Big Buck Bunny\"\n        videoData.videoId = \"bigbuckbunny\"\n        videoData.videoSeries = \"animation\"\n\n        MUXSDKStatsTHEOplayer.monitorTHEOplayer(self.player, name: playerName, playerData: playerData, videoData: videoData, softwareVersion: \"1.1.1\")\n        self.player.play()\n    }\n}\n```\n\n\nThe only required field is env_key. But without some more metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nMetadata fields are provided via the MUXSDKCustomerPlayerData and MUXSDKCustomerVideoData objects.\n\nFor the full list of properties view the header files for this interfaces:\n\n- MUXSDKCustomerPlayerData.h\n- MUXSDKCustomerVideoData.h\n\nFor more details about each property, view the Make your data actionable guide.\n\n\n```swift\nlet playName = \"iOS AVPlayer\"\nlet playerData = MUXSDKCustomerPlayerData(environmentKey: \"ENV_KEY\");\nplayerData.viewerUserId = \"1234\"\nplayerData.experimentName = \"player_test_A\"\n// note that the 'playerName' field here is unrelated to the 'playName' variable above\nplayerData.playerName = \"My Main Player\"\nplayerData.playerVersion = \"1.0.0\"\n\nlet videoData = MUXSDKCustomerVideoData();\nvideoData.videoId = \"abcd123\"\nvideoData.videoTitle = \"My Great Video\"\nvideoData.videoSeries = \"Weekly Great Videos\"\nvideoData.videoDuration = 120000 // in milliseconds\nvideoData.videoIsLive = false\nvideoData.videoCdn = \"cdn\"\n\n\nMUXSDKStatsTHEOplayer.monitorTHEOplayer(self.player, name: playerName, playerData: playerData, videoData: videoData, softwareVersion: \"1.1.1\")\nself.player.play()\n```\n\n\nChanging the video\nIf you want to change the video in the player, you'll need to let the Mux SDK know by calling videoChangeForPlayer. From the perspective of Mux Data, this will create a new view.\n\n\n```swift\nlet videoData = MUXSDKCustomerVideoData()\nvideoData.videoTitle = \"New Video\"\nvideoData.videoId = \"newVideoId\"\nMUXSDKStatsTHEOplayer.videoChangeForPlayer(name: self.playerName, videoData: videoData)\n\nlet typedSource = TypedSource(src: \"https://stream.mux.com/tNrV028WTqCOa02zsveBdNwouzgZTbWx5x.m3u8\", type: \"application/vnd.apple.mpegurl\")\nlet source = SourceDescription(source: typedSource, ads: [], textTracks: nil, poster: nil, analytics: nil, metadata: nil)\nself.player.source = source\nself.player.play()\n```\n\n\nHandling Errors manually\n\nBy default, automaticErrorTracking is enabled which means the Mux SDK will catch errors that the player throws and track an error event. Error tracking is meant for fatal errors. When an error is thrown it will mark the view as having encountered an error in the Mux dashboard and the view will no longer be monitored.\n\nIf you want to disable automatic and track errors manually you can do by passing in automaticErrorTracking false when calling monitorTHEOplayer\n\nWhether automatic error tracking is enabled or disabled, you can dispatch errors manually with dispatchError.\n\n\n```swift\nMUXSDKStatsTHEOplayer.monitorTHEOplayer(self.player, name: playerName, playerData: playerData, videoData: videoData, softwareVersion: \"1.1.1\", automaticErrorTracking: false)\nMUXSDKStatsTHEOplayer.dispatchError(name: playerName, code: \"1234\", message: \"Something is not right\")\n```\n\n\nCurrent release\n\nv0.12.0\n- Update range of supported THEOplayer versions to major version 8\n\nPrevious Releases\n\nv0.11.0\n- Relax THEOplayer version constraint to allow installation alongside any version of THEOplayer whose major version is 7\n- Add an ads integration presence check to remove console warning when no ads integration is present\n\nv0.10.0\n- Support use in tvOS applications\n- Update minimum supported THEOplayer dependency to 7.1.0\n- Update pinned MuxCore dependency to 4.7.1\n\nv0.9.0\n- Update minimum supported THEOplayer dependency to 6.12.1\n- Update pinned MuxCore dependency to 4.7.0\n- The minimum deployment target is now iOS 12.0\n\nv0.8.0\n- Add support for THEOplayer 5.9 and above\n- Add support for installation with Swift Package Manager\n\nv0.7.0\n- Remove the THEOplayerSDK.framework from build artifact\n- Add THEOplayerSDK.framework to .gitignore\n\nv0.6.0\n- Add MUXSDKCustomerData\n- Custom data support through customer data object\n\nv0.5.0\n- Update to use xcframeworks to provide Xcode 13 and M1 compatibility\n\nv0.4.1\n- Fix an issue where an error message could be wrongly set when an AdError occurs\n\nv0.4.0\n- Fix an issue with error message and code in AdError events\n- Fix compatibility with Xcode 12\n\nv0.3.0\n- Add error code tracking as well as error message when handling errors\n- Bump the required THEOplayer.framework SDK for iOS to > v2.76\n\nv0.2.0\n- Add option to disable automatic error tracking when calling monitorTHEOplayer\n- Add API to manually dispatch an error with MUXSDKStatsTHEOplayer.dispatchError\n\nYou probably will not need to use these features, but if your player is throwing noisy non-fatal errors or you want to catch the player errors yourself and take precise control over the error code and error message then you now have that ability.\n\n- (bugfix) fix build script for frameworks for AppStore error ITMS-90562: Invalid Bundle in the CFBundleSupportedPlatforms plist\n- (bugfix) fix crash that can happen when using Google IMA ads with THEOplayer\n\nv0.1.0\n- Initial release"
  },
  {
    "id": "95-_guides/developer/monitor-theoplayer-web",
    "title": "Monitor THEOplayer (Web)",
    "path": "_guides/developer/monitor-theoplayer-web.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-theoplayer-web",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video.\n\n<CodeExamples\n  examples={{\n    npm: npm install --save @mux/mux-data-theoplayer,\n    yarn: yarn add @mux/mux-data-theoplayer,\n    cdn:\n\n,\n  }}\n  exampleOrder=\"npm,yarn,cdn\"\n/>\n\nCall new THEOplayer.Player like you normally would. Call initTHEOplayerMux with a reference to the player instance and the Mux SDK options.\n\nPassing in THEOplayer global\n\nYou'll see the 3rd argument to initTHEOplayerMux is THEOplayer. This is the global THEOplayer object. If you are using a bundler and importing THEOplayer with require or import then you'll need to pass in the THEOplayer object.\n\nIf no THEOplayer object is passed in, then initTHEOplayerMux will look for THEOplayer on then global window object.\n\nThe only required field in the options that you pass into initTHEOplayerMux is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data on initialization.\n\n\n```js\n// player here is the instance of THEOplayer.Player\ninitTHEOplayerMux(player, {\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n    // Site Metadata\n    viewer_user_id: '', // ex: '12345'\n    experiment_name: '', // ex: 'player_test_A'\n    sub_property_id: '', // ex: 'cus-1'\n    // Player Metadata\n    player_name: '', // ex: 'My Main Player'\n    player_version: '', // ex: '1.0.0'\n    player_init_time: '', // ex: 1451606400000\n    // Video Metadata\n    video_id: '', // ex: 'abcd123'\n    video_title: '', // ex: 'My Great Video'\n    video_series: '', // ex: 'Weekly Great Videos'\n    video_duration: '', // in milliseconds, ex: 120000\n    video_stream_type: '', // 'live' or 'on-demand'\n    video_cdn: '' // ex: 'Fastly', 'Akamai'\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first call initTHEOplayerMux. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\n// player is the instance of THEOplayer.Player\nlet monitor = initTHEOplayerMux(player, {\n  debug: false,\n  data: {\n    env_key: 'ENV_KEY', // required\n\n    video_id: 'abcd123',\n  }\n});\n\nmonitor.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\nFor THEOplayer, you do not need to emit the videochange event when the player source property of the player is updated. The sourcechange event that is fired when you update the source property of the player is handled automatically. However, you still need to pass the updated video metadata under metadata.mux, as shown in the example below.\n\nWhen this is done, it removes all previous video data and resets all metrics for the video view. Note: the previous method using changeMuxVideo has been deprecated, but will continue to work for 2.x versions of this plugin.\n\n\n```js\nplayer.source = {\n  sources: {\n    // ...your source\n  },\n  metadata: {\n    mux: {\n      video_id: 'new-ID',\n      video_title: 'New title',\n      // ... other metadata\n    }\n  }\n}\n```\n\n\nNew program\n\n\n```js\n// player is the instance of THEOplayer.Player\nlet monitor = initTHEOPlayerMux(player, {\n  debug: false,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n\n// emit `programchange` when the content within the stream changes\nmonitor.emit('programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\n// player here is the instance of THEOplayer.Player\ninitTHEOplayerMux(player, {\n  debug: false,\n  disableCookies: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\n// player is the instance of THEOplayer.Player\ninitTHEOplayerMux(player, {\n  debug: false,\n  respectDoNotTrack: true,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, @mux/mux-data-theoplayer will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\n// player is the instance of THEOplayer.Player\nlet monitor = initTHEOPlayerMux(player, {\n  debug: false,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n\n// emit the `error` event when an error occurs\nmonitor.emit('error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\n// player is the instance of THEOplayer.Player\ninitTHEOplayerMux(player, {\n  debug: false,\n  errorTranslator,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\n// player is the instance of THEOplayer.Player\ninitTHEOplayerMux(player, {\n  debug: false,\n  automaticErrorTracking: false,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nAds tracking with @mux/mux-data-theoplayer\n\nMux has been tested with and supports THEOplayer's Ads integration. Simply configure the ads as you would with THEOplayer normally, and Mux will track ads automatically. No additional configuration is needed.\n\nOther THEOplayer ad integrations, such as Google IMA, may work out of the box but have not currently been tested. Please contact us with any questions.\n\nCustomize beacon collection domain\n\n\n```js\n// player is the instance of THEOplayer.Player\ninitTHEOplayerMux(player, {\n  debug: false,\n  beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n```\n\n\nDestroy the monitor\n\nIn some cases, you may want to stop tracking an instance of THEOplayer. To this, we provide a destroy method within the returned object of initTHEOplayerMux, which will immediately end the active Mux Data view and stop tracking the THEOplayer instance.\n\n\n```\n// player is the instance of THEOplayer.Player\nlet monitor = initTHEOplayerMux(player, {\n  debug: false,\n  data: {\n    env_key: \"ENV_KEY\",\n    // ...\n  }\n});\n\n// once ready to destroy the monitor\nmonitor.destroy();\n```\n\n\nCurrent release\n\nv5.4.0\n\n- fix issue with sourcechange causing metadata conflicts\n\nPrevious releases\n\nv5.3.15\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nv5.3.14\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv5.3.13\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv5.3.12\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv5.3.11\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv5.3.10\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv5.3.9\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv5.3.8\n\n- Fix issue with audio tracking where the player is not initialized\n\nv5.3.7\n\n- Update mux-embed to v5.9.0\n\nv5.3.6\n\n- Update mux-embed to v5.8.3\n\nv5.3.5\n\n- Update mux-embed to v5.8.2\n\nv5.3.4\n\n- Update mux-embed to v5.8.1\n\nv5.3.3\n\n- Update mux-embed to v5.8.0\n\nv5.3.2\n\n- Update mux-embed to v5.7.0\n\nv5.3.1\n\n- Update mux-embed to v5.6.0\n\nv5.3.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv5.2.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv5.2.2\n\n- Update mux-embed to v5.4.2\n\nv5.2.1\n\n- Update mux-embed to v5.4.1\n\nv5.2.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv5.1.9\n\n- Update mux-embed to v5.3.3\n\nv5.1.8\n\n- Update mux-embed to v5.3.2\n\nv5.1.7\n\n- Update mux-embed to v5.3.1\n\nv5.1.6\n\n- Update mux-embed to v5.3.0\n\nv5.1.5\n\n- fix an issue where video bitrate for renditionchange events could be calculated incorrectly for non-dash streams\n- fix an issue where request/response interceptors were not removed on destroy\n\nv5.1.4\n\n- utilize width and height directly from THEOplayer's API for renditionchange events\n- add support for detecting frame rate, name, and codec for renditionchange events\n- Update mux-embed to v5.2.1\n\nv5.1.3\n\n- Update mux-embed to v5.2.0\n\nv5.1.2\n\n- Fix issue when videoTracks or audioTracks is undefined\n\nv5.1.1\n\n- Ensure seeking/seeked and rebuffering/rebuffered events are better distinguished.\n\nv5.1.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv5.0.4\n\n- Update mux-embed to v5.0.0\n\nv5.0.3\n\n- Update mux-embed to v4.30.0\n\nv5.0.2\n\n- Update mux-embed to v4.29.0\n\nv5.0.1\n\n- Update mux-embed to v4.28.1\n\nv5.0.0\n\n- use a new mechanism to track rebuffering for better accuracy\n  - fix an issue where player time was reported in the wrong units\n  - improved internal cleanup for memory management\n\n- Update mux-embed to v4.28.0\n\nv4.17.1\n\n- Fixed the README files (public and internal) with correct information\n\nv4.17.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv4.16.0\n\n- Fix error context reporting for HLS manifests\n\nv4.15.3\n\n- Update mux-embed to v4.26.0\n\nv4.15.2\n\n- Update mux-embed to v4.25.1\n\nv4.15.1\n\n- Update mux-embed to v4.25.0\n\nv4.15.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv4.14.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv4.13.4\n\n- Update mux-embed to v4.22.0\n\nv4.13.3\n\n- Update mux-embed to v4.21.0\n\nv4.13.2\n\n- Update mux-embed to v4.20.0\n\nv4.13.1\n\n- Update mux-embed to v4.19.0\n\nv4.13.0\n\n- Set Mux Error Context with additional error information from THEOplayer\n\nv4.12.1\n\n- Fall back to player element size to get better player resolutions\n- Update mux-embed to v4.18.0\n\nv4.12.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv4.11.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv4.10.0\n\n- Expose utils on SDK initialization function to expose utils.now() for player_init_time\n\n- Record request_url and request_id with network events\n- Update mux-embed to v4.15.0\n\nv4.9.5\n\n- Update mux-embed to v4.14.0\n\nv4.9.4\n\n- Update mux-embed to v4.13.4\n\nv4.9.3\n\n- Update mux-embed to v4.13.3\n\nv4.9.2\n\n- Update mux-embed to v4.13.2\n\nv4.9.1\n\n- Fixes an issue with accessing the global object\n- Update mux-embed to v4.13.1\n\nv4.9.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv4.8.6\n\n- Publish package to NPM\n\nv4.8.5\n\n- Update mux-embed to v4.12.1\n\nv4.8.4\n\n- Update mux-embed to v4.12.0\n\nv4.8.3\n\n- Update mux-embed to v4.11.0\n\nv4.8.2\n\n- Update mux-embed to v4.10.0\n\nv4.8.1\n\n- Update mux-embed to v4.9.4\n\nv4.8.0\n\n- Allow for passing in the THEOplayer instance instead of using the instance on window\n\nv4.7.6\n\n- Use common function for generating short IDs\n- Update mux-embed to v4.9.3\n\nv4.7.5\n\n- Update mux-embed to v4.9.2\n\nv4.7.4\n\n- Update mux-embed to v4.9.1\n\nv4.7.3\n\n- Update mux-embed to v4.9.0\n\nv4.7.2\n\n- Update mux-embed to v4.8.0\n\nv4.7.1\n\n- Update mux-embed to v4.7.0\n\nv4.7.0\n\n- Introducing HLS Session Data support\n\n- Update mux-embed to v4.6.2\n\nv4.6.1\n\n- Update mux-embed to v4.6.1\n\nv4.6.0\n\n- Bump mux-embed to 4.6.0\n\nv4.5.1\n\n- Update mux-embed to v4.4.4\n- Stops emitting a requestcompleted event for every manifest request\n\nv4.5.0\n\n- Update mux-embed to v4.4.2\n\nv4.4.0\n\n- Add support for bandwidth metrics\n\nv4.3.1\n\n- Fix an issue where normal events were being fired as ad events\n\nv4.3.0\n\n- Update mux-embed to v4.4.0\n- Support latency metrics when using HLS\n\nv4.2.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv4.1.1\n\n- Fix an issue where bitrate reported for HLS streams would be double the expected value\n\nv4.1.0\n\n- Update mux-embed to v4.1.1\n- Add support for custom dimensions\n- Fix an issue where player_remote_played may not be tracked correctly\n\nv4.0.0\n\n- Update mux-embed to v4.0.0\n- Support server-side device detection\n\nv3.1.0\n\n- Add renditionchange tracking event\n\nv3.0.1\n\n- Inject metadata for certain edge case startup sequences\n\nv3.0.0\n\n- Update mux-embed to 3.0.0"
  },
  {
    "id": "96-_guides/developer/monitor-video-js",
    "title": "Monitor video.js",
    "path": "_guides/developer/monitor-video-js.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitor-video-js",
    "content": "Include the Mux JavaScript SDK on every page of your web app that includes video. You can use the Mux-hosted version of the script or install via npm. videojs-mux follows semantic versioning and the API will not change between major releases.\n\nCall video.js like you normally would and include the Mux plugin options.\n\nThe only required field in the options that you pass into videojs-mux is env_key. But without some metadata the metrics in your dashboard will lack the necessary information to take meaningful actions. Metadata allows you to search and filter on important fields in order to diagnose issues and optimize the playback experience for your end users.\n\nPass in metadata under the data on initialization.\n\n\n```js\nvideojs('#my-player', {\n  plugins: {\n    mux: {\n      debug: false,\n      data: {\n        env_key: 'ENV_KEY', // required\n        // Site Metadata\n        viewer_user_id: '', // ex: '12345'\n        experiment_name: '', // ex: 'player_test_A'\n        sub_property_id: '', // ex: 'cus-1'\n        // Player Metadata\n        player_name: '', // ex: 'My Main Player'\n        player_version: '', // ex: '1.0.0'\n        // There is no need to provide player_init_time, tracked automatically\n        // player_init_time: '', // ex: 1451606400000;\n        // Video Metadata\n        video_id: '', // ex: 'abcd123'\n        video_title: '', // ex: 'My Great Video'\n        video_series: '', // ex: 'Weekly Great Videos'\n        video_duration: '', // in milliseconds, ex: 120000\n        video_stream_type: '', // 'live' or 'on-demand'\n        video_cdn: '' // ex: 'Fastly', 'Akamai'\n      }\n    }\n  }\n});\n```\n\n\nFor more information, view Make your data actionable.\n\nThere are some cases where you may not have the full set of metadata until after the video playback has started. In this case, you should omit the values when you first initialize the Mux SDK. Then, once you have the metadata, you can update the metadata with the updateData method.\n\n\n```js\n// player is the instance returned by the `videojs` function\nplayer.mux.updateData({ video_title: 'My Updated Great Video' });\n```\n\n\nNew source\n\n\n```js\n// player is the instance returned by the `videojs` function\nplayer.mux.emit('videochange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nNew program\n\n\n```js\n// player is the instance returned by the `videojs` function\nplayer.mux.emit('programchange', {\n  video_id: 'abc345',\n  video_title: 'My Other Great Video',\n  video_series: 'Weekly Great Videos',\n  // ...\n});\n```\n\n\nDisable cookies\n\n\n```js\nvideojs('#my-player', {\n  plugins: {\n    mux: {\n      debug: false,\n      disableCookies: true,\n      data: {\n        env_key: \"ENV_KEY\",\n        // ...\n      }\n    }\n  }\n});\n```\n\n\nOver-ride 'do not track' behavior\n\n\n```js\nvideojs('#my-player', {\n  plugins: {\n    mux: {\n      debug: false,\n      respectDoNotTrack: true,\n      data: {\n        env_key: \"ENV_KEY\",\n        // ...\n      }\n    }\n  }\n});\n```\n\n\nCustomize error tracking behavior\n\nErrors tracked by mux are considered fatal meaning that they are the result of playback failures. If errors are non-fatal they should not be captured.\n\nBy default, videojs-mux will track errors emitted from the video element as fatal errors. If a fatal error happens outside of the context of the player, you can emit a custom error to the mux monitor.\n\n\n```js\n// player is the instance returned by the `videojs` function\nplayer.mux.emit('error', {\n  player_error_code: 100,\n  player_error_message: 'Description of error',\n  player_error_context: 'Additional context for the error'\n});\n```\n\n\nError translator\n\n\n```js\nfunction errorTranslator (error) {\n  return {\n    player_error_code: translateCode(error.player_error_code),\n    player_error_message: translateMessage(error.player_error_message),\n    player_error_context: translateContext(error.player_error_context)\n  };\n}\n\nvideojs('#my-player', {\n  plugins: {\n    mux: {\n      debug: false,\n      errorTranslator,\n      data: {\n        env_key: \"ENV_KEY\",\n        // ...\n      }\n    }\n  }\n});\n```\n\n\nDisable automatic error tracking\n\n\n```js\nvideojs('#my-player', {\n  plugins: {\n    mux: {\n      debug: false,\n      automaticErrorTracking: false,\n      data: {\n        env_key: \"ENV_KEY\",\n        // ...\n      }\n    }\n  }\n});\n```\n\n\nAds tracking with videojs-mux\n\nIf you are using videojs-ima, Brightcove's IMA3 FreeWheel or OnceUX plugins with VideoJS then videojs-mux will track ads automatically. No extra configuration is needed.\n\nCustomize beacon collection domain\n\n\n```js\nvideojs('#my-player', {\n  plugins: {\n    mux: {\n      debug: false,\n      beaconCollectionDomain: 'CUSTOM_DOMAIN', // ex: 'foo.bar.com'\n      data: {\n        env_key: \"ENV_KEY\",\n        // ...\n      }\n    }\n  }\n});\n```"
  },
  {
    "id": "97-_guides/developer/monitoring-metrics",
    "title": "Understand Monitoring Metrics and Dimensions",
    "path": "_guides/developer/monitoring-metrics.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/monitoring-metrics",
    "content": "Mux Data Monitoring offers near real-time metrics to measure Engagement metrics such as current concurrent viewers and QoE metrics to measure streaming performance. These metrics are available in the Monitoring Dashboard and API for Mux Data customers on a Media plan. Monitoring Metrics are offered at sub 20 second latency for a 24 hour period.\n\nEngagement Metrics\n\nCurrent Concurrent Viewers (CCV)\n\nThe number of viewers currently watching a video. This includes viewers currently waiting for the video to start playing, experiencing rebuffering, or who just experienced a playback failure. It does not include viewers that are paused or have been rebuffering more than five consecutive minutes.\n\nCCV by Geography\nA visualization of viewers currently watching a video on an interactive world map. Select a specific country to zoom into a regional breakdown.\n\nTop Titles by CCV\nThe top video titles based on the number of viewers currently watching. The definition of Current Concurrent Viewers (CCV) is used to rank these video titles.\n\nQuality of Experience Metrics\n\nVideo startup failures by startup attempts\n\nThe number of viewers who have just experienced a video startup failure (an error that prevents the user from seeing the first frame of video, be it ads or content) as a percent of Start Attempts. Start Attempts is defined as the number of viewers who are in the video loading state or have just experienced a jump from the video loading state to video startup success, video startup failure, or exits before video starts.\n\nPlayback Failures by CCV\n\nThe number of viewers who have just experienced a playback failure (a fatal error that prevents future playback) as a percent of Current Concurrent Viewers (CCV). Errors defined as non-fatal are not included in this metric.\n\nThe Playback Failures by CCV metric is measured differently from the Playback Failure Percentage in the Mux QoE Metrics.\n\nExits Before Video Start by Start Attempts\n\nThe number of viewers who have just abandoned a video view while waiting at least one second for the video to start playing, as a percent of Start Attempts. Examples where this may happen include closing the app/browser or clicking to a different video before playback begins.\n\nThe Exits Before Video Start by Start Attempts metric is measured differently from Exits Before Video Start in the Mux QoE Metrics.\n\nCurrent Rebuffering Percentage\n\nCurrent Rebuffering Percentage measures the amount of time viewers spent in the rebuffering state, from the last time measured to the current time, as a percentage of the total watch time. The total watch time is the amount of time viewers spent watching or attempting to watch video, which includes startup time, rebuffering time, and time actually watching the video (it does not include paused, errored, or exited states).\n\nCurrent Rebuffering Percentage is measured differently from the Rebuffer Percentage in the Mux QoE Metrics.\n\nCurrent Average Bitrate\n\nThe average of the video bitrates shown to viewers over the time period. The bitrate for a view is the value indicated in the video manifest for the rendition that is played for the viewer during the time period.\n\nVideo Startup Time\n\nVideo Startup Time measures the current median startup time. This could be considered a \"typical\" startup time across viewers; half experience a faster startup time and half experience a slower startup time.\n\nMonitoring Dimensions\n\nCurrent concurrent viewers, current rebuffering percentage, exits before video start, playback failure percentage, current average bitrate, video startup failure percentage can be filtered and broken down by the following dimensions.\n| Dimension | Description |\n|-----------|-------------|\n| ASN | An autonomous system number (ASN) is a number assigned to a local network, registered into the carrier's routing community and placed under the umbrella of an administrative domain called an autonomous system. An ASN is often correlated with an ISP, though a single ISP may operate multiple ASNs. |\n| CDN | The Content Delivery Network used to deliver the video. If using an SDK that supports CDN header extraction, this value will be auto-populated. |\n| Operating System | Operating System (iOS, Windows, etc.) |\n| Player Name | You can provide a name for the player (e.g. My Player) if you want to compare different configurations or types of players around your site or application. This is different from the player software (e.g. Video.js), which is tracked automatically by the SDK. |\n| Region | A geographical subunit of a country. Examples include region, province, or state. |\n| Stream Type | The type of video stream (e.g: live or on-demand) |\n| Sub-property ID | A sub property is an optional way to group data within a property. For example, sub properties may be used by a video platform to group data by its own customers, or a media company might use them to distinguish between its many websites. |\n| Video Series | The series of the video (e.g.: Season 1 or Awesome Show) |\n| Video Title | Title of the video (e.g.: Awesome Show: Pilot) |\n| View Has Ad | Tracks if an ad is present during a view. |\n| Video ID | Your internal ID for the video |\n| Mux Asset ID | Mux generated ID for Mux Video Assets |\n| Mux Livestream ID | Mux generated ID for Mux Video Livestreams |\n| Mux Playback ID | Mux generated Playback ID enabling streaming videos and live streams from Mux. An Asset or Livestream may have more than one Mux Playback Id. |"
  },
  {
    "id": "98-_guides/developer/mux-background-video",
    "title": "Mux Background Video",
    "path": "_guides/developer/mux-background-video.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/mux-background-video",
    "content": "Mux Background Video is a lightweight component and HLS engine for creating background videos using Mux HLS streams.\n\n- React: React component for easy integration\n- Web Component: Custom element for easy integration\n- Lightweight: Minimal bundle size with no dependencies\n- Preload Control: Control video preloading behavior\n- Audio Control: Optionally enable audio tracks for background videos\n- Resolution Control: Set maximum resolution for optimal performance\n\nInstallation\n\n\n```bash\nnpm install @mux/mux-background-video\n```\n\n\nUsage\n\nRequires Mux Basic or Premium video quality currently because transmuxing of .ts segments is not supported.\n\nHTML Custom Element\n\nThe easiest way to use Mux Background Video is with the custom element:\n\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <title>Background Video</title>\n  <style>\n    html,\n    body {\n      height: 100%;\n    }\n\n    body {\n      margin: 0;\n      padding: 0;\n    }\n\n    mux-background-video,\n    img {\n      display: block;\n      width: 100%;\n      height: 100%;\n      object-fit: cover;\n    }\n  </style>\n  <script type=\"module\" src=\"http://cdn.jsdelivr.net/npm/@mux/mux-background-video/html/+esm\"></script>\n</head>\n<body>\n  <mux-background-video src=\"https://stream.mux.com/YOUR_PLAYBACK_ID.m3u8\">\n    <img src=\"https://image.mux.com/YOUR_PLAYBACK_ID/thumbnail.webp?time=0\" alt=\"Mux Background Video\" />\n  </mux-background-video>\n</body>\n</html>\n```\n\n\nJavaScript Import\n\nYou can also import the custom element directly:\n\n\n```ts\nimport '@mux/mux-background-video/html';\n\n// The custom element is automatically registered\n// You can now use <mux-background-video> in your HTML\n```\n\n\nReact Component\n\nFor React applications, use the React component:\n\n\n```tsx\nimport { MuxBackgroundVideo } from '@mux/mux-background-video/react';\n\nfunction HeroSection() {\n  return (\n    <MuxBackgroundVideo src=\"https://stream.mux.com/YOUR_PLAYBACK_ID.m3u8\">\n      <img src=\"https://image.mux.com/YOUR_PLAYBACK_ID/thumbnail.webp?time=0\" alt=\"Mux Background Video\" />\n    </MuxBackgroundVideo>\n  );\n}\n```\n\n\nTo enable Mux data collection for your background videos, include the Mux embed script in your HTML page before the Mux Background Video script:\n\n\n```html\n<script defer src=\"https://cdn.jsdelivr.net/npm/mux-embed\"></script>\n```\n\n\nOnce this script is included, Mux data will automatically be enabled for all background videos on the page, providing you with detailed analytics and insights about video performance.\n\nHTML Custom Element: `\n\nThe  element automatically handles HLS streaming.\n\nAttributes\n\n- src: The Mux HLS stream URL (required)\n- max-resolution: Maximum resolution for the video (e.g., \"720p\", \"1080p\")\n- audio: Enable audio track (default: false)\n- preload: Controls video preloading behavior (default: auto)\n  - \"none\": No preloading\n  - \"metadata\": Preload only metadata\n  - \"auto\": Preload video data\n\nHTML Structure\n\n\n```html\n<mux-background-video audio max-resolution=\"720p\" src=\"YOUR_STREAM_URL\">\n  <img src=\"https://image.mux.com/YOUR_PLAYBACK_ID/thumbnail.webp?time=0\" alt=\"Mux Background Video\" />\n</mux-background-video>\n```\n\n\nJavaScript Attributes\n\nYou can also set attributes programmatically:\n\n\n```typescript\nconst element = document.querySelector('mux-background-video');\n\n// Set maximum resolution\nelement.setAttribute('max-resolution', '1080p');\n\n// Enable audio track\nelement.toggleAttribute('audio', true);\n\n// Set preload behavior\nelement.setAttribute('preload', 'metadata');\n\n// Set the stream URL\nelement.setAttribute('src', 'https://stream.mux.com/NEW_PLAYBACK_ID.m3u8');\n\n// Get current values\nconsole.log(element.getAttribute('src'));\nconsole.log(element.getAttribute('max-resolution'));\nconsole.log(element.hasAttribute('audio'));\nconsole.log(element.getAttribute('preload'));\n```\n\n\nReact Component:\n\nProps\n\n- src: The Mux HLS stream URL (required)\n- maxResolution: Maximum resolution for the video (e.g., \"720p\", \"1080p\")\n- audio: Enable audio track (default: false)\n- preload: Controls video preloading behavior (default: auto)\n  - \"none\": No preloading\n  - \"metadata\": Preload only metadata\n  - \"auto\"`: Preload video data\n\nExample\n\n\n```tsx\n<MuxBackgroundVideo\n  src=\"https://stream.mux.com/YOUR_PLAYBACK_ID.m3u8\"\n  maxResolution=\"720p\"\n  audio={true}\n>\n  <img src=\"https://image.mux.com/YOUR_PLAYBACK_ID/thumbnail.webp?time=0\" alt=\"Mux Background Video\" />\n</MuxBackgroundVideo>\n```"
  },
  {
    "id": "99-_guides/developer/mux-data-faqs",
    "title": "Mux Data FAQs",
    "path": "_guides/developer/mux-data-faqs.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/mux-data-faqs",
    "content": "Why use Mux Data?\nMux Data uncovers four key dimensions of video quality of service: playback failures, startup time, rebuffering, and video quality. If your aim is broadcast-quality video streaming, Mux Data enables you to monitor these critical video metrics.\n\nWith each Mux Data metric, you can monitor and track what matters to your viewers. For example, Overall Viewer Experience Score is a metric that quickly summarizes your video platform's performance.\n\nTo get familiar with more of the features of Mux Data, see this introduction to Mux Data.\n\nWhat is the Mux Data Dashboard and what can you do with it?\nThe Mux Data Dashboard is an interface that lets you set filters and view graphs that monitor each specific key metric you are interested in. With each metric, you can monitor and track what matters to your viewers.\n\nYou can also immediately see what is happening before users do with Anomaly Alerts and Threshold Alerts. It is easy to set these alerts for prompt notifications. Check your dashboard to track the source or sources.\n\nYou may want to apply Filters to the alert definition to track only specific data. Finally can also use the List Insights feature as a way of _impact sorting_ which browsers, devices, regions, CDNs, players, ads and videos are creating the most problems for your viewers.\n\nWhat is the Monitoring Dashboard and what can you do with it?\nThe Mux Data Monitoring Dashboard, previously called the Real-time Dashboard, allows you to monitor your critical metrics in one operational dashboard that updates in real-time. This lets you respond to major streaming issues quickly.\n\nRead this blog post as a great example and resource:\n\nRespond to and Resolve Incidents with the Monitoring (formerly Real-time) Dashboard.\n\nIt dives into how to use tools on the Monitoring Dashboard to investigate the incident, communicate with stakeholders, resolve the issue, and improve your resiliency.\n\nCan I access Mux Data via an API?\n\nYes, all Mux Data views and metrics are all available through the Data API. Raw video view data can be exported via the API. Additionally, here is a detailed blog post describing how to create graphs using the Mux API.\n\nWhere do I find Mux Data Pricing? What features are included in the Pay-as-you-go, Media, and Custom Media Plans?\nChoose a Mux Data pricing plan on the Data Pricing page. Here you can view a breakdown of all features that Mux includes with each plan including Pay-as-you-go, Media, and Custom Media.\n\nOr, contact our Sales team to acquire more detailed information.\n\nWhere do I find all supported metrics, dimensions, and devices?\nYou can find more Technical Specs here covering all tracked video metrics, available filters, and supported players.\n\nCan I use Mux Data to monitor audio-only content?\nYes, Mux Data can be used to monitor audio content that uses the `` element. Mux Data will track Engagement metrics, such as the number of plays and length of playback time, as well as basic Quality of Experience metrics including Startup Time, Rebuffering Percentage, and others. Video Quality metrics are not calculated for audio content.\n\nIs Mux Video delivery usage API similar to watch time in Mux Data?\nNo, these two measurements are quite different. Mux Video's Delivery Usage API is based on the number of minutes delivered to clients. This is a server-side (CDN) metric. Whereas Mux Data collects metrics from the client-side and calculates watch time based on the user's interaction with the player.\n\nIf a user watches a video, rewinds, and watches the video again that content was only delivered one time to the device but it was watched multiple times. In this scenario Mux Video's delivery usage would be lower than the watched time in Mux Data.\n\nMore commonly, the client will build up a buffer of downloaded video content. The user will watch some of it and then leave before watching the full length of the video. In this scenario Mux Video's minutes delivered would be higher than the watched time in Mux Data because the client downloaded more minutes of video than it watched.\n\nAnother factor to keep in mind is that because Mux Data runs as a client-side SDK, it is susceptible to being blocked by ad-blockers.\n\nHow should I use Mux environments?\nEnvironments allow you to separate data collected from players to more accurately analyze your video engagement and performance. A Development and Production environment are created automatically when you sign up, and this is the most common way of organizing environments. You can rename your environments or add additional environments as needed, but we recommend keeping development and production data separate.\n\nMultiple sites or apps can use the same environment and Mux Data environment key. For example, if you have both web and mobile players, and want to view and compare metrics across them, you should use the same environment. Additionally, if you are using Mux Video, use the same environment for Mux Data. Views tracked by Mux Data for videos or live streams streamed from Mux Video are automatically populated with Mux Video identifiers when they’re within the same environment. This allows you to easily view metrics for your assets and live streams in your Mux dashboard. Learn more in our blog post on Data features for Mux Video.\n\nHow are Mux Data environment keys used?\nEach environment has a client-side key associated with it, which you can find on your Environments page. You’ll also see it in Get Started with Data (accessed from the Overview page) for any environment you haven’t integrated yet. When integrating a Mux Data SDK, your environment key allows us to associate the views collected with that SDK to the correct environment. Environment keys are not secret. In rare cases where you would like to change your environment key, contact us and we can change it for you."
  },
  {
    "id": "100-_guides/developer/mux-data-playback-events",
    "title": "Mux playback events",
    "path": "_guides/developer/mux-data-playback-events.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/mux-data-playback-events",
    "content": "Playback events overview\n\nThe main component of a player integration revolves around events. Most players trigger or fire events for the common playback events such as play, pause, error, and others, but these events are typically named differently on different platforms. The primary purpose of each player integration is to translate these events into the events that the core libraries expect.\n\nEach language library has a slightly different naming scheme to the events, but they should be in-line with each other aside from some slight syntax.\n\nOptional events provide additional detail in tracking views, but are not necessarily required for base Quality of Experience tracking within a player.\n\nEach event occurrence contains a common set of time values that are submitted to the server and contained in the view exports:\n\n| Field | Description |\n|-------|-------------|\n| viewer_time | The wall clock time from the device when the event occurred, in milliseconds since unix epoch |\n| playback_time | The playhead position at the time of the event, in milliseconds |\n| event_time | The wall clock time on the server when the event is received, in milliseconds since unix epoch (populated in the view exports, not submitted with the event) |\n\nGeneral playback events\n\nThe main playback events that Mux SDKs expect are defined as follows:\n\nplayerready\nSignals that the player initialization process has completed, and the player is ready for interaction. A video may or may not have been loaded in the player; this event is specific to the player completed any tasks in initial startup of the player.\n\nviewinit\nSignals that a new view is beginning and should be recorded. This must be called first before any additional playback events. Note that this should only be emitted for the first view within a player; for a change of videos within the same player, videochange should be used.\n\nThis event is only required for building integrations using the Objective-C Core SDK. This is handled automatically as a side effect of initialization of the JavaScript and Java Core SDKs.\n\nvideochange\nSignals that the video being played in the player has changed. This must be called if a new video is loaded within the same player. The event should be fired immediately after the new video has been given to the player.\n\nThis event is only available within the JavaScript Core SDK. For Objective-C, see the section on changing the video in Custom Objective-C Integration. For Java, there are helper methods for this exposed within MuxStats.\n\nplay\nSignals that the player is beginning its attempt to play back the video. The video is not yet showing on the screen (or moving forward in the case of a resume). The buffer may be empty or full depending on the pre-loading strategy.\n\nFor the HTML5 video element, this correlates to the play event on the video element.\n\nFor ad playback, once resuming from the ad break, the play event should be fired immediately after the adbreakend event, assuming the player will continue playing content after the ad break without interaction from the viewer.\n\nplaying\nSignals that the video is now actually playing. The buffer is full enough that the player has decided it can start showing frames. In other words, this is when the first moving frame is displayed to the end user.\n\nFor the HTML5 video element, this correlates to the playing event on the video element.\n\npause\nSignals that playback has been intentionally delayed, either by the viewer or by the player (e.g. starting an ad).\n\nFor the HTML5 video element, this correlates to the pause event on the video element.\n\nIn the case of playback breaking to play an ad, the pause event should be fired just before the adbreakstart event is fired.\n\ntimeupdate\nSignals that the playback has advanced some non-zero amount forward. This event should be emitted at _least_ every 250 milliseconds, but can be sent more often than this.\n\nFor the HTML5 video element, this correlates to the timeupdate event on the video element.\n\nIf the timeupdate event is not sent, the integration must provide the ability to retrieve the playhead time in the player callback for the SDK. See each language SDK for details on this callback. In all SDKs, emitting the timeupdate event is preferred, even if the playhead time callback is provided. In addition, on Java platforms, while emitting timeupdate is preferred, you must also provide the callback for getCurrentPosition within the IPlayerListener interface.\n\nIf the timeupdate event is sent, you must include the playhead position, in milliseconds, via the following mechanisms:\n - JavaScript: provided as player_playhead_time key within the data object passed along with timeupdate to the call to emit.\n - Java: provided via PlayerData.setPlayerPlayheadTime on the PlayerData emitted with the event.\n - Objective-C: provided via [MUXSDKPlayerData setPlayerPlayheadTime: time] in the MUXSDKPlayerData object emitted with the event.\n\nFor integrations using the Objective-C Core SDK, this event is required to be sent.\n\nseeking\nSignals that the user has attempted to seek forward or backward within the timeline of the video.\n\nFor the HTML5 video element, this correlates to the seeking event on the video element.\n\nseeked\nSignals that the player has the video data for the new playback position, and is ready to immediately start playing at this new position.\n\nFor the HTML5 video element, this correlates to the seeked event on the video element.\n\nrebufferstart\nSignals that the player has stopped playing back content when it is expected that playback should be progressing.\n\n  For JavaScript and Objective-C/Swift integrations, this event is internal to the core library and must not be emitted by the player integration.\n\n  For Java integrations, after v6.0.0 of the core library, this event must be emitted by the player integration.\n\nrebufferend\nSignals that the player has resumed playing back content after playback previous stalled while attempting to play back.\n\n  For JavaScript and Objective-C/Swift integrations, this event is internal to the core library and must not be emitted by the player integration.\n\n  For Java integrations, after v6.0.0 of the core library, this event must be emitted by the player integration.\n\nerror\nSignals an error that will be associated with the view. Error severity can be set to fatal (i.e. not recoverable) or warning. Errors will be assumed to be playback failures within Mux by default but can be categorized as business exceptions either on the client and on the server. See the Error Categorization guide for more details.\n\nFor the HTML5 video element, this correlates to the error event on the video element.\n\nThis specific event should be accompanied by the following metadata:\n\n| Field | Description |\n|-------|-------------|\n| player_error_code | An integer that provides a category of the error. You should not send a distinct code for each possible error message, but rather group similar errors under the same code. For instance, if your library has two different conditions for network errors, both should have the same player_error_code but different messages. |\n| player_error_message | Details about the error encountered, though should remain relatively generic. It shouldn't include a full stack trace, for instance, as this field is used to group like errors together. |\n| player_error_context | Used to provide instance-specific details for the error, such as stack trace, segment number, or URL. |\n\nended\nSignals that the current video has played to completion.\n\nFor the HTML5 video element, this correlates to the ended event on the video element.\n\nrenditionchange (optional)\nSignals that the current rendition that is actively being played has changed. Note that this event should be triggered when the playing rendition changes, not necessarily when the player logic has started requesting a different rendition.\n\nThis specific event should be accompanied by the following metadata:\n\n| Field | Required | Description |\n|-------|----------|-------------|\n| video_source_bitrate | Required | The current rendition's bitrate (combined video and audio), in bits per second (bps) |\n| video_source_width | Optional for web/Java, Required for iOS | Optional for web and Java integrations, assuming video_source_width is returned by the appropriate callback (e.g. getStateData for web) |\n| video_source_height | Optional for web/Java, Required for iOS | Optional for web and Java integrations, assuming video_source_width is returned by the appropriate callback (e.g. getStateData for web) |\n| video_source_codec | Optional for web/Java, Required for iOS | |\n| video_source_fps | Optional for web/Java, Required for iOS | |\n| video_source_name | Optional for web/Java, Required for iOS | |\n\norientationchange (optional)\nSignals that a device orientation has been changed during the view. On most platforms this information is not available directly to the player SDK so the customer implementation will notify the Mux SDK when the orientation is changed and Mux will fire an event based on the notification.\n\nThis specific event should be accompanied by the following metadata:\n - viewer_device_orientation. The device's orientation after the change. The orientation is expressed as a  (x, y, z) coordinate system, with the most common orientations being (0,0,90) for portrait and (0,0,0) for landscape.\n\nplaybackmodechange (optional)\nSignals that the mode of playback has changed. You can use a defined preset or a custom value based on your playback offering.\n\n| Field | Type | Required | Description |\n| playbackmode| string | Required | The name of the playback mode. Presets include standard, inline, fullscreen, pip, miniplayer, background. You can also pass a custom string.\n| playbackmodedata | string (json) | Optional | minified json | Optional string that is valid json that contains metadata which can be used for more detailed analysis. Non json strings will be ignored.\n\nheartbeat\nInternal event that is used to provide periodic updates on the playback state, while the player is not paused. Each core library emits heartbeat events (hb) automatically, and custom integrations should not need to emit this.\n\nviewend\nInternal event that is used to signal the end of a view tracked by Mux. Each core library emits the viewend event automatically as a result of either tearing down the SDK or changing the video (videochange). Custom integrations do not need to emit this manually.\n\nAd Events\n\nFor players that support ad playback, the following events are expected. If you do not provide these events, playback will still be monitored, but there will not be ad-specific metrics or knowledge of ads vs content.\n\nThese events require additional data to be provided. See Building a Custom Integration.\n\nadrequest (optional)\nSignals that an ad request is about to be made, or was just made but the response has not been received.\n\nIn the process of the player retrieving an ad payload, multiple adrequest and adresponse events may be fired (either due to waterfall, or for an ad break that has multiple ads). In the case that these requests are made in parallel, the player integration must send an ad_request_id in the data along with each adrequest and adresponse event, so that Mux can match them up correctly.\n\nadresponse (optional)\nSignals that a response was received from the ad server.\n\nIn the process of the player retrieving an ad payload, multiple adrequest and adresponse events may be fired (either due to waterfall, or for an ad break that has multiple ads). In the case that these requests are made in parallel, the player integration must send a ad_request_id in the data object along with each adrequest and adresponse event, so that Mux can match them up correctly.\n\nThe adresponse event can only be fired by the player integration if the adrequest events are fired as well.\n\nadbreakstart\nSignals that an ad break has begun. This coincides with the playback of the video being paused in order to display the ads at the current position. This event should come immediately after the pause event is fired due to attempting to play back an ad break, and before any adplay, adplaying, adpause, or adended.\n\nThe adbreakstart event may come before, during, or after the adrequest/adresponse events, depending on the player’s configuration for making ad requests.\n\nadplay\nSignals that the player is beginning its attempt to play back an individual advertisement video. The ad is not yet showing on the screen (or moving forward in the case of a resume). The buffer may be empty or full depending on the pre-loading strategy.\n\nThis event is the ad-specific equivalent of play.\n\nadplaying\nSignals that an advertisement is now actually playing. The buffer is full enough that the player has decided it can start showing frames for the ad.\n\nThis event is the ad-specific equivalent of playing.\n\nadpause\nSignals that playback of an advertisement has been intentionally delayed, either by the viewer or by the player (e.g. user pressing pause on the ad player controls).\n\nThis event is the ad-specific equivalent of pause.\n\nadfirstquartile (optional)\nSignals that the current advertisement has progressed past the first quartile in playback. This event should coincide with the point in time that the ad integration would fire the firstQuartile ad tracking beacon (in VAST terminology).\n\nadmidpoint (optional)\nSignals that the current advertisement has progressed past the midpoint in playback. This event should coincide with the point in time that the ad integration would fire the midpoint ad tracking beacon (in VAST terminology).\n\nadthirdquartile (optional)\nSignals that the current advertisement has progressed past the third quartile in playback. This event should coincide with the point in time that the ad integration would fire the thirdQuartile ad tracking beacon (in VAST terminology).\n\nadended\nSignals that the advertisement has played to completion.\n\nThis event is the ad-specific equivalent of ended.\n\nadbreakend\nSignals that all ads in the ad break have completed, and playback is about to resume on the main content. This event should be come immediately after the last adended event in the ad break, and before the resuming play event signifying that playback of the main content is resuming.\n\nThere may be multiple adplay/adended combinations within a single ad break.\n\naderror\nSignals that an error has occurred that relates to the ad break currently in play or the ad request/response.\n\nBandwidth throughput events\n\nLike the Ad-specific events, these events are not required. However, if you include any of these, you must include all of them. Each of these events refers to a network request made for some component of the media playback. This includes but, depending on your exact configuration, may not be limited to:\n manifests and content segment requests for HLS playback\n manifests, init fragment, and content fragment requests for DASH playback\n\nThese events should _not_ be fired for ad requests and require additional data to be sent along with them. See Network Request Data.\n\nrequestcompleted\nSignals that a network request for a piece of content returned successfully.\n\nrequestfailed\nSignals that a network request for a piece of content returned unsuccessfully.\n\nrequestcanceled\nSignals that a network request for a piece of content was aborted before it could return (either successfully or unsuccessfully).\n\nAccompanying Data\n\nEach core SDK has its own mechanism for providing data along with each event. This data is used to provide information such as player state (e.g. paused or playhead time), and potentially to override the data that is pulled automatically from the player.\n\nFor the most part, most data is retrieved automatically, and you will not need to provide any accompanying data. The notable exceptions for this are in regards to ad information, as well as network request information.\n\nSee the following guides for each library on how to provide additional data with each event.\n\nAd-Specific Data\n\nThe following data should be sent while emitting the ad-specific events, where possible.\n\nad_type\nThe type of ad used during playback: preroll, midroll, postroll\n\nad_asset_url\nThe URL for the current ad being played. For example, in a VAST response, this would correspond with the MediaFile URL that is being played.\n\nNote: this data should only be included alongside adplay, adplaying, adpause, adended, adfirstquartile, admidpoint, adthirdquartile events, as they are the only events that correlate with the ad asset that is being played.\n\nad_tag_url\nThe URL for the current ad tag/ad request being made. For example, this could be the URL that is expected to return a VMAP or VAST document detailing what ad(s) to play.\n\nNote: this data should only be included alongside adrequest and adresponse events, as those are the only events that correlate with the ad tag URL being used currently.\n\nad_creative_id\nThe Creative Id of the ad. This usually is the Ad-Id of the selected creative in the VAST response.\n\nad_id\nThe Id of the ad. This usually is unique in the Ad Provider's system and specified in the VAST response.\n\nad_universal_id\nThe Universal Id of the ad. This usually is globally unique for the ad across all Ad Providers.\n\nNote: the above 3 metadata can be included in all ad events except for adrequest and adresponse events.\n\nNetwork Request Data\n\nThe following data should be sent along with any of the network events (request*).\n\nrequest_start\nTimestamp that the request was initiated, in milliseconds since the Unix epoch.\n\nInclude alongside: requestcompleted, requestfailed, requestcanceled\n\nrequest_bytes_loaded\nThe total number of bytes loaded as part of this request.\n\nInclude alongside: requestcompleted\n\nrequest_response_start\nTimestamp that the response to the request began (i.e. the first byte was received), in milliseconds since the Unix epoch.\n\nInclude alongside: requestcompleted\n\nrequest_response_end\nTimestamp that the response was fully received (i.e. the last byte was received), in milliseconds since the Unix epoch.\n\nInclude alongside: requestcompleted\n\nrequest_type (optional but recommended)\nThe type of content being requested. Specifying the video as the request_type for video segements is recommended to ensure CDN tracking accuracy. One of the following:\n\n| Type | Description |\n|------|-------------|\n| manifest | Used when the request is for a master or rendition manifest in HLS, or a DASH manifest. |\n| video | Used when the request is for a video-only segment/fragment |\n| audio | Used when the request is for an audio-only segment/fragment |\n| video_init | Used when the request is for the video init fragment (DASH only) |\n| audio_init | Used when the request is for the audio init fragment (DASH only) |\n| media | Used when the type of content being request cannot be determined, is audio+video, or is some other type. |\n| subtitle | Used when the request is for subtitle or caption content |\n| encryption | Used when the request is for a DRM encryption key |\n\nInclude alongside: requestcompleted, requestfailed, requestcanceled\n\nrequest_hostname\nThe hostname portion of the URL that was requested.\n\nInclude alongside: requestcompleted, requestfailed, requestcanceled\n\nrequest_id (optional)\nThe id for identifying the individual request. CDNs often include a request id in their responses which can be used for correlating requests across the player and CDN.\n\nInclude alongside: requestcompleted, requestfailed, requestcanceled\n\nrequest_url (optional)\nThe URL that was requested.\n\nInclude alongside: requestcompleted\n\nrequest_labeled_bitrate (optional)\nLabeled bitrate (in bps) of the video, audio, or media segment that was downloaded.\n\nInclude alongside: requestcompleted\n\nrequest_response_headers (optional)\nA map of response headers and their values. You should include whatever headers are available to the client, as this information may be used to determine routing of each request. The most important header, though, is the X-CDN header as described in CDN Configuration for Request-Level Metadata.\n\nInclude alongside: requestcompleted\n\nrequest_media_duration (optional)\nThe duration of the media loaded, in seconds. Should not be included for requestcompleted events for manifests.\n\nInclude alongside: requestcompleted\n\nrequest_video_width (optional)\nFor events with media or video request_type, the width of the video included in the segment/fragment that was downloaded.\n\nInclude alongside: requestcompleted\n\nrequest_video_height (optional)\nFor events with media or video request_type, the height of the video included in the segment/fragment that was downloaded.\n\nInclude alongside: requestcompleted\n\nrequest_error\nThe name of the error event that occurred. Note this is not the status code of the request itself, but rather something along the lines of FragLoadError.\n\nInclude alongside: requestfailed\n\nrequest_error_code\nThe response code of the request that spawned the error (i.e. 401, 400, 500, etc).\n\nInclude alongside: requestfailed\n\nrequest_error_text\nThe message returned with the failed status code.\n\nInclude alongside: requestfailed\n\nSample Sequence of Events\n\nA sample sequence of events for an integration would look like the following:\n\n| Event | Description |\n|-------|-------------|\n| playerready | |\n| viewinit | When the video is about to be loaded in a player |\n| play | When the user presses play to attempt playing back the video |\n| playing | When the first frame of video is displayed |\n| timeupdate | At least every 250 ms with progress of the playhead time |\n| pause | When the viewer presses pause |\n| play | When the viewer resumes playback |\n| playing | When the first frame is displayed after resuming |\n| timeupdate | |\n| ended | When the video playback is complete |\n| viewend | When the view is complete - e.g. the user is no longer attempting to watch the video |\n\nAt the end, if the viewer loads a new video into the player, a videochange event should be emitted instead of the viewend event, with the new video data."
  },
  {
    "id": "101-_guides/developer/mux-player-android",
    "title": "Mux Player for Android",
    "path": "_guides/developer/mux-player-android.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/mux-player-android",
    "content": "The Mux Player SDK is a thin wrapper on top of Google's media3 player SDK with convenient tools for Mux Video users. This SDK is not required to use Mux Video, but it can help you do things like controlling your data and delivery usage, playing Mux assets by ID, automatically supporting player features like caching, and transparently tracking performance and engagement with Mux Data\n\nThis guide will help you install the Mux Video SDK in your app, use it to play a Mux Video asset, configure Mux Player for your specific app and media, and show you how to handle less-common scenarios like using Mux Video's custom domains.\n\nAdd our repository to your Gradle project\n\nAdd Mux's maven repository to your gradle files. Newer projects require declaring this in settings.gradle, and older projects require it to be set in the project-level build.gradle.\n\nAdd the dependency to your app\n\nAdd our library to the dependencies block for your app.\n\n<CodeExamples\n  examples={{\n    gradle_kts:\nimplementation(\"com.mux.player:android:1.0.0\")\n    ,\n    gradle_groovy:\nimplementation \"com.mux.player:android:1.0.0\"\n    ,\n  }}\n  exampleOrder=\"gradle_kts,gradle_groovy\"\n/>\n\nCreate a MuxPlayer\n\nTo use the SDK, you must create a MuxPlayer object using its Builder. The basic configuration will enable all of Mux Video's features, and you can make additional config changes using our Builder. Almost all of our default config options are the same as ExoPlayer's. We only change things about the default configuration when we need to in order to support a Mux Player feature.\n\n<CodeExamples\n  examples={{\n    kotlin:\nval player: MuxPlayer = MuxPlayer.Builder(context = this)\n  .enableLogcat(true) // Optional. Only applies to Mux. Media3 logging is not touched\n  .applyExoConfig {\n    // Call ExoPlayer.Builder methods here (but not build()!)\n    setHandleAudioBecomingNoisy(true)\n  }\n.build()\n    ,\n    java:\nMuxPlayer player = new MuxPlayer.Builder(context)\n  .enableLogcat(true) // Optional. Only applies to Mux. Media3 logging is not touched\n  .plusExoConfig((config) -> {\n    // Call ExoPlayer.Builder methods here (but not build()!)\n    config.setHandleAudioBecomingNoisy(true);\n  })\n  .build();\n\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nPlay a Mux Video asset\n\nTo play a Mux Video asset using this SDK, you can use our MediaItems API to create new instances of media3's MediaItem or MediaItem.Builder. For the basic example, we'll leave everything default and play an asset you've already uploaded to Mux Video\n\n<CodeExamples\n  examples={{\n    kotlin:\n// Use the MediaItems class instead of MediaItem.Builder()\nval mediaItem = MediaItems.builderFromMuxPlaybackId(\"YOUR PLAYBACK ID\")\n  // It's just a MediaItem from here, so you can configure it however you like\n  .setMediaMetadata(\n    MediaMetadata.Builder()\n      .setTitle(\"Hello from Mux Player on Android!\")\n      .build()\n  )\n  .build()\n\n// From here, everything is exactly the same as ExoPlayer\nplayer.setMediaItem(mediaItem)\nplayer.prepare()\nplayer.playWhenReady = true\n    ,\n    java:\nMediaMetadata metadata = new MediaMetadata.Builder()\n  .setTitle(\"Hello from Mux Player on Android\")\n  .build();\n// Use the MediaItems class instead of MediaItem.Builder()\nMediaItem item = MediaItems.builderFromMuxPlaybackId(\"YOUR PLAYBACK ID\")\n  // It's just a MediaItem from here, so you can configure it however you like\n  .setMediaMetadata(metadata)\n  .build();\n\n// From here, everything is exactly the same as ExoPlayer\nplayer.setMediaItem(item);\nplayer.setPlayWhenReady(true);\nplayer.prepare();\n\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nProtecting your content\n\nMux Video offers options for securing your content from unauthorized playing or recording. For more information, see below\n\nEnable smart caching to improve experience and decrease usage\n\nMux Player can cache content as it is requested from Mux Video and store it for later requests. Caching can reduce overall data usage and costs by storing some streamed video locally in a private directory on the device. This way content doesn't need to be downloaded again if the user watches the content over, when playback loops, or during seeking. Mux Player's caching is automatic when enabled, and we manage the cache files for you.\n\nIf you are interested in Mux Player's caching features, you can enable them when you build your MuxPlayer.\n\n<CodeExamples\n  examples={{\n    kotlin:\nval player: MuxPlayer = MuxPlayer.Builder(context)\n  // disabled by default\n  .enableSmartCache(true)\n  .build()\n    , java:\nMuxPlayer player = new MuxPlayer.Builder(context)\n    // disabled by default\n    .enableSmartCache(true)\n    .build()\n\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nLimit data and delivery usage\n\nDepending on your use case and app, you may need to control your either Mux Video usage or your app's data bandwidth usage. Doing this can allow you to save costs and minimize playback interruptions for users on slower devices or data plans. Mux provides some tools to manage costs and resource usage by limiting the maximum resolution your app can stream from Mux Video. To take advantage of this feature, you can supply a PlaybackResolution to our MediaItems class.\n\n<CodeExamples\n  examples={{\n    kotlin:\nval mediaItem = MediaItems.builderFromMuxPlaybackId(\n  \"YOUR PLAYBACK ID\",\n  maxResolution = PlaybackResolution.FHD_1080, // limit playback resolution to 1080p\n  )\n  // .. configure your MediaItem further if required\n  .build()\n\n// .. Add the MediaItem to your MuxPlayer like you normally would\n    , java:\nMediaItem mediaItem = MediaItems.builderFromMuxPlaybackId(\n        \"YOUR PLAYBACK ID\",\n        PlaybackResolution.FHD_1080 // limit playback resolution to 1080p\n    )\n    // .. configure your MediaItem further if required\n    .build();\n\n// .. Add the MediaItem to your MuxPlayer like you normally would\n\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nGuarantee a minimum resolution\n\nSome use cases require a minimum playback resolution. Applications like screen-sharing for instance, may wish to preserve a certain level of visual quality even if play has to be interrupted to buffer more data. Apps that need their video playback to always be above a certain resolution, regardless of network conditions, can request a minium resolution.\n\n<CodeExamples\n  examples={{\n    kotlin:\nval mediaItem = MediaItems.builderFromMuxPlaybackId(\n  \"YOUR PLAYBACK ID\",\n  minResolution = PlaybackResolution.HD_720,\n  )\n  // .. configure your MediaItem further if required\n  .build()\n\n// .. Add the MediaItem to your MuxPlayer like you normally would\n    , java:\nMediaItem mediaItem = MediaItems.builderFromMuxPlaybackId(\n      \"YOUR PLAYBACK ID\",\n      null, // null for default\n      /minResolution =/ PlaybackResolution.HD_720\n  )\n  // .. configure your MediaItem further if required\n  .build();\n\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nFor more information about controlling your data and platform usage, please see our guide on controlling playback resolution.\n\nThe Mux Player SDK transparently integrates with Mux Data in order to monitor for issues and track engagement with your content. To verify this is working, you can simply play the video in your app, and wait for your session to appear on the Mux Data dashboard. Your session should appear in your Mux Data environment automatically in the same environment as your video asset.\n\nAutomatically-Detected Metadata\n\nMux will automatically collect information about your stream, playback environment, and current playback session (\"view\") to send to Mux Data. Examples of the kind of information collected are Mux Asset and Playback IDs, player and stream resolution, the start and end times of the view, and some basic information about the end users device like OS and model number.\n\nCustomize metadata about your player, viewer, or playback session\n\nThe SDK can automatically detect a lot of information about the media you're playing, but you can customize this information if you need to, via the CustomerData class. Anything you specify this way will override metadata values that would ordinarily be detected automatically.\n\nYou can initialize your player with whatever custom metadata you like, and you can also update that metadata at any time.\n\n<CodeExamples\n  examples={{\n    kotlin:\nprivate fun createPlayer(context: Context): MuxPlayer {\n  return MuxPlayer.Builder(context)\n    .addMonitoringData(\n      CustomerData().apply {\n        customerViewData = CustomerViewData().apply {\n          viewSessionId = UUID.generateUUID()\n        }\n        customerVideoData = CustomerVideoData().apply {\n          videoSeries = \"My Series\"\n          videoId = \"abc1234zyxw\"\n        }\n        customData = CustomData().apply {\n          customData1 = \"my custom metadata field\"\n          customData2 = \"another custom metadata field\"\n          customData10 = \"up to 10 custom fields\"\n        }\n      }\n    )\n    .build()\n}\n    , java:\nprivate MuxPlayer createPlayer(Context context) {\n  CustomerData customerData = new CustomerData();\n  CustomerVideoData videoData = new CustomerVideoData();\n  videoData.setVideoTitle(\"Lots of custom data\");\n  videoData.setVideoSeries(\"my series\");\n  videoData.setVideoId(\"my app's id for the media\");\n  CustomData customData = new CustomData();\n  customData.setCustomData1(\"my custom data field\");\n  customData.setCustomData2(\"another custom metadata field\");\n  customData.setCustomData10(\"up to 10 custom fields\");\n\n  customerData.setCustomerVideoData(videoData);\n  customerData.setCustomData(customData);\n\n  return new MuxPlayer.Builder(context)\n    .addMonitoringData(customerData)\n    .build();\n}\n\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nDepending on the needs of your business and your users, you may need to secure your videos against unauthorized copying or viewing. Mux Video offers options for securing your playback experience. The right option for your app depends on your own use case. Your best option, if any, is a trade-off between security, complexity, and loading time for the end user.\n\nSigned Playback URLs\n\nMux Player supports playing Mux Video assets with signed playback. Signed playback uses a JSON web token (JWT) signed on your application server, created using a key identifier created using our APIs. For more information about how to set up signed playback, check out our secure video playback guide.\n\nFor this guide, we'll focus on what to do on the client, once you have the JWT from your app's backend server. To play the asset securely you can supply your JWT to MediaItems.fromMuxPlaybackId or MediaItems.builderFromMuxPlaybackId. The resulting MediaItem will be configured to play the asset securely using your token.\n\n<CodeExamples\n  examples={{\n    kotlin:\nprivate fun playSomething(jwt: String, context: Context) {\n  val player = createPlayer(context)\n  val mediaItem = MediaItems.builderFromMuxPlaybackId(\n    PlaybackIds.TEARS_OF_STEEL,\n    playbackToken = jwt,\n  )\n    .setMediaMetadata(\n      MediaMetadata.Builder()\n        .setTitle(\"Private Playback ID Example\")\n        .build()\n    )\n    .build()\n  player.setMediaItem(mediaItem)\n\n  // .. Then prepare and play your media as normal\n}\n  ,\n  java:\nMuxPlayer player = createPlayer(context);\nMediaItem mediaItem = MediaItems.builderFromMuxPlaybackId(\n      PlaybackIds.TEARS_OF_STEEL,\n      PlaybackResolution.QHD_1440,\n      PlaybackResolution.LD_540,\n      RenditionOrder.Descending,\n      / domain = / null, // null for default\n      // put your Signed Playback Token here\n      /playbackToken = / jwt\n  )\n  .setMediaMetadata(\n      new MediaMetadata.Builder()\n          .setTitle(\"Private Playback ID Example\")\n          .build()\n  )\n  .build();\nplayer.setMediaItem(mediaItem);\n\n// .. Then prepare and play your media as normal\n\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nDigital Rights Management (DRM)\n\nMux Player for Android can be configured to protect videos from unauthorized use via Widevine DRM. Support for DRM is automatically enabled in the player. As long as you have both a signed playback token (see above) and a DRM token, your DRM-protected asset can be played using Mux Player. The process of setting up DRM is somewhat complex, and is detailed here in our DRM Guide. This guide will focus on what to do once you have obtained a Playback Token and DRM Token from your application server.\n\n1. Setting up DRM for an asset\n\nTo use DRM playback for your asset, you'll need to set up a DRM configuration and DRM-enabled playback ID. The process for doing this is the same regardless of your player, and you can read more about it in our DRM Guide. Once you have an environment and asset set up with DRM, you can use your that asset's DRM Token, Playback Token, and Playback ID with Mux Player to do DRM playback transparently.\n\n2. Playing a DRM-protected asset\n\nTo play your DRM-protected asset, simply provide the Playback Token and DRM Token you generated in the last step. You can provide them as parameters to MediaItems.fromMuxPlaybackId(). No other configuration is required in order to use DRM with Mux Player.\n\n<CodeExamples\n  examples={{\n    kotlin:\nprivate fun playSomething(myPlaybackId: String, myPlaybackToken: String, myDrmToken: String, context: Context) {\n  val player = createPlayer(context)\n  val mediaItem = MediaItems.builderFromMuxPlaybackId(\n    playbackId,\n    playbackToken = myPlaybackToken,\n    drmToken = myDrmToken,\n  )\n    .setMediaMetadata(\n      MediaMetadata.Builder()\n        .setTitle(\"DRM playback Example\")\n        .build()\n    )\n    .build()\n  player.setMediaItem(mediaItem)\n\n  // .. Then prepare and play your media as normal\n}\n  ,\n  java:\nMuxPlayer player = createPlayer(context);\nMediaItem mediaItem = MediaItems.builderFromMuxPlaybackId(\n      PlaybackIds.TEARS_OF_STEEL,\n      PlaybackResolution.QHD_1440,\n      PlaybackResolution.LD_540,\n      RenditionOrder.Descending,\n      / domain = / null, // null for default\n      // put your Signed Playback Token here\n      /playbackToken = / jwt,\n      /drmToken = / drmToken,\n  )\n  .setMediaMetadata(\n      new MediaMetadata.Builder()\n          .setTitle(\"Private Playback ID Example\")\n          .build()\n  )\n  .build();\nplayer.setMediaItem(mediaItem);\n\n// .. Then prepare and play your media as normal\n\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nEnable smart caching to improve experience and decrease usage\n\nMux Player can cache content as it is requested from Mux Video and store it for later requests. This caching is automatic, and we manage the cache content and cache files for you. To enable smart caching, all you need to do is set the parameter when you build your MuxPlayer.\n\n<CodeExamples\n  examples={{\n    kotlin:\nval player: MuxPlayer = MuxPlayer.Builder(context)\n  .enableSmartCache(true)\n  .build()\n    ,\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nUse a custom Mux Video domain\n\nIf you are using a Mux Video Custom Domain, you can specify the domain on a per-MediaItem basis. The URL of the stream will have the specified domain and the stream. subdomain\n\n<CodeExamples\n  examples={{\n    kotlin:\nval mediaItem = MediaItems.builderFromMuxPlaybackId(\n  \"YOUR PLAYBACK ID\",\n  domain = \"customdomain.com\", // https://stream.customdomain.com/...\n  )\n  // .. configure your MediaItem further if required\n  .build()\n\n// .. Add the MediaItem to your MuxPlayer like you normally would\n    ,\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nUse a specific Mux Data Environment Key\n\nOrdinarily, Mux Data will record views and monitoring data in the same Environment as the Mux Video asset being played. If you are using a different Mux Data environment for some reason, you can specify another Mux Data Env Key for your player to use.\n\n<CodeExamples\n  examples={{\n    kotlin:\nprivate fun createPlayer(context: Context): MuxPlayer {\n  return MuxPlayer.Builder(context)\n    .setMuxDataEnv(\"Another Mux Data Env Key\") // replace with your other key\n    .build()\n}\n    , java:\nMuxPlayer player = new MuxPlayer.Builder(context)\n    .setMuxDataEnv(\"Another Mux Data Env Key\") // replace with your other key\n    .build()\n\n  }}\n  exampleOrder=\"kotlin, java\"\n/>\n\nInstant Clipping\n\nInstant Clips\n\nInstant clips are an alternative to our long-standing asset-based clipping feature. Requesting instant clips using relative time is now available for use with all video on-demand (VOD) assets.\n\nInstant clipping allows you to request a stream whose start time is at some later point in the video, relative to the start time of the asset. Likewise you're able to request a stream that ends sooner than when the underlying asset completes. Instant clips do not incur the wait time or expense of a creating a new asset.\n\nUnlike asset-based clipping, instant clipping is done by trimming your VOD assets HLS manifest. This means that instant clipping operates at the segment level of accuracy. You should expect that the content that you clip out may be several seconds longer than you’ve requested. We always make sure to include the timestamps that you request, but your content may start a few seconds earlier, and end a few seconds later.\n\nAssets that originate from a livestream can also be converted into instant clips using program date time epochs. Support for these clips will be available in a future Mux Player Android release."
  },
  {
    "id": "102-_guides/developer/mux-player-ios",
    "title": "Mux Player for iOS",
    "path": "_guides/developer/mux-player-ios.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/mux-player-ios",
    "content": "This guide will help you install the Mux Player SDK in your native iOS or iPadOS application. If you encounter any issues please let us know by filing an issue on Github.\n\nLet's start by installing the SDK. We'll use the Swift Package Manager. Step-by-step guide on using Swift Package Manager in Xcode.\n\nOpen your applications project in Xcode. In the Xcode menu bar select File > Add Packages. In the top-right corner of the modal window that opens enter the SDK repository URL which is https://github.com/muxinc/mux-player-swift.\n\nBy default Xcode will fetch the latest version of the SDK available on the main branch. If you need a specific package version or to restrict the range of package versions used in your application, select a different Dependency Rule. Here's an overview of the different SPM Dependency Rules and their semantics.\n\nClick on Add Package to begin resolving and downloading the SDK package. When completed, select your application target as the destination for the MuxPlayerSwift package product. To use the SDK in your application, import it's module: import MuxPlayerSwift.\n\nUse MuxPlayerSwift to setup an AVPlayerViewController or AVPlayerLayer that can download and stream a Mux asset with only a playback ID. The SDK will also enable Mux Data monitoring to help you measure the performance and quality of your application's video experiences.\n\n\n```swift\nimport AVFoundation\nimport AVKit\nimport MuxPlayerSwift\n\n/// After you're done testing, you can check this video out to learn more about video and players (as well as some philosophy)\nlet playbackID = \"qxb01i6T202018GFS02vp9RIe01icTcDCjVzQpmaB00CUisJ4\"\n\n/// Prepare an AVPlayerViewController to stream and monitor a Mux asset\nfunc preparePlayerViewController(\n  playbackID: String\n) -> AVPlayerViewController {\n\n  let playerViewController = AVPlayerViewController(\n    playbackID: playbackID\n  )\n\n  return playerViewController\n}\n\nlet examplePlayerViewController = preparePlayerViewController(playbackID: playbackID)\n\n/// Prepare an AVPlayerLayer to stream and monitor a Mux asset\nfunc preparePlayerLayer(\n  playbackID: String\n) -> AVPlayerLayer {\n\n  let playerLayer = AVPlayerLayer(\n    playbackID: playbackID\n  )\n\n  return playerLayer\n}\n```\n\n\nYour application can customize how Mux Video delivers video to the player using playback URL modifiers. A playback URL modifier is appended as a query parameter to a public playback URL. The MuxPlayerSwift exposes a type-safe Swift API that constructs these URLs.\n\n\n```swift\nimport AVFoundation\nimport AVKit\nimport MuxPlayerSwift\n\n/// After you're done testing, you can check out this video out to learn more about video and players (as well as some philosophy)\nlet playbackID = \"qxb01i6T202018GFS02vp9RIe01icTcDCjVzQpmaB00CUisJ4\"\n\n/// Prepares a ready-for-display AVPlayer instance that will not exceed 720 x 1280 resolution\n/// when streaming video\nfunc preparePlayerViewController(\n  playbackID: String\n) -> AVPlayerViewController {\n  let playbackOptions = PlaybackOptions(\n    maximumResolution: .upTo720p\n  )\n\n  let playerViewController = AVPlayerViewController(\n    playbackID: playbackID,\n    playbackOptions: playbackOptions\n  )\n\n  return playerViewController\n}\n\nlet examplePlayerViewController = preparePlayerViewController(playbackID: playbackID)\n```\n\n\nThe example above delegated constructing the playback URL and appending playback modifiers to the SDK.\n\nWhen using the AVPlayerViewController or AVPlayerLayer convenience initializers provided by the MuxPlayerSwift there are no required steps to enable Mux Data monitoring for video streamed from a Mux playback URL.\n\nSee the below section for more details and how to customize Mux Data monitoring.\n\nAVPlayerLayer-backed views\n\nIf you're using UIView that is backed by an AVPlayerLayer to display video, MuxPlayerSwift exposes APIs to setup an existing AVPlayerLayer for playback.\n\n\n```swift\nimport AVFoundation\nimport UIKit\n\nimport MuxPlayerSwift\n\n/// Prepare an already initialized AVPlayerLayer to stream and monitor a Mux asset\nfunc preparePlayerLayer(\n  playbackID: String,\n  playerView: UIView\n) {\n\n  // Check to make sure the player view backing\n  // layer is of the correct type and get a\n  // reference if it is\n\n  guard let playerLayer = playerView.layer as? AVPlayerLayer else {\n    print(\"Unexpected backing layer type!\")\n    return\n  }\n\n  // Prepares the player layer to stream media\n  // and monitor playback with Data\n  playerLayer.prepare(\n    playbackID: playbackID\n  )\n}\n\n```\n\n\nYour application can also customize playback or monitoring with Mux Data by using the same parameters as shown for the AVPlayerLayer initializers above.\n\nBy default Mux Data metrics will be populated in the same environment as your playback ID.  Learn more about Mux Data metric definitions here.\n\nRead on for additional (and optional) setup steps to modify or extend the information Mux Data tracks.\n\nUse MonitoringOptions to set custom monitoring-related parameters.\n\nIf you're already using the Mux Data SDK for AVPlayer this initializer) allows you to any of your existing logic for constructing MUXSDKCustomerData.\n\n\n```swift\nimport AVKit\nimport MuxPlayerSwift\n\nfunc preparePlayerViewController(\n  playbackID: String\n) -> AVPlayerViewController {\n\n  let customEnvironmentKey = \"ENV_KEY\"\n\n  let playerData = MUXSDKCustomerPlayerData()\n  playerData.environmentKey = customEnvironmentKey\n\n  let videoData = = MUXSDKCustomerVideoData()\n  videoData.videoTitle = \"Video Behind the Scenes\"\n  videoData.videoSeries = \"Video101\"\n\n  let customerData = MUXSDKCustomerData()\n  customerData.playerData = playerData\n  customerData.videoData = videoData\n\n  let monitoringOptions = MonitoringOptions(\n    customerData: customerData\n  )\n\n  let playerViewController = AVPlayerViewController(\n      playbackID: playbackID,\n      monitoringOptions: monitoringOptions\n  )\n\n  return playerViewController\n\n}\n\n```\n\n\nMux Video offers several levels of playback access control. See here for more.\n\nSigned Playback URLs\n\nMuxPlayerSwift supports playback of assets enabled for access with signed playback URLs. Playing back assets with a signed playback policy requires the player to include a valid and unexpired JSON Web Token (JWT) when requesting media from Mux.\n\nYour application should generate and sign the JWT in a trusted environment that you control like a server-side application. As a security measure any playback modifiers must be passed through the JWT as additional claims.\n\nOnce your application is in possession of the JWT, it can begin streaming.\n\nTo start playback, use the JWT to initialize PlaybackOptions. Then, initialize AVPlayerViewController or AVPlayerLayer with your playback ID, as in prior examples.\n\n\n```swift\nimport AVFoundation\nimport AVKit\nimport UIKit\n\nimport MuxPlayerSwift\n\n/// Prepare an AVPlayerViewController to stream and monitor a Mux asset\n/// with a playback ID that has a signed playback policy\nfunc preparePlayerViewController(\n  playbackID: String,\n  playbackToken: String\n) -> AVPlayerViewController {\n\n  let playbackOptions = PlaybackOptions(playbackToken: playbackToken)\n\n  let playerViewController = AVPlayerViewController(\n      playbackID: playbackID,\n      playbackOptions: playbackOptions\n  )\n\n  return playerViewController\n\n}\n\n/// Prepare an AVPlayerLayer to stream and monitor a Mux asset\n/// with a playback ID that has a signed playback policy\nfunc preparePlayerLayer(\n  playbackID: String,\n  playbackToken: String\n) -> AVPlayerLayer {\n\n  let playbackOptions = PlaybackOptions(playbackToken: playbackToken)\n\n  let playerLayer = AVPlayerLayer(\n      playbackID: playbackID,\n      playbackOptions: playbackOptions\n  )\n\n  return playerLayer\n}\n\n/// Prepare an already initialized AVPlayerLayer to stream and monitor a Mux asset\n/// with a playback ID that has a signed playback policy\nfunc preparePlayerLayer(\n  playbackID: String,\n  playbackToken: String,\n  playerView: UIView\n) {\n\n  let playbackOptions = PlaybackOptions(playbackToken: playbackToken)\n\n  // Check to make sure the player view backing\n  // layer is of the correct type and get a\n  // reference if it is\n  guard let playerLayer = playerView.layer as? AVPlayerLayer else {\n    print(\"Unexpected backing layer type!\")\n    return\n  }\n\n  // Prepares the player layer to stream media\n  // and monitor playback with Data\n  playerLayer.prepare(\n    playbackID: playbackID,\n    playbackOptions: playbackOptions\n  )\n}\n\n```\n\n\nIf your JWT includes a playback restriction, Mux will not be able perform domain validation when the playback URL is loaded by AVPlayer because no referrer information is supplied.\n\nTo allow AVPlayer playback of referrer restricted assets set the allow_no_referrer boolean parameter to true when creating a playback restriction. Conversely, a playback restriction with allow_no_referrer to false will disallow AVPlayer playback. See here for more.\n\nDigital Rights Management\n\nDRM (Digital Rights Management) provides an extra layer of content security for video content streamed from Mux.\nFor more details see the Protect Your Videos with DRM guide.\n\nMux uses the industry standard FairPlay protocol for delivering DRM'd video content to native iOS and iPadOS applications. To play back DRM'd content on these platforms, you'll need to obtain a FairPlay deployment package (also called a “Fairplay certificate”), see more details from Apple here. _Without this, DRM’d content will not be playable in your application on these platforms._\n\n\n```swift\nimport AVFoundation\nimport AVKit\nimport UIKit\n\nimport MuxPlayerSwift\n\n/// Prepare an AVPlayerViewController to stream and monitor a Mux asset\n/// with a playback ID configured for DRM\nfunc preparePlayerViewController(\n  playbackID: String,\n  playbackToken: String,\n  drmToken: String\n) -> AVPlayerViewController {\n\n  let playbackOptions = PlaybackOptions(\n    playbackToken: playbackToken,\n    drmToken: drmToken\n  )\n\n  let playerViewController = AVPlayerViewController(\n      playbackID: playbackID,\n      playbackOptions: playbackOptions\n  )\n\n  return playerViewController\n\n}\n\n```\n\n\nMore tools to control playback behavior\n\nRestrict Resolution Range\n\nMux Video gives you extra control over the available resolutions of your video.\n\nMuxPlayerSwift exposes convenience APIs to adjust the maximum and minimum resolutions if they are available.\n\nSetting a maximum resolution helps reduce delivery costs while setting a minimum resolution helps ensure visual quality of your video. Maximum and minimum resolutions can be set independently or composed together.\n\nIf you're using signed URLs, you'll need to embed min_resolution and max_resolution into the JWT claims. Full documentation available here.\n\nThis example restricts the resolution range AVPlayer requests to be between 720p and 1080p.\n\n\n```swift\nimport AVKit\nimport MuxPlayerSwift\n\n/// Prepare an AVPlayerViewController to stream a Mux asset\n/// with a resolution range between 720p and 1080p\nfunc preparePlayerViewController(\n  playbackID: String,\n  maximumResolution: MaxResolutionTier,\n  minimumResolution: MinResolutionTier\n) -> AVPlayerViewController {\n\n  let playbackOptions = PlaybackOptions(\n    maximumResolutionTier: .upTo1080p,\n    minimumResolutionTier: .atLeast720p\n  )\n\n  let playerViewController = AVPlayerViewController(\n    playbackID: playbackID,\n    playbackOptions: playbackOptions\n  )\n\n  return playerViewController\n\n}\n\n```\n\n\nThis example restricts the resolution AVPlayer requests to a single fixed resolution of 720p.\n\n\n```swift\n/// Prepare an AVPlayerViewController to stream a Mux asset\n/// at a fixed 720p resolution\nfunc preparePlayerViewController(\n  playbackID: String,\n  singleRenditionResolutionTier: SingleRenditionResolutionTier,\n) -> AVPlayerViewController {\n\n  let playbackOptions = PlaybackOptions(\n    singleRenditionResolutionTier: .only720p\n  )\n\n  let playerViewController = AVPlayerViewController(\n    playbackID: playbackID,\n    playbackOptions: playbackOptions\n  )\n\n  return playerViewController\n\n}\n\n```\n\n\nAdjust Resolution Selection\n\nWhen AVPlayer requests delivery of HLS content, it first downloads a series of text files, commonly called manifests or playlists, to describe the available qualities of a video and the location of all the segments that comprise the video.\n\nThe order of renditions in the initial manifest or playlist can influence the resolution level a player selects. When using the Mux Player Swift SDK your application can manipulate that order in the PlaybackOptions provided to AVPlayerViewController or AVPlayerLayer.\n\nIf your Mux asset is publicly playable, specify a RenditionOrder.\n\n\n```swift\nimport AVKit\nimport MuxPlayerSwift\n\n/// Prepare an AVPlayerViewController to stream a Mux asset\n/// with a descending rendition order\nfunc preparePlayerViewController(\n  playbackID: String\n) -> AVPlayerViewController {\n\n  let playbackOptions = PlaybackOptions(\n    renditionOrder: .descending\n  )\n\n  let playerViewController = AVPlayerViewController(\n    playbackID: playbackID,\n    playbackOptions: playbackOptions\n  )\n\n  return playerViewController\n}\n\n```\n\n\nThe available values for rendition order are listed here.\n\nIf using signed playback URLs in your application, you'll need \"rendition_order\" : \"desc\" for descending rendition order into your JWT claims. Full documentation available here.\n\n\nSee the Mux blog and this guide for more on these options.\n\nInstant Clips\n\nInstant clips are an alternative to our long-standing asset-based clipping feature. Requesting instant clips using relative time is now available for use with all video on-demand (VOD) assets.\n\nInstant clipping allows you to request a stream whose start time is at some later point in the video, relative to the start time of the asset. Likewise you're able to request a stream that ends sooner than when the underlying asset completes. Instant clips do not incur the wait time or expense of a creating a new asset.\n\nUnlike asset-based clipping, instant clipping is done by trimming your VOD assets HLS manifest. This means that instant clipping operates at the segment level of accuracy. You should expect that the content that you clip out may be several seconds longer than you’ve requested. We always make sure to include the timestamps that you request, but your content may start a few seconds earlier, and end a few seconds later.\n\nAssets that originate from a livestream can also be converted into instant clips using program date time epochs. Support for these clips will be available in a future Mux Player Swift release.\n\n\n```swift\nimport AVKit\nimport MuxPlayerSwift\n\n/// Prepare an AVPlayerViewController to stream\n/// just a highlight clip of your publicly viewable asset.\n/// The clip starts about 10 seconds after your asset starts\n/// and finishes approximately 10 more seconds after that.\n/// A few extra seconds of video may be included in the clip.\nfunc preparePlayerViewController(\n  playbackID: String\n) -> AVPlayerViewController {\n\n  let playbackOptions = PlaybackOptions(\n    instantClipping: InstantClipping(\n      assetStartTimeInSeconds: 10,\n      assetEndTimeInSeconds: 20\n    )\n  )\n\n  let playerViewController = AVPlayerViewController(\n    playbackID: playbackID,\n    playbackOptions: playbackOptions\n  )\n\n  return playerViewController\n}\n\n```\n\n\nIf using signed playback URLs in your application, you'll need to include asset_start_time and asset_end_time keys in your JWT claims to enable instant clipping. Full documentation available here.\n\nAVPlayer supports playing back HTTP live streams without pre-loading. When playing the same video more than once in this case, AVPlayer does not provide a means for making sure cached video files are used for subsequent playback. This may result in higher network throughput and additional video delivery cost when the same video is played more than once.\n\nOne alternative is to enable static renditions for your Mux asset that your application can download and persist using URLSession and FileManager APIs.\n\nAnother is to first preload streams. As with static renditions, it requires your application to manage downloads and handling storage. (See the Apple offline playback and storage documentation for more details on pre-loading).\n\nMux Player Swift offers a caching mechanism for streams that only provide a single rendition to the player. This cache is primarily tested against and provides the most cost-savings benefit when constraining playback to a single rendition. Your application is required to select a resolution tier to which playback will be constrained when using the smart cache.\n\nThis avoids manual intervention required by the previous two options.\n\nLike a browser’s cache, cached segments can be used by all players in your application, as long as they’re configured to use the smart cache.  If your application uses multiple player instances, you can enable smart cache for them by using the convenience initializers provided by the SDK.\n\nThe example below enables the smart cache with playback at single fixed resolution.\n\n\n```swift\nimport AVKit\nimport MuxPlayerSwift\n\n/// Prepare an AVPlayerViewController to stream a Mux asset\n/// at a single pre-selected resolution with smart caching enabled\nfunc preparePlayerViewController(\n  playbackID: String,\n  singleRenditionResolutionTier: SingleRenditionResolutionTier\n) -> AVPlayerViewController {\n\n  // Requires a single rendition resolution tier\n  // available values can be found here\n  // https://devdocs.mux.dev/mux-player-swift/documentation/muxplayerswift/singlerenditionresolutiontier\n  //\n  let playbackOptions = PlaybackOptions(\n    enableSmartCache: true,\n    singleRenditionResolutionTier: singleRenditionResolutionTier\n  )\n\n  let playerViewController = AVPlayerViewController(\n    playbackID: playbackID,\n    playbackOptions: playbackOptions\n  )\n\n  return playerViewController\n}\n```\n\n\nThe smart cache will be automatically purged after your application is terminated. It may be purged by the operating system at any time when your application is suspended in the background.\n\nMux supports HLS video delivery with Transport Stream segments or Common Media Application Format (CMAF) chunks. Both are supported by the smart cache. See this explainer for a general introduction to video delivery."
  },
  {
    "id": "103-_guides/developer/mux-player-web",
    "title": "Mux Player for web",
    "path": "_guides/developer/mux-player-web.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/mux-player-web",
    "content": "Mux Player is a drop-in component that you can put in your web application to play Mux assets. Mux Player supports:\n\n- on-demand assets\n- live streams\n- low-latency live streams\n- DVR mode for live or low-latency live streams\n\nMux Player can be used as a web component (` from @mux/mux-player), as a React component ( from @mux/mux-player-react), or as a web embed ()\n\nMux Player is fully-featured video player for content hosted by Mux Video. Mux Player is fully integrated with Mux Data without any extra configuration. Mux Player provides a responsive UI based on video player dimensions and stream type, automatic thumbnail previews and poster images, and modern video player capabilities (fullscreen, picture-in-picture, Chromecast, AirPlay).\n\nHere are some examples of Mux Player in action.\n\nHTML element\n\nInstall with either npm, yarn or load Mux Player from the hosted script.\n\nNPM\n\n\n```shell\nnpm install @mux/mux-player@latest\n```\n\n\nYarn\n\n\n```shell\nyarn add @mux/mux-player@latest\n```\n\n\nHosted\n\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-player\" defer></script>\n```\n\n\nExample HTML element implementation\n\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-player\" defer></script>\n<mux-player\n  playback-id=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n  metadata-video-title=\"Test VOD\"\n  metadata-viewer-user-id=\"user-id-007\"\n></mux-player>\n```\n\n\nWhen using the HTML element version of Mux Player, you will see the Player Software in Mux Data come through as mux-player.\n\nHTML Embed\nExample HTML embed implementation\n\n\n```html\n<iframe\n  src=\"https://player.mux.com/EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs?metadata-video-title=Test%20VOD&metadata-viewer-user-id=user-id-007\"\n  allow=\"accelerometer; gyroscope; autoplay; encrypted-media; picture-in-picture;\"\n  allowfullscreen=\"true\"\n></iframe>\n```\n\n\nWhen using the HTML embed version of Mux Player, you will see the Player Software in Mux Data come through as mux-player-iframe.\n\nReact\n\nYou will need to select one of the package options below. Both examples will automatically update the player. You can always anchor the package to a specific version if needed.\n\nNPM\n\n\n```shell\nnpm install @mux/mux-player-react@latest\n```\n\n\nYarn\n\n\n```shell\nyarn add @mux/mux-player-react@latest\n```\n\n\nExample React implementation\n\nWhen using the React version of Mux Player, you will see the Player Software in Mux Data come through as mux-player-react.\n\nAs shown in the examples above, the available controls will adjust based on your video's stream type, live or on-demand.\n\nMux Player will also take into account the size that the player is being displayed at, regardless of the browser window size, and will selectively hide controls that won't fit in the UI.\n\nIn the latest version of Mux Player stream type is automatically set and you don't need to manually provide this. Player themes other than the default theme that need to know what the stream type is may need it defined to avoid the player having a delay in showing the correct controls. In this instance, you would set stream-type (streamType in React) to either on-demand or live so that the UI can adapt before any information about the video is loaded.\n\nThe following will also appear in some use cases based on support detection:\n\n- AirPlay\n- Chromecast. Requires an extra step, see the customize look and feel guide.\n- Fullscreen\n- Picture-in-picture button\n- Volume controls\n\n  <GuideCard\n    title=\"Core functionality\"\n    description=\"Understand the features and core functionality of Mux Player\"\n    links={[\n      {\n        title: \"Read the guide\",\n        href: \"/docs/guides/player-core-functionality\",\n      },\n    ]}\n  />\n  <GuideCard\n    title=\"Integrate Mux Player\"\n    description=\"Interate Mux Player in your web application. See examples in popular front end frameworks.\"\n    links={[\n      {\n        title: \"Read the guide\",\n        href: \"/docs/guides/player-integrate-in-your-webapp\",\n      },\n    ]}\n  />\n  <GuideCard\n    title=\"Customize the look and feel\"\n    description=\"Customize Mux Player to match your brand\"\n    links={[\n      {\n        title: \"Read the guide\",\n        href: \"/docs/guides/player-customize-look-and-feel\",\n      },\n    ]}\n  />\n\nThe default accent color of the player is Mux pink fa50b5. You should override this with your brand color. Use the accent-color HTML attribute or accentColor` React prop.\n\n\n```html\n<mux-player\n  playback-id=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n  accent-color=\"#ea580c\"\n  metadata-video-title=\"Test VOD\"\n  metadata-viewer-user-id=\"user-id-007\"\n></mux-player>\n```\n\n\nFor React:\n\n\n```jsx\n<MuxPlayer\n  playbackId=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n  accentColor=\"#ea580c\"\n  metadata={{\n    videoTitle: \"Test VOD\",\n    ViewerUserId: \"user-id-007\"\n  }}\n/>\n```"
  },
  {
    "id": "104-_guides/developer/mux-uploader",
    "title": "Mux Uploader for web",
    "path": "_guides/developer/mux-uploader.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/mux-uploader",
    "content": "Mux Uploader is a drop-in web component that makes it easy to upload video files to Mux.\n\nThis component allows you to build a fully-functional, customizable video upload UI in your application using a single line of code. Mux Uploader supports:\n\n- Manual file selection\n- Drag and drop for files\n- Optional pausing and resuming of uploads\n- Automatic offline/online detection with upload resumes\n- And more!\n\nMux Uploader can be used as either a web component (` from @mux/mux-uploader), or a React component ( from @mux/mux-uploader-react).\n\nQuick start\n\nHere are some examples of Mux Uploader in action.\n\nMux Uploader HTML element\n\nInstall with either npm, yarn or load Mux Uploader from the hosted script.\n\nNPM\n\n\n```shell\nnpm install @mux/mux-uploader@latest\n```\n\n\nYarn\n\n\n```shell\nyarn add @mux/mux-uploader@latest\n```\n\n\nHosted\n\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-uploader\"></script>\n```\n\n\nExample HTML element implementation\n\n\n```html\n<script\n  src=\"https://cdn.jsdelivr.net/npm/@mux/mux-uploader\"\n></script>\n<mux-uploader></mux-uploader>\n```\n\n\nMux Uploader React component\n\nYou will need to select one of the package options below. Both examples will automatically update the uploader. You can always anchor the package to a specific version if needed.\n\nNPM\n\n\n```shell\nnpm install @mux/mux-uploader-react@latest\n```\n\n\nYarn\n\n\n```shell\nyarn add @mux/mux-uploader-react@latest\n```\n\n\nExample React Usage\n\n\n```jsx\nimport MuxUploader from \"@mux/mux-uploader-react\";\n\nexport default function App() {\n  return (\n    <MuxUploader/>\n  );\n}\n```\n\n\nUpload a video\n\nMux Uploader allows you to use upload URLs provided by Mux's Direct Uploads in your web application.\nIt takes care of rendering a file selector, uploading your video file, displaying progress updates to the user, handling retries, and more.\n\nThis does mean that you'll need to provide a new upload URL whenever a user will be uploading a new video file in your application. You provide that URL value via the endpoint attribute or property. It looks like this:\n\nHTML example\n\nThe endpoint indicates the direct upload URL that will receive the video file you're uploading.\n\nYou can generate a signed direct upload URL by making a server-side API call to Mux's Create Direct Upload endpoint,\nor you can use curl based on the example from the link if you just want to test it out.\n\nIn a successful API response, you will receive a unique signed upload URL that can then be passed along to your client application and set as the endpoint property on a mux-uploader element. The URL for a Direct Upload looks like \"https://storage.googleapis.com/video...\".\n\nIn the following examples, you will replace the value of the endpoint property with your unique direct upload URL.\n\nReact example\n\nOverview of the upload process\n\nVideo uploads and processing take time. Processing time can vary depending on the file size and type of video that you upload.\n\nMux uses webhooks to keep your application informed about what's happening with your uploaded video — from when the upload completes to when the video is ready to be played.\n\nTo minimize processing time, consider following Mux's guide for handling standard video input.\n\nThe overall flow generally looks like this:\n\n1. Set up webhooks\n- Set up a public webhook endpoint in your application to receive events from Mux\n- Configure the webhook in your Mux dashboard to send events to this endpoint\n\n2. Upload the video\n- Create a direct upload URL using the Mux API\n- Save the upload ID to your database\n- Pass the URL to the endpoint property on the Mux Uploader component\n\n3. Wait for video to be ready\n- When the upload completes, show a \"processing\" indicator to the user.\n- Poll your database to check if the video is ready for playback.\n\n4. Handle webhook events\n\nListen for specific webhook events, particularly:\n\n- video.upload.asset_created which indicates that the upload has completed and an asset has been created\n- video.asset.ready which indicates that the video has been processed and is ready for playback\n\nThe video.upload.asset_created event contains the asset_id in the event payload.\nThe video.asset.ready event contains the playback_id in the event payload.\n\n5. Store the information in your database\n\nSave the asset_id and playback_id to your database, associating them with the user or relevant entity in your application.\n\nHere's an example of how you might structure your database table schema:\n\n| videos                    |                        |            |\n|--------------------------|------------------------|------------|\n| id                       | uuid (primary key)     |            |\n| user_id                  | uuid (foreign key)     | References users.id |\n| upload_id                | string                 | From initial upload |\n| asset_id                 | string                 | From Mux webhook |\n| playback_id              | string                 | From Mux webhook |\n| title                    | string                 | Optional metadata |\n| status                   | enum                   | e.g. preparing, ready |\n| created_at               | timestamp              |            |\n| updated_at               | timestamp              |            |\n\n6. Use the IDs\n\nWhile Mux generates several IDs during the upload and processing flow, there are two key IDs you'll primarily work with:\n\n1. The asset_id: This is used when you need to manage your video through the Mux API (like deleting the video or checking its status)\n2. The playback_id: This is what you'll use to actually play your video, either by:\n   - Adding it to Mux Player\n   - Creating a URL where your video can be played\n\nNote that this process happens asynchronously, so your application should be designed to handle the delay between the initial upload and when the video becomes available for playback.\n\nFor more detailed implementations, you can refer to the examples provided in the Mux documentation for various frameworks:\n\n- Next.js\n- SvelteKit\n- Astro\n- Remix\n\nFetching the upload URL async\n\nAt the time you render the , you may not have the direct upload URL yet. Instead, you might want to retrieve it async from your server after a user selects a file. You can do that by setting the endpoint property value to a custom function instead of a URL.\n\n\n```html\n<mux-uploader></mux-uploader>\n\n<script>\n  const muxUploader = document.querySelector(\"mux-uploader\");\n  /*\n    Endpoint should be a function that returns a promise and resolves\n    with a string for the upload URL.\n  */\n  muxUploader.endpoint = function () {\n    /*\n      In this example, your server endpoint would return the upload URL\n      in the response body \"https://storage.googleapis.com/video...\"\n    */\n    return fetch(\"/your-server/api/create-upload\").then(res => res.text());\n  };\n</script>\n```\n\n\nThis is even easier using React props:\n\n\n```jsx\nimport MuxUploader from \"@mux/mux-uploader-react\";\n\nexport default function App() {\n  return (\n    <MuxUploader\n      endpoint={() => {\n        return fetch(\"/your-server/api/create-upload\")\n          .then(res => res.text());\n      }}\n    />\n  );\n}\n```\n\n\nCustomizing the UI\n\nAs you can see in the examples above, Mux Uploader provides a fairly feature rich and reasonably styled (albeit basic) UI by default.\n\nIt will automatically update based on different stages or states of uploading, like showing a UI for file selection before a video has been picked,\nshowing progress as the file is uploaded, showing when the file upload has completed, and showing error state with the option to retry if something\ngoes wrong with the upload.\n\nIn addition, Mux Uploader provides many ways to customize this look and feel, including:\n\n- attributes / properties like no-drop or pausable to enable/disable UI components\n- intuitive styling with CSS, just like any other HTML element.\n- state transition attributes like upload-in-progress or upload-error for responsive styling\n- attribute / property based data customization for things like dynamic-chunk-size or max-file-size\n- overridable and composable components like  or ` for full flexibility of UI\n\n  <GuideCard\n    title=\"Core functionality\"\n    description=\"Understand the features and core functionality of Mux Uploader\"\n    links={[\n      {\n        title: \"Read the guide\",\n        href: \"/docs/guides/uploader-web-core-functionality\",\n      },\n    ]}\n  />\n  <GuideCard\n    title=\"Integrate Mux Uploader\"\n    description=\"Interate Mux Uploader in your web application. See examples in popular front end frameworks.\"\n    links={[\n      {\n        title: \"Read the guide\",\n        href: \"/docs/guides/uploader-web-integrate-in-your-webapp\",\n      },\n    ]}\n  />\n  <GuideCard\n    title=\"Customize the look and feel\"\n    description=\"Customize Mux Uploader to match your brand and needs\"\n    links={[\n      {\n        title: \"Read the guide\",\n        href: \"/docs/guides/uploader-web-customize-look-and-feel\",\n      },\n    ]}\n  />"
  },
  {
    "id": "105-_guides/developer/pagerduty-alert-notifications",
    "title": "PagerDuty Alert Notifications",
    "path": "_guides/developer/pagerduty-alert-notifications.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/pagerduty-alert-notifications",
    "content": "How the integration works\n\nAlerts can be defined by specified thresholds or based on levels dynamically defined by machine learned anomaly detection.\n\nVideo metrics that cause the creation of a new incident in Mux Data will also send a trigger event to PagerDuty which generates a new incident in the configured service or event rule set.\n\nWhen an alert incident is resolved in Mux Data, a resolve event is sent to PagerDuty and the associated PagerDuty incident will be closed.\n\nIntegration walk-through in PagerDuty\n\nThere are two ways to integrate with PagerDuty: via Global Event Routing or on a PagerDuty Service.\n\nIf you are adding this integration to an existing PagerDuty service, please skip to the Integrating with a PagerDuty Service section of this guide.\n\nIntegrating with Global Event Routing\n\nIntegrating with Global Event Routing enables you to route events to specific services based on the payload of the event from your tool. If you would like to learn more, please visit the PagerDuty article on Global Event Routing.\n\n1. From the Configuration menu, select Event Rules.\n\n2. On the Event Rules screen, click on the arrow next to Incoming Event Source to display the Integration key information. Copy your Integration Key. This is the same integration key you will use for any other tool you want to integrate with using event rules. When you have finished setting up the integration in your tool, you will return to this interface to specify how to route events from your tool to services in PagerDuty.\n\nIntegrating With a PagerDuty Service\n1. From the Configuration menu, select Services.\n2. There are two ways to add an integration to a service:\n    If you are adding your integration to an existing service: Click the name of the service you want to add the integration to. Then, select the Integrations tab and click the New Integration button.\n    If you are creating a new service for your integration: Please read our documentation in section Configuring Services and Integrations and follow the steps outlined in the Create a New Service section, selecting Mux Data as the Integration Type in step 4. Continue with the In Mux Data section (below) once you have finished these steps.\n3. Enter an Integration Name in the format monitoring-tool-service-name (e.g.  Mux Data-Production) and select  Mux Data  from the Integration Type menu.\n4. Click the Add Integration button to save your new integration. You will be redirected to the Integrations tab for your service.\n5. An Integration Key will be generated on this screen. Keep this key saved in a safe place, as it will be used when you configure the integration with Mux Data  in the next section.\n\nIntegration walk-through in Mux Data\n\n1. From the navigation menu, choose Alerts and then Notifications.\n\n2. Click on the Add Channel button to create a new notification channel that sends alerts to PagerDuty.\n\n3. In the New Channel dialog, for the Service choose PagerDuty, enter the Integration Key for the Service or Event Rule from the steps above, and choose which types of Mux Data alerts you would like sent to PagerDuty. Anomaly will send all automatically generated Anomaly alerts to the PagerDuty service, Threshold will send the notifications generated by the alerts you explicitly configure, and All will send all alert notifications generated in Mux Data to PagerDuty.\n\n4. Click Add Channel to create the notification channel for PagerDuty.\n\nHow to Uninstall\n\nTo stop notifying PagerDuty of alert incidents, delete the PagerDuty Notification Channel in Mux Data.\n\n1. From the Alerts Notification Channels tab, scroll to the PagerDuty channel you would like to delete. Click the garbage can icon to delete the channel.\n\nFAQ\n\nCan you trigger incidents for more than one PagerDuty service or event rule from Mux Data?\n\nTo send alert notifications to multiple services or event rules, you can create more than one PagerDuty Notification Channel in Mux Data. Each PagerDuty Notification Channel in Mux Data can be set with the Integration Key from the desired service or event rule that should be notified when an alert is trigger or resolved.\n\nRequirements\n Mux Data integrations require access to Anomaly or Threshold Alerts. If you do not have access to this feature, please contact Mux for more information.\n\nSupport\nIf you need help with this integration or information about Mux, please contact:\n Technical Support: https://www.mux.com/support\n* Information: info@mux.com"
  },
  {
    "id": "106-_guides/developer/play-drm-protected-videos-on-google-cast",
    "title": "Play DRM protected videos on Google Cast Devices",
    "path": "_guides/developer/play-drm-protected-videos-on-google-cast.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/play-drm-protected-videos-on-google-cast",
    "content": "Google Cast is a popular method for sending video from one device to be played on another, often from a phone to a TV. Most players support Google Cast out of the box, but if your video is protected by DRM, you will need to do a little more work.\n\nOverview\n\nGoogle Cast integrations are made up of two parts, a \"sender\" and a \"receiver\". In the example of a phone casting to a TV, the player in a mobile browser is the sender and the receiver is a webpage sent to the TV.\n\nThere are quite a few steps in this process, so here's a quick overview:\n\n1. Create a sender, either with the Mux Player or by writing your own\n2. Create your playback ID, playback token and DRM token, and add them to the sender\n3. Register your test device in the Google Cast dashboard\n4. Create a custom receiver and register it on the Google Cast dashboard\n5. Add the registered receiver ID to the custom sender\n\nSender Setup\n\nA Google Cast sender is an app with a \"cast\" button. Clicking the cast button performs two actions.\n\n1. If you're not yet connected to another device, the cast button helps set up that connection.\n2. Once you're connected to a device, the sender sends everything needed to play a video to the receiver.\n\nIn this section we'll walk through how to write your own web-based Google Cast sender.\n\nMux Player Sender\n\nThe easiest way to set up your own sender is with Mux Player for Web. In addition to the usual playback-id property, you'll need to include additional security and Google Cast fields:\n\n- playback-token: A signed playback token, as documented in our Guide to Secured Video Playback\n- drm-token: A signed DRM token, as documented in the Sign a DRM license token section of our DRM guide\n- cast-receiver: The application ID of your custom receiver, as documented in the Custom Receiver section below\n\nThis is only supported in Mux Player version 3.4.1 or greater\n\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-player\" defer></script>\n<mux-player\n  id=\"player\"\n  playback-id=\"your-playback-id\"\n  playback-token=\"your-playback-token\"\n  drm-token=\"your-drm-token\"\n  cast-receiver=\"your-cast-receiver-app-id\"\n></mux-player>\n```\n\n\nCustom Web Sender\n\nIf you're not using Mux Player, Google offers SDKs for Web, Android and iOS. In this section we'll walk through installing the Web SDK and sending a video with DRM to a custom receiver.\n\nRequirements\n\nBefore you build your own custom web sender, you'll need to create a playback token and a DRM license token.\n\nNote: Google Cast and DRM only works in secure contexts, such as HTTPS or localhost.\n\nImport Cast SDK\n\nInclude the following script wherever you want to show a cast button.\n\n\n```html\n<script src=\"https://www.gstatic.com/cv/js/sender/v1/cast_sender.js?loadCastFramework=1\"></script>\n```\n\n\nConfigure Cast SDK\n\nBefore we can cast any videos we need to configure the cast context. The cast framework gives us a great place to do that, in the global __onGCastApiAvailable function.\n\n\n```javascript\nwindow['__onGCastApiAvailable'] = function(isAvailable) {\n  if (isAvailable) {\n    cast.framework.CastContext.getInstance().setOptions({\n      receiverApplicationId: 'your-receiver-app-id',\n      autoJoinPolicy: chrome.cast.AutoJoinPolicy.ORIGIN_SCOPED,\n    });\n  }\n};\n```\n\n\nFor DRM, you'll need to build your own receiver and add the ID to receiverApplicationId. We can help you with that in our custom receiver guide.\n\nSend Video to Receiver\n\nLet's write a function to encapsulate sending our video over to the receiver.\n\nFirst we're going to collect all the data we need to play the video in variables at the top.\n\n\n```javascript\nfunction playVideo(context) {\n  const playbackId = 'your-playback-id';\n  const playbackToken = 'your-playback-token';\n  const drmToken = 'your-drm-token';\n  const mediaUrl = `https://stream.mux.com/${playbackId}.m3u8?token=${playbackToken}`;\n```\n\n\nEach of these variables help identify a single asset.\n\n- playbackId: An asset can have one or many playback IDs. This is different from the asset ID. You can find it in the API, or in the Mux Dashboard.\n- playbackToken: A signed playback token, as documented in our Guide to Secured Video Playback.\n- drmToken: A signed DRM token, as documented in the Sign a DRM license token section of our DRM guide.\n\nThen we'll build a MediaInfo object to include all the information Google Cast needs to play the video.\n\n\n```javascript\nlet mediaInfo = new chrome.cast.media.MediaInfo(mediaUrl, 'application/x-mpegurl');\n\n// Mux HLS URLs with DRM will always use `fmp4` segments.\nmediaInfo.hlsSegmentFormat = chrome.cast.media.HlsSegmentFormat.FMP4;\nmediaInfo.hlsVideoSegmentFormat = chrome.cast.media.HlsVideoSegmentFormat.FMP4;\n\n// Send the information needed to create a new license url.\nmediaInfo.customData = {\n  mux: {\n    playbackId,\n    tokens: {\n      drm: drmToken\n    }\n  }\n}\n```\n\n\nAnd finally we'll ask the receiver to load the video.\n\n\n```javascript\nconst request = new chrome.cast.media.LoadRequest(mediaInfo);\n\n// Cast the video.\ncontext.getCurrentSession().loadMedia(request).then(() => {\n  console.log('Successfully loaded the media');\n}).catch((err) => {\n  console.log(`Media playback error code: ${err}`);\n});\n```\n\n\nHere's the function in its entirety:\n\n\n    View example code\n\n\n\n```javascript\n    function playVideo(context) {\n      const playbackId = 'your-playback-id';\n      const playbackToken = 'your-playback-token';\n      const drmToken = 'your-drm-token';\n      const mediaUrl = `https://stream.mux.com/${playbackId}.m3u8?token=${playbackToken}`;\n      let mediaInfo = new chrome.cast.media.MediaInfo(mediaUrl, 'application/x-mpegurl');\n\n      // Mux HLS URLs with DRM will always use `fmp4` segments.\n      mediaInfo.hlsSegmentFormat = chrome.cast.media.HlsSegmentFormat.FMP4;\n      mediaInfo.hlsVideoSegmentFormat = chrome.cast.media.HlsVideoSegmentFormat.FMP4;\n\n      // Send the information needed to create a new license url.\n      mediaInfo.customData = {\n        mux: {\n          playbackId,\n          tokens: {\n            drm: drmToken\n          }\n        }\n      }\n\n      const request = new chrome.cast.media.LoadRequest(mediaInfo);\n\n      // Cast the video.\n      context.getCurrentSession().loadMedia(request).then(() => {\n        console.log('Load Succeeded');\n      }).catch((err) => {\n        console.log(`Error code: ${errorCode}`);\n      });\n    }\n    ```\n\n\n\nNow we need to hook it up to the cast action. In this example we'll send it as soon as possible by listening for the cast session to start.\n\n\n```javascript\nlet context = cast.framework.CastContext.getInstance();\ncontext.addEventListener(cast.framework.CastContextEventType.SESSION_STATE_CHANGED, function(event) {\n  switch (event.sessionState) {\n    case cast.framework.SessionState.SESSION_STARTED:\n    case cast.framework.SessionState.SESSION_RESUMED:\n      playVideo(context);\n      break;\n  }\n});\n```\n\n\nAdd Cast Button\n\nOnce all your code is hooked up, adding the button is the easiest part. Put this in the HTML of your page and you're good to go.\n\n\n```html\n<google-cast-launcher>Launch</google-cast-launcher>\n```\n\n\nMore Docs\n\n- JavaScript SDK\n- iOS SDK\n- Android SDK\n\nReceiver Setup\n\nA Google Cast receiver is a web page that receives data from a sender and plays your video. This is always a webpage, written in HTML and JavaScript, even if you're using a mobile SDK for casting.\n\nReceiver Prerequisites\n\nBefore we can write the code, we need to take care of a couple prerequisites.\n\n1. You need a way for devices to access this web page with a public URL. We recommend either you host the files yourself, or use ngrok during development to expose local files on a public URL.\n2. You need to register the receiver's public URL with Google in the Google Cast SDK Developer Console. If you have not joined the Google Cast Developer program, do so now.\n3. Once you have registered your receiver, you will see your app listed in the dashboard with a unique Application ID. This is the same receiver ID you will configure in the Mux Player or Custom Sender.\n4. Until your app is published, you can only cast to registered development devices. This registration requires the destination device's serial number. If you can't find the serial number on the outside of the device, you can use the Chrome browser to cast the dashboard directly to the device. This will show a new screen, prominently displaying the device's serial number.\n\nReceiver Implementation\n\nGoogle's custom receiver SDK has a lot of functionality built in, so we don't have to do a lot of work. The only thing we need to do is manage the DRM license URL. Before we start working with License URLs, we'll want a small HTML file to describe the playback UI. Here's a minimal example.\n\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <meta charset=\"utf-8\">\n        <title></title>\n        <!-- Web Receiver SDK -->\n        <script src=\"//www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js\"></script>\n        <!-- Cast Debug Logger -->\n        <script src=\"//www.gstatic.com/cast/sdk/libs/devtools/debug_layer/caf_receiver_logger.js\"></script>\n    </head>\n\n    <body>\n        <cast-media-player></cast-media-player>\n        <footer>\n            <script src=\"js/receiver.js\"></script>\n        </footer>\n    </body>\n</html>\n```\n\n\nIn the above example, the two script tags in the header load the SDK and the Google Cast logger. Further on you'll see a `, which the Google Cast SDK automatically turns into a video player, and a script for managing the DRM.\n\nNow let's create that script. To start, we're going to grab a reference to the cast context and configure the logger.\n\n\n```javascript\nconst context = cast.framework.CastReceiverContext.getInstance();\n\n/**\n * DEBUGGING\n */\nconst castDebugLogger = cast.debug.CastDebugLogger.getInstance();\nconst LOG_TAG = 'MUX';\ncastDebugLogger.setEnabled(true);\n\n// Debug overlay on tv screen.\n// You don't need this if you're debugging using the cast tool (https://casttool.appspot.com/cactool) as it will show the logs in your browser.\ncastDebugLogger.showDebugLogs(true);\n\ncastDebugLogger.loggerLevelByTags = {\n  [LOG_TAG]: cast.framework.LoggerLevel.DEBUG,\n};\n```\n\n\nNext we're going to intercept all playback requests and see if the request includes DRM license information.\n\n\n```javascript\ncontext.getPlayerManager().setMediaPlaybackInfoHandler((loadRequest, playbackConfig) => {\n  const customData = loadRequest.media.customData || {};\n\n  if(customData.mux && customData.mux.tokens.drm){\n```\n\n\nIn that conditional, let's build our license URL and add it to the playbackConfig.\n\n\n```javascript\n    playbackConfig.licenseUrl = `https://license.mux.com/license/widevine/${customData.mux.playbackId}?token=${customData.mux.tokens.drm}`;\n  }\n\n  playbackConfig.protectionSystem = cast.framework.ContentProtection.WIDEVINE;\n  castDebugLogger.debug(LOG_TAG, 'license url', playbackConfig.licenseUrl);\n\n  return playbackConfig;\n});\n```\n\n\nFinally, we start listening for incoming requests with the line\n\n\n```javascript\ncontext.start();\n```\n\n\nClick the button below to view the full JavaScript file.\n\n\n    View example code\n\n\n\n```javascript\n    /**\n     * DEBUGGING\n     */\n    // https://developers.google.com/cast/docs/debugging/cast_debug_logger\n    const castDebugLogger = cast.debug.CastDebugLogger.getInstance();\n    const LOG_TAG = 'MUX';\n    castDebugLogger.setEnabled(true);\n\n    // Debug overlay on tv screen. You don't need this if you're debugging using the cast tool (https://casttool.appspot.com/cactool) as it will show the logs in your browser.\n    castDebugLogger.showDebugLogs(true);\n\n    castDebugLogger.loggerLevelByTags = {\n        [LOG_TAG]: cast.framework.LoggerLevel.DEBUG,\n    };\n\n    /**\n     * DRM SUPPORT\n     */\n    context.getPlayerManager().setMediaPlaybackInfoHandler((loadRequest, playbackConfig) => {\n      const customData = loadRequest.media.customData || {};\n\n      if(customData.mux && customData.mux.tokens.drm){\n        castDebugLogger.debug(LOG_TAG, 'Setting license URL.');\n        playbackConfig.licenseUrl = `https://license.mux.com/license/widevine/${customData.mux.playbackId}?token=${customData.mux.tokens.drm}`;\n      }\n\n      playbackConfig.protectionSystem = cast.framework.ContentProtection.WIDEVINE;\n\n      castDebugLogger.debug(LOG_TAG, 'license url', playbackConfig.licenseUrl);\n\n      return playbackConfig;\n    });\n\n    /**\n     * START LISTENING FOR CASTS\n     */\n    context.start();\n    ```\n\n\n\nMore docs\n\n- Google's custom receiver docs\n- Debug logger docs\n- Adding the Mux Data SDK to Chromecast\n\nTesting\n\nOnce you've completed every step (Triple check the overview steps!) load up your sender, click the cast button and choose to cast to your test device. After a quick loading screen your DRM-protected video will start playing.\n\nIf you're testing our example, the video will automatically start playing behind the cast log. You can remove the cast log by commenting out the line castDebugLogger.setEnabled(true);` in your custom receiver."
  },
  {
    "id": "107-_guides/developer/play-your-videos",
    "title": "Play your videos",
    "path": "_guides/developer/play-your-videos.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/play-your-videos",
    "content": "Each asset and each live_stream in Mux can have one or more Playback IDs.\n\nThis is an example of the \"playback_ids\" from the body of your asset or live_stream in Mux. In this example, the PLAYBACK_ID is \"uNbxnGLKJ00yfbijDO8COxTOyVKT01xpxW\" and the policy is \"public\".\n\nPlayback IDs can have a policy of \"public\" or \"signed\". For the purposes of this guide we will be working with \"public\" playback IDs.\n\nIf this is your first time using Mux, start out with \"public\" playback IDs and then read more about securing video playback with signed URLs later.\n\n\n```json\n\"playback_ids\": [\n  {\n    \"policy\": \"public\",\n    \"id\": \"uNbxnGLKJ00yfbijDO8COxTOyVKT01xpxW\"\n  }\n],\n```\n\n\nHLS is a standard protocol for streaming video over the internet. Most of the videos you watch on the internet, both live video and on-demand video is delivered over HLS. Mux delivers your videos in this standard format.\n\nBecause HLS is an industry standard, you are free to use any HLS player of your choice when working with Mux Video.\n\nHLS URLs end with the extension .m3u8. Use your PLAYBACK_ID to create an HLS URL like this:\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8\n```\n\n\nIf you're curious to learn more about how HLS works you might find this informational site howvideo.works makes for some good bedtime reading.\n\nOther formats\n\nHLS (.m3u8) is used for streaming assets (video on demand) and live streams. For offline viewing and post-production editing take a look at the guide for download your videos which covers mp4 formats and master access.\n\nMost browsers do not support HLS natively in the video element (Safari and IE edge are exceptions). Some JavaScript will be needed in order to support HLS playback in your web application.\n\nThe default player in iOS and TVOS (AVPlayer) supports HLS natively, so no extra effort is needed. In the Swift example below we're using the VideoPlayer struct that comes with SwiftUI and AVKit.\n\nSimilarly, the default player ExoPlayer on Android also supports HLS natively.\n\nIf you're using Next.js or React for your application, the with-mux-video example is a good place to start.\n\nnpx create-next-app --example with-mux-video with-mux-video-app\n\nThe examples below are meant to be a starting point. You are free to use any player that supports HLS with Mux videos. Here's some popular players that we have seen:\n\nMux Player\n\n<CodeExamples\n  product=\"video\"\n  example=\"muxPlayerQuickstart\"\n  exampleOrder=\"html,react,embed\"\n/>\n\nSee the Mux Player guide for more details and configuration options.\n\nMux Video Element\n\nIf Mux Player does more than you're looking for, and you're interested in using something more like the native HTML5 ` element for your web application, take a look at the  element. The Mux Video Element is a drop-in replacement for the HTML5  element, but it works with Mux and has Mux Data automatically configured.\n\n- HTML: Mux Video element\n- React: MuxVideo component\n\nPopular web players\n\n HLS.js is free and open source. This library does not have any UI components like buttons and controls. If you want to either use the HTML5  element's default controls or build your own UI elements HLS.js will be a great choice.\n Plyr.io is free and open source. Plyr has UI elements and controls that work with the underlying  element. Plyr does not support HLS by default, but it can be used _with_ HLS.js. If you like the feel and theming capabilities of Plyr and want to use it with Mux videos, follow the example for using Plyr + HLS.js.\n Video.js is a free and open source player. As of version 7 it supports HLS by default. The underlying HLS engine is videojs/http-streaming.\n JWPlayer is a commercial player and supports HLS by default. The underlying HLS engine is HLS.js.\n Brightcove Player is a commercial player built on Video.js and HLS is supported by default.\n Bitmovin Player is a commercial player and supports HLS by default.\n THEOplayer is a commercial player and supports HLS by default. The player chrome is built on Video.js, but the HLS engine is custom.\n Agnoplay is a fully agnostic, cloud-based player solution for web, iOS and Android with full support for HLS.\n\nUse Video.js with Mux\n\nVideo.js kit is a project built on Video.js with additional Mux specific functionality built in.\nThis includes support for:\n\n- Enabling timeline hover previews\n- Mux Data integration\n- playback_id helper (we'll figure out the full playback URL for you)\n\nFor more details, head over to the Use Video.js with Mux page.\n\nPlayback with subtitles/closed captions\n\nSubtitles/Closed Captions text tracks can be added to an asset either on asset creation or later when they are available. Mux supports SubRip Text (SRT) and Web Video Text Tracks format for ingesting Subtitles and Closed Captions text tracks. For more information on Subtitles/Closed Captions, see this blog post and the guide for subtitles.\n\nMux includes Subtitles/Closed Captions text tracks in HLS (.m3u8) for playback. Video Players show the presence of Subtitles/Closed Captions text tracks and the languages available as an option to enable/disable and to select a language. The player can also default to the viewer's device preferences.\n\nIf you are adding text tracks to your Mux videos, make sure you test them out with your player.\n\nIn addition, Mux also supports downloading of Subtitles/Closed Captions text tracks as \"sidecar\" files when downloading your videos.\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}/text/{TRACK_ID}.vtt\n```\n\n\nReplace {PLAYBACK_ID} with your asset's playback ID and {TRACK_ID} with the unique identifier value returned when this subtitle/closed caption text track was added to this asset.\n\nAdd delivery redundancy with Redundant Streams\n\nMux Video streams are delivered using multiple CDNs. The best performing CDN is selected for the viewer initiating the playback. Video is then streamed by that CDN for that particular user. When the selected CDN has a transient or regional failure, the viewer's playback experience could be interrupted for the duration of the failure. If this happens your application should handle the playback failure and re-initiate the playback session. Mux Video's CDN selection logic would then select a different CDN for streaming.\n\nThe redundant streams modifier allows Mux to list each rendition for every CDN in the HLS manifest. The order is based on CDN performance with the best performing one listed first. If your video player supports redundant streams then the player will detect the failure mid-playback and switch to the next CDN on the list during a failure without interrupting the playback.\n\nFor more information on the Redundant Streams playback modifier and player support based on our tests, see this blog post.\n\nTo use this feature in your application add redundant_streams=true to the HLS URL:\n\n\n```none\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?redundant_streams=true\n```\n\n\nUsing redundant_streams with signed URLs\n\nIf you are using signed playback URLs make sure you include the extra parameter in your signed token.\n\nThis table shows the support of various video players for redundant streams. This table will be updated as more players are tested or updated. If your player isn't listed here, please reach out.\n\n| Player | Version | Manifest 4xx | Manifest 5xx | Media 4xx | Media 5xx |\n| :-- | :-- | :-- | :-- | :-- | :-- |\n| Video.js | >= 7.6.6 |✅ |✅ |✅ |✅ |\n| HLS.js | >= 0.14.11 |✅ |✅ |✅ |✅ |\n| JWPlayer | Production Release Channel |✅ |✅ |✅ |✅ |\n| Safari iOS (AVPlayer) | >= iOS 13.6.1 |✅ |✅ |✅ |✅ |\n| Safari MacOS | Safari >= 13.1.2 MacOS 10.15.X |✅ |✅ |✅ |✅ |\n| ExoPlayer | >= r2.12.0 |✅ |✅ |✅ |✅ |\n\nSecuring video playback\n\nWhen using a policy of \"public\" for your playback IDs, your HLS playback URLs will work for as long as the playback ID exists. If you use a \"signed\"` policy then you can have more control over playback access. This involves creating signing keys and using JSON web tokens to generate signatures on your server. See the guide for secure video playback.\n\n  <GuideCard\n    title=\"Get images from a video\"\n    description=\"Now that you have playback working, build rich experiences into your application by previewing your videos with thumbnails and gifs.\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/get-images-from-a-video\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Track your video performance\"\n    description=\"Add the Mux Data SDK to your player and start collecting playback performance metrics.\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/track-your-video-performance\"},\n    ]}\n  />"
  },
  {
    "id": "108-_guides/developer/playback-videojs-with-mux",
    "title": "Use Video.js with Mux",
    "path": "_guides/developer/playback-videojs-with-mux.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/playback-videojs-with-mux",
    "content": "Video.js kit is a project built on Video.js with additional Mux specific functionality built in.\nThis includes support for:\n\n- Enabling timeline hover previews\n- Mux Data integration\n- playback_id helper (we'll figure out the full playback URL for you)\n\nVideo.js kit is hosted on npm. To install it, navigate to your project and run:\n\n\n```text\n// npm\nnpm install @mux/videojs-kit\n\n// yarn\nyarn add @mux/videojs-kit\n```\n\n\nNow import the JavaScript and CSS in your application like this:\n\n\n```js\n// include the video.js kit JavaScript and CSS\nimport videojs from '@mux/videojs-kit';\nimport '@mux/videojs-kit/dist/index.css';\n```\n\n\nIf you're not using a package manager such as npm, there are hosted versions provided by jsdelivr.com available too.\nUse the hosted versions by including this in your HTML page:\n\n\n```html\n// script\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/videojs-kit@latest/dist/index.js\"></script>\n// CSS\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@mux/videojs-kit@latest/dist/index.css\">\n```\n\n\nThen, on your page include a ` element where you want to add your player.\n\n\n```html\n<video\n  id=\"my-player\"\n  class=\"video-js vjs-16-9\"\n  controls\n  preload=\"auto\"\n  width=\"100%\"\n  data-setup='{}'\n>\n  <source src=\"{PLAYBACK_ID}\" type=\"video/mux\" />\n</video>\n```\n\n\nReplace the \\{PLAYBACK_ID\\} with the playback_id of your video from Mux.\n\nIntegrate using Video.js's default playback engine.\n\nVideo.js kit by default uses hls.js.\nAs of version 0.8.0, you can now integrate with Video.js's default playback engine.\n\nTo do so, you can follow the steps above but swap out the specific import file to be index.vhs.js.\n\nFor import:\n\n```js\n// include the video.js kit JavaScript and CSS\nimport videojs from '@mux/videojs-kit/dist/index.vhs.js';\n```\n\n\nFor a script tag:\n\n```html\n<script src=\"https://unpkg.com/@mux/videojs-kit@latest/dist/index.vhs.js\"></script>\n```\n\n\nSource Code\n\nVideo.js kit is open source and can be found on GitHub here: https://github.com/muxinc/videojs-mux-kit\n\nThere are some built in additional features which can be set when you initialize video.js kit.\n\nInclude a timeline hover preview\nYou can enable a timeline hover preview by including timelineHoverPreviews: true in the configuration options when you create your player.\n\n\n```html\n<video id=\"my-player\" class=\"video-js vjs-16-9\" controls preload=\"auto\" width=\"100%\"\n  data-setup='{\n    \"timelineHoverPreviews\": true\n  }'\n>\n  <source src=\"{PLAYBACK_ID}\" type=\"video/mux\" />\n</video>\n```\n\n\nEnable Mux Data\nYou can enable Mux Data by including the following options when you create your player.\n\n\n```html\n<video id=\"my-player\" class=\"video-js vjs-16-9\" controls preload=\"auto\" width=\"100%\"\n  data-setup='{\n    \"plugins\": {\n      \"mux\": {\n        \"debug\": true,\n        \"data\":{\n          \"env_key\": \"ENV_KEY\",\n          \"video_title\": \"Example Title\"\n        }\n      }\n    }\n  }'\n>\n  <source src=\"{PLAYBACK_ID}\" type=\"video/mux\" />\n</video>\n```\n\n\nThe videojs-mux data plugin is included by default, so you don't need to include this in addition to video.js kit. To link your data integration to your account,\nyou should replace the ENV_KEY in the configuration with an appropriate Mux environment key, as well as set metadata.\n\nSet the video source\n\nYou can set the video source using the playback_id from your video in Mux, and we'll figure out the fully formed playback URL automatically.\n\nWhen you set the source for video.js, make sure you set the type as video/mux and the src as your playback_id.\n\n\n```html\n<video id=\"my-player\" class=\"video-js vjs-16-9\" controls preload=\"auto\" width=\"100%\">\n  <source src=\"{PLAYBACK_ID}\" type=\"video/mux\" />\n</video>\n\n```\n\n\nInitialize with JavaScript\n\nThe options above can also be initialized with JavaScript. Here's an example showing how you could enable all options with JavaScript.\n\n\n```html\n<video id=\"my-player\" class=\"video-js vjs-16-9\" controls preload=\"auto\" width=\"100%\">\n</video>\n\n<script>\nconst player = videojs('my-player', {\n  timelineHoverPreviews: true,\n  plugins: {\n    mux: {\n      debug: false,\n      data: {\n        env_key: 'ENV_KEY',\n        video_title: 'Example Title'\n      }\n    }\n  }\n});\n\nplayer.src({\n  src: \"{PLAYBACK_ID}\",\n  type: \"video/mux\",\n});\n</script>\n```\n\n\nPlayback of Mux videos with a signed playback policy is now supported from v0.3.0 onward.\n\nBefore continuing, ensure you have followed the secure video playback guide, and are comfortable generating JSON Web Tokens (JWTs) to use with Mux.\n\nPlayback a video with a signed URL\n\nUse the playback_id from your video in Mux and then append your video JWT token\nlike this {PLAYBACK_ID}?token={YOUR_VIDEO_JWT} as your player source. When you set the source for video.js, make sure you set the type as video/mux.\n\nIn HTML:\n\n```html\n<video id=\"my-player\" class=\"video-js vjs-16-9\" controls preload=\"auto\" width=\"100%\" data-setup=\"{}\">\n  <source src=\"{PLAYBACK_ID}?token={JWT_VIDEO_TOKEN}\" type=\"video/mux\" />\n</video>\n\n```\n\n\nOr, achieve the same result using JavaScript:\n\n```html\n<video id=\"my-player\" class=\"video-js vjs-16-9\" controls preload=\"auto\" width=\"100%\">\n</video>\n\n<script>\nconst player = videojs('my-player', {\n  plugins: {\n    mux: {\n      debug: false,\n      data: {\n        env_key: 'ENV_KEY',\n        video_title: 'Example Title'\n      }\n    }\n  }\n});\n\nplayer.src({\n  src: `{PLAYBACK_ID}?token={JWT_VIDEO_TOKEN}`,\n  type: `video/mux`,\n});\n\n</script>\n```\n\n\nEnable a timeline hover preview from a signed URL\n\nMux requires a separate JWT token to access the timeline hover preview storyboard URL, which isn't something that Video.js Kit is able to automatically figure out,\nunlike with public playback URLs. Instead, we require the fully formed URL to be passed to the player.\n\nTo setup timeline hover previews with a signed URL, first make sure that timelineHoverPreviews is set to false or not set at all, which stops the automatic URL generation taking place.\nThen, either set the timelineHoverPreviewsUrl in the player configuration like this:\n\n\n```html\n<video id=\"my-player\"\n  class=\"video-js vjs-16-9\"\n  controls\n  preload=\"auto\"\n  width=\"100%\"\n  data-setup='{\n    \"timelineHoverPreviewsUrl\": \"https://image.mux.com/{PLAYBACK_ID}/storyboard.vtt?token={JWT_STORYBOARD_TOKEN}\"\n  }'>\n  <source src=\"{PLAYBACK_ID}?token={JWT_VIDEO_TOKEN}\" type=\"video/mux\" />\n</video>\n\n```\n\n\nOr, achieve the same result using JavaScript and use the player.timelineHoverPreviews() function:\n\n```html\n<video id=\"my-player\" class=\"video-js vjs-16-9\" controls preload=\"auto\" width=\"100%\">\n</video>\n\n<script>\nconst player = videojs('my-player', {\n  plugins: {\n    mux: {\n      debug: false,\n      data: {\n        env_key: 'ENV_KEY',\n        video_title: 'Example Title'\n      }\n    }\n  }\n});\n\nplayer.src({\n  src: `{PLAYBACK_ID}?token={JWT_VIDEO_TOKEN}`,\n  type: `video/mux`,\n});\n\nplayer.timelineHoverPreviews({\n  enabled: true,\n  src: \"https://image.mux.com/{PLAYBACK_ID}/storyboard.vtt?token={JWT_STORYBOARD_TOKEN}\"\n});\n\n</script>\n```\n\n\nplayer.timelineHoverPreviews is a function that can be used to set, update or remove timeline hover previews from a player, and takes a single object parameter.\n\nThe object has two properties, src which should be a string pointing to the VTT file which contains the timeline hover previews information, and enabled which can be\neither true for the player to attempt to use the provided source and setup the timeline hover previews, or false which will disable any timeline hover previews which are\ncurrently configured on the player.\n\nRemove timeline hover previews\n\nTo switch off timeline hover previews, you can use the following API;\n\n\n```js\n\nplayer.timelineHoverPreviews({\n  enabled: false,\n});\n```\n\n\nAs of version v0.10.0, Video.js kit comes bundled with the [videojs-contrib-quality-levels][] and [videojs-http-source-selector][] plugins. They are not enabled by default.\n\nTo enable them, you can pass it in as part of the plugins object:\n\n```html\n<video id=\"my-player\" class=\"video-js vjs-16-9\" controls preload=\"auto\" width=\"100%\"\n  data-setup='{\n    \"plugins\": {\n      \"mux\": {\n        \"debug\": true,\n        \"data\":{\n          \"env_key\": \"ENV_KEY\",\n          \"video_title\": \"Example Title\"\n        }\n      },\n      \"httpSourceSelector\": {}\n    }\n  }'\n>\n  <source src=\"{PLAYBACK_ID}\" type=\"video/mux\" />\n</video>\n```\n\n\nOr, you call the httpSourceSelector function manually on the player:\n\n```html\n<video id=\"my-player\" class=\"video-js vjs-16-9\" controls preload=\"auto\" width=\"100%\">\n</video>\n\n<script>\nconst player = videojs('my-player', {\n  timelineHoverPreviews: true,\n  plugins: {\n    mux: {\n      debug: false,\n      data: {\n        env_key: 'ENV_KEY',\n        video_title: 'Example Title'\n      }\n    }\n  }\n});\n\nplayer.src({\n  src: \"{PLAYBACK_ID}\",\n  type: \"video/mux\",\n});\n\n// enable the quality selector plugin\nplayer.httpSourceSelector();\n</script>\n```\n\n\nIf you want to use another plugin but when you load up your page, but the plugin isn't loading up in Video.js, you'll need to configure Webpack, or another bundler specially.\nThis is due to the internals of how Video.js and Video.js kit are built. When using the default build, Video.js kit doesn't use the default Video.js built, but rather Video.js's core.js build. This means that Video.js plugins need to be configured use the same build.\nThis can be done with Webpack's resolve.alias configuration:\n\n```js\nconfig.resolve = {\n  alias: {\n    'video.js': 'video.js/core',\n  }\n};\n```\n\n\nCurrent release: v0.11.0\nView v0.11.0\n\nThis release enables configuring hls.js via Video.js options:\n\n\n```js\nvideojs('mux-default', {\n  html5: {\n    hls: {\n      capLevelToPlayerSize: true\n    }\n  }\n});\n```\n\n\nFor advanced use cases, the hlsjs instance is exposed on the tech.\n\nPrevious releases\n\nv0.10.0\nView v0.10.0\n\n- This release includes [videojs-contrib-quality-levels][] and [videojs-http-source-selector][] by default.\n\nv0.9.3\nView v0.9.3\n\n- Update Video.js version to v7.18.1.\n\nv0.9.2\nView v0.9.2\n\n- Update hls.js to v1.1.5\n\nv0.9.1\nView v0.9.1\n\n- As part of 0.7.0, tighter error handling integration with hls.js made all errors be triggered on the player. This meant that errors that don't inhibit playback and that hls.js handled automatically were treated the same as fatal errors that hls.js doesn't handle automatically. Now, only errors that hls.js considers fatal will trigger an error event.\n\nv0.9.0\nView v0.9.0\n\n- Integrate with videojs-contrib-quality-levels`.\n\nv0.8.0\nView v0.8.0\n\n- Introduce VHS build file\n\nCheck the GitHub releases page for the full version history.\n\n[videojs-http-source-selector]: https://github.com/jfujita/videojs-http-source-selector\n[videojs-contrib-quality-levels]: https://github.com/videojs/videojs-contrib-quality-levels"
  },
  {
    "id": "109-_guides/developer/player-ads",
    "title": "Running ads with Mux Player",
    "path": "_guides/developer/player-ads.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-ads",
    "content": "Mux Player doesn’t have a built-in way to integrate ads. We will show you how this can be achieved though using client side ad insertion with the Google IMA SDK. This guide will demonstrate how you can enable preroll ads, but midroll and postroll ads could also be achieved using this approach.\n\nIf you're unfamiliar with the Google IMA SDK, we recommend reading the documentation as well as the examples in this repository.\n\nWithin web video, ad insertion typically comes in two flavors:\n\n- SSAI - Server Side Ad Insertion: A mechanism to insert advertisements into the linear video stream so that it’s played out _without_ any other needed technology on the viewing side.\n- CSAI - Client Side Ad Insertion: A method whereby the video player requests an ad from an ad server via the video player located inside an application or website. When the ad server has received the ad request from the video player, it sends back an ad and displays it inside the video content.\n\nThe following guide is using vanilla JS, however it can applied to any popular framework (React, Angular, etc.)\n\n1. Set up Mux Player\n\nFirst, make sure you have Mux Player set up on your webpage. Include the following CDN links:\n\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-player\" defer></script>\n```\n\n\nThen add Mux Player within a containing div element. This div element will act as a container for both Mux Player and the Ad layer\n\n\n```html\n<div id=\"mainContainer\">\n    <mux-player\n    playback-id=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n    metadata-video-title=\"Test VOD\"\n    metadata-viewer-user-id=\"user-id-007\"\n    ></mux-player>\n</div>\n```\n\n\n See the related player documentation\n\n2. Include the Google IMA SDK\n\n\n```html\n<script src=\"//imasdk.googleapis.com/js/sdkloader/ima3.js\"></script>\n```\n\n\nWhile developing locally, the newer versions of Google Chrome might block the loading of this script because of the lack of HTTPS/SSL support\n\n3. Create an ad container\n\nWe need to add two container elements. One to contain the ad itself, which will overlay Mux Player, and another to wrap around both of them\n\n\n```html\n<div id=\"mainContainer\">\n    <mux-player\n    playback-id=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n    metadata-video-title=\"Test VOD\"\n    metadata-viewer-user-id=\"user-id-007\"\n    ></mux-player>\n    <div id=\"ad-container\"></div>\n</div>\n```\n\n\nNow we add some CSS to position the ad on top of the player. It's important that the ad-container is the exact same size as the player element, so that ads are displayed at the same size as the video.\n\n\n```css\nmux-player {\n    width: 640px;\n    height: 360px;\n}\n\n#mainContainer {\n    position: relative;\n    width: 640px;\n    height: 360px;\n}\n\n#ad-container {\n    position: absolute;\n    top: 0;\n    left: 0;\n    width: 100%;\n    height: 100%;\n    z-index: 1000;\n}\n```\n\n\n4. Initialize the IMA SDK and handle playback\n\nInitialize the IMA SDK and configure it to use the ad container element we created earlier. The code below initializes the Google IMA SDK for client-side ad insertion. It creates an AdDisplayContainer object, which is used to overlay ads on top of Mux Player. Then, an AdsLoader object is created, which loads the IMA SDK ads. Create an AdsRequest object and request ads using the IMA SDK. You’ll need to have an ad tag URL from your ad server.\n\n\n```javascript\nlet muxPlayer = document.querySelector('mux-player'); // initialize for later use\n\nconst adDisplayContainer = new google.ima.AdDisplayContainer(document.getElementById('ad-container'));\nconst adsLoader = new google.ima.AdsLoader(adDisplayContainer);\nlet adsManager; // initializes the adsManager that get's utilized in later event handlers\n\nadsLoader.addEventListener(google.ima.AdsManagerLoadedEvent.Type.ADS_MANAGER_LOADED, onAdsManagerLoaded, false);\nadsLoader.addEventListener(google.ima.AdErrorEvent.Type.AD_ERROR, onAdError, false);\n\nlet adsRequest = new google.ima.AdsRequest();\nadsRequest.adTagUrl = 'https://pubads.g.doubleclick.net/gampad/ads?iu=/21775744923/external/single_ad_samples&sz=640x480&cust_params=sample_ct%3Dlinear&ciu_szs=300x250%2C728x90&gdfp_req=1&output=vast&unviewed_position_start=1&env=vp&impl=s&correlator=';\n\n// The above is a testing preroll ad. Please fill in your tag URL from your ad server.\n\nadsRequest.linearAdSlotWidth = 640;\nadsRequest.linearAdSlotHeight = 360;\nadsRequest.nonLinearAdSlotWidth = 640;\nadsRequest.nonLinearAdSlotHeight = 150;\n\nadsLoader.requestAds(adsRequest);\n```\n\n\nWhen ads are loaded, initialize the AdsManager to start playing them. This sets up the Google IMA SDK's AdsManager and attaches event listeners to handle ad events. It also initializes and starts the AdsManager, ensuring that ads are played correctly. If an error occurs during initialization or ad playback, the content will be played instead.\n\n\n```javascript\nfunction onAdsManagerLoaded(adsManagerLoadedEvent) {\n    let adsRenderingSettings = new google.ima.AdsRenderingSettings();\n    adsManager = adsManagerLoadedEvent.getAdsManager(muxPlayer, adsRenderingSettings);\n\n    // Add event listeners to the ads manager here\n    adsManager.addEventListener(google.ima.AdErrorEvent.Type.AD_ERROR, onAdError);\n    adsManager.addEventListener(google.ima.AdEvent.Type.CONTENT_PAUSE_REQUESTED, onContentPauseRequested);\n    adsManager.addEventListener(google.ima.AdEvent.Type.CONTENT_RESUME_REQUESTED, onContentResumeRequested);\n\n    try {\n        adsManager.init(640, 360, google.ima.ViewMode.NORMAL);\n        adsManager.start();\n    } catch (adError) {\n        muxPlayer.play(); // If ad fails, continue with the content\n    }\n}\n\nfunction onAdError(adErrorEvent) {\n    console.log(adErrorEvent.getError());\n    if (adsManager) {\n        adsManager.destroy();\n    }\n    muxPlayer.play(); // Continue with the content\n}\n\nfunction onContentPauseRequested() {\n    muxPlayer.pause();\n}\n\nfunction onContentResumeRequested() {\n    muxPlayer.play();\n}\n```\n\n\nUnder adsManager.init(640, 360, google.ima.ViewMode.NORMAL), the values of 640 and 360 should match the values of the ad and main container dimensions. Otherwise you will see some unwanted results with the ad dimensions\n\n5. Link Mux Player events with IMA SDK\n\nThese event listeners synchronize ad playback with video playback, ensuring that everything is tied together.\n\n\n```javascript\nmuxPlayer.addEventListener('play', function () {\n    adDisplayContainer.initialize();\n});\n\nmuxPlayer.addEventListener('pause', function () {\n    if (adsManager) {\n        adsManager.pause();\n    }\n});\n\nmuxPlayer.addEventListener('playing', function () {\n    if (adsManager) {\n        adsManager.resume();\n    }\n});\n```\n\n\n6. Start the ad and content\n\nEnsure the ad is initialized and content plays accordingly.\n\nPlease be mindful when testing if you're using an adblocker as you will not receive any ads"
  },
  {
    "id": "110-_guides/developer/player-advanced-usage",
    "title": "Advanced usage of Mux Player",
    "path": "_guides/developer/player-advanced-usage.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-advanced-usage",
    "content": "Listen for events\n\nMux Player emits all of events available on the HTML5 video element.\n\nEvents are unavailable if you are using the Mux Player HTML embed through player.mux.com.\n\nFor example, if you want to keep track of how much of a particular video a user has watched, you probably want to use the timeupdate event like this:\n\nHTML element\n\nIn React, the events are camel-cased and prefixed with on\\*. For example timeupdate becomes onTimeUpdate:\n\nReact\n\n\n```jsx\nfunction saveWatchProgress(event) {\n  /* event */\n}\n\n<MuxPlayer onTimeUpdate={saveWatchProgress} />;\n```\n\n\nSecure your playback experience\n\nMux offers a couple of ways to secure your media content:\n- using signed URLs, which ensures only people with a valid, unexpired token can load your video in allowed playback contexts\n- using Digital Rights Management\n\nBoth options are easy to use with Mux Player and are discussed below.\n\nUse signed URLs\n\nIf you followed the guide for Secure video playback then you are using signed URLs and a few extra steps are required to use Mux Player (or any player for that matter).\n\nFirst off, you should already be creating JSON Web Tokens (JWTs) on your server. If you're not doing that already, head over to that guide and do that part first.\n\nNote that JWTs are granular, so a unique token is used for each resource:\n\n- Playback is used to get the actual video.\n- Thumbnail is used to get a still image from the video. Mux Player uses it for a poster image\n- Storyboard is used for timeline hover previews. This only works for on-demand video, live streams aren't supported.\n- DRM is used for playing DRM-protected content. See the section below.\n\nEach JWT will look something like this below. These examples were created with playback ID qIJBqaJPkhNXiHbed8j2jyx02tQQWBI5fL6WkIQYL63w.\n\nPlayback token:\n\n\n```\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6ImFkamYzb2JpYURUcEF0QVlpS3NCMkpvRlkwMXBpbEJMTHdYcUQzaHpJYURJIn0.eyJleHAiOjE5NjE2NDY0MDMsImF1ZCI6InYiLCJzdWIiOiJxSUpCcWFKUGtoTlhpSGJlZDhqMmp5eDAydFFRV0JJNWZMNldrSVFZTDYzdyJ9.mukZou10_iwaqPeHVFbXwTZShMK1D8kWpFAFOl6bwuIMB7hx0bAqscZxj5FwrIB8dzB6s_9YtJEEVXcR6ezxOhOc_y2ij1XM4YQYCuGH-elJc3rapHbahv2K7L_asz9Bdu1Ld6i6Ux7keNpEuGSYCDmsPmvdII7_XAPmzU01ZTvaXqCgzCY2PO7xz6z3hu1HOww2eL41TSif_Zu0okNZlhfHE9U-nyr4OVpuS9Q-rTtVvfE2ILSd9Ezt02AuOK-JkBCeR3Xf-UrbXB33ZFHLJrYVA-B516Iym0CGRfVssZsAn80_PNaxS_3M_OmVzyaDJ4zudb-YjGcaNl0yf96h6w\n```\n\n\nThumbnail token:\n\n\n```\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6ImFkamYzb2JpYURUcEF0QVlpS3NCMkpvRlkwMXBpbEJMTHdYcUQzaHpJYURJIn0.eyJleHAiOjE5NjE2NTkzMzAsImF1ZCI6InQiLCJzdWIiOiJxSUpCcWFKUGtoTlhpSGJlZDhqMmp5eDAydFFRV0JJNWZMNldrSVFZTDYzdyJ9.zQ0tDimpgu7nsT9Tb7GBgitMpYSbLBodwS-fSc7U0K0WT-giCUgxXXSqXquwpHMjEEfSuCsCU3Y1gq2P7WaJUBGTOTLKT5GOwyhjeoJzTPXEQqW7T-tpKXhjEDVwy_H2UPNVdA9ZALos5R9rrWyiTQA53sxT56FWy-IhvaISpiB16nzankRKCAo98kh6lloexE8p3lXnUhLwIK8Hqco4hRmHSmWqUndnJrbq0_kag0o8R0drffSMj6CvKas8_f6v3MtHXDhW0JkJ1TZKwICt7W-jrSyMfhgAb9wltBCUXdNHYvQTXkFfFnsI1R-BuZodQL2zN3pVBqzuhQA0UPADMw\n```\n\n\nStoryboard token (only needed for on-demand):\n\n\n```\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6ImFkamYzb2JpYURUcEF0QVlpS3NCMkpvRlkwMXBpbEJMTHdYcUQzaHpJYURJIn0.eyJleHAiOjE5NjE2NTkzMTQsImF1ZCI6InMiLCJzdWIiOiJxSUpCcWFKUGtoTlhpSGJlZDhqMmp5eDAydFFRV0JJNWZMNldrSVFZTDYzdyJ9.QxvtM-FBakS8IPl_mZloBKLKyHRU8md7IbSifAYbAVHrLwUre3-CXlOcsd6sKi0hVen_DnSqQeuuFTYF6o2TeS31gnBsf5U4W7JDpOjxAepj4ODM6bpPJBu6XDpZmMTduuwVrIXP9pQWSwiHSQ93hk6RR17YrPgGz6sCXIL5gt0re_WqkSEazwYEscu9eByMN3F_sM7W830C7Wzeatb1TMeEf6wQhbpKABLB33VM0FOuM5ojjI9DWmDhJksfFVrOxaZtoju4hjiWQtNPVBCFP28J9LHNLA7brRXvDGaIUxHG5-vrcVuImlghdWgPyrAOb0lWYSiklYx2ObHhNWJK1g\n```\n\n\nWhen you have generated the 3 tokens, pass them into Mux Player:\n\n<CodeExamples\n  product=\"player\"\n  example=\"tokens\"\n  exampleOrder=\"html,react,embed\"\n/>\n\nIf you are using JavaScript and the Mux Player Web Component or React component, you can use the tokens property too:\n\n\n```javascript\nconst muxPlayer = document.querySelector(\"mux-player\");\nmuxPlayer.tokens = {\n  playback: \"eyJhbGciOiJSUzI1NiI...\",\n  thumbnail: \"eyJhbGciOiJSUzI1N...\",\n  storyboard: \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsI...\",\n};\n```\n\n\nMux Player send errors to Mux Data when tokens are incorrect. The most common error cases with signed URLs that Mux Player detects are:\n\n- Playback ID mismatch\n- Expired token\n- Malformatted token\n\nThese errors will be logged to the browser console and sent to your Mux Data dashboard.\n\nUse Digital Rights Management (DRM)\n\n  This feature is currently in beta. Learn more about DRM.\n\n  To play DRM protected content on iOS and iPadOS devices the device should be running the current minor and patch version of iOS or iPadOS.\n\n  We strongly recommend that viewers use the latest version of iOS/iPadOS 17 or 18 when viewing DRM protected content.\n\n  Playing DRM protected content on an OS version that is not the latest minor and patch version of a major release is known to result in playback failures.\n\nIf you've setup your playback ID to be DRM-protected, playback is as simple as adding the DRM token to your set of tokens used.\n\n<CodeExamples\n  product=\"player\"\n  example=\"tokensDrm\"\n  exampleOrder=\"html,react,embed\"\n/>\n\nIf you are using JavaScript and the Mux Player Web Component or React component, you can use the tokens property too:\n\n\n```javascript\nconst muxPlayer = document.querySelector(\"mux-player\");\nmuxPlayer.tokens = {\n  playback: \"eyJhbGciOiJSUzI1NiI...\",\n  drm: \"eyJhbGciOiJSUzI1NiIs...\",\n  thumbnail: \"eyJhbGciOiJSUzI1N...\",\n  storyboard: \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsI...\",\n};\n```\n\n\nControlling an iframe-embedded Mux Player with Player.js\nMux Player embedded within an iframe with player.mux.com supports the Player.js spec. This means you can control the player from your own window's JavaScript. See the Player.js docs for more information.\n\nPreloading assets\n\nBy default preload will behave similar to the HTML5 ` element.\n\nUse the preload= attribute with values of \"none\", \"metadata\" or \"auto\".\nOr omit it for the default behavior.\n\nWhen there is no preload attribute, the player will use the behavior that the browsers set initially.\nMost browsers use \"auto\", but some (like Chrome) use \"metadata\" instead.\nOn mobile devices, preload is always none.\nFor the most consistent user experience, we recommended providing the preload attribute.\n\nThe value \"auto\" will start loading the video as soon as possible and give the user the best experience with the shortest startup time.\n\nIf you want to preserve bandwidth (and delivery cost) set preload=\"none\" (load nothing until the user tries to play) or preload=\"metadata\" (load the minimum amount of data for the media to get basic information like its duration).\n\nThe tradeoff with using preload=\"metadata\" or preload=\"none\" is that when the user plays the video they will experience a slower startup time because the video has to load before playback can start. You'll see the slower startup time reflected in your Mux Data dashboard and this will negatively impact the Overall Viewer Experience metric.\n\nUse custom video domains\n\nBy default, all Mux Video assets will be hosted on mux.com. This includes things like posters, storyboards, and media sources.\n\nCustom Domains, is a feature which allows you to stream these assets from a domain of your choice.\n\nOnce you have your custom domain set up, provide it via the custom-domain attribute or customDomain property. If your custom domain is media.example.com then internally Mux Player will take that value and expand it to image.media.example.com for images and stream.media.example.com for video.\n\n<CodeExamples\n  product=\"player\"\n  example=\"customDomains\"\n  exampleOrder=\"html,react,embed\"\n/>\n\nIf you are using JavaScript and the Mux Player Web Component or React component, you can use the customDomain property too:\n\n\n```javascript\nconst muxPlayer = document.querySelector(\"mux-player\");\nmuxPlayer.customDomain = \"media.example.com\";\n```\n\n\nAccess the underlying video element\n\nThe media.nativeEl property is a reference to the underlying video element. When using the Mux Player Web Component or React component, Yyu can use this to access the video element's properties and methods.\n\n\n```jsx\n  <MuxPlayer\n    playbackId=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n    ref={(muxPlayerEl) => console.log(muxPlayerEl.media.nativeEl)}\n    metadata={{\n      video_id: \"video-id-54321\",\n      video_title: \"Test video title\",\n      viewer_user_id: \"user-id-007\",\n    }}\n  />\n```\n\n\nChange playback engine\n\nMux Player will automatically handle Adaptive Bitrate Streaming with your Mux Asset. For a beginner's guide on how this works, howvideo.works is an informational site that explains the basic concepts. Under the hood, Mux Player uses HLS.js and Mux Player will pick the optimal HLS.js configuration based on the provided stream-type.\n\nOn iOS, iPadOS, and MacOS, Mux Player will use Apple's native HLS streaming engine. On Android, Mux Player will use HLS.js.\n\nIt is not recommended, but if you have a good reason to control whether Mux Player uses HLS.js (MSE, Media Source Extension) or native HLS playback you can with the prefer-playback attribute (in React preferPlayback). Values can be \"mse\" or \"native\". When a value is provided for prefer-playback, Mux Player will use that playback strategy if available.\n\nNote that setting the prefer-playback attribute should be done with caution. If you are setting this, make sure you thoroughly test playback on the various operating systems and browsers that Mux Player will be running in. Also, keep an eye on Mux Data to verify that your playback metrics are on track.\n\nRe-using player instances\n\nMux Player instances can be re-used by re-setting the playback-id.\n\nIn React, this is done by changing the playbackId prop to a new value.\n\nIn the web component, this can be done by either calling setAttribute with a new value for the playback-id attribute or by assigning the playbackId property. Both are equally valid ways of interacting with the  element instance.\n\n\n```js\nconst muxPlayer = document.querySelector('mux-player');\n\n// using setAttribute\nmuxPlayer.setAttribute('playback-id', 'new-playback-id-xxx');\n// using the `playbackId` prop\nmuxPlayer.playbackId = 'new-playback-id-xxx';\n```\n\n\nDebugging\n\nAdd the debug attribute or React prop in order to print verbose logging to the developer console. This will enable verbose logging from:\n\n- Mux Player itself (prefixed with [mux-player])\n- HLS.js\n- Mux Data\n\nNote that this must be set before setting a playback-id to take full advantage of debug logging.\n\nDisabling cookies\n\nEven though Mux Data cookies do not contain any personally identifiable information (PII) and are used for more reliable and informative QOE metrics, there are times when you may want or need cookies to be disabled.\n\nIn those cases, you can use the disable-cookies attribute or disableCookies React prop to turn off use of cookies by Mux Data. Note this must be set before setting a playback-id to take effect.\n\nFor more on the use of cookies in Mux Data, see the docs.\n\nCustom storyboards\n\nBy default Mux Player will use the storyboard WebVTT text track that corresponds to your plaback-id\n\nhttps://image.mux.com/{PLAYBACK_ID}/storyboard.vtt?format=webp\n\nIf you want to use a different WebVTT source file for your storyboard, you can use the storyboard-src attribute or storyboardSrc React prop to override it. Keep in mind that the WebVTT source file must conform to our expectations for storyboards.\n\nAdd chapters and time-based metadata\n\nThe Mux Player Web Component and React component support both chapters and time-based metadata (cue points). Chapters visually split the timeline into sections with titles that users can click to jump to. Cue points allow you to associate custom metadata with ranges of time in the timeline. Both support getting a callback when the chapter or cue point has become active. You can use either individually or both at the same time, depending on your use-case.\n\nIf you omit endTime from a cue point or chapter, it will automatically end when the next one begins by joining them together without gaps. If you include an endTime, you can have gaps between your chapters or cue points.\n\nBoth chapters and cue points will be removed if you unload the media or change the current playback ID.\n\nChapters example\n\nA chapter is defined as: {startTime: number; endTime?: number; value: string}, with the value containing the chapter's title and endTime being optional. Both startTime and endTime are in seconds.\n\n\n```js\nconst muxPlayerEl = document.querySelector('mux-player');\n\nfunction addChaptersToPlayer() {\n  // Chapters can also specify an `endTime` if we don't want them to automatically join up\n  muxPlayerEl.addChapters([\n    { startTime: 1, value: 'Chapter 1' },\n    { startTime: 3, value: 'Chapter 2' },\n    { startTime: 10, value: 'Chapter 3 - will span to the end' },\n  ]);\n}\n\n// NOTE: We need to wait until the player has loaded some data first\n// otherwise, we have no media to associate them with\nif (muxPlayerEl.readyState >= 1) {\n  addChaptersToPlayer();\n} else {\n  muxPlayerEl.addEventListener('loadedmetadata', addChaptersToPlayer, { once: true });\n}\n\nmuxPlayerEl.addEventListener('chapterchange', () => {\n  console.log(muxPlayerEl.activeChapter);\n  console.log(muxPlayerEl.chapters);\n});\n```\n\n\nChapters currently work with streaming assets (video on demand) and audio, but not live content.\n\nTime-based metadata (cue points)\n\nA CuePoint is defined as: { startTime: number; endTime?: number; value: any; }, with the value being a JSON-serializable value that you want to associate with that range of time. Like chapters, start and end times are in seconds and endTime is optional.\n\n\n```js\nconst muxPlayerEl = document.querySelector('mux-player');\nfunction addCuePointsToPlayer() {\n  // CuePoints can also specify an `endTime` if we don't want them to automatically join up\n  const cuePoints = [\n    { startTime: 1, value: 'Simple Value' },\n    { startTime: 3, value: { complex: 'Complex Object', duration: 2 } },\n    { startTime: 10, value: true },\n    { startTime: 15, value: { anything: 'That can be serialized to JSON and makes sense for your use case' } }\n  ];\n\n  muxPlayerEl.addCuePoints(cuePoints);\n}\n\n// We're using `duration` and `'durationchange'` to determine if the `<mux-player>` element has loaded src.\n// This gives us the opportunity to compare our CuePoints against the duration of the media if needed.\n// You could use other events, such as `'loadedmetadata'` if that makes more sense for your use case.\nif (playerEl.duration) {\n  addCuePointsToPlayer();\n} else {\n  muxPlayerEl.addEventListener('durationchange', addCuePointsToPlayer, { once: true });\n}\n\nmuxPlayerEl.addEventListener('cuepointchange', () => {\n  console.log(muxPlayerEl.activeCuePoint);\n  console.log(muxPlayerEl.cuepoints);\n});\n```\n\n\nIf cue points are specified without an endTime, then like chapters they will automatically be joined up end-to-end. This means that if a user seeks anywhere between two cue points, the cuepointchange event will fire and the activeCuePoint will be the earlier cue point. If you only care about the activeCuePoint when the currentTime is roughly the same as the startTime of a cue point, you can add some custom logic to account for that, e.g.:\n\n\n```js\nfunction cuePointChangeListener() {\n  // Only do something with the activeCuePoint if we're \"near\" its `startTime`.\n  const cuePointBuffer = 1; // how close the playhead needs to be to the CuePoint, in seconds\n  if (Math.abs(muxPlayerEl.currentTime - muxPlayerEl.activeCuePoint.startTime) <= cuePointBuffer) {\n    console.log('Active CuePoint playing near its time!', muxPlayerEl.activeCuePoint);\n  }\n}\n```\n\n\nSynchronize video playback\n\nTo facilitate synchronizing video playback across players, Mux Player exposes currentPdt and getStartDate().\n\nIf the stream includes Program Date Time tags, currentPdt and getStartDate() will return a [Date][] object that corresponds to the PDT at the current time or at the begining of the stream.\nIf there is no PDT, or if the video hasn't loaded yet, currentPdt and getStartDate() will return an Invalid Date object.\n\nSee Synchronize video playback for more information.\n\n  currentPdt and getStartDate() currently require that Slates are enabled on your stream.\n  If Slates are not enabled, it is possible that the times provided are not accurate.\n\nRefer to this sample for the usage below:\n\n```text\n#EXTM3U\n#EXT-X-VERSION:7\n#EXT-X-TARGETDURATION:2\n#EXT-X-MAP:URI=\"https://chunk-gce-us-east1-production.cfcdn.mux.com/v1/chunk/3aJUOua6jsMHYybcqXRBpcXH82aCYXTu02TPTKHzIokndAPmz300ZThlCZbeNAy1t73003iytFZNJdjcvjTsOrCVTaGZgQ9J00uU/18446744073709551615.m4s?skid=default&signature=NjBmMjFkODBfYWVhMjIyZTdmMDU0ZmI0YWU2ZWJkZTJiYTY4MzhmYWQzNWQ2YzMyMTVlYjdjNmM0NzZiZjBmZGU0ODU1MTUyNQ==\"\n#EXT-X-PLAYLIST-TYPE:VOD\n\n#EXT-X-PROGRAM-DATE-TIME:2021-06-28T17:53:25.533+00:00\n#EXTINF:2,\nhttps://chunk-gce-us-east1-production.cfcdn.mux.com/v1/chunk/3aJUOua6jsMHYybcqXRBpcXH82aCYXTu02TPTKHzIokndAPmz300ZThlCZbeNAy1t73003iytFZNJdjcvjTsOrCVTaGZgQ9J00uU/0.m4s?skid=default&signature=NjBmMjFkODBfOWJkMzMyMTc5YzgwY2VmMTdlYzIwODgzZGI2NWFiMThiM2U1NDM0NzM0NDZhMmQwOThhZmI0NDQ5OWY5N2VmMA==\n\n#EXT-X-PROGRAM-DATE-TIME:2021-06-28T17:53:27.533+00:00\n#EXTINF:2,\nhttps://chunk-gce-us-east1-production.cfcdn.mux.com/v1/chunk/3aJUOua6jsMHYybcqXRBpcXH82aCYXTu02TPTKHzIokndAPmz300ZThlCZbeNAy1t73003iytFZNJdjcvjTsOrCVTaGZgQ9J00uU/1.m4s?skid=default&signature=NjBmMjFkODBfMjA1ZWNmYzgzYWRhMzNjMTY5YmEyYmM2NzE4MDk5N2I1MWE3NzhjODlhNGIzNWI3NGIwNTA5ZTIxOWQyNjI5OQ==\n\n#EXT-X-PROGRAM-DATE-TIME:2021-06-28T17:53:29.533+00:00\n#EXTINF:2,\nhttps://chunk-gce-us-east1-production.cfcdn.mux.com/v1/chunk/3aJUOua6jsMHYybcqXRBpcXH82aCYXTu02TPTKHzIokndAPmz300ZThlCZbeNAy1t73003iytFZNJdjcvjTsOrCVTaGZgQ9J00uU/2.m4s?skid=default&signature=NjBmMjFkODBfZTIyOTA5YWFjZjMzYTY4MzQ4YWEzZDBiNDkyODk1NTg2ODE2M2YwZjI3NmY2MTVhOTM5MTA2MzQ4ODIyNTNkOQ==\n\n#EXT-X-PROGRAM-DATE-TIME:2021-06-28T17:53:31.533+00:00\n#EXTINF:2,\nhttps://chunk-gce-us-east1-production.cfcdn.mux.com/v1/chunk/3aJUOua6jsMHYybcqXRBpcXH82aCYXTu02TPTKHzIokndAPmz300ZThlCZbeNAy1t73003iytFZNJdjcvjTsOrCVTaGZgQ9J00uU/3.m4s?skid=default&signature=NjBmMjFkODBfNDRkZTNhYTE5M2RhYTA4MTA4MWFkODc0YzgyMDcyMGMwODFmZWIxOGRiNWM4YzJhMTM0YTNiNGRhYmYyMWE1Nw==\n\n#EXT-X-ENDLIST\n```\n\n\ncurrentPdt\n\nThis will return a JavaScript [Date][] object that is based on the currentTime.\nIf there is no PDT in the stream, an invalid date object is returned.\n\n\n```js\nconst player = document.querySelector('mux-player');\n// assuming the above stream, the initial currentPdt would be\nplayer.currentPdt;\n// Mon Jun 28 2021 13:53:25 GMT-0400 (Eastern Daylight Time)\nplayer.currentPdt.getTime();\n// 1624902805533\n\n// now if we seek forward, by 10 seconds\nplayer.currentTime = 10;\n\nplayer.currentPdt;\n// Mon Jun 28 2021 13:53:35 GMT-0400 (Eastern Daylight Time)\nplayer.currentPdt.getTime();\n// 1624902815533\n```\n\n\ngetStartDate()`\n\nThis will return a JavaScript [Date][] object that is based on the beginning of the stream.\nThis method is a reflection of the HTML specified method.\n\n\n```js\nconst player = document.querySelector('mux-player');\n// assuming the above stream, getStartDate() would return\nplayer.getStartDate();\n// Mon Jun 28 2021 13:53:25 GMT-0400 (Eastern Daylight Time)\nplayer.getStartDate().getTime();\n// 1624902805533\n// notice that when currentTime is 0, getStartDate() is equivalent to currentPdt\n\n// now if we seek forward, by 10 seconds\nplayer.currentTime = 10;\n\nplayer.getStartDate();\n// Mon Jun 28 2021 13:53:25 GMT-0400 (Eastern Daylight Time)\nplayer.getStartDate().getTime();\n// 1624902805533\n// notice that even though we seeked forward, we still get the same value.\n```\n\n\n[Date]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date\n\nFull API reference\n\nAny features or settings not mentioned above can be found in our full API reference covering all of the available events, attributes, properties, and methods exposed by the player."
  },
  {
    "id": "111-_guides/developer/player-core-functionality",
    "title": "Core functionality of Mux Player",
    "path": "_guides/developer/player-core-functionality.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-core-functionality",
    "content": "Mux Platform integration\n\nMux Player is built for playing assets hosted with Mux Video. Features like timeline hover previews and automatically pulling poster images work with minimal configuration because the video is hosted by Mux.\n\nMux Player will use the optimal HLS.js settings based on the type of stream being played, on-demand or live. New versions of Mux Player will contain upgraded versions of HLS.js that are known to be stable versions and tested with Mux Player.\n\nMux Data integration\n\nMux Player is integrated with Mux Data automatically to measure the performance and quality of experience. See the Understand metric definitions guide to learn more about the metrics that are tracked with Mux Data.\n\nYour Mux Data environment will be inferred from the playback ID provided to Mux Player. No configuration is necessary. If you would like to override that default and send the video views to a specific Mux environment, you can pass the env-key (HTML element) attribute or envKey (React) prop.\n\nResponsiveness\n\nMux Player has different UI permutations based on stream type (on-demand or live), feature support (like AirPlay), and player size.\n\nNote that the responsiveness of Mux Player is based on the size of the container that it is being rendered in, not the viewport size. If you have a collection of small players in a large viewport, the layout of the controls for each player will be sized appropriately.\n\n<InteractiveCodeExample\n  product=\"player\"\n  example=\"coreResponsiveness\"\n/>\n\nHere is a CodeSandbox environment you can view samples in\n\nControls and UI\n\nMux Player will show or hide controls based on availability.\n\nOn iPhone browsers Mux Player uses Apple's fullscreen functionality.\n\nOn iPhone and iPad browsers, the volume slider is not present. Volume level must be controlled via the hardware buttons. This is a restriction of iOS and iPadOS.\n\nThe fullscreen button will not show if fullscreen functionality is not available on the page. For example, if Mux Player is embedded inside of an iframe that does not include the allow=\"fullscreen\" attribute. This is currently the case on CodeSandbox examples and other similar code testing platforms.\n\nIf you are embedding Mux Player in an iframe, use the ` in order to access fullscreen functionality.\n\nYou'll notice the controls are different for on-demand and live stream types.\n\nQuality selector\n\nBy default Mux Player will show a quality selector in the control bar. This is not strictly necessary, the player will use an adaptive bitrate algorithm to determine the highest quality that can be streamed smoothly. However, in some scenarios users may want to pin to a higher rendition for text legibility or because they simply have a preference for viewing the higher quality resolution than what the adaptive bitrate algorithm determines. In these scenarios it's important to understand that there is a tradeoff. If the user is selecting a higher rendition than what the player would naturally use, they will likely experience rebuffering because the available bandwidth is lower than the quality they want to view. That is perfectly okay, but they have to be willing to make that tradeoff.\n\n<Image\n  src=\"/docs/images/mux-player-quality-selector.png\"\n  width={342}\n  height={358}\n  alt=\"Mux Player quality selector\"\n/>\n\nCaveats with quality selector\n\nThere's some details to understand about when the quality selector will be available depending on the device, operating system and browser. The quality selector is only available in environments that use Media Source Extensions (a.k.a. MSE) to power the streaming.\n\nFor Mux Player, that means:\n\n- The quality selector is available in all non-Safari desktop browsers because Mux Player uses MSE in these browsers\n- The quality selector is available on Android, because Mux Player uses MSE in Android browsers.\n- The quality selector is not available by default on MacOS Safari and any iPadOS browser because Mux Player uses Apple's internal HLS playback engine on these platforms. However, MSE is supported on these platforms so the quality selector can be enabled by forcing MSE with the attribute playback-engine=\"mse\" (web component & iframe embed) or playbackEngine=\"mse\" (React). See more here about changing the default playback engine.\n- The quality selector is not available and cannot be enabled on any iOS browsers because MSE is not supported on iOS (instead iOS requires that HLS playback is done via Apple's internal HLS playback engine, which we do not have programmatic access to)\n\nIf you prefer to hide the quality selector all together, you can do that in the web component or React with the CSS variable which sets the display property on the control:\n\n\n```css\nmux-player {\n  --rendition-menu-button: none;\n}\n```\n\n\nSee more about styling with CSS in the Customize look and feel guide\n\nMulti-track audio selector\n\nBy default, if your stream has multiple audio tracks (e.g. descriptive audio, dubs for another language, etc.), Mux Player will show an audio track selector in the control bar. If there is only one or no audio track, the control will be automatically hidden.\n\n<Image\n  src=\"/docs/images/mux-player-audio-track-selector.png\"\n  width={326}\n  height={302}\n  alt=\"Mux Player audio track selector\"\n/>\n\nIf you prefer to hide the audio track selector all together, you can do that in the web component or React with the CSS variable which sets the display property on the control:\n\n\n```css\nmux-player {\n  --audio-track-menu-button: none;\n}\n```\n\n\nFor more details on how to use multi-track audio, including adding it via Mux Video, check out our blogpost.\n\nChromecast\n\nChromecast support is built-in.\n\n- For Mux player >= v2.3.0 no additional configuration is needed.\n- For Mux player \\ of your webpage.\n\n\n```html\n<script\n  defer\n  src=\"https://www.gstatic.com/cv/js/sender/v1/cast_sender.js?loadCastFramework=1\"\n></script>\n```\n\n\nWhen this script is loaded and a Chromecast is detected on the network then Mux Player will show the Chromecast button in the control bar.\n\nNote that the default Chromecast receiver app does not currently support low-latency Live Streams. If you have your own receiver app that you want to use instead of the default Chromecast receiver app you can over-ride the variable: chrome.cast.media.DEFAULT_MEDIA_RECEIVER_APP_ID to point to your receiver app ID.\n\nLive Stream playback\n\nWhen live streaming with Mux you have 2 options for viewers:\n\n- Non-DVR mode: This is most common. Use the playback_id associated with the Live Stream for playback. Non-DVR mode keeps viewers on the \"live edge\" of the live content and does not allow them to seek backwards while the stream is live.\n- DVR mode: This is less common, but might be what you want depending on the use case. Use the playback_id associated with the Asset that corresponds to the Live Stream for playback. DVR mode allows users to seek backwards while the stream is still live.\n\nFor more information about non-DVR mode and DVR mode and some of the tradeoffs to consider, take a look at this guide.\n\nWhen viewing live streams with Mux Player you have 2 options:\n\n1. Use the playback_id associated with the Live Stream itself.\n2. Live Streams created in Mux have a corresponding Asset. Use the playback_id associated with the Asset in order to view the live stream in DVR-mode.\n\nWhen using DVR-mode in Mux Player, the UI will show a timeline for users to scroll back to the beginning of the Live Stream while the Live Stream is still active.\n\nTimeline hover previews\n\nTimeline hover previews show a small thumbnail of the video content at a given timestamp. They help to provide a contextual visual for the viewer based on where their cursor is positioned over the timeline.\n\nWhen you play back a video hosted on Mux using Mux Player, you’ll see built-in timeline hover previews for the video with no extra work on your end.\n\n<Image\n  src=\"/docs/images/mux-player-desktop-on-demand.png\"\n  width={799}\n  height={464}\n  alt=\"Timeline hover preview example\"\n/>\n\nAccessibility\n\nMux Player has taken steps to being fully WCAG AA compliant. At this time Mux Player supports:\n\n- Keyboard navigation\n- Screen reader compatibility with the Accessibility Object Model\n- Closed captions / subtitles will show by default (if the video has them)\n\nMake sure to take accessibility into consideration when customizing Mux Player. See the guide for customizing the look and feel of Mux Player to change things like primary color, secondary color, or styling with CSS.\n\nWhen setting color variables and changing styles make sure your implementation meets the contrast ratio requirements for WCAG 2.1.\n\nError handling\n\nMux Player will internally make every attempt to recover from errors and maintain smooth playback.\n\nWhen Mux Player encounters unrecoverable fatal errors, it will try to:\n\n1. Make it clear to the viewer where the error is coming from and what, if anything, they can do about it.\n2. Provide context for a developer to debug and prevent the error from happening in the future. Developer logs prefixed with [mux-player] will contain debugging details and a link to more information.\n3. The error will be tracked with details in your Mux Data dashboard.\n\nAudio player\n\nIf you have an audio-only Mux asset, you can set the audio attribute on mux-player to display the audio player. You can also add the audio attribute to a video asset to make a video look like an audio player.\n\n<InteractiveCodeExample\n  product=\"player\"\n  example=\"coreAudio\"\n/>\n\nAutoplay\n\nLike the native ` element, Mux Player supports the standard autoplay attribute.\n\n\n```html\n<mux-player\n  playback-id=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n  autoplay\n></mux-player>\n```\n\n\nThe main difference between this and the native autoplay attribute when being used on a  element is that Mux Player is explicitly calling .play() on the underlying video, which has a better chance of autoplay working.\n\nCheck out our general autoplay guide for more details on why autoplay doesn't always work\n\nThe Mux Player autoplay attribute also supports some additional values:\n\n- autoplay=\"muted\" - will first attempt to mute the audio before calling .play() on the video, increasing the odds of successful playback\n- autoplay=\"any\"` - will attempt playback with the currently set player options. If this fails it will fall back to trying again after muting the audio"
  },
  {
    "id": "112-_guides/developer/player-customize-look-and-feel",
    "title": "Customize the look and feel of Mux Player",
    "path": "_guides/developer/player-customize-look-and-feel.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-customize-look-and-feel",
    "content": "Mux Player is a fully-featured player out of the box that is made to look good and be fully functional and responsive for different screen sized. You can customize things on Mux Player like the colors and which controls are showing up.\n\nIf you want to go further with customization on things like icons, breakpoints, or where controls are shown, you will want to go down the path of using a different theme or creating your own theme.\n\nCustomize the poster image\n\nBy default Mux Player will pull the default poster image from the middle of the video based on the Playback ID that you provide. The default poster image is the mid-point of the Mux asset.\n\nhttps://image.mux.com/{PLAYBACK_ID}/thumbnail.jpg\n\nIf you want to change the poster image, you have two options:\n\n1. Pass in thumbnail-time (React: thumbnailTime) with the value in seconds of the thumbnail that you want to pull from the video.\n\n   - The thumbnail-time attribute (React: thumbnailTime) are only available if you're NOT using Signed URLs.\n   - If you _are_ using Signed URLs you'll need to add the time= parameter to your signed token (see the Usage with signed URLs guide).\n\n2. Use the poster= attribute.\n   - You can set any arbitrary image URL the same way you would do with the HTML5 ` element. For the best viewer experience, your poster image should match the aspect ratio of the video.\n\nProvide a placeholder while the poster image loads\n\nWhile the poster image loads, Mux Player will display the contents of the placeholder= attribute. Consider using a Data URL so that the placeholder is immediately available without a network request.\n\nMux Player embedded in an iframe through player.mux.com will automatically generate a Data URL placeholder for you.\n\nIf you are generating your pages with a Node.js server (like Next.js), you can generate Data URLs for Mux Videos with the @mux/blurup package.\n\nThe Data URLs generated by @mux/blurup contain lightweight multicolor gradients that visually represent what the default poster image will look like once it has fully loaded.\n\nFor example:\n\n<MultiImage\n  images={[\n    { src: \"/docs/images/blurup-loading.png\", width: 409, height: 230 },\n    { src: \"/docs/images/blurup-loaded.png\", width: 409, height: 227 },\n  ]}\n/>\n\n\n```js\n// Server-Side\nimport { createBlurUp } from '@mux/blurup';\n\nconst options = {};\nconst muxPlaybackId = 'O6LdRc0112FEJXH00bGsN9Q31yu5EIVHTgjTKRkKtEq1k';\n\nconst getPlaceholder() = async () => {\n  const { blurDataURL, aspectRatio } = await createBlurUp(muxPlaybackId, options);\n  console.log(blurDataURL, aspectRatio);\n  // data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"100%\" ...\n};\n```\n\n\n\n```html\n<!-- Client-Side -->\n<mux-player\n  playback-id=\"{playbackId}\"\n  placeholder=\"{blurDataUrl}\"\n  style=\"aspect-ratio: {aspectRatio}\"\n></mux-player>\n```\n\n\nIf you change the thumbnail time with thumbnailTime, you should also pass a time configuration to createBlurUp(playbackId, { time: customThumbTime }) to generate the correct placeholder.\n\nYou can learn more about @mux/blurup on GitHub.\n\nIf you have a client-side-only application and you _can't_ generate a blur placeholder, you might want to pass a smaller resolution poster image URL as the placeholder value that will load more quickly than the final hi-res poster.\n\nThis placeholder is provided for you if you're using Mux Player in an iframe through player.mux.com.\n\nAdd a video title\n\nUse the title attribute to add a title in the top left corner on Mux Player. This title is visible when the player is wide enough to accommodate it. Note that this is different that metadata-video-title, which is a Mux Data metadata field.\n\nStyle with CSS\n\nThe Mux Player Web Component can be styled and positioned with CSS just like you would any other HTML element. For example:\n\n\n```css\nmux-player {\n  width: 100%;\n  max-width: 800px;\n  margin: 40px auto;\n}\n```\n\n\nIn React, you can style the  component the same way you style other components; with styled-components or directly with the style= prop.\n\nYou can not style Mux Player with CSS if you are using the HTML embed through player.mux.com.\n\nAspect ratio\n\nThe Mux API will provide you the aspect ratio of your video in the form of w:h. You should save this aspect_ratio in your database or CMS alongside the playback_id and other asset details. Then you can use that with CSS in the form of w / h. This is using the CSS aspect-ratio property which is supported in all evergreen browsers.\n\nSetting the aspect ratio of the player is important for preventing Cumulative Layout Shift on the page.\n\n\n```css\nmux-player {\n  aspect-ratio: 16 / 9;\n}\n{/* or if you're using the iframe embed */}\niframe {\n  aspect-ratio: 16 / 9;\n}\n```\n\n\nRounded corners\n\nYou can add rounded corners to the player by wrapping it in a div with the style attribute set to border-radius.\n\n\n```html\n<div style=\"border-radius: 10px; overflow: hidden; display: flex;\">\n  <mux-player></mux-player>\n</div>\n```\n\n\nVideo size and position\n\nYou can change the way that video is sized within its  element. Mux Player provides two css variables that you can use to override the standard object-fit and object-position css properties.\n\n\n```css\nmux-player {\n  --media-object-fit: cover;\n  --media-object-position: center;\n}\n```\n\n\nWhen using the player.mux.com iframe embed, you can not use CSS to style mux-player directly, so you won't have access to these CSS Custom Properties.\n\nHiding controls with CSS\n\nBy default, Mux Player will show all the controls associated with the current player size and stream type.\n\nTo hide certain controls, use CSS variables like this:\n--seek-backward-button will control the display of the seek backward button. Set it to none to hide it completely.\n\n\n```css\nmux-player {\n  --seek-backward-button: none;\n  --seek-forward-button: none;\n}\n```\n\n\nCSS vars can also be passed inline\n\n\n```html\n<mux-player\n  style=\"--seek-backward-button: none; --seek-forward-button: none;\"\n></mux-player>\n```\n\n\nWhen using the iframe embed, you can not use CSS to style mux-player directly, so you won't have access to these CSS Custom Properties.\n\nControls sections\n\nYou can target specific sections of the player by prefixing the CSS vars with the section. The following sections are available:\n\n- top the top control bar that shows on the small player size\n- center the center controls that show the seek forward/backward button and play button\n- bottom the bottom control bar\n\n\n```html\n<mux-player\n  style=\"--center-controls: none; --top-captions-button: none;\"\n></mux-player>\n```\n\n\nAvailable CSS variables\n\nThe below CSS selector shows all available CSS vars for hiding, each one can be prefixed with a section.\n\n\n```css\nmux-player {\n  /* Hide all controls at once */\n  --controls: none;\n\n  /* Hide the error dialog */\n  --dialog: none;\n\n  /* Hide the loading indicator */\n  --loading-indicator: none;\n\n  /* Target all sections by excluding the section prefix */\n  --play-button: none;\n  --live-button: none;\n  --seek-backward-button: none;\n  --seek-forward-button: none;\n  --mute-button: none;\n  --captions-button: none;\n  --airplay-button: none;\n  --pip-button: none;\n  --fullscreen-button: none;\n  --cast-button: none;\n  --playback-rate-button: none;\n  --volume-range: none;\n  --time-range: none;\n  --time-display: none;\n  --duration-display: none;\n  --rendition-menu-button: none;\n\n  /* Target a specific section by prefixing the CSS var with (top|center|bottom) */\n  --center-controls: none;\n  --bottom-play-button: none;\n}\n```\n\n\nControls Backdrop Color\n\nMux Player exposes a CSS variable (--controls-backdrop-color) to set the controls backdrop color.\nThis is the background color that will show up behind the controls in the player.\n\n\n```css\nmux-player {\n  --controls-backdrop-color: rgb(0 0 0 / 60%);\n}\n```\n\n\nThe backdrop color is turned off by default. Note if you change this color be sure to make the contrast against the controls high enough as it has implications on the accessibility of the controls as they may not meet the contrast ratio requirements for WCAG 2.1.\n\nCSS Parts\n\nMux Player uses a shadow DOM to encapsulate its styles and behaviors. As a result, it's not possible to target its internals with the usual CSS selectors. Instead, some components expose parts that can be targeted with the CSS part selector, or ::part().\n\n\n```html\n<style>\n  mux-player::part(center play button) {\n    display: none;\n  }\n</style>\n<mux-player playback-id=\"DS00Spx1CV902MCtPj5WknGlR102V5HFkDe\"></mux-player>\n```\n\n\nSupported parts: live, layer, media-layer, poster-layer, vertical-layer, centered-layer, gesture-layer, top, center, bottom, play, button, seek-backward, seek-forward, mute, captions, airplay, pip, cast, fullscreen, playback-rate, volume, range, time, display.\n\nCSS parts allow you to style each element individually with a selector like ::part(center play button) or target multiple elements if the part is assigned to multiple elements internally, usage ::part(button). Every CSS property can be declared in the selector, this makes it a very powerful API.\n\nNote that if you are using advanced styling with ::parts selectors then be sure to test out your custom styles when upgrading to new versions of Mux Player.\n\nProvide color variables\n\nThe colors of Mux Player can be customized with the following options:\n\n| HTML Attribute | React Prop | Description |\n| ------------- | ---------- | ----------- |\n| accent-color | accentColor | Changes the color used to accent the controls |\n| primary-color | primaryColor | Changes the color of the control icons |\n| secondary-color | secondaryColor | Sets the background color of the control bar |\n\nWhen using the iframe embed, you can not use CSS to style mux-player directly, so you won't have access to these CSS Custom Properties.\n\nHTML element example\n\nReact example\n\nChange default behavior\n\nBelow are the attributes (Web Component) / props (React) available to enable, disable, hide, or change aspects of various controls to suit your use case.\n\nMute\n\nWhile Mux Player defaults to enabling sound, you can pass an attribute/prop to start playback muted.\n\nmuted is a boolean value that, when true, defaults sound to a muted state. Users can still unmute and manage volume as desired.\n\nSkip forward/backward\n\nThe amount of time for skip forward/backward defaults to 10 seconds. This can be changed by passing the following attributes (HTML element) / props (React), which updates both the seek buttons and keyboard (\"hotkey\") behaviors.\n\n| Attribute (HTML) | React Prop | Description | Example |\n| --------------- | ---------- | ----------- | ------- |\n| forward-seek-offset | forwardSeekOffset | Sets the number of seconds to skip forward | forward-seek-offset=\"5\" will apply a 5 second skip forward |\n| backward-seek-offset | backwardSeekOffset | Sets the number of seconds to skip backward | backward-seek-offset=\"5\" will apply a 5 second skip backward |\n\nClosed captions\n\nWhen captions are available on an asset, we show the control for them and enable their appearance by default.\n\nYou can opt to disable their appearance (while still showing the control) by using the default-hidden-captions (HTML element & embed) attribute or defaultHiddenCaptions (React) prop and a boolean value.\n\nStart time\n\nIf you'd like to set a specific time stamp as the start of playback for an asset, you can use the start-time (HTML element & embed) attribute or startTime (React) prop and a time value.\n\nWhen start-time is provided, it will also be used for the thumbnail-time if no thumbnail-time is explicitly provided.\n\nExample: start-time=\"13\" will begin playback at 13 seconds into the asset.\n\nLooping content\n\nYou can automatically loop the asset once playback completes with the loop attribute and a boolean value.\n\nIf you have a background looping video on your page for example, you might want to: turn off all controls, autoplay, mute and loop the video:\n\n\n```html\n<style>\n  mux-player {\n    --controls: none;\n  }\n</style>\n\n<mux-player\n  playback-id=\"23s11nz72DsoN657h4314PjKKjsF2JG33eBQQt6B95I\"\n  autoplay=\"muted\"\n  loop\n></mux-player>\n```\n\n\nWhen using the iframe embed, you can not use CSS to style mux-player directly, so you won't have access to the --controls CSS Custom Properties.\n\nAutoplay\n\nAutoplay in browsers is a difficult beast. See this doc if you're curious about the details. The good news is that Mux Player can help you handle autoplay when it is warranted.\n\nBefore you decide to autoplay your assets, first ask yourself: _Is this necessary?_ Often times it negatively impacts accessibility, and many viewers find autoplay to be an impediment to their experience.\n\nHere are your options for autoplay:\n\n| Attribute (HTML & embed) | Prop (React) | Description | Behavior |\n| --------------- | ------------ | ----------- | -------- |\n| autoplay | autoPlay | Basic autoplay | Will try to autoplay with sound on (likely to fail) |\n| autoplay=\"muted\" | autoPlay=\"muted\" | Muted autoplay | Will autoplay the video in muted state (likely to work) |\n| autoplay=\"any\" | autoPlay=\"any\" | Fallback autoplay | Will try autoplay with sound first, then fall back to muted if that fails |\n\nKeyboard shortcuts\n\nBy default, Mux Player has several keyboard shortcuts, or hotkeys, enabled. These hotkeys will only function if the player or one of the player controls are focused.\n\nDefault hotkeys\n\n| Key   | Name to turn off | Behavior                        |\n| ----- | ---------------- | ------------------------------- |\n| Space | nospace        | Toggle Playback                 |\n| c   | noc            | Toggle captions/subtitles track |\n| k   | nok            | Toggle Playback                 |\n| m   | nom            | Toggle mute                     |\n| f   | nof            | Toggle fullscreen               |\n| ⬅️    | noarrowleft    | Seek back 10s                   |\n| ➡️    | noarrowright   | Seek forward 10s                |\n\nTurning hotkeys off\n\nYou can turn off all hotkeys or individual ones.\n\nTurning all hotkeys off\n\nTo turn all hotkeys off, add the nohotkeys attribute to the Mux Player element:\n\n\n```html\n<mux-player\n  nohotkeys\n  playback-id=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n  metadata-video-title=\"Test video title\"\n  metadata-viewer-user-id=\"user-id-007\"\n></mux-player>\n<!-- or for the embed... -->\n <iframe\n  src=\"https://player.mux.com/EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs?nohotkeys=true\n  style=\"aspect-ratio: 16/9; width: 100%; border: 0;\"\n  allow=\"accelerometer; gyroscope; autoplay; encrypted-media; picture-in-picture;\"\n  allowfullscreen=\"true\"\n></iframe>\n```\n\n\nWith the Mux Player Web Component or React component can also do it via JavaScript:\n\n\n```js\nconst player = document.querySelector(\"mux-player\");\n// disable all hotkeys\nplayer.nohotkeys = true;\n\n// re-enable all hotkeys\nplayer.nohotkeys = false;\n```\n\n\nTurning off specific hotkeys\n\nIf you only want to turn off specific hotkeys, you can do so via JavaScript or HTML.\n\nUsing the \"Name to turn off\" above, you can add those to a hotkey attribute to turn off the specific hotkeys you don't want enabled.\n\nFor example, to turn off seeking with the arrow keys:\n\n\n```html\n<mux-player\n  hotkeys=\"noarrowleft noarrowright\"\n  playback-id=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n  metadata-video-title=\"Test video title\"\n  metadata-viewer-user-id=\"user-id-007\"\n></mux-player>\n<!-- or for the embed... -->\n <iframe\n  src=\"https://player.mux.com/EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs?hotkeys=noarrowleft%20noarrowright\"\n  style=\"aspect-ratio: 16/9; width: 100%; border: 0;\"\n  allow=\"accelerometer; gyroscope; autoplay; encrypted-media; picture-in-picture;\"\n  allowfullscreen=\"true\"\n/></iframe>\n```\n\n\nIf you're using the Mux Player Web Component or React component, you can also do this programmatically via the hotkeys property on the element. This provides a DOM Token List, a la classList, that allows you to add or remove each key.\n\n\n```jsx\nconst player = document.querySelector(\"mux-player\");\n\n// turn off seeking with the arrow keys\nplayer.hotkeys.add(\"noarrowright\", \"noarrowleft\");\n\n// re-enable the arrow keys\nplayer.hotkeys.remove(\"noarrowright\", \"noarrowleft\");\n```\n\n\nStyling captions\n\nAlthough the ::cue CSS selector/psuedo-element exists and has good browser support on paper, actual support of individual CSS properties when combined with it is very inconsistent. FireFox particularly doesn't support many of them.\n\nThere are two unique CSS properties that you can use to do very basic styling of the captions text though. Combined with the ::part() selector we can apply them like this:\n\n\n```css\nmux-player::part(media-layer) {\n  -webkit-text-fill-color: red;\n  -webkit-text-stroke: 1px blue;\n}\n```\n\n\nDespite being -webkit-` prefixed, these have good cross-browser support.\n\nBroader and more advanced support for caption styling will be available in a future version of the player.\n\nYou can not style the Mux Player element with CSS if you are using the HTML embed through player.mux.com."
  },
  {
    "id": "113-_guides/developer/player-examples",
    "title": "Mux Player examples",
    "path": "_guides/developer/player-examples.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-examples",
    "content": "<GuideCard\n    imageSrc=\"/docs/images/example-player-loop@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"Looping background video\"\n    description=\"Display a looping background video on your site with the Mux Player.\"\n    links={[\n      {\n        title: \"View on CodeSandbox →\",\n        href: \"https://codesandbox.io/s/looping-hero-background-video-op53sr\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/example-player-ambient-mode@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"Ambient mode\"\n    description=\"Create a dynamic background gradient that matches colors from the video.\"\n    links={[\n      {\n        title: \"View on CodeSandbox →\",\n        href: \"https://codesandbox.io/s/ambient-mode-vv63e9\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/example-player-audio-viz@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"Audio visualization with audio parameter\"\n    description=\"Display a visual representation of the audio in your video during playback.\"\n    links={[\n      {\n        title: \"View on CodeSandbox →\",\n        href: \"https://codesandbox.io/s/audio-visualization-o52wog\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/example-player-metadata@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"Sending detailed metadata to Mux Data\"\n    description=\"Display a visual representation of the audio in your video during playback.\"\n    links={[\n      {\n        title: \"View on CodeSandbox →\",\n        href: \"https://codesandbox.io/s/send-detailed-metadata-wm6o44\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/example-player-disable-seek@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"Disable seeking\"\n    description=\"Prevent you viewers from seeking to a specific point in the video.\"\n    links={[\n      {\n        title: \"View on CodeSandbox →\",\n        href: \"https://codesandbox.io/s/disable-seeking-w7pltk\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/example-player-playlist@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"Play videos in a playlist\"\n    description=\"Play through a set of audio or video sources.\"\n    links={[\n      {\n        title: \"View on CodeSandbox →\",\n        href: \"https://codesandbox.io/s/mux-player-media-playlist-ntj11i\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/example-player-loop@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"Mux Player Meditate (Audio Only + CuePoints)\"\n    description=\"Use Mux Player + CuePoints for advanced customization of playback and interactivity.\"\n    links={[\n      {\n        title: \"View on CodeSandbox →\",\n        href: \"https://codesandbox.io/p/sandbox/mux-player-audio-cuepoints-vl2r9b\",\n      },\n    ]}\n  />"
  },
  {
    "id": "114-_guides/developer/player-faqs",
    "title": "Mux Player FAQs",
    "path": "_guides/developer/player-faqs.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-faqs",
    "content": "Do you support non-Mux HLS streams?\n\nMux Player is designed with the Mux Platform in mind. Being tightly coupled with Mux Video is what enables features like timeline hover previews, and those sweet, descriptive errors in Mux Data.\n\nHow can I access the underlying video element using Mux Player?\n\nThe media.nativeEl property is a reference to the underlying video element. You can use this to access the video element's properties and methods.\n\n\n```jsx\n  <MuxPlayer\n    playbackId=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n    ref={(muxPlayerEl) => console.log(muxPlayerEl.media.nativeEl)}\n    metadata={{\n      video_id: \"video-id-54321\",\n      video_title: \"Test video title\",\n      viewer_user_id: \"user-id-007\",\n    }}\n  />\n```\n\n\nThis isn't possible when using the iframe-embedded version of Mux Player through player.mux.com. You can control the embedded version of Mux Player through the Player.js spec.\n\nDo you have a Mux Player for native mobile?\n\nYes, we have public beta SDKs for iOS and Android. If you're building directly in Swift/Objective-C or Kotlin/Java then you can use these SDKs directly. If you're building with Flutter or React Native you will need to bridge these native SDKs into your framework.\n\nI would love to speak to someone on the team about a feature idea or a problem I'm running into with the player, how can I do that?\n\nPlease leave us some feedback and we'll be in touch!\n\nHow is Mux Player built?\n\nMux Player is built with Web Components. Web Components is a native browserAPI for defining custom HTML tags that can be used in the DOM.\nMux Player is built on top of Media Chrome and the Mux Video HTML element. You can think of it like this:\n\n- Mux Video HTML element handles the HLS playback tech behind the scenes and integration with Mux Data.\n- Media Chrome is the UI layer.\n  Both the Mux Video HTML element and Media Chrome are maintained and under active development by Mux.\n\nWhat are the developer system requirements?\n\nMux Player package targets ES2019, if you're targeting an older JavaScript runtime Mux Player might not be compatible with your build setup.\n\nEvergreen browser support\n\nMux Player supports the most recent versions of evergreen browsers on desktop and mobile. Evergreen browsers are the modern browsers that are automatically updated:\n\n- Chrome (Mac, Windows, Linux, iOS, iPadOS, Android)\n- Safari (Mac, iOS, iPadOS)\n- Firefox (Mac, Windows, Linux, Android)\n- Edge (Mac, Windows, Linux)\n\nTypeScript support\n\nMux Player is fully written in TypeScript version 4.5. If you are on an older version of TypeScript (pre-4.0), you will likely have to upgrade your TypeScript package in order to get the TypeScript benefits."
  },
  {
    "id": "115-_guides/developer/player-integrate-in-your-webapp",
    "title": "Integrate Mux Player into your web application",
    "path": "_guides/developer/player-integrate-in-your-webapp.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-integrate-in-your-webapp",
    "content": "Install Mux Player\n\nMux Player has 2 packages:\n\n- @mux/mux-player: the web component, compatible with all frontend frameworks\n- @mux/mux-player-react: the React component, for usage in React\n\nBoth are built with TypeScript and can be installed either via npm, yarn or the hosted option on jsdelivr. @mux/mux-player can also be used as an ` embed.\n\nNPM\n\n\n```shell\nnpm install @mux/mux-player@latest #or @mux/mux-player-react@latest\n```\n\n\nYarn\n\n\n```shell\nyarn add @mux/mux-player@latest #or @mux/mux-player-react@latest\n```\n\n\nCDN\n\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-player\" defer></script>\n<!--\nor\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-player-react\" defer></script>\n-->\n```\n\n\nEmbed\n\n```html\n<iframe\n  src=\"https://player.mux.com/{PLAYBACK_ID}\"\n  allow=\"accelerometer; gyroscope; autoplay; encrypted-media; picture-in-picture;\"\n  allowfullscreen=\"true\"\n></iframe>\n```\n\n\nProviding attributes\n\nWhile syntax differs between React and HTML, there are two recommended values to provide in either approach:\n\n- Playback ID: Used by the player to create a URL that describes where the video can be streamed from. Under the hood this looks like stream.mux.com/{PLAYBACK_ID}.m3u8.\n- metadata: Information about the video to be tracked by Mux Data as part of a view. At a minimum, you should provide video_id, video_title, and viewer_user_id. See: Mux Data Metadata.\n\nHTML Web Component attributes\n\nIn the HTML web component, using JavaScript it can be assigned as a property on the element:\n\n\n```js\ndocument.querySelector(\"mux-player\").metadata = { video_id: \"video-id-123\" };\n```\n\n\nOr, you can add them as attributes to the player in the HTML using the metadata-* prefix:\n\n\n```html\n<mux-player\n  playback-id=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n  metadata-video-id=\"video-id-123456\"\n  metadata-video-title=\"Big Buck Bunny\"\n  metadata-viewer-user-id=\"user-id-bc-789\"\n>\n```\n\n\nHTML embed attributes\nIn the HTML embed, you can add most supported attributes to the URL as query parameters.\n\n  Remember that query parameters should be URL encoded. You might do this with encodeURIComponent().\n\n\n```html\n<iframe\n  src=\"https://player.mux.com/{PLAYBACK_ID}?metadata-video-id=video-id-123456&metadata-video-title=Bick%20Buck%20Bunny&metadata-viewer-user-id=user-id-bc-789\"\n  allow=\"accelerometer; gyroscope; autoplay; encrypted-media; picture-in-picture;\"\n  allowfullscreen=\"true\"\n></iframe>\n```\n\n\nReact attributes\n\nFollowing JavaScript conventions, attributes in React are camelCased rather than kebab-cased. For example, playback-id becomes playbackId.\n\nmetadata is specified as an object in props.\n\n\n```jsx\n<MuxPlayer\n  playbackId=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n  metadata={{\n    video_id: 'video-id-123456',\n    video_title: 'Big Buck Bunny',\n    viewer_user_id: 'user-id-bc-789',\n  }}\n></MuxPlayer>\n```\n\n\nExamples\n\nHTML element\n\nWhen using the HTML element version of Mux Player, you will see the Player Software in Mux Data come through as mux-player.\n\nHTML embed\n\nWhen using the HTML embed version of Mux Player, you will see the Player Software in Mux Data come through as mux-player-iframe.\n\nReact\n\nWhen using the React version of Mux Player, you will see the Player Software in Mux Data come through as mux-player-react.\n\nSvelte\n\nSince Svelte supports web components, here is an examples of using @mux/mux-player component. View the Sveltkit example in the Mux Elements repo for a fully functioning example.\n\n\n```html\n<script context=\"module\" lang=\"ts\">\n  export const prerender = true;\n</script>\n\n<script lang=\"ts\">\n  // this prevents the custom elements from being redefined when the REPL is updated and reloads, which throws an error\n  // this means that any changes to the custom element won't be picked up without saving and refreshing the REPL\n  // const oldRegister = customElements.define;\n  // customElements.define = function(name, constructor, options) {\n  // \tif (!customElements.get(name)) {\n  // \t\toldRegister(name, constructor, options);\n  // \t}\n  // }\n  // import { page } from '$app/stores';\n  import { onMount } from \"svelte\";\n  onMount(async () => {\n    await import(\"@mux/mux-player\");\n  });\n</script>\n\n<mux-player\n  playback-id=\"g65IqSFtWdpGR100c2W8VUHrfIVWTNRen\"\n  metadata-video-id=\"video-id-54321\"\n  metadata-video-title=\"Svelte Kit: Episode 2\"\n  metadata-viewer-user-id=\"user-id-sveltekit007\"\n/>\n```\n\n\nVue\n\nSince Vue supports web components, here is an examples of using @mux/mux-player` component. View the Vue example in the Mux Elements repo for a fully functioning example.\n\n\n```html\n<script setup lang=\"ts\">\n  import \"@mux/mux-player\";\n</script>\n\n<template>\n  <main>\n    <mux-player\n      playback-id=\"g65IqSFtWdpGR100c2W8VUHrfIVWTNRen\"\n      metadata-video-id=\"video-id-54321\"\n      metadata-video-title=\"Vue 3: Episode 2\"\n      metadata-viewer-user-id=\"user-id-vue3007\"\n    />\n  </main>\n</template>\n```\n\n\n  <GuideCard\n    title=\"Customize the look and feel\"\n    description=\"Customize Mux Player to match your brand\"\n    links={[\n      {\n        title: \"Read the guide\",\n        href: \"/docs/guides/player-customize-look-and-feel\",\n      },\n    ]}\n  />\n  <GuideCard\n    title=\"Advanced usage\"\n    description=\"Learn about advanced usage of Mux Player\"\n    links={[\n      {\n        title: \"Read the guide\",\n        href: \"/docs/guides/player-advanced-usage\",\n      },\n    ]}\n  />"
  },
  {
    "id": "116-_guides/developer/player-lazy-loading",
    "title": "Lazy-loading Mux Player",
    "path": "_guides/developer/player-lazy-loading.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-lazy-loading",
    "content": "Installation\n\nReact\nAfter installing @mux/mux-player-react, import Mux Player React Lazy from @mux/mux-player-react/lazy:\n\nDepending on your bundler your import might look a little different. If you're having trouble with the import try:\n\n- @mux/mux-player-react/lazy\n- @mux/mux-player-react/dist/lazy.mjs\n- @mux/mux-player-react/dist/lazy\n\n  Mux Player React Lazy will not be available if you are using the hosted option\n  on jsdelivr.com.\n\nPreventing cumulative layout shift\n\nBecause the player is added to the DOM after the page loads, it will cause a cumulative layout shift, pushing content down and causing a jarring jump for your users. To prevent this, make sure your player has an aspectRatio style property. @mux/mux-player-react/lazy will display a placeholder with this aspect ratio while the player loads.\n\n\n```jsx\n<MuxPlayer\n  playbackId=\"EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs\"\n  // without this line, the player will cause a layout shift when it loads\n  style={{ aspectRatio: 16/9 }}\n/>\n```\n\n\nCustomizing the placeholder\n\nWhile Mux Player React Lazy loads, it will display a placeholder with the same background color as the player. (By default, a black background).\n\n<Player\n  playbackId=\"Wd01CoLZp2Adx00qefHtyGVPSP2h4wO33OZqR00vf7wCnQ\"\n  style={{ aspectRatio: \"495 / 274\", '--center-controls': 'none' }}\n/>\n\nIf the placeholder= attribute is defined, the attribute's contents will display in the placeholder before load. You can generate placeholders that match your video poster with @mux/blurup. See the placeholder guide to learn more.\n\n<Player\n  playbackId=\"bXA3Oh7v22fRBU013damYqUxFK6HrmJcrI00Q00b2OSvmc\"\n  style={{ aspectRatio: \"656 / 277\", '--center-controls': 'none' }}\n/>\n\nDefining when to load\n\nIn addition to the standard attributes that Mux Player React accepts, Mux Player React Lazy will also accept a loading attribute:\n\n- loading=\"page\": Loads the player and replaces a placeholder after the page loads and the initial JavaScript bundle is executed\n- loading=\"viewport\": (Default) Extends loading=\"page\" by also waiting until the placeholder has entered the viewport\n\nUsing other frameworks\n\nIf you are working in an environment that supports dynamic imports, like Webpack, Rollup, Parcel, or many modern browsers, you can reproduce the behavior of Mux Player React Lazy.\n\nIf you have access to a Node.js server, generate a placeholder that matches your video with @mux/blurup.\n\n\n```js\n// Server-Side\nimport { createBlurUp } from '@mux/blurup';\n\nconst options = {};\nconst muxPlaybackId = 'O6LdRc0112FEJXH00bGsN9Q31yu5EIVHTgjTKRkKtEq1k';\n\nconst getPlaceholder() = async () => {\n  const { blurDataURL, aspectRatio } = await createBlurUp(muxPlaybackId, options);\n  console.log(blurDataURL, aspectRatio);\n  // data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"100%\" ...\n};\n```\n\n\nThen, use a dynamic import to load Mux Player. When the load is complete, replace the placeholder with the player."
  },
  {
    "id": "117-_guides/developer/player-releases-android",
    "title": "Mux Player for Android releases",
    "path": "_guides/developer/player-releases-android.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-releases-android",
    "content": "Current release\n\nv1.5.0\nImprovements:\n Update media3 version to 1.6.1\n Update Mux Data to v1.8.0\n\nFixes:\n fix: DRM playback broken\n\nPrevious releases\n\nv1.4.0\nUpdates:\n Add method for updating CustomerData\n\nImprovements:\n Track player dimensions when using the default PlayerView (or SurfaceView or TextureView)\n\nNotes:\n MuxPlayer now implements Player instead of ExoPlayer. Most people shouldn't have a problem, but if you referred to our player as an ExoPlayer, you'll need to change it to Player or ExoPlayer\n\nv1.3.0\nUpdate:\n update: Update Mux Data to v1.6.2 and Media3 to v1.5.0\n\nv1.2.2\nFixes\n fix: Rendering issues on Compose UI & API 34 (upstream from media3: link)\n\nImprovements\n Update media3 to 1.4.1 + mux data to 1.6.0\n\nv1.2.1\nFixes\n Fix cache errors when switching sources extremely quickly\n\nv1.2.0\nImprovements\n Add Instant Clipping asset relative time parameters to MediaItems\n\nv1.1.3\nImprovements:\n fix: playback fails sometimes when changing videos\n\nv1.1.2\nPlease prefer to use v1.1.3\n\nv1.1.1\nPlease prefer to use v1.1.3\n\nv1.1.0\nImprovements\n- Adds DRM support\n\nv1.0.0\nUpdates:\n Bump to version 1.0.0\n Added a 'Default' rendition order\n\nFixes:\n Remove option for non-existent Ascending rendition order\n\nImprovements:\n Misc API & code quality improvements\n Complete public API docs\n\nv0.3.1\nImprovements:\n fix: Player should always request redundant_streams\n feat: Set player software name as mux-player-android\n\nv0.3.0\nNew:\n new: Add max and min playback resolution\nUpdates:\n* update: Improve example app appearance + misc updates"
  },
  {
    "id": "118-_guides/developer/player-releases-ios",
    "title": "Mux Player for iOS releases",
    "path": "_guides/developer/player-releases-ios.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-releases-ios",
    "content": "Current release\n\nv1.4.0\n\nImprovements\n- Resolves an issue where DRM playback would fail to start after a media services reset. It is still required to recreate the player and assets after such an event.\n- Improvements to the DRM registration process for more consistent startup latency\n\nPrevious releases\n\nv1.3.0\n\nUpdates\n- Allow disabling Mux Data automatic error tracking via MonitoringOptions\n- Allow creating AVPlayerItems with Mux PlaybackOptions without using our AVPlayerViewController or AVPlayerLayer APIs. See the header docs for more details\n\nv1.2.1\n\nImprovements\n- Updated and relaxed mux-stats-sdk-avplayer dependency\n- Added default message \"No additional information.\" for Monitor handleUpdatedPlayerError\n\nv1.2.0\n\nImprovements\n- Support instant clipping using relative time for publicly playable assets\n\nv1.1.1\n\nImprovements\n- Capture additional details in Mux Data when experiencing an error playing video with DRM\n\nv1.1.0\n\nImprovements\n- Adds DRM support\n\nv1.0.0\n\nImprovements\n- Enable caching when streaming on-demand at a fixed resolution tier\n- Updated Mux Data dependencies to meet App Store privacy manifest requirements\n\nAPI Changes\n- Add convenience initializers to constrain playback to a single rendition with a preset resolution tier\n- Add additional AVPlayerViewController extensions that configure an already existing instance for playing back a video from Mux\n- Remove ascending option for RenditionOrder this parameter is not supported by Mux Video\n\nv0.5.0\n\nImprovements\n- Sets player software name and version to default values when reporting playback events to Mux Data\n\nv0.4.0\n\nAPI Changes\n- Add 1440p max resolution playback modifier\n\nFixes\n- Correct SDK version\n\nv0.3.0\n\nAPI Changes\n- Add: maximum resolution playback modifiers for 1080p and 2160p\n\nv0.2.0\n\nAdditions\n- Initialize an AVPlayerLayer to stream and monitor video with a public or signed playback ID\n- Setup an already existing AVPlayerLayer to stream and monitor video with a public or signed playback ID\n\nBreaking\n- The SDK module has been renamed to MuxPlayerSwift.\n    - Update SPM package links from https://github.com/muxinc/mux-avplayer-sdk to https://github.com/muxinc/mux-player-swift\n    - Replace any import statements: import MuxAVPlayerSDK to import MuxPlayerSwift\n\nThis SDK is pre-release software and may contain issues or missing functionality. We recommend against submitting apps based on it to the App Store.\n\nv0.1.0\n\nInitial Release\n- Feature: setup AVPlayerViewController to stream and monitor video with a public or signed playback ID\n- Feature: automatic Mux Data monitoring setup\n- Feature: passthrough of all metadata supported by the AVPlayer Data SDK\n- Feature: custom domains for playback\n- Feature: support for limiting playback resolution to 720p\n\nKnown Issues\n- Mux Data monitoring will not automatically stop when AVPlayerViewController is no longer in use, call stopMonitoring on AVPlayerViewController to stop monitoring manually."
  },
  {
    "id": "119-_guides/developer/player-releases-web",
    "title": "Mux Player for web releases",
    "path": "_guides/developer/player-releases-web.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-releases-web",
    "content": "Current release\n\n3.10.1\n\n- Fix: Default playback to MSE except for Safari to cover all Chromium browsers which support native HLS playback now\n\nPrevious releases\n\n3.10.0\n\n- Feature: Add max-auto-resolution attribute for automatic resolution capping\n- Fix: Improvements to DRM for Airplay playback\n\n3.9.2\n\n- Fix: Upgrade ce-la-react to fix missing key warning\n\n3.9.1\n\n- Fix: Upgrade hls.js to 1.6.15\n\n3.9.0\n\n- Feature: Add typed CSSProperties for mux-player custom CSS vars\n- Fix: Add MENU_ITEM constant for styling of menu items with CSS\n- Fix: Upgrade media-chrome to 4.16.0 and media-tracks to 0.3.4\n\n3.8.0\n\n- Feature: Add nomutedpref prop to mux player\n- Feature: Add support to define custom fullscreen element\n- Fix: Default playback to MSE check for Google Chrome 142+\n- Fix: Upgrade media-chrome to 4.15.1\n\n3.7.0\n\n- Feature: Expose centered layout in themes\n- Fix: Default playbackto MSE for Google Chrome which supports native HLS playback now\n- Fix: Upgrade hls.js to 1.6.13\n\n3.6.1\n\n- Fix: Upgrade media-chrome to 4.14.0\n\n3.6.0\n\n- Feature: Add switch to control the behavior of the ended event\n- Feature: Add classic theme video title\n- Fix: Disable spacebar shortcut if nohotkeys enabled\n- Fix: Remove error dialog for audio only\n\n3.5.3\n\n- Fix: Stop-gap solution to some architectural layer + src-related prop setting causing early and incorrect playback-core initialization\n\n3.5.2\n\n- Fix: Update order of props setting so playback id always comes first to resolve session-based expectations (e.g. mux data metadata)\n\n3.5.1\n\n- Fix: Upgrade hls.js to 1.6.6, remove workaround for MTA (multi-track audio)\n\n3.5.0\n\n- Feature: Add Google IMA support for mux-player and mux-video variants\n- Feature: Add retry logic for 412 not playable errors\n- Feature: Add free plan logo to the player\n\n3.4.1\n\n- Fix: Bring back cast button for drm protected videos\n- Fix: Change default of preferCmcd to 'none' for improved cacheability\n- Fix: rendition-menu visual improvements\n\n3.4.0\n\n- Feature: Add fullscreen API on player element\n- Feature: Add video-title attribute & videoTitle property\n- Fix: defaultHiddenCaptions property bug for React\n- Fix: Casting devices discovery after new video load\n\n3.3.4\n\n- Fix: Allow extension less Mux m3u8 url as src\n\n3.3.3\n\n- Feature: Add optional Mux logo to Mux video\n- Fix: Remove redundant FPS DRM generateRequest() for native playback\n\n3.3.2\n\n- Fix: default-hidden-captions attribute bug for Vue\n\n3.3.1\n\n- Fix: Player controls unresponsive after casting prompt\n\n3.3.0\n\n- Feature: Implement Mux badge that can be enabled via a proudly-display-mux-badge attribute\n- Fix: Update hls.js version to fix multi-DRM playready bug\n- Fix: Update media-chrome to fix a bug with the error dialog not hiding on error recovery\n- Fix: Media Chrome theme flicker on load\n\n3.2.0\n\n- Feature: Set Mux data default player init time for greater accuracy. Expose attribute and property for externally defined player init time\n- Feature: Use Media Chrome's error dialog\n- Feature: NPM package includes provenance statements from now on\n- Fix: Slot behavior of child elements\n\n3.1.0\n\n- Feature: Error handling rearchitecture (including more granular and DRM error cases)\n- Feature: Add asset start and end time props and attrs\n- Fix: Chapters disapearing after preload none\n- Fix: Menu CSS vars to hide menu button\n- Fix: Update peer dependencies for React 19 RC\n- Chore: Upgrade to Media Chrome v4.2.1\n\n3.0.0\n\n- Fix: addChapters and addCuepoints now have correct TypeScript method types\n- Fix: Removed seek forwards and backwards buttons from mobile pre-playback UI\n- Fix: Added missing buttons to mobile live audio view (play, live and mute)\n- Chore: Upgrade to Media Chrome v4.1.1\n- Feature: New tooltips for buttons in the UI, enabled by default\n\n2.8.1\n\n- Fix: Use CSS to disable subtitle shifting for iOS in fullscreen\n- Chore: Upgrade to Media Chrome v3.2.5\n\n2.8.0\n\n- Feature: Adds DRM support\n- Fix: Pseudo-ended eval case where media is not attached\n- Fix: Hide cast button by default when using DRM\n- Chore: Upgrade to Media Chrome v3.2.3\n- Chore: Upgrade hls.js, custom-media-element, castable-video, and media-tracks\n\n2.7.0\n\n- Feature: PDT Clipping Support\n- Feature: Add addChapters() API\n\n2.6.0\n\n- Feature: Add 'use client' to components for better out of box functionality with Next.JS\n- Fix: Cleanup TypeScript types\n\n2.5.0\n\n- Chore: Upgrade to mux-embed v5.2.0 & Media Chrome v3.2.0,\n- Chore: Upgrade hls.js and React TypeScript types\n- Feature: Add disable-tracking / disableTracking attribute / property to disable Mux Data tracking\n\n2.4.1\n\n- Fix: Make sure we do not apply holdback to seekable when live streams have ended\n\n2.4.0\n\n- Chore: Upgrade to Media Chrome v3.1.1 (major version bump)\n- Fix: Cleanup various issues with DVR UI (including seekable time updates for time range and time display cases)\n- Fix: Polish new time preview w/ shifting arrow\n- Fix: Polish using easing gradients for UI backdrop\n- Feature: forward-seek-offset / forwardSeekOffset + backward-seek-offset / backwardSeekOffset attributes / properties now also update keyboard hotkeys offsets\n\n2.3.3\n\n- Chore: Upgrade Media Chrome\n- Fix: Enable chapters & metadata tracks if cloned and appended to native video element\n- Fix: Fire an ended event if playback is stalled near the end of playback\n\n2.3.2\n- Chore: Upgrade Media Chrome\n- Fix: Subtitles selection edge cases\n\n2.3.1\n\n- Fix: Remove unneeded target-live-window=\"NaN\" attribute sprouting\n- Fix: Upgrade media-chrome to 2.0.1 fixing an undefined type error\n- Fix: Upgrade custom-media-element and media-tracks packages improving types\n\n2.3.0\n\n- Feature: Upgrade to Media Chrome v2 and castable-video v1\n  The Google cast framework script is now automatically loaded, see guide\n  Usage of the standard Remote Playback API\n- Feature: Add extra-source-params / extraSourceParams attribute / property for advanced usage\n- Feature: Add the ability to set default-duration / defaultDuration before media loads\n- Feature: Allow forcibly showing buttons that we usually hide at small sizes via CSS vars\n- Feature: Add unofficial _hlsConfig property to media elements and playback core\n- Feature: Add additional CSS parts for export\n- Fix: Audio controls styling, controlbar background color and timerange width\n- Fix: Attributes mismatch to make sure controls don't overlap\n- Fix: Android tap issues on show and hide of controls\n\n2.2.0\n\n- Feature: Use playback rate selectmenu for the new theme\n- Fix: Use solid accent color in rate menu\n- Fix: Upgrade Media Chrome\n- Fix: Update menu styles\n\n2.1.0\n\n- Feature: Add support for manifest manipulation and other media stream query param properties\n- Fix: Prevent clicks on background gradients\n- Fix: Add volume slider to live player UI\n\n2.0.1\n\n- Fix: Make sure accent-color gets set properly\n\n2.0\n\n- Feature: New default theme named gerwig 🎉\n  No functional breaking changes, only visual changes\n- See Upgrade guide from 1.x to 2.0\n- See blog post\n- See Twitter / X.com thread\n\n1.14.1\n\n- Fix: Resolve regression so title will be used by Mux Data as video_title if not overridden by explicit metadata\n- Fix: Resolve issue where MTA implementation could cause load issues/hangs in playback for LL-HLS streams\n\n1.13.0\n\n- Feature: Add custom poster slot to mux-player and mux-player-react to allow for server-side progressive enhancement 🎉 See issue 590\n- Feature: Add muti-track audio selector 🗣️ (see guide)\n\n1.12.1\n\n- Fix: Improve dist exports for greater compatibility with different build tools, including not declaring non-existent exports in package.json\n\n1.12.0\n\n- Feature: Add quality selector see guide\n- Feature: Expose underlying poster image CSS part for advanced styling\n- Fix: Fix bug around loading themes in React\n\n1.11.4\n\n- Fix issue with edge case assets when used in Next.js production builds in Chrome causing hundreds of requests for 0.ts segment. See issue 688\n\n1.11.3\n\n- Chore: media chrome version bump, fixes a resize observer crash that can happen in CodeSandbox\n\n1.11.2\n\n- Chore: bump media chrome and Hls.js to latest versions\n\n1.11.1\n\n- Chore: bump media chrome and Hls.js to latest versions\n\n1.11.0\n\n- Fix: Upgrade hls.js to v1.4.1.\n- Feat: Add no-volume-pref attribute to turn off saving the user selected volume in local storage.\n\n1.10.1\n\n- Fix: Force theme to be ltr direction.\n- Fix: Use webkit pseudo element for captions movement, where available.\n\n1.10.0\n\n- Feature: Add support for synchronizing video playback (currentPdt and getStartDate())\n- Fix: Fix resetting currentTime to 0 in mux-player-react.\n\n1.9.0\n\n- Feature: Add support for Media Chrome themes.\n- Feature: Add minimal and microvideo theme exports.\n- Feature: Add cuepoint event handlers for mux-player-react.\n- Feature: Use Mux Data player_error_context to get better error grouping.\n- Feature: Add --dialog and --loading-indicator CSS vars.\n- Fix: Upgrade hls.js to v1.4.0-beta.2.\n- Fix: Update hls.js configs to optimize streaming performance.\n- Fix: Update types and improve support for Angular projects.\n\n1.8.0\n\n- Feature: Add max-resolution attribute on mux-player and mux-video.\n- Feature: Add API for CuePoints metadata.\n- Fix: Typescript error for Vite based apps like Sveltekit, Nuxt, Vue.\n- Fix: Explicitly clean up text tracks, even for native (non-hls.js) playback.\n\n1.7.1\n\n- Fix: Only initialize with setupCuePoints when using hls.js for playback (resolves Safari playback error)\n\n1.7.0\n\n- Feature: Introduce a captions menu button.\n- Fix: Bring back play button to the control bar for small player size.\n- Fix: Migrate to use new Media Chrome media-live-button.\n- Fix: Improve attribute empty behavior.\n- Fix: Upgrade Media Chrome v0.18.1.\n- Fix: Use new Media Chrome template syntax.\n\n1.6.0\n\n- Feature: Add storyboard-src attribute and corresponding prop\n- Fix: Use webp format instead of jpg, less bandwidth\n- Fix: Memory leaks related to the playback engine not being torn down properly.\n\n1.5.1\n\n- Fix: Allow setting of a Media Chrome theme template via a property.\n\n1.5.0\n\n- Feature: Mux player uses a new HTML based templating syntax as preparation for\n  Media Chrome theme compatibility which will give developers an easy way to change\n  the look and feel of the player.\n- Feature: Allow ` web component to receive any Mux Data metadata-* fields, beyond metadata-video-title, metdata-video-id and metadata-viewer-user-id, now things like metadata-sub-property-id and any other Mux Data fields can be passed with this syntax. Note the muxPlayer.metadata = { video_title: \"My Title\", sub_property_id: \"Sub prop 123\" } syntax also still works.\n- Fix: Prevent the player of duplicate rendering the top-level internal elements in edge cases.\n\n1.4.0\n\n- Feature: Player design update: removed the backdrop shade by default.\n- Fix: Attributes set after the playback-id are now correctly passed in playback core.\n\n1.3.0\n\n- Feature: Add disable-cookies attribute and disableCookies property.\n- Feature: Add experimental-cmcd attribute and experimentalCmcd property for headers-based CMCD usage.\n- Feature: Add ability to unset poster\n- Feature: Conditionally use title for title metadata in Mux Data\n- Feature: Add storyboard getter on player\n- Fix: Check JWT before setting poster and storyboard urls\n- Fix: Don't register prop for --controls-backdrop-color CSS var\n- Fix: Upgrade to Media Chrome v0.15.1\n- Fix: Various edge case fixes in Media Chrome UI\n- Fix: Improve hiding controls behavior when interacting with play or fullscreen buttons.\n\n1.2.0\n\n- Feature: Implement React lazy for mux-player-react\n- Feature: Add type-compliant seekable property to the API\n- Fix: playbackRate for mux-player-react\n\n1.1.3\n\n- Fix: Add default values to object-fit and object-position\n\n1.1.2\n\n- Fix: Upgrade Media Chrome to v0.14.0\n- Fix: Properly check iPhones for fullscreen unavailability\n- Fix: Properly unset poster image sources when they're removed\n\n1.1.1\n\n- Fix: Add --media-object-fit and --media-object-position to mux-video\n\n1.1.0\n\n- Feature: Add ability to unset poster by setting it to an empty string\n- Fix: Turn off backdrop color when controls are disabled\n\n1.0.0 🎉\n\n- Feature: Replace prefer-mse with prefer-playback for more control\n- Feature: Add default width 100% to avoid unexpected CLS and resizing scenarios\n- Feature: Disable unusable controls when playback-id is unset\n- Feature: Add hotkey for toggling closed captions (c)\n- Fix: Google Chrome v106 caption positioning bug\n- Fix: Disable all controls when error dialog is open (a11y)\n- Fix: Hide fullscreen button when fullscreen is unavailable (e.g. iframe usage)\n- Fix: Ignore Safari for captions movement.\n- Fix: audio UI height bugs\n- Fix: Add missing setter for defaultHiddenCaptions prop.\n- Fix: Clean up crossOrigin and playsInline usage while respecting defaults/availability.\n- Fix: Make player interface compliant with more of HTMLVideoElement type expectations, even on initialization\n- Fix: Handle removing/nil playback-id\n- Fix: Add preload property support\n- Fix: title property bug\n- Fix: Use CSS.registerProperty on vars to declare them as colors for better resilience/fallback\n- Fix: (Mux Player React) Resolve issues with currentTime prop\n- Fix: (Mux Player React) Remove vestigial code for tertiaryColor prop\n\n1.0.0-beta.0\n\n- Feature: add video CSS part for styling the  element\n- Feature: add --controls-backdrop-color CSS var to allow changing the backdrop color\n- Feature: upgrade hls.js to version v1.2.3\n- Feature: prefer Media Source Extensions on Android\n- Feature: refresh seek backward and forward icons\n- Fix: memory leak of hls.js instances\n- Fix: start-time attribute now works on iOS\n- Fix: a11y tab order of player controls\n- Fix: control bar icon alignment was off by a few pixels\n- Fix: restore right-click video menu\n\n0.1.0-beta.27\n\n- Feature: configure playback rates for the player\n- Feature: add a title component to the player\n- Feature: allow hiding controls based on CSS variables\n- Feature: allow turning off keyboard shortcuts via the hotkeys attribute, don't allow seeking in live streams with the arrow keys\n- Feature: use Media Chrome's poster image element for posters\n- Fix: don't pollute global in SSR\n- Fix: change position of the live indicator\n\n0.1.0-beta.26\n\n- Improvement: update the warning logged when an incorrect stream type is passed to the player.\n\n0.1.0-beta.25\n\n- Feature: add keyboard shortcuts and a nohotkeys attribute to turn off keyboard shortcuts.\n- Feature: expose CSS parts for targeting controls via CSS.\n\n0.1.0-beta.24\n\n- Improvement: Improve time range behavior; add preview time code, smooth playhead progress and fine seek control, keep preview thumb in player bounding box.\n- Improvement: Add Mux flavored cast icon.\n- Feature: Add defaultMuted and defaultPlaybackRate properties.\n- Feature: Add textTracks property, addTextTrack() and removeTextTrack() methods.\n\n0.1.0-beta.23\n\n- Update: Rely on Media Chrome availability states where appropriate.\n  Remove unneeded code from mux-player.\n\n0.1.0-beta.22\n\n- Improvement: Optimize mux-player tests.\n\n0.1.0-beta.21\n\n- Update: Mux Player (and all Mux Elements) are now published under the @mux NPM scope. Please update @mux/mux-player references to @mux/mux-player as of 0.1.0-beta.21.\n\n0.1.0-beta.20\n\n- Feature: Chromecast is built in -- via castable-video. See docs in the Core Features section for details on how to enable it.\n\n0.1.0-beta.19\n\n- Fix: import for castable-video while we hammer on Chromecast.\n\n0.1.0-beta.18\n\n- Fix: Some captions shifting jankyness on live streams when shifting wasn't necessary.\n- Fix: Captions offset for Safari\n- Feature: Support for audio-only Mux assets with the audio attribute\n- Feature: Experimental Chromecast support added with castable-video. This is intentionally undocumented while we work out the kinks.\n- Improvement: Better progress bar alignment.\n\n0.1.0-beta.17\n\n- Fix: Some recoverable errors were incorrectly being sent to Mux Data -- this caused an inflated playback error percentage metric in your Mux Data dashboard. This incorrect error tracking was especially prevalent on live streams. We fixed this after it was discovered at TMI.\n\n0.1.0-beta.16\n\n- Fix: Log an error if a token is passed in with playback-id (playback tokens should be passed in via playback-token attribute)\n\n0.1.0-beta.15\n\n- Fix: update commonjs import files to cjs.js. This fixes some build systems that rely on the cjs.js extension\n\n0.1.0-beta.14\n\n- Improvement: Tweaked a few Hls.js configuration settings for live and low-latency live based on some recent testing (backed up by Mux Data, of course). This is the kind of thing the team working on Mux Player worries about so that you don't have to!\n\n0.1.0-beta.13\n\n- Fix: For live streams on non-Safari browsers the red (live) / gray (behind live) dot indicator was being a little too aggressive about switching to gray, which indicates the viewer is behind the live edge. This is fixed now, you shouldn't fall back from the live edge unless you pause or rebuffer.\n\n0.1.0-beta.12\n\n- Important fix for fullscreen. In previous versions if you entered fullscreen you would get stuck there\n- Improve interaction so that clicks (not taps) anywhere on the video player will play/pause. Many people expected and asked for this behavior, so now you have it.\n\n0.1.0-beta.11\n\n- Added thumbnail-time optional attribute that can be used to set the poster image thumbnail (if you're not using signing tokens)\n- Point to github/template-parts@0.5.2 instead of Mux's fork because they were so kind to get a fix in for us. Thanks GitHub!\n\n0.1.0-beta.10\n\n- Improvement: The progress bar now shows above the controls, it's cleaner 💅🏼\n- Fix: when changing playback-id on an existing mux-player instance we had some leftover state around\n- Fix: full screen was incorrectly using the controls layout depending on the size of the player before it entered full screen. That meant if the player was small and you went full screen you still saw the small controls. Bad!\n\n0.1.0-beta.9\n\n- Your beautiful errors will now flow nicely into Mux Data. Your Mux Data errors dashboard just got a whole lot more useful. This is a big one.\n- Mux Player is now implemented as a Media Chrome \"theme\" under the hood. Laying some groundwork for some exciting Media Chrome things to come\n- Fix for adding event listeners on mux-player, if mux-player JavaScript was loaded after your HTML, events wouldn't get registered. Sorry about that -- fixed now. And we have tests to make sure we don't accidentally introduce a regression down the road.\n- The .hls property on mux-player is super-secret and should not be used unless you are a serious professional. We make no guarantee and your warranty is void if you use this property. To reflect this stance, it has been renamed to _hls.\n- Fixed some seek to live behavior\n- When the error dialog is open we no longer steal the focus of the document. Much better.\n\n0.1.0-beta.8\n\n- If you're using Webpack 4, maybe upgrade? But if not, we got you covered. Fixed package.json to point browser field at mjs so that Webpack 4 is happy\n\n0.1.0-beta.7\n\n- Fix: make mux-player size based on video element\n- Fix: make mux-player errors more uniform\n\n0.1.0-beta.6\n\n- Fix: messed up the release in beta.5, quick follow-on\n\n0.1.0-beta.5\n\n- Fix: clear out some state that was hanging around when playback-id is changed on an existing Mux Player instance, and add some test coverage for this sort of thing\n- Fix: mux-player web component metadata- attributes were not always propagating down\n- Fix: prevent non-fatal Hls.js errors from propagating and causing error states\n\n0.1.0-beta.4\n\n- Paid off some technical debt to handle web components being upgraded after existing in the DOM\n- Fix primary-color attribute so that it is used for all controls, both icons + text. Previously it was only being applied to icon colors\n\n0.1.0-beta.3\n\n- Fix developer log links that go to GitHub\n- Make sure internal state monitoring setup happens when the element exists. Fixes a bug in React when the captions button was sometimes not showing.\n\n0.1.0-beta.2\n\n- Added descriptive error handling. This is important so that you and your viewers are able to easily and quickly understand why a video is not playing. Is your local network connection offline? Is the signed URL expired? Maybe you mixed up PlaybackIDs and you have the wrong signed URL? Is it a problem specific to the media on your device? Often times video-related playback errors are cryptic and difficult to understand the root cause of. We put extra effort into this and we hope it helps you when things go wrong 💖.\n- Fix conditional rendering bug when attributes are removed sometimes the template wasn't updating.\n\n0.1.0-beta.1\n\n- When the control bar is engaged, slide the captions/subtitles up so they are still visible and don't get obscured\n\n0.1.0-beta.0\n\nFirst beta tag release 🎉\n\n- Extended autoplay options autoplay, autoplay=\"muted\" and autoplay=\"any\" are all options now. See docs above for details.\n- Started tracking Player Startup Time with Mux Data. The mo' QoE data we can get, the better!\n- Changed the behavior of the time display, it now defaults to ascending time (current time) and on click will toggle to show remaining time. Previously it showed only remaining time and that was confusing.\n- Fixed a bug related to storyboards on the thumbnails track when the underlying source changed. This should have impacted exactly 0 developers but we wanted to make sure to squash it anyway. If you somehow ran into this bug then you're welcome.\n\n0.1.0-alpha.7\n\n- Support for Signed URLs (see advanced usage section)\n- No longer require env-key` to be passed in (Mux Data will infer environment based on the PlaybackID)"
  },
  {
    "id": "120-_guides/developer/player-themes",
    "title": "Choose a theme for Mux Player",
    "path": "_guides/developer/player-themes.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/player-themes",
    "content": "Mux Player is built on top of Media Chrome\nthat comes with simple but powerful theming\ncapabilities. It allows you to fully control the video player UI layout\nand style but keeps the complexity of media state management out of the way.\n\nThemes are unavailable if you are using the Mux Player HTML embed through player.mux.com.\n\nMux themes\n\nThe minimal and microvideo themes require one extra import,\nthen set the theme attribute and you're ready to go!\n\nMinimal theme\n\nThis theme pares down the Mux Player experience to the bare bones controls\nviewers need, ideal for those that want a simpler player experience.\n\nHere's an example of a React app using the Minimal theme.\n\nMicrovideo theme\n\nThis theme optimizes for shorter content that doesn't need the robust playback\ncontrols that longer content typically requires.\n\nHere's an example of a HTML page using the Microvideo theme.\n\nClassic theme\n\nThis theme is the classic 1.x version of Mux Player. Here's an example of a HTML page using the Classic theme.\n\nStyling\n\nYou can use the same styling methods like explained in\ncustomize look and feel.\n\nNote that the CSS variables, CSS parts and styling guidelines are relevant to themes that ship from @mux/mux-player/themes. Any other Media Chrome themes created by you or a third party will not necessarily share the same CSS variables and parts.\n\nUnlike the Mux Player default theme, these themes come with some buttons disabled by default.\nHowever these can still be enabled by setting some CSS vars.\n\n| Button | CSS Variable |\n| --- | --- |\n| Seek backward button | --seek-backward-button: block; |\n| Seek forward button | --seek-forward-button: block; |\n| PiP (Picture-in-Picture) button | --pip-button: block |\n\nMedia Chrome themes\n\nMux Player uses Media Chrome themes to layout and style the UI of\nthe video player. Please read the\nthemes documentation\nto learn how to create a theme.\n\nThere are two ways to consume a Media Chrome theme in Mux player.\n\nVia an inline `\n\nSee the example on Codesandbox\n\nVia a custom element `\n\nSee the example on Codesandbox"
  },
  {
    "id": "121-_guides/developer/protect-videos-with-drm",
    "title": "Protect videos with DRM",
    "path": "_guides/developer/protect-videos-with-drm.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/protect-videos-with-drm",
    "content": "Check out our blog on \"What is DRM\" to learn more about the concepts of DRM.\n\nDRM (Digital Rights Management) provides an extra layer of content security for video content streamed from Mux.\n\nLeveraging DRM blocks or limits the impact of:\n\n- Screen recording\n- Screen sharing\n- Downloading tools\n\nMux uses the industry standard protocols for delivering DRM protected video content, specifically Google Widevine, Microsoft PlayReady, and Apple FairPlay.\n\nDRM requires the use of Signed URLs, and when combined with Domain and User-Agent restrictions, can provide a very strong content protection story, up to and including security levels that satisfy the requirements of Hollywood studios.\n\nHow Mux DRM Protects Your Content\n\nMux Video's DRM is built to support the strongest protection available for each device without affecting playability. This protection comes in three parts.\n\n- Video encryption: ensures you can't play the video without the proper license.\n- Screen capture protection: ensures that you can't take screenshots or record the screen.\n- HDCP: prevents recording video from video outputs like HDMI.\n\nHowever, not every device supports all three protection layers. Mux has configured DRM at a security level that ensures broad device compatibility while still providing meaningful protection. The following table shows the types of protection you can expect across different devices:\n\n| Device Type | Encrypted Video | Screen Capture Protection | HDCP Enforced | Details |\n| ----- | ----- | ----- | ----- | ----- |\n| iPhone/iPad | ✅ Yes | ✅ Yes | ✅ Yes | Apple supports hardware-level protection on all devices created since the iPhone 5s. |\n| Modern Android devices | ✅ Yes | ✅ Usually | ❌ No | Newer devices such as Google Pixel phones or Samsung phones with Android 12+, or any device with Widevine level 1 support can prevent screen capture. |\n| Older, and lower end Android devices | ✅ Yes |  Sometimes | ❌ No | Many lower end Android devices are missing the secure hardware necessary for Widevine level 3 and hardware decryption. Many of these lower end devices still try to block screen capture, but it's not nearly as secure. |\n| Chrome/Edge browsers on desktop | ✅ Yes | Sometimes | ❌ No | Browser-based playback usually relies on software decryption. Many of these devices still try to block screen capture but it's not nearly as secure. |\n\nAdditional protections\n\nIf you're distributing premium content with strict security requirements (like major studio releases), you may need additional types of protection. For this you have a few options:\n\n Device-level security upgrades: Some players allow you to request stronger DRM when devices support it. This ensures hardware-backed devices get enhanced protection while others play at baseline levels.\n Custom DRM configuration: We're investigating more granular security controls and looking for early partners to help test these features. Reach out for more information.\n Video watermarking: Add visible watermarks using Mux's watermarking feature, which embeds them directly into the video and prevents misattribution. This doesn't support per-user or forensic watermarking, but you can add per-user watermarks by overlaying images on your player - just know these are easier to bypass since they're not baked into the video. Forensic watermarking isn't currently available, but if it would be valuable for your use case, let us know.  We'd love to hear your feedback.\n Trust the DRM Configuration: Attempting to increase security by detecting device capabilities or security levels yourself will be painful. The device landscape changes constantly and maintaining accuracy is nearly impossible. This is better addressed with custom DRM configurations.\n\nIf you need any of these additional protections, or something we've overlooked, contact us. We'd love to hear from you.\n\nBefore you can start using Mux DRM you must complete the onboarding process. The following is a quick overview of the entire process, and you can find additional detail later in this guide.\n\n1. Request a FairPlay certificate for playback on Apple Devices. Don't worry about Widevine and PlayReady certificates, we'll handle those for you.\n2. While waiting on FairPlay approval, Send us a link to any environments that need DRM and we'll set it up.\n3. After we enable DRM on your environments we'll send you a DRM configuration ID and tell you how to securely send us your FairPlay certificates.\n\nOnce these steps are complete you will have your DRM configuration ID and be able to test DRM playback on non-Apple devices. Once you've sent us your FairPlay certificates you can test on Apple devices.\n\nStep 1: Request a FairPlay certificate\n\nDRM playback will work out of the box on every supported platform except for Apple devices. Apple requires you to request your own FairPlay Streaming Deployment package (FPS, often simply referred to as a \"FairPlay Certificate\"). An FPS can only be requested if you meet the following requirements.\n\n1. You have an Apple Developer account with an active subscription.\n2. If you're part of a team account, you are logged in as the owner of a team account.\n\nOnce you've met these requirements, you will need to fill out a form. The initial questions ask about your DRM infrastructure, which is Mux. Here's some guidance on how to answer those questions.\n\n|    |    |\n| :---- | :---- |\n| Does your organization have a working FPS development server where you'll use the FPS certificate? | Select \"Yes\" You will use Mux's verified FPS implementation. |\n| Do you have a third-party streaming distribution partner? | Select \"Yes\". Mux is that third-party partner. |\n| Streaming Distribution (DRM License Server) Partner Name | Enter \"Mux, Inc.\". |\n| Streaming Distribution (DRM License Server) Partner Website | Enter \"https://mux.com\". |\n| Your Company | Describe your company and the services they provide. |\n| Your Content | Describe the type of content you will be protecting with FairPlay and why that content needs DRM. |\n| Do you own the content you want to stream? | If you hold full copyright ownership of your content, select \"Yes\". Otherwise select \"No\" and answer the following two additional questions that appear: |\n| Do you have a content licensing agreement with the owner of the content? | If you license third-party content, select \"Yes\". |\n| Your Content Provider | If you license third-party content, include the name of that provider and a description of the rights you have to use their content. |\n| Is this your first request for FPS credentials? | If this is your first time submitting this form or requesting a FairPlay certificate, select \"Yes\".\n| Do you assert that the account holder of this developer account owns, or has a license to use, the content that you will be streaming? | Select the most appropriate answer for your situation. |\n\nOnce you've submitted the request, approval may take several days. Once approved, Apple will provide documentation for generating the final certificate. This includes generating a private key via your terminal and filling out a form.\n\nOnce you've created your FairPlay deployment package, contact us and we'll walk you through securely sending us the files.\n\n  You do not need to request a Widevine or PlayReady certificate, Mux manages these for you.\n\nStep 2: Request DRM for your environment\n\nGo to Settings -> Digital Rights Management to request DRM access. This page will walk you through the necessary requirements and allow you to request access. You will receive a response via email with next steps.\n\nStep 3: Receive your DRM configuration ID\n\nAfter we enable DRM on your environment you can find your DRM configuration ID in Settings -> Digital Rights Management. You'll need this when you add a DRM playback ID to an asset.\n\nYou can also use the DRM Configurations API to list the DRM Configurations available to your account.\n\nMux Video supports applying DRM to both live streams and assets.\n\nCreating a DRM protected asset\n\nWhen using the Create Asset API, you can add DRM protection by including advanced_playback_policies with your DRM configuration ID. Make sure to set the video_quality to plus or premium, as DRM is only supported on these quality levels.\n\n\n```json\n// POST /video/v1/assets\n{\n  \"inputs\": [\n    {\n      \"url\": \"https://storage.googleapis.com/muxdemofiles/mux.mp4\"\n    }\n  ],\n  \"advanced_playback_policies\": [\n    {\n      \"policy\": \"drm\",\n      \"drm_configuration_id\": \"your-drm-configuration-id\"\n    }\n  ],\n  \"video_quality\": \"plus\"\n}\n```\n\n\nWhen working with advanced_playback_policies, keep in mind that you can't use both the playback_policy field and advanced_playback_policies field in the same request. When working with DRM, stick to advanced_playback_policies. If you need more than one playback policy, such as for static renditions, you can include multiple policies in the advanced_playback_policies array.\n\nIf you need to add DRM protection to an existing asset, you can use the Playback IDs API to retroactively add a DRM playback policy. This works for any asset created after DRM was enabled in your environment.\nCreating a DRM protected live stream\n\nJust like creating a DRM protected asset, DRM protected live streams require configuration ID must be set in the live stream's advanced_playback_policies.\n\nIn the example below, we also set the new_asset_settings to also use DRM, so any DVR assets and on-demand assets also have DRM applied.\n\n\n```json\n// POST /video/v1/live-streams\n{\n  \"advanced_playback_policies\": [\n    {\n      \"policy\": \"drm\",\n      \"drm_configuration_id\": \"your-drm-configuration-id\"\n    }\n  ],\n  \"new_asset_settings\": {\n    \"advanced_playback_policies\": [\n      {\n        \"policy\": \"drm\",\n        \"drm_configuration_id\": \"your-drm-configuration-id\"\n      }\n    ]\n  }\n}\n```\n\n\nMux supports three types of DRM: Widevine, FairPlay, and PlayReady. These three DRM systems cover the vast majority of devices in use today, including desktop browsers, mobile browsers, and living room devices (OTT).\n\nSupported Platforms\n\nBefore you start to build your DRM integration, make sure Mux's DRM supports your target platforms. Mux's DRM is verified to work on all of the following platforms, but likely works on additional platforms. If you would like us to verify an additional platform, please contact us.\n\nDesktop Browsers\nThe following desktop browsers support Mux DRM via the Mux Web Player, or any of the players listed in our player documentation.\n- Chrome (macOS and Windows)\n- Firefox (macOS and Windows)\n- Safari (macOS)\n- Edge (Windows)\n- Legacy Edge (Windows)\n\nMobile Browsers\nThe following mobile browsers support Mux DRM via the Mux Web Player, or any of the players listed in our player documentation.\n- Chrome on Android\n- Firefox on Android\n- All browsers on iOS\n\nNative Mobile Apps\n- Android apps using Mux Player for Android\n- iOS apps using Mux Player for iOS\n\nLiving room devices (OTT)\nThe following living room devices support Mux DRM, and link to the relevant documentation.\n- Chromecast\n- Google TV\n- Apple TV (tvOS)\n- Roku\n- Fire TV\n\nCreating your playback and license tokens\n\nTo successfully play back content protected by Mux DRM you will need your asset's playback ID and two secure tokens; a playback token and a DRM license token. These tokens are both signed using the JWT requirements laid out in our secure video playback guide.\n\nIf you're using our node library to sign your license URLs we offer a helper function:\n\n```js\nconst mux = new Mux({\n  tokenId: \"your-access-token-id\",\n  tokenSecret: \"your-access-token-secret\",\n  jwtSigningKey: \"your-environment-signing-public-key\",\n  jwtPrivateKey: \"your-environment-signing-private-key\"\n});\n\nconst playbackToken = await mux.jwt.signPlaybackId(\"your-playback-id\", {expiration: '7d'});\nconst drmLicenseToken = await mux.jwt.signDrmLicense(\"your-playback-id\", {expiration: '7d'});\n```\n\n\nOnce you have created your signing tokens, you can use them directly in a Mux player. If you are using a non-Mux player you use these tokens to build your playback and license URLs.\n\nPlayback in Mux players\n\nNow that you have the necessary tokens, we can hook them into a Mux Player.\n\nMux Web Player\n\nTo play back DRM protected content, you should instantiate the player with the new drm-token parameter set to the DRM license token that you generated previously. In Mux Player React, you'll use the tokens prop to set the drm token.\n\n  Support for DRM in Mux Player was added in version 2.8.0.\n\n<CodeExamples\n    product=\"player\"\n    example=\"tokensDrm\"\n    exampleOrder=\"html,react,embed\"\n/>\n\nYou can see a demo of this working in codesandbox here.\n\nWith your new tokens all wired up correctly, you should be able to play back your freshly DRM protected content!\n\nHere's a demo page with some pre-prepared DRM protected content you can also test a device against.\n\nFull documentation for using DRM with Mux Player for web can be found here.\n\nMux Player iOS\n\n  Support for DRM in Mux Player for iOS was added in version 1.1.0.\n\nThe DRM license token can be configured on PlaybackOptions using the following API:\n\n\n```swift\nlet playbackOptions = PlaybackOptions(\n  drmToken: \"your-drm-license-token\",\n  playbackToken: \"your-playback-token\",\n)\n\nlet playerItem = AVPlayerItem(\n  playbackID: \"your-playback-id\",\n  playbackOptions: playbackOptions\n)\n```\n\n\nFull documentation for using DRM Mux Player for iOS can be found here.\n\nMux Player Android\nThe DRM license token can be configured when instantiating a MediaItem using the MediaItems factory class as follows:\n\n  Support for DRM in Mux Player for Android was added in version 1.1.0.\n\n\n```kotlin\n// You don't need to add your own DrmSessionManager, we take care of this\n\nval player = // Whatever you were already doing\n\nval mediaItem = MediaItems.mediaItemFromPlaybackId(\n  playbackId = \"your-playback-id\",\n  playbackToken = \"your-playback-token\",\n  drmToken = \"your-drm-license-token\"\n)\n\n// Normal media3 boilerplate\nplayer.setMediaItem(mediaItem)\nplayer.prepare()\n```\n\n\nFull documentation for using DRM Mux Player for Android can be found here.\n\nPlayback in third-party players\nIf you can't use one of the Mux players, you still have options. Mux's DRM is compatible with a wide range of third party players. Because these players don't know exactly how Mux's DRM works, you'll need to build the correct playback and license URLs, then add them to the player.\n\nCreating license URLs\nThe following examples demonstrate the license URL structure for each of the supported DRM providers.\n\nWidevine\n\n\n```\nhttps://license.mux.com/license/widevine/{playback-id}?token={drm-license-token}\n```\n\n\nFairPlay\n\nBefore you can use FairPlay DRM, you must request the proper certificate from Apple. Once FairPlay is enabled on your account, you will use one license url and one certificate URL.\n\nLicense URL\n\n\n```\nhttps://license.mux.com/license/fairplay/{playback-id}?token={drm-license-token}\n```\n\n\nCertificate URL\n\n\n```\n\nhttps://license.mux.com/appcert/fairplay/{playback-id}?token={drm-license-token}\n```\n\n\nPlayReady\n\n\n```\nhttps://license.mux.com/license/playready/{playback-id}?token={drm-license-token}\n```\n\n\nThird party players\nThe following third-party players have been tested with Mux DRM. If you are using a player not listed here, check out our notes on other players.\n\nRoku\n\nIn order to play back DRM protected content in Roku, add your DRM Configuration to your content node. This includes the following:\n\n1. Add the following two fields to your channel's manifest:\n\n```jsx\n    requires_widevine_drm=1\n    requires_widevine_version=1.0\n    ```\n\n2. When preparing your contentNode, ensure you reference the DRM configuration and license URL as follows:\n\n\n```jsx\ndrmParams = {\n  keySystem: \"Widevine\",\n  licenseServerURL: \"https://license.mux.com/license/widevine/${PLAYBACK_ID}?token=${DRM_LICENSE_JWT}\"\n}\n\ncontentNode = CreateObject(\"roSGNode\", \"ContentNode\")\ncontentNode.url = \"<content URL>\"\ncontentNode.drmParams = drmParams\ncontentNode.title = \"<your title>\"\ncontentNode.length = <duration in seconds>\n\n' other contentNode properties can be added here,\n' then play your video as you normally would\n```\n\n\nChromecast\nChromecast devices use Google Cast to send videos from one device to another. There are quite a few steps to set up Google Cast, so we recommend you check out our Google Cast guide for more details.\n\nHLS.js\n\nHLS.js supports DRM via configuration keys in any browser with native MSE support (e.g. old versions of Safari). For browsers that do not support MSE, you will need to use the native video element. Both flows are included in the example below.\n\n\n```js\n// This browser supports MSE and EME, so we can use hls.js\nif (Hls.isSupported()) {\n  var hls = new Hls({\n    emeEnabled: true,\n    drmSystems: {\n      'com.widevine.alpha': {\n        licenseUrl: 'https://license.mux.com/license/widevine/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}'\n      },\n      'com.microsoft.playready': {\n        licenseUrl: 'https://license.mux.com/license/playready/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}'\n      },\n      'com.apple.fps': {\n        licenseUrl: 'https://license.mux.com/license/fairplay/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}',\n        serverCertificateUrl: 'https://license.mux.com/appcert/fairplay/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}',\n      }\n    }\n  });\n// This browser supports EME but not MSE, so we need to use the native video element\n} else if (video.canPlayType('application/x-mpegURL')) {\n  video.src = mediaUrl;\n\n  video.addEventListener('encrypted', async function(event) {\n    const initDataType = event.initDataType;\n    const initData = event.initData;\n\n    // Retrieve a MediaKeySystemAccess object to interact with the DRM system\n    const access = await navigator.requestMediaKeySystemAccess('com.apple.fps', [{\n        initDataTypes: [initDataType],\n        videoCapabilities: [{ contentType: 'application/vnd.apple.mpegurl', robustness: '' }],\n        distinctiveIdentifier: 'not-allowed',\n        persistentState: 'not-allowed',\n        sessionTypes: ['temporary'],\n    }]);\n\n    if (!access) {\n        console.error('Cannot play DRM-protected content with current security configuration on this browser. Try playing in another browser.');\n        return;\n    }\n\n    // Create DRM keys\n    const keys = await access.createMediaKeys();\n\n    // Get the FairPlay license and certificate\n    const certificate = await fetch('https://license.mux.com/appcert/fairplay/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}').then(async (res) => {\n        const keyBuffer = await res.arrayBuffer();\n        return new Uint8Array(keyBuffer);\n    });\n\n    if (!certificate) {\n        console.error('Failed to fetch certificate');\n        return;\n    }\n\n    // Attach the certificate to the DRM keys\n    await keys.setServerCertificate(certificate);\n\n    // Attach the keys to the video element\n    await video.setMediaKeys(keys);\n\n    // Create a playback session\n    const session = (video.mediaKeys).createSession();\n\n    // Create the data necessary to make a DRM license request\n    const message = await new Promise((resolve, reject) => {\n        session.generateRequest(initDataType, initData);\n        session.addEventListener('message', (messageEvent) => {\n            resolve(messageEvent.message);\n        }, { once: true });\n    });\n\n    // Get a DRM license\n    const response = await fetch('https://license.mux.com/license/fairplay/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}', {\n        method: 'POST',\n        headers: { 'Content-type': 'application/octet-stream' },\n        body: message,\n    });\n\n    // Attach the license key to the session\n    const licenseData = await response.arrayBuffer();\n    await session.update(licenseData);\n  });\n}\n```\n\n\nFor more details, check out the HLS.js DRM docs.\n\nVideo.js\n\nVideo.js supports DRM via the videojs-contrib-eme plugin.\n\n\n```js\nconst player = videojs('vid1', {});\n\nplayer.eme();\nplayer.src({\n  src: 'https://stream.mux.com/{playback-id}.m3u8?token={JWT}',\n  type: 'application/x-mpegURL',\n  keySystems: {\n    'com.widevine.alpha': 'https://license.mux.com/license/widevine/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}',\n    'com.apple.fps.1_0': {\n      certificateUri: 'https://license.mux.com/appcert/fairplay/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}',\n      licenseUri: 'https://license.mux.com/license/fairplay/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}',\n    },\n    'com.microsoft.playready': 'https://license.mux.com/license/playready/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}'\n  }\n});\n```\n\n\nFor more details check, out the videojs-contrib-eme docs.\n\nShaka player\n\nShaka player supports DRM via configuration keys.\n\n\n```js\nplayer.configure({\n  drm: {\n    servers: {\n      'com.widevine.alpha': 'https://license.mux.com/license/widevine/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}',\n      'com.apple.fps.1_0': 'https://license.mux.com/license/fairplay/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}',\n      'com.microsoft.playready': 'https://license.mux.com/license/playready/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}'\n    },\n    advanced: {\n      'com.apple.fps.1_0': {\n        serverCertificateUri: 'https://license.mux.com/appcert/fairplay/${PLAYBACK_ID}?token=${DRM_LICENSE_TOKEN}'\n      }\n    }\n  }\n});\n```\n\n\nFor more details, check out the Shaka player DRM docs.\n\nOther players\n\nWhile we have only tested playback with our supported players, there are many others that will work just fine. If your platform supports playback of HLS, CMAF packaged streams, with Widevine, PlayReady, or FairPlay DRM, using CBCS encryption, then Mux might work by following the custom players guide. If you would like us to support additional platforms, let us know.\n\nTesting that DRM is working\n\nChecking your video is DRM protected is pretty simple: just take a screenshot! If DRM is working correctly, you should see the video replaced with either a black rectangle, or a single frame from the start of the video.\n\nCurrently Mux's DRM feature defaults to a balance of security and playability, including automatically leveraging higher security levels on devices where this is available.\n\nAt times customers may want to adjust this balance to increase security levels, specifically for example to meet contractual Hollywood studio security requirements. Please contact us if you need to discuss or adjust the security levels used.\n\nIn the future, we will allow self-serve adjustment of security levels through the DRM Configurations API.\n\nIn line with common industry practices, only video tracks are currently DRM protected, meaning that audio-only assets and audio-only live streams are not protected by DRM.\n\nDRM is an add-on feature to Mux Video, with a $100/month access fee + $0.003 \"per license\", and discounts available for high volumes.\n\nWhat is a DRM license?\nOne DRM license request typically corresponds to one video view. When a viewer starts watching a DRM-protected video, the player requests a license to decrypt and play the content. While licenses and video views usually line up, the exact count can vary depending on each player's caching behavior."
  },
  {
    "id": "122-_guides/developer/reduce-live-stream-latency",
    "title": "Reduce live stream latency",
    "path": "_guides/developer/reduce-live-stream-latency.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/reduce-live-stream-latency",
    "content": "Mux Video live streaming is built with RTMP ingest and HLS delivery. HLS inherently introduces latency.\nTo the broadcasting industry, this latency is called glass-to-glass latency. Standard glass-to-glass latency with HLS\nis greater than 20 seconds and typically about 25 to 30 seconds.\n\nTo clarify some terminology and industry jargon:\n\n- Glass-to-glass latency: Also sometimes referred to as end-to-end latency. This latency is defined as the time lag between when a camera captures an action and when that action reaches a viewer’s device.\n- Wall-clock time: Also might be referred to as \"realtime\". If you have a clock on the wall where you are capturing video content, this would be the time on that clock.\n\nThe nature of HLS delivery means that clients are not necessarily synchronized. Some clients might be 15 seconds behind wall-clock time and others might be 30 seconds behind.\n\nWhere does the latency come from?\nYou don't have to worry about these gritty details when using Mux for live streams, but to give you an idea of how a live stream works:\n\n1. Captured by a camera\n2. Processed by an encoder - If the computer running the encoder is running out of CPU this process can get behind and start lagging.\n3. Send to an RTMP ingest server - This server is ingesting the video content in real-time. This part is called the \"first mile\", it's happening over the internet, often times on consumer or cellular network connections so things like TCP packet-loss and random network disconnects are always happening.\n4. Ingest server decodes and encodes - Assuming all the content is traveling over the internet fast enough, the encoder on the other end needs to keep up and have enough CPU available to package up segments of video as they come in. The encoder has to ingest video, build up a buffer of content and then start decoding, processing and encoding for HLS delivery.\n5. Manifest files and segments of video delivered - After all of that, files are created and delivered over HTTP through multiple CDNs to reach end users. Each file becomes available after the entire segment's worth of data is ready. This part also happens over the internet where the same risks around packet-loss and network congestion are factors. Network issues are especially a factor for the last mile of delivery to the end user.\n6. Decoded and played on the client - When video makes it all the way to the client. The player has to decode and playback the video. Players do not play each segment on the screen as they receive it, they keep a buffer of playable video in-memory which also contributes to the glass-to-glass latency experienced by the end user.\n\nWhen you consider each of the steps above, any point of that pipeline has the potential to slow down or get backed up. The more latency you can tolerate,\nthe safer the system is and the lower probability you have for an unhappy viewer. If any single step gets backed up momentarily, the whole system has a chance\nto catch up before an interruption in playback. And, when everything is running smoothly, the player has extra time to spend downloading the higher quality version of your content.\n\nAs shown in the image above, there is latency added at every step. However, Mux does not control any latency added during video capture on the camera,\nencoder processing delays, and amount of video buffered & the decoding time of the video player.\n\nReconnect Window\nWhen an end-user is streaming from their encoder to Mux, we need to know how to handle situations when the client disconnects unexpectedly.\n\nThere are situations when a client disconnects on purpose: for example hitting \"Stop streaming\" on OBS.\nThose are intentional disconnects, we're talking about times when the client just stops sending video.\nIn order to handle this, live streams have a reconnect_window. After an unexpected disconnect,\nMux will keep the live stream \"active\" for the given period of time and wait for the client to reconnect and start streaming again.\n\nWhen the reconnect_window expires, the live stream transitions back into the idle state. In HLS terminology,\nMux writes the EXT-X-ENDLIST tag to the HLS manifest. At this point, your player can consider the live stream to have ended.\nBy default, reconnect_window is 60 (seconds) - you can set this as high as 1800 (30 minutes).\n\nBy adding the slate image, you can improve your viewer's video playback experience during the Reconnect window time interval.\nYou can learn more on Reconnect Windows and Slates here.\n\nLower latency Options\nMux live streams have options for \"reduced\" and \"low\" latency. The \"latency_mode\": \"reduced\" option gets your latency down to a range of 12-20 seconds and\nthe \"latency_mode\": \"low\" further reduces the latency to as low as 5 seconds. But your viewers might see some variance to the glass-to-glass latency because\nthe latency depends on many factors, including player configurations, your viewer's geographic location, and their internet connectivity speed.\n\nInput Requirements\n\nYou should only set latency_mode to reduced or low if you have control over the following:\n- the encoder software\n- the hardware the encoder software is running on\n- the network the encoder software is connected to\n\nTypically, home networks in cities and mobile connections are not stable enough to reliably use reduced or low latency options.\n\nCreate a live stream with the \"reduced\" latency option\n\nCheck out our Live Stream API Reference and find the latency_mode parameter and set the parameter to \"reduced\" in the request to create a live stream.\n\nSet the latency mode on a live stream to reduced by making this POST request:\n\n\n```json\n//POST https://api.mux.com/video/v1/live-streams\n\n{\n    \"latency_mode\": \"reduced\",\n    \"reconnect_window\": 60,\n    \"playback_policies\": [\"public\"],\n    \"new_asset_settings\": {\n        \"playback_policies\": [\"public\"]\n    }\n}\n```\n\n\nYou can read more about the reduced latency feature in this blog post about Reduced Latency.\n\nCreate a live stream with the \"low\" latency option\n\nCreate Live Stream is also used to set the \"latency_mode\": \"low\" flag.\n\nSet the latency mode on a live stream to low by making this POST request:\n\n\n```json\n//POST https://api.mux.com/video/v1/live-streams\n\n{\n    \"latency_mode\": \"low\",\n    \"reconnect_window\": 60,\n    \"playback_policies\": [\"public\"],\n    \"new_asset_settings\": {\n        \"playback_policies\": [\"public\"]\n    }\n}\n```\n\n\nA live stream can only be configured as \"reduced\" or \"low\" or \"standard\" latency.\n\nLow-latency FAQs\n\nIs low-latency HLS different from standard latency HLS?\nYes. The \"latency_mode\": \"low\" mode uses Apple's new low-latency HLS (LL-HLS) spec\nthat allows your viewers to play live streams with as low as 5 seconds glass-to-glass latency. In comparison, the other latency modes are based on the\nearlier version of the HLS spec which puts a cap on the lower limits of the glass-to-glass latency.\n\nMux has closely followed the new low-latency HLS spec and published about the development of the new spec a few times on our blog\nin June 2019\nand again in January 2020.\n\nDo video players support low-latency HLS?\nYes. Because \"latency_mode\": \"low\" mode uses a recent version of Apple's LL-HLS spec, you may need to upgrade your video player. Below is the list of the\nmost commonly used video players and the minimum version.\n\nThe video player may have supported LL-HLS spec in earlier versions. However, the minimum video player version mentioned below represents\nthe version we used for evaluating Mux's low-latency feature.\n\nAdditionally, the video player companies are continuously improving video\nplayback experience as the LL-HLS spec is more widely adopted and used in the real world.\nWe recommend updating your video player versions frequently whenever possible to get the latest fixes and improvements.\n\n| Player | Version | Additional details |\n| :-- | :-- | :-- |\n| HLS.js | >= 1.1.5 | Other potentially relevant issues to track - (3596) |\n| JW Player | >= 8.20.5 | Setting the liveSyncDuration configuration option can increase latency. So you should not set this option for low-latency playback. |\n| THEOplayer | >= 6.0.0 | LL-HLS playback is enabled by default. |\n| THEOplayer | >= 2.84.1 | Requires enabling LL-HLS add-on on your player instance and set lowlatency parameter to true in the player configuration. |\n| VideoJS | >= 8.0.0 | LL-HLS playback is enabled by default. |\n| VideoJS | >= 7.16.0 | Enabling low latency playback requires initializing videojs-https-streaming with the experimentalLLHLS flag. See FAQs.|\n| Mux Player | >= 1.0 | |\n| Mux Video.js Kit | >= 0.4 | Mux Video.js Kit uses HLS.js so the same issues apply. |\n| Apple iOS (AVPlayer) | 13. | Requires com.apple.developer.coremedia.hls.low-latency app entitlement for your iOS apps. Also, there are known issues that occasionally cause playback failures. |\n| Apple iOS (AVPlayer) | 14. | There are known issues that occasionally cause playback issues. |\n| Apple iOS (AVPlayer) | 15.* | |\n| Android ExoPlayer | >= 2.14 | |\n| Agnoplay | >= 1.0.33 | |\n\nMy video player does not support the LL-HLS spec. Can it still play a low-latency live stream?\nMaybe. Apple's LL-HLS specification is backward compatible. So your video player should fall back to playing standard HLS.\nThose viewers will have noticeably higher glass-to-glass latency. However, your video player does need support for demuxed audio & video tracks\n(each track requested separately) in MP4 format for being backward compatible. Most video players already support demuxed audio &\nvideo tracks in MP4 format.\n\nMy video player is running into issues when playing a low-latency live stream. Can I play the same live stream without the low-latency?\nYes. You can add the low_latency=false parameter to the video playback URL. Mux can revert back to delivering the same live stream\nusing standard HLS by adding this low_latency=false parameter. However, your video player does need support for demuxed audio & video tracks\n(each track requested separately) in MP4 format for the low_latency=false parameter to work.\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?low_latency=false\n```\n\nIf your playback_id is signed, then all query parameters, including low_latency need to be added to the claims body. Take a look at\nthe signed URLs guide for details.\n\nHow do you enable LL-HLS playback on VideoJS player prior to 8.0.0?\nYou can enable low latency playback using Apple's LL-HLS spec by initializing videojs-http-streaming\nmodule with the experimentalLLHLS flag along with any other options.\n\n```\nvar player = videojs(video, {\n  html5: {\n    vhs: {\n      experimentalLLHLS: true\n    }\n  }\n});\n```\n\n\nCan I change my existing live stream's latency to low latency?\nYes. You can change your existing live stream's latency and set the latency to any of the available options -\nstandard or reduced or low using the Live Stream PATCH.\nYou can only execute this API when the live stream status is idle and helpful in migrating your live stream based on the streamer's\nrequirements. After Mux successfully runs this API, your webhook endpoint also receives video.live_stream.updated event.\n\n\n```json\n//PATCH https://api.mux.com/video/v1/live-streams/{LIVE_STREAM_ID}\n\n{\n    \"latency_mode\": \"low\"\n}\n```"
  },
  {
    "id": "123-_guides/developer/save-and-share-filter-sets",
    "title": "Save and share filter sets",
    "path": "_guides/developer/save-and-share-filter-sets.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/save-and-share-filter-sets",
    "content": "What are filter sets?\n\nFilter sets allow you to save and share commonly used filter combinations into sets to ensure data consistency and streamline operational workflows.\n\n1. To create a filter set, select the filter set button on any dashboard that supports filters.\n2. Select ‘create new filter set’ from the menu.\n\n3. Select a name for your filter set.\n\n4. Choose if your filter set is public or private. Private means that only you will see it in the menu under your ‘private’ filter sets. Public means that all users in an environment will be able to see and select the filter set.\n\n5. Select the filters that you wish to add to your filter set. The filter values that were selected on the page will automatically populate in this menu. You can remove or add new dimension and metric filters before saving.\n\nAdd a new filter value to a filter set\n\nYou can manually create a new filter value if it doesn’t yet exist in Mux Data. This is useful for an upcoming event or new product launch.\n\n1. In the filter menu, select the dimension type on the left.\n2. Type the value of the dimension that you wish to add.\n3. The value you entered will appear in the results with zero views.\n4. Select that value to add it to your filter set.\n5. Select apply.\n6. Select save.\n\nThis value will now be associated with your saved filter set. When selecting this filter set, it will show zero views until there are views that match that criteria.\n\nNavigating with filter sets\nWhen a filter set is selected, it will persist when navigating across dashboards in Mux Data. Not all filters are supported across all dashboards.\n\nIf you navigate to a dashboard on Mux that doesn’t support a filter in your selected filter set, that filter will be deactivated while on that dashboard. A warning message will appear and the filter set will appear yellow if all values are not applicable to that page. The filter will also appear in a deactivated state in the filter display menu.\n\nOnce you navigate to a dashboard where that filter is applicable, it will be reactivated.\n\nFilter sets and Custom Dashboards\n\nWhen you build a Custom Dashboard, filters and filter sets are saved as a setting of that dashboard. When you navigate to a Custom Dashboard, all selected filters and filter sets will be reset to the values saved to that dashboard.\n\nFilter sets can be added to custom dashboards. However, filter sets are not available to be applied to custom dashboard components.\n\nDelete a filter set\n\n1. Select the edit filter set icon for the filter set you wish to delete.\n2. In the filter set menu, select delete filter set icon.\n\n<MultiImage\n  images={[\n    { sm: true, src: \"/docs/images/save-and-share-filter-sets-5.png\", width: 1130, height: 924, alt: \"A Mux Metrics dashboard with the filter menu open. The filter dropdown lists private saved filter sets titled “IBC Conference” and “Engaged Views,” along with an option to create a new filter set. The dashboard displays graphs for views and overall viewer experience.\" },\n    { sm: true, src: \"/docs/images/save-and-share-filter-sets-6.png\", width: 822, height: 1130, alt: \"A Mux modal titled “Edit Filter Set.” The name field shows “IBC Conference.” Privacy is set to Private. One dimension filter is applied — a long video ID string. The bottom of the modal includes Cancel and Save buttons.\" },\n  ]}\n/>"
  },
  {
    "id": "124-_guides/developer/secure-video-playback",
    "title": "Secure video playback",
    "path": "_guides/developer/secure-video-playback.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/secure-video-playback",
    "content": "If you add an asset or start a live stream through Mux without passing a playback policy, you'll be unable to access it in your browser using a URL. This may seem counterintuitive at first, however, this gives you the ability to be explicit about who can access your content, as well as exactly how, where, or when they can access it.\n\nThere may be instances where you upload a video to Mux that is not intended to be made available for public viewing. For example, maybe you have a membership site that your users must join to access your videos, or you are offering a pay-to-access live stream.\n\nFor these scenarios, Mux offers playback policies that allow you to control the different ways users can view and interact with your content.\n\nUnderstanding playback policies\n\nWhen you upload a video or initiate a live stream through Mux, you also have the option to define what type of fine-grained access should apply to your content. This is done by specifying a playback policy.\n\nMux offers two kinds of playback policies: public and signed.\n\n- Public playback policies will enable playback URLs that can be watched anywhere, at any time, without any restrictions. This option is perfect for sharing your viral cat videos with the whole world.\n- Signed playback policies will enable playback URLs that require a valid JSON Web Token (JWT) to gain access. The JWT should be signed and generated by your application on a protected server, not on a public client.\n\nA playback policy can be specified when you create a new asset or live stream, or can be added to an existing asset or live stream.\n\nOnce an asset or live stream has been assigned a playback policy, the asset will be issued a new playback ID that's associated with its corresponding playback policy. It's possible for each asset or live stream to have multiple playback IDs.\n\nSee Create a playback ID to learn how to add a new playback policy and ID to an existing Asset or Live Stream.\n\nPublic playback policies are pretty self-explanatory, so let’s dig into the signed playback policies.\n\nA closer look at signed playback policies\n\nWhen you apply a signed playback policy to your content, there are two distinct ways you can restrict video playback:\n\n1. Expiration time (required) allows you to specify a point in time when your issued JWT should be considered expired. Viewers with a valid token can watch videos until your specified expiration time value passes. All HTTP requests made to access your content past the expiration time are denied.\n2. Playback Restrictions (optional) allow you to implement additional rules for playing videos. For example, let’s consider Referrer Validation. When you create a signed playback policy, you can supply a list of websites that are allowed to host and serve your content. Any requests from domains that aren't on the allow list are denied if they attempt to play back your content.\n\nReferrer and User-Agent Validation Playback Restrictions are supported today; Mux plans to add more types of restrictions in the future.\n\nLet’s walk through a typical workflow for creating a valid JWT used to access a Mux asset with a signed playback policy.\n\n1. Create an Asset or Live Stream with a signed playback policy\n\nLet’s start from scratch and add a new asset to our Mux account using a standard authenticated API call. Notice how we set the playback_policy value to signed during this Create Asset request:\n\n\n```json\n// POST https://api.mux.com/video/assets\n\n{\n  \"inputs\": [\n    {\n      \"url\": \"https://storage.googleapis.com/muxdemofiles/mux-video-intro.mp4\"\n    }\n  ],\n  \"playback_policies\": [\n    \"signed\"\n  ],\n  \"video_quality\": \"basic\"\n}\n```\n\n\n2. Create a signing key for your Mux account environment\n\nNext, we'll need to create a Mux signing key. Signing keys are used to generate valid JWTs for accessing your content. Signing keys can be managed (created, deleted, listed) from the Signing Keys settings of the Mux dashboard or via the Mux System API.\n\n  Remember: Mux signing keys are different than Mux API keys.\n\nWhen you create a new signing key, the API generates a 2048-bit RSA key-pair and returns the private key and a generated key-id. You should securely store the private key for signing the token, while Mux stores the public key to validate the signed tokens.\n\nSigning keys are created and deleted independently of assets. You probably only need one signing key active at a time, but you can create multiple to enable key rotation, creating a new key and deleting the old one only after any existing signed URLs have expired.\n\nSee Create a URL signing key for full documentation.\n\n\n```json\n//POST https://api.mux.com/system/v1/signing-keys\n\n{\n  \"data\": {\n    \"private_key\": \"(base64-encoded PEM file with private key)\",\n    \"id\": \"(unique signing-key identifier)\",\n    \"created_at\": \"(UNIX Epoch seconds)\"\n  }\n}\n```\n\n\n3. Create an optional Playback Restriction for your Mux account environment\n\nMux supports two types of playback restriction:\n Referrer Validation: Restricts whether the domain specified in the HTTP Referer request header or when no referrer domain is specified will be allowed for playback.\n User Agent Validation: Restricts whether a high risk user agent specified in the User-Agent request header or when no user agent is specifed will be allowed for playback.\n\nDuring playback, a restriction is applied using a JWT claim, which will be covered in the next two sections.\n\n  Playback restrictions exist at the environment level. However, creating a playback restriction in an environment does not mean all assets are automatically restricted by it.\n\n  Instead, you should apply a given restriction to a playback by referencing it in the token you create for a signed playback ID.\n\nIf you don’t need to use playback restrictions for your content, feel free to jump to the next step.\n\nCreate a Playback Restriction\n\nMost commonly, you want all the videos on your Mux account to be watched only on your website https://example.com. To do so, you can create a new Playback Restriction by adding example.com domain as the only allowed domain that can play your videos.\n\nSee Playback Restriction for full documentation.\n\nExample API Request\n\n```json\n//POST https://api.mux.com/video/v1/playback-restrictions\n\n{\n  \"referrer\": {\n    \"allowed_domains\" : [\n      \"example.com\"\n\t  ],\n    \"allow_no_referrer\" : false\n  }\n}\n```\n\n\nExample API Response\n\n```json\n{\n  \"data\": {\n    \"updated_at\": \"1634595679\",\n    \"referrer\": {\n      \"allowed_domains\": [\n        \"example.com\"\n      ],\n    },\n    \"id\": \"JL88SKXTr7r2t9tovH7SoYS8iLBVsjZ2qTuFS8NGAQY\",\n    \"created_at\": \"1634595679\"\n  }\n}\n```\n\n\nStore the id value from the API response above as PLAYBACK_RESTRICTION_ID in your application for later use when generating the signed JWT.\n\nPlayback Restriction Syntax\n\nWhen you create a playback restriction, you may specify the referrer domains and/or user agent restrictions in the same request. The referrer field allows you to specify the referrer restrictions and the user_agent field allows you to specify the user agent restrictions. For the referrer allowed_domains list, you may specify up to 100 unique domains or subdomains where your videos will be embedded.  Specify this in the referrer.allowed_domains array using valid DNS-style wildcard syntax. For example:\n\n\n```json\n{\n  \"referrer\": {\n    \"allowed_domains\": [\n      \"*.example.com\",\n      \"foo.com\"\n    ],\n    \"allow_no_referrer\": false\n  },\n  \"user_agent\": {\n    \"allow_no_user_agent\": false,\n    \"allow_high_risk_user_agent\": false\n  }\n}\n```\n\n\nChoose from the following options:\n\n- To deny video playback requests for all domains, use an empty Array: []\n- To allow playback on example.com and all the subdomains of example.com, use the syntax: [\".example.com\", \"example.com\"]\n- Use a single wildcard  entry to allow video playback requests from any domain: [\"\"]\n- Use a wildcard for one subdomain level. For instance, video playback will be denied from xyz.foo.example.com when you include [\".example.com\"].\n\nPlayback Restriction considerations\n\nHere are some things to consider when using Playback Restrictions.\n\n- You can create up to 100 different Playback Restrictions per environment on your Mux account.\n\n- You can use a Playback Restriction ID for playing a single video or a group of videos.\n\n- You have a lot of flexibility for associating Playback Restrictions with videos. For instance, you can create one Playback Restriction for each of your clients if your service or application supports multiple clients.\n\n- You can add up to 100 different domains to each Playback Restriction.\n\n- You can restrict playing video on domains added to the Playback Restriction. For instance, if you want multiple partner sites to play a video, you can add the partner site domain to the same Playback Restriction, thereby restricting playback only on those domains.\n\n- If your player supports Chromecast, like Mux Player, make sure you add the Chromecast domain (www.gstatic.com) to your playback restrictions, otherwise casting will fail.\n\n- if your player supports AirPlay, like Mux Player, you will only be able to AirPlay to third party devices by adding the AirPlay domain (mediaservices.cdn-apple.com) to your playback restrictions. Because first-party Apple devices never forward the referrer header, allow_no_referrer must be set to true in order to work on those devices, otherwise airplaying will fail.\n\nReach out to Mux Support if you have a use case that requires more than 100 Playback Restrictions or want to add more than 100 domains per Playback Restriction.\n\nUsing Referer HTTP Header for validation\n\nWeb browsers send the website address requesting the video in the Referer HTTP header.\nMux matches the domains configured in the Playback Restriction, with the domain in the Referer HTTP header. No video is delivered if there is no match.\n\nThe Referer HTTP header is only sent by web browsers, while native iOS and Android applications do not send this header. Therefore, Mux cannot perform domain validations on any requests from native iOS and Android applications. For this reason, you can configure the Playback Restrictions to allow or deny all HTTP requests without the Referer HTTP header by setting the allow_no_referrer boolean parameter.\n\nFirst party Apple devices, like Apple TV 4K, never set a referrer header regardless of the source. Therefore if airplaying to first party Apple devices is required then allow_no_referrer will need to be set to true in order to succeed.\n\nPlease note that setting allow_no_referrer to true can result in content playback from unauthorised locations. As such, we strongly recommend creating two Playback Restriction objects, one with allow_no_referrer set to true, and one set to false, and setting the appropriate Playback Restriction ID in the JWT for Web vs. native iOS and/or Android applications.\n\nUsing User-Agent HTTP Header for validation\n\nThe User-Agent HTTP header value is used to validate against a playback restriction. If the allow_no_user_agent field is set to false, the playback will be denied if the request does not include an User-Agent value.  For the allow_high_risk_user_agent validation, Mux maintains a list of user agents that have been known to be associated with higher risk video playback, such as playback devices that are not associated with legitimate end users of most systems. For more information, please reach out to Mux Support.\n\n4. Generate a JSON Web Token (JWT)\n\nAll signed requests have a JWT with the following standard claims:\n\n| Claim Code | Description | Value |\n| :-- | :-- | :-- |\n| sub | Subject of the JWT | Mux Video Playback ID |\n| aud | Audience (intended application of the token) | v (Video or Subtitles/Closed Captions)  t (Thumbnail)  g (GIF)  s (Storyboard)  d (DRM License)|\n| exp | Expiration time | UNIX Epoch seconds when the token expires. This should always exceed the current-time plus the duration of the video, else portions of the video may be unplayable. |\n| kid | Key Identifier | Key ID returned when signing key was created |\n\nYou can also include the following optional claims depending on the type of request.\n\n| Claim Code | Description | Value |\n| :-- | :-- | :-- |\n| playback_restriction_id | Playback Restriction Identifier | PLAYBACK_RESTRICTION_ID from the previous step. Mux performs validations when the PLAYBACK_RESTRICTION_ID is present to the JWT claims body. This claim is supported for all aud types. |\n\nThe Image (Thumbnails, Animated GIFs, Storyboard and others) API accepts several options to control image selection and transformations. More details on generating JWT for image can be found here.\n\nFor Playback IDs that use a public policy, the thumbnail options are supplied as query parameters on the request URL.\n\nFor Playback IDs that use a signed policy, the thumbnail options must be specified in the JWT claims when using signed URLs. This ensures that the thumbnail options are not altered, such as changing the timestamp or the dimensions of the thumbnail image. For example, if you uploaded a 4K video and wanted to restrict a thumbnail to a width of 600 pixels and a specific timestamp, then simply include the width and time keys in the JWT claims.\n\nA note on expiration time\n\nExpiration time should be at least the duration of the Asset or the expected duration of the Live Stream. When the signed URL expires, the URL will no longer be playable, even if playback has already started. Make sure you set the expiration to be sufficiently far in the future so that users do not experience an interruption in playback.\n\nYour application should consider cases where the user loads a video, leaves your application, then comes back later and tries to play the video again. You will likely want to detect this behavior and make sure you fetch a new signed URL to make sure playback can start.\n\n5. Sign the JSON Web Token (JWT)\n\nThe steps can be summarized as:\n\n1. Load the private key used for signing\n2. Assemble the claims (sub, exp, kid, aud, etc) in a map\n3. Encode and sign the JWT using the claims map and private key and the RS256 algorithm.\n\nThere are dozens of software libraries for creating & reading JWTs. Whether you’re writing in Go, Elixir, Ruby, or a dozen other languages, don’t fret, there is most likely some JWT library you can rely on.\n\n  The following examples assuming you're working with either a private key returned from the Signing Keys API, or copy &amp; pasted from the Dashboard, not when downloaded as a PEM file.\n\n6. Include the JSON Web Token (JWT) in the media URL\n\nSupply the JWT in the resource URL using the token query parameter. The Mux Video service will inspect and validate the JWT to make sure the request is allowed.\n\nVideo URL example:\n\n\n```sh\nhttps://stream.mux.com/{playback-id}.m3u8?token={JWT}\n```\n\n\nThumbnail options are supplied as query parameters when using a public policy. When using a signed policy, the thumbnail options must be specified as claims in the JWT following the same naming conventions as with query parameters.\n\nThumbnail URL example:\n\n\n```sh\nhttps://image.mux.com/{playback-id}/thumbnail.{format}?token={JWT}\n```\n\n\nIf you include a token= query parameter for a \"public\" playback ID, the URL will fail. This is intentional as to not create the false appearance of security when using a public playback ID.\n\nIf your application uses a mix of \"public\" and \"signed\" playback IDs, you should save the playback policy type in your database and include the token parameter only for the signed playbacks.\n\nNote on query parameters after signing\n\nWhen you're signing a URL, you're signing the parameters for that URL as well. After the parameters are signed for a playback ID, the resulting signed URL should _only_ contain the token parameter. This is important because leaving the parameters in the URL would both:\n\n- expose more information about the underlying asset than you may want\n- result in an incorrect signature since the extraneous parameters would alter the URL.\n\nWhile the JWT helper we expose in our Node SDK passes in additional parameters as an extra hash, when working with the JWT directly, these params should be embedded directly in your claims body.\n\nExample:\n\nLet's say we're taking the following public example and making a signed URL:\n- https://image.mux.com/{public_playback_id}/thumbnail.jpg?time=25\n\nGenerate a signed URL with {time: 25} in the claims body. Using the helper example we wrote above, this would look like:\n- sign(signedPlaybackId, { ...requiredTokenOptions, params: { time: 25 } })\n\nCorrect Signed URL:\n- https://image.mux.com/{signed_playback_id}/thumbnail.jpg?token={token}\n\nBad Signed URL:\n- https://image.mux.com/{signed_playback_id}/thumbnail.jpg?time=25&token={token}\n\nIncluding query parameters in the token also applies to playback modifiers like default_subtitles_lang, redundant_streams and roku_trick_play. The JWT claims body must include the extra parameter:\n\n\n```json\n{\n  \"sub\": \"{PLAYBACK_ID}\",\n  \"aud\": \"{AUDIENCE_TYPE}\",\n  \"exp\": \"{EXPIRATION_TIME}\",\n  \"redundant_streams\": true\n}\n```\n\n\nPassing custom parameters to a signed token\n\nWith signed URLs, you can pass extra parameters via a custom key in the claims body like the example above.\n\nThis may be useful in order to identify bad actors that share signed URLs in an unauthorized way outside of your application. If you find out that a signed URL gets shared then you can decode the parameters and trace it back to the user who shared it. When including extra parameters like this, be sure to respect the following guidelines:\n\n Do NOT under any circumstances include personally identifiable information (PII) like a name or email address.\n Put your custom parameters nested inside the \"custom\" key.\n\n\n```json\n{\n  \"sub\": \"{PLAYBACK_ID}\",\n  \"aud\": \"{AUDIENCE_TYPE}\",\n  \"exp\": \"{EXPIRATION_TIME}\",\n  \"custom\": {\n    \"session_id\": \"xxxx-123\"\n  }\n}\n```"
  },
  {
    "id": "125-_guides/developer/see-how-many-people-are-watching",
    "title": "Show how many people are watching your videos",
    "path": "_guides/developer/see-how-many-people-are-watching.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/see-how-many-people-are-watching",
    "content": "In this guide you will learn how to use the Engagement Counts API in order to embed the latest view and unique viewer counts for a particular video ID into your applications.\n\nYou will use JSON Web Tokens to authenticate to this API.\n\n1. Create a Signing Key\n\nSigning keys can be managed (created, deleted, listed) from the Signing Keys settings of the Mux dashboard or via the Mux System API.\n\n  When making a request to the System API to generate a signing key, the access\n  token being used must have the System permission. You can confirm whether your\n  access token has this permission by going to Settings > API Access Token. If\n  your token doesn't have the System permission listed, you'll need to generate\n  another access token with all of the permissions you need, including the\n  System permission.\n\nWhen creating a new signing key, the API will generate a 2048-bit RSA key pair and return the private key and a generated key ID; the public key will be stored at Mux to validate signed tokens. Store the private key in a secure manner.\n\nYou probably only need one signing key active at a time and can use the same signing key when requesting counts for multiple videos. However, you can create multiple signing keys to enable key rotation, creating a new key and deleting the old only after any existing signed URLs have expired.\n\nExample request\n\n\n```bash\ncurl -X POST \\\n-H \"Content-Type: application/json\" \\\n-u ${MUX_TOKEN_ID}:${MUX_TOKEN_SECRET} \\\n'https://api.mux.com/system/v1/signing-keys'\n```\n\n\nExample response\n\n\n```json\n// POST https://api.mux.com/system/v1/signing-keys\n{\n  \"data\": {\n    \"private_key\": \"(base64-encoded PEM file with private key)\",\n    \"id\": \"(unique signing-key identifier)\",\n    \"created_at\": \"(UNIX Epoch seconds)\"\n  }\n}\n```\n\n\n  Be sure that the signing key's environment (Staging, Production, etc.) matches\n  the environment of the views you would like to count! When creating a signing\n  key via API, the environment of the access token used for authentication will\n  be used.\n\nThis can also be done manually via the UI. If you choose to create and download your signing key as a PEM file from UI, you will need to base64 encode it before using it with (most) libraries.\n\n\n```bash\n❯ cat /path/to/file/my_signing_key.pem | base64\nLS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktL...\n```\n\n\n2. Generate a JSON Web Token\n\nThe following JWT claims are required:\n\n| Claim Code | Description                | Value                                                                                                                                                              |\n| :--------- | :------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| sub      | Subject of the JWT         | The ID for which counts will be returned                                                                                                                           |\n| aud      | Audience (identifier type) | video_id (Mux Data Video ID)  asset_id (Mux Video Asset ID)  playback_id (Mux Video Playback ID)  live_stream_id (Mux Video Live Stream ID) |\n| exp      | Expiration time            | UNIX Epoch seconds when the token expires. Use this to ensure any tokens that are distributed become invalid after a period of time.                               |\n| kid      | Key Identifier             | Key ID returned when signing key was created                                                                                                                       |\n\n  Each of these ID types (used for the aud claim) are distinct and cannot be\n  used interchangeably. Video ID is an optional Data dimension provided by the\n  customer (you!). For more information on leveraging Video ID, see how to Make your data actionable. Mux Video Asset ID, Playback ID and Live Stream ID are available to Mux\n  Video customers only and are generated by Mux. Be sure to double check both\n  the query ID type and value!\n\nExpiration time\n\nExpiration time should be at least the duration of the video or the expected duration of the live stream. When the signed URL expires, you will no longer receive counts from the API.\n\nYour application should consider cases where the user loads a video, leaves your application, then comes back later at some time in the future and tries to play the video again. You will likely want to detect this behavior and make sure you fetch a new signed URL to make sure the counts that are displayed in your application continue to display.\n\n See the related video documentation\n\n3. Signing the JWT\n\nThe steps can be summarized as:\n\n1. Load the private key used for signing\n2. Assemble the claims (sub, aud, exp, kid etc) in a map\n3. Encode and sign the JWT using the claims map and private key and the RS256 algorithm.\n\nThere are dozens of software libraries for creating and reading JWTs. Whether you’re writing in Go, Elixir, Ruby, or a dozen other languages, don’t fret, there’s probably a JWT library that you can rely on. For a list of open source libraries to use, check out jwt.io.\n\n  The following examples assume you're working with either a private key\n  returned from the API, or copy &amp; pasted from the Dashboard, not when\n  downloaded as a PEM file. If you've downloaded it as a PEM file, you will need\n  to base64 encode the file contents.\n\n4. Making a Request\n\nSupply the JWT in the resource URL using the token query parameter. The API will inspect and validate the JWT to make sure the request is allowed.\n\nExample:\n\n\n```bash\ncurl 'https://stats.mux.com/counts?token={JWT}'\n```\n\n\nResponse:\n\n\n```json\n{\n  \"data\": [{ \"views\": 95, \"viewers\": 94, \"updated_at\": \"2021-09-28T18:21:19Z\" }]\n}\n```\n\n\n views is the total (non-unique) number of views happening\n viewers is the total unique number of views happening\n\nUniqueness is determined by the viewer_user_id metadata field. See the Metadata guide for details on adding metadata fields."
  },
  {
    "id": "126-_guides/developer/setup-alerts",
    "title": "Set up alerts",
    "path": "_guides/developer/setup-alerts.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/setup-alerts",
    "content": "Rule: Criteria for when an alert should be triggered based on a metric, threshold, and filter criteria.\n\nIncident: A specific instance when the conditions of an alert Rule are met and an alert is triggered.\n\nStart Time: The timestamp of when a metric initially crosses over an alert rule threshold.\n\nEnd Time: The timestamp of when a metric crosses out of an alert rule threshold.\n\nTrigger Interval: The time period from when a metric initially crosses over an alert rule threshold to when an alert incident notification occurs.\n\nResolution Interval: The time period from when a metric crosses out of an alert rule threshold to when an alert incident notification occurs.\n\nIncident Duration: The total length of time spent in an incident, from the start of the open interval to the start of the close interval.\n\nThere are two types of alerts supported by Mux Data: Anomaly and Threshold.\n\nAnomaly alerts are configured automatically based on the historical failure rate of views in the organization.\n\nThreshold alerts allow you to define specific criteria for viewer experience metrics that will trigger notifications.\n\nAnomaly Alerts\n\nAnomaly alerts are generated when failures are elevated over a historical level. The historical level is determined by measuring the overall failure rate of videos in each organization over the recent past using a moving window.\n\nThere are two levels of playback failures that are used for anomaly detection:\n Organization-wide: The failure rate is calculated using all video views that are tracked within the organization.\n Per Video Title: The failure rates are calculated using the video views of every video title tracked within each environment separately.\n\nTo determine whether failure rates are elevated, the anomaly detector groups the on-going views in buckets ordered by time and compares the failure rate of each bucket to the historical organization-wide failure rate. If the failure rate of the bucket of views is determined to be an extreme outlier the failed views will be flagged as anomalous, and an incident will be opened.\n\nThe bucket sizes are based on the anomaly alert level:\n Organization-wide: 1000 views\n Per Video Title: 100 views for each video title\n\nThe outlier determinations are set dynamically based on your historical values so there is no need for configuring the specific thresholds in the anomaly alerts.\n\nAnomaly alert incidents are automatically closed when the error-rate returns to normal levels. An incident for a video title or organization that hasn't received views in the last 8 days will be marked as expired.\n\nThreshold Alerts\n\nThreshold Alerts are available on Mux Data Media plans. Learn more about Mux Data Plans or contact support.\n\nThreshold alerts allow you to define specific criteria for alerts that will trigger incident notifications.\n\nAlert rules can be created for metrics collected in the Monitoring Dashboard:\n Failures\n Rebuffering Percentage\n Video Start Time\n Concurrent Viewers\n\n<Image\n  src=\"/docs/images/alert-rules-1.png\"\n  width={1217}\n  height={643}\n/>\n\nFrom the menu on the right of list item on the Alert Rules list page, the following actions can be taken:\n Edit\n Duplicate\n Delete\n\n<Image\n  src=\"/docs/images/alert-rules-dropdown.png\"\n  width={1217}\n  height={643}\n/>\n\nFilters\n\nFilters are applied to the alert definition to track only the specific data you want considered for the alert. Data for alert rules can be included or excluded from the following dimensions:\n ASN\n CDN\n Country\n Mux Asset ID\n Mux Live Stream ID\n Mux Playback ID\n Operating System\n Player Name\n Region / State\n Stream Type\n Sub Property ID\n Video Series\n Video Title\n\nValue (\"trigger if\")\n\nThe threshold value the metric must cross for the alert condition to be met.\n\nAbove/Below (\"rises above/falls below\")\n\nFor alerts specified with the Concurrent Viewers metric, the criteria can be specified to trigger when the metric is above or below a threshold. Other metrics are specified to trigger when the metric is above the threshold.\n\nAlert Interval (\"for at least X minutes\")\n\nThe amount of time the threshold criteria needs to be met in order to open or close an alert incident. The interval length can be set between 1 and 60 minutes.\n\nMinimum Audience (\"with a minimum audience of X average concurrent views\")\n\nThe average number of concurrent viewers must be over the specified value in order to enter or exit an alert incident.\n\nIf the number of concurrent viewers falls below the specified minimum audience during an alert incident the incident will continue. The number of concurrent viewers needs to be over the minimum audience in order to for the alert incident to close.\n\nNote: If a rule definition is changed, any open incident based on that rule is automatically closed. A new incident will be opened after the alert interval time if the updated rule criteria is met.\n\nListing Incidents\nWhen Anomaly and Threshold alert incidents are generated, they are listed in the \"Incidents\" tab.\n\nYou can choose the type of alert in the list:\n Threshold\n Anomaly\n\nBy default, currently \"Open\" issues are shown but all historical issues can be viewed by choosing \"All\".\n\n<Image\n  src=\"/docs/images/incident-page-1.png\"\n  width={1252}\n  height={496}\n/>\n\nIncidents\n\nWhen an alert is triggered, the metric performance is captured in an Incident. The Incident page provides a place to see the characteristics of the alert and the metric behavior at start and end of the incident.\n\n<Image\n  src=\"/docs/images/incident-open-page.png\"\n  width={931}\n  height={1153}\n/>\n\nIncidents contain the following information:\n\nAlert Name: Name for the alert as defined in the rule definition\n\nStarted: The timestamp when the metric first crossed over the threshold defined in the alert rule.\n\nEnded: The timestamp when the metric first crossed out of the metric threshold defined in the alert rule.\n\nDuration: The length of time the alert was firing, the time between the Started and End times.\n\n[Metric] The value of the metric when the alert incident is triggered\n\nAt End: The value of the metric when the alert incident is resolved\n\nPeak: The peak value of the metric while the alert is firing\n\nSome data is only shown once an alert is closed such as the Closed time, Duration, etc.\n\nIncident Start/Close Charts\n\nCharts and additional details are captured in the Incident page when an alert incident is opened and closed.\n\nIncident Start:\n\n[Metric] The value of the metric when the alert incident is triggered\n\nConcurrent Viewers: The number of viewers when the incident started.\n\nIn order to provide context on your video platform performance as the incident occurs, the chart shows up to 10 minutes before the incident starts and up to 5 minutes after the incident is opened. The lead-up time may be shorter than 10 minutes is the alert rule directly triggers an alert after it is saved.\n\nIncident Close:\n\n[Metric] The value of the metric when the alert incident is resolved\n\nConcurrent Viewers: The number of viewers when the incident ended.\n\nFor post-mortem reviews, the performance of the metric is captured in a chart that shows up to 10 minutes as the incident is resolved and the next 5 minutes after it ends.\n\nIncidents can be queried via the List Incidents API.\n\nNote: If an incident is open when it's rule definition is modified, the incident will be automatically closed. Any configuration data about the incident, such the threshold value or filters applied will reflect the rule configuration as of when the incident is opened.\n\nMux Data can send notifications when alert incidents are opened and closed. Notifications are sent to channels that define the method and address of the services where the notifications should be delivered.\n\nChannels are available for:\n Email\n Slack\n* PagerDuty\n\nNotification configuration can be found on the Alerts page in the \"Notification Channels\" tab. To setup a new channel, click the \"Add Channel\" button. From there you can choose the notification channel type, enter the destination address (email, Slack channel, or PagerDuty integration key).\n\nYou can choose what types of alerts are sent to each channel. Choose \"Anomaly\" If you only want to receive notification of alerts generated automatically by Mux Data,  \"Threshold\" will be notified of alerts that are configured in the environment, and \"All\" will sent notifications for all alerts."
  },
  {
    "id": "127-_guides/developer/show-live-stream-health-stats",
    "title": "Show live stream health stats to your streamer",
    "path": "_guides/developer/show-live-stream-health-stats.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/show-live-stream-health-stats",
    "content": "In this guide you will learn how to use the Live Stream Health Stats API in order to embed the live stream health stats for a particular live stream ID into your applications. A common use case is when you want to show the live stream stats to your streamer during a live event, so that the streamer can monitor the status and take actions when issues occur.\n\n  The Live Stream Stats API is not a 1:1 mapping of what you see on the Live Stream Health page in the Mux dashboard.\n\nYou will use JSON Web Tokens to authenticate to this API.\n\n1. Understand Live Stream Stats\nThe Live Stream Stats API returns Stream Drift Session Average, Stream Drift Deviation From Rolling Average, and Status. Before we dive into each of them, understanding a couple of terms here might be helpful:\n\n Wallclock time: Also called the real-world time.\n Stream drift: The difference between elapsed media time and elapsed wallclock time. For example, if your encoder has been connected for 10 seconds and it has sent 5 seconds of media during that time, then your current stream drift would be 5s.\n\nNow keep reading below for the metrics the API returns and their definitions.\n\nStream Drift Session Average\nStream Drift Session Average is the running average of stream drift for the lifetime of an ingest connection. It applies a smoothing function to the potentially jagged, fluctuating raw metric. Use this metric as an indication of the average offset between the elapsed wallclock time and media time throughout the whole session.\n\nThe value we return from the API is measured in miliseconds and is continuously updated with each measurement taken. It is reset whenever the encoder disconnects.\n\nStream Drift Deviation From Rolling Average\nTo get an indication of whether the current drift is consistent (good) or growing (bad), use Deviation From Rolling Average. It is the difference between current stream drift and current stream drift rolling average. The rolling average only takes the last ~30s of data into account, so it represents the recent drift, rather than measurements taken potentially long time ago. Disparities between current drift and the rolling average can be a good indicator because session average moves slower and may not reflect the latest status.\n\nUse this metric to understand whether the stream is experiencing issues at the moment. When it is, the Deviation From Rolling Average will likely be high.\n\nStatus\nThe status returned from the Live Stream Health API could be any of the following values: excellent, good, poor, or unknown.\n\n excellent: The Stream Drift Deviation From Rolling Average is less than or equal to 500ms\n good: The Stream Drift Deviation From Rolling Average is less than or equal to 1s but greater than 500ms\n poor: The Stream Drift Deviation From Rolling Average is greater than 1s\n unknown: We are unable to calculate the stream drift. This is usually because the live stream is inactive and/or we have not received any data about it for a few minutes.\n\nUse status as an indicator of the latest health status of the live stream ingest. A common use case is to render color coded UI for your streamer's ease-of-use based on the status information, such as green, yellow, or red. You can also check out our pre-built UI to monitor the status by going to the Mux Dashboard for the specific live stream.\n\n2. Create a Signing Key\n\nSigning keys can be managed (created, deleted, listed) from the Signing Keys settings of the Mux dashboard or via the Mux System API.\n\n  When making a request to the System API to generate a signing key, the access\n  token being used must have the System permission. You can confirm whether your\n  access token has this permission by going to Settings > API Access Token. If\n  your token doesn't have the System permission listed, you'll need to generate\n  another access token with all of the permissions you need, including the\n  System permission.\n\nWhen creating a new signing key, the API will generate a 2048-bit RSA key pair and return the private key and a generated key ID; the public key will be stored at Mux to validate signed tokens. Store the private key in a secure manner.\n\nYou probably only need one signing key active at a time and can use the same signing key when requesting live stream stats for multiple live streams. However, you can create multiple signing keys to enable key rotation, creating a new key and deleting the old only after any existing signed URLs have expired.\n\nExample request\n\n\n```bash\ncurl -X POST \\\n-H \"Content-Type: application/json\" \\\n-u ${MUX_TOKEN_ID}:${MUX_TOKEN_SECRET} \\\n'https://api.mux.com/system/v1/signing-keys'\n```\n\n\nExample response\n\n\n```json\n// POST https://api.mux.com/system/v1/signing-keys\n{\n  \"data\": {\n    \"private_key\": \"(base64-encoded PEM file with private key)\",\n    \"id\": \"(unique signing-key identifier)\",\n    \"created_at\": \"(UNIX Epoch seconds)”\n  }\n}\n```\n\n\n  Be sure that the signing key's environment (Staging, Production, etc.) matches\n  the environment of the live streams you would like to call for! When creating a signing\n  key via API, the environment of the access token used for authentication will\n  be used.\n\nThis can also be done manually via the UI. If you choose to create and download your signing key as a PEM file from UI, you will need to base64 encode it before using it with (most) libraries.\n\n\n```bash\n❯ cat /path/to/file/my_signing_key.pem | base64\nLS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktL...\n```\n\n\n3. Generate a JSON Web Token\n\nThe following JWT claims are required:\n\n| Claim Code | Description                | Value                                                                                                                                                              |\n| :--------- | :------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| sub      | Subject of the JWT         | The ID for which counts will be returned                                                                                                                           |\n| aud      | Audience (identifier type) | live_stream_id (Mux Video Live Stream ID) |\n| exp      | Expiration time            | UNIX Epoch seconds when the token expires. Use this to ensure any tokens that are distributed become invalid after a period of time.                               |\n| kid      | Key Identifier             | Key ID returned when signing key was created                                                                                                                       |\n\n  Live Stream ID is available to Mux\n  Video customers only and is generated by Mux. Be sure to double check both\n  the query ID type and value!\n\nExpiration time\n\nExpiration time should be at least the duration of the live stream. When the signed URL expires, you will no longer be able to receive live stream stats data from the API.\n\n See the related video documentation\n\n4. Signing the JWT\n\nThe steps can be summarized as:\n\n1. Load the private key used for signing\n2. Assemble the claims (sub, aud, exp, kid etc) in a map\n3. Encode and sign the JWT using the claims map and private key and the RS256 algorithm.\n\nThere are dozens of software libraries for creating and reading JWTs. Whether you’re writing in Go, Elixir, Ruby, or a dozen other languages, don’t fret, there’s probably a JWT library that you can rely on. For a list of open source libraries to use, check out jwt.io.\n\n  The following examples assume you're working with either a private key\n  returned from the API, or copy &amp; pasted from the Dashboard, not when\n  downloaded as a PEM file. If you've downloaded it as a PEM file, you will need\n  to base64 encode the file contents.\n\n5. Making a Request\n\nSupply the JWT in the resource URL using the token query parameter. The API will inspect and validate the JWT to make sure the request is allowed.\n\nExample:\n\n\n```bash\ncurl 'https://stats.mux.com/live-stream-health?token={JWT}'\n```\n\n\nResponse:\n\n\n```json\n{\n  \"data\": [\n    {\n      \"ingest_health\": {\n        \"updated_at\": \"2022-11-14T17:32:23\",\n        \"stream_drift_session_avg\": 384,\n        \"stream_drift_deviation_from_rolling_avg\": 12,\n        \"status\": \"excellent\",\n        },\n    },\n  ],\n}\n```\n\n\n stream_drift_session_avg is the session average of stream drift. Use this to represent the overall health of the stream.\n stream_drift_deviation_from_rolling_avg is the delta between the current stream drift and the rolling average. Use this to represent the latest stream health."
  },
  {
    "id": "128-_guides/developer/signing-jwts",
    "title": "Signing JWTs",
    "path": "_guides/developer/signing-jwts.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/signing-jwts",
    "content": "What is a JWT?\nJWTs are made up of a header, a payload, and a signature. The header contains metadata useful for decrypting the rest of the token. The payload contains configuration options. And the signature is generated from a signing key-pair. More information can be found at jwt.io.\n\nIn order to sign the JWT you must create a signing key. Signing keys can be created from the Signing Keys section of the Mux Dashboard or via the Mux System API. This key-pair will be used by a cryptographic function to sign JWTs.\n\nSigning JWTs during Development\n\nWhile developing an app, you may want an easy way to generate JWTs locally because you're not yet ready to set up a full blown production system that signs JWTs for client-side applications. There are a few different options for generating these JWTs.\n\nWeb Based JWT Signer\n\nPasting credentials into a web browser is generally a bad practice. This web-based tool signs JWTs on the client which means your credentials never leave your machine. This is a tool designed by Mux, intended to be used with Mux credentials, and will always be hosted on a Mux domain. Never use a tool like this if it is hosted on a non-Mux domain.\n\nMux provides a web based JWT Signer at https://jwt.mux.dev. Simply input the Signing key-pair and configure the claims you wish to test your app with. Then, copy the JWT into your application code and run it.\n\n<Image\n  src=\"/docs/images/jwt-signer.gif\"\n  width={600}\n  height={440}\n  alt=\"Mux's JWT Signer\"\n/>\n\nNode based CLI\nMux provides a Node.js based CLI for performing common tasks including signing JWTs for playback IDs.\n\nAfter installing Node.js, the Mux CLI must be initialized with an Access Token. Follow this guide to create an Access Token. With your newly created Access Token, initialize the Mux CLI.\n\n\n```\nnpx @mux/cli init\n```\n\n\nNow that the Mux CLI is initialized with your credentials, you can sign a JWT for Video Playback.\n\n\n```\nnpx @mux/cli sign PLAYBACK-ID\n```\n\n\nFor more details, refer to https://github.com/muxinc/cli.\n\nYou should only sign a JWT on the server, where you can keep your signing key secret. You should not put your signing key in the client itself.\n\nSetup a REST endpoint behind your own authentication system that provides your client-side code with signed JWTs. That way, the sensitive secret from the signing key-pair stays on the server instead of being included in the client.\n\nSigning JWTs for Production\n\nOnce you're ready for customers to start using your app, you need a way to sign JWTs securely at-scale. Use the code examples below depending on which Mux product you would like to sign JWTs for.\n\nSign Video Playback JWTs\n\nSign Data JWTs"
  },
  {
    "id": "129-_guides/developer/spaces-to-livekit",
    "title": "Migrate to LiveKit Web SDK",
    "path": "_guides/developer/spaces-to-livekit.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/spaces-to-livekit",
    "content": "LiveKit provides real-time video services, including both an open-source stack and a cloud-hosted option,\nand will provide a simple integration with Mux to produce a Live Stream broadcast of any real-time video interactions.\n\nWhen migrating from Mux Spaces to LiveKit you'll find most of the concepts are the same but there are a few terminology\nchanges. We recommend using one of LiveKit's Server SDKs to manage\nany communication with LiveKit's API.\n\nSpaces\n\nThe LiveKit equivalent of a Space is called a Room. Rooms can be created manually\nor will be auto-created when the first participant joins. With LiveKit you must provide a unique\nname for the room.\n\nOne notable difference between Spaces and Rooms is the behavior of the auto subscription functionality.\nSpaces' automatic subscription mode works by subscribing to a maximum of 20 participants which have the highest priority server-side.\nLiveKit's behavior around automatic subscription will subscribe participants to every other participant.\n\nBroadcasts\n\nThe LiveKit equivalent of a Broadcast is called a Composite Recording.\n\nLiveKit will provide a native integration with Mux to produce a Live Stream broadcast of any real-time video interactions.\nIn the mean time you can also use Composite Recording to send an RTMP stream to Mux as a Live Stream.\n\nBroadcast Layouts\n\nLiveKit has their own built-in layouts for Composite Recordings but Mux is also open-sourcing\nthe layouts we used for Broadcasts so you can use them within LiveKit.\nSee the GitHub page muxinc/spaces-livekit-broadcast-layouts\nfor more details\n\nJWTs are fundamental to using both Mux’s Real-Time Video & LiveKit but there are some major differences in their claim structure.\nSee the LiveKit documentation for more details.\n\nJWT Claims\n\n| Claim | Mux | LiveKit |\n|-------|-----|---------|\n| exp | Expiration time of the token | No changes |\n| iss | N/A | API key ID used to issue this token |\n| kid | API Key ID used to sign this token | N/A |\n| sub | Space ID | Unique identity of the participant |\n| aud | \"rt\" | N/A |\n| participant_id | Unique identity of the participant | N/A |\n| role | publisher or subscriber | N/A |\n| metadata | N/A | Participant metadata |\n| video.room | N/A | name of room the participant will join |\n| video.roomJoin | N/A | true if the participant is allowed to join the room |\n| video.canPublish | N/A | true if the participant is allowed to publish media to the room |\n| video.canSubscribe | N/A | true if the participant is allowed to subscribe to media in the room |\n| video.canPublishData | N/A | true if the participant is allowed to publish data (Equivalent to Mux's custom events) to the room |\n| video.canUpdateOwnMetadata | N/A | true if the participant is allowed to update their own metadata (required for participant to set their own display name) |\n\nExample of a Publisher JWT\n\n<CodeExamples\n  examples={{\n    Mux: {\n\t\"exp\": 1750137631,\n\t\"kid\": \"{ KEY ID HERE }\",\n\t\"sub\": \"{ SPACE ID HERE }\",\n\t\"aud\": \"rt\",\n\t\"participant_id\": \"bob\",\n\t\"role\": \"publisher\"\n}\n    ,\n    LiveKit: {\n\t\"exp\": 1750137631,\n\t\"iss\": \"{ KEY ID HERE }\",\n\t\"sub\": \"bob\",\n\t\"metadata\": \"details about bob\",\n\t\"video\": {\n\t\t\"room\": \"{ ROOM ID HERE }\",\n\t\t\"roomJoin\": true,\n\t\t\"canPublish\": true,\n\t\t\"canSubscribe\": true,\n\t\t\"canUpdateOwnMetadata\": true,\n\t\t\"canPublishData\": true\n\t}\n}\n    ,\n  }}\n  exampleOrder=\"Mux,LiveKit\"\n  args={{ Mux: { lang: 'text' }, LiveKit: { lang: 'text' }}}\n/>\n\nIn order to make the transition to LiveKit easier we have created an adapter that will allow you\ncontinue using the Mux Spaces Web SDK while using LiveKit under the hood.\n\n  The adapter is not a long term solution and we recommend that you migrate to the LiveKit Web SDK as soon as possible.\n\nInstall the adapter\n\nUpdate your package.json file to pull in the adapter using @mux/spaces-web as an alias\nso that you can continue to use the same import statements followed by an npm install.\n\n\n```json\n\"@mux/spaces-web\": \"npm:@mux/spaces-livekit-adapter@^0.1.9\",\n```\n\n\nThe only client side change you'll need to make is to update the Space constructor\nto tell it which LiveKit instance to use.\n\n\n```js\nnew Space(/* Your LiveKit JWT */, /* Your LiveKit URL */);\n```\n\n\nAt this point your application should be using LiveKit under the hood & you can stop here.\nContinue reading when you want to migrate to the LiveKit Web SDK directly.\n\n\n```bash\nyarn add livekit-client\n```\n\n\nReplace instances in your imports of @mux/spaces-web with livekit-client,\nsome of the types will not be found but we'll fix them in the following steps.\n\nWe'll begin the code migration by finding where the Space is first initialized &\nreplace it with the equivalent new Room call. Before proceeding you'll need your updated JWT\n& your LiveKit URL. If you're using LiveKit Cloud you'll be provided one upon signing up,\notherwise it'll be the URL where you're hosting LiveKit.\n\nThe call flow is roughly the same but with new Room() instead of new Space()\nand .connect() instead of .join(). Some parameters are also shifted from the Space\nconstructor to the room connect method.\n\n<CodeExamples\n  examples={{\n    Mux: const space: Space = new Space(/ jwt: string /, / options?: SpaceOptionsParams /);\nconst localParticipant = await space.join();\n    ,\n    LiveKit: const room: Room = new Room(/ options?: RoomOptions /);\nawait room.connect(/ url /, / token /, / opts? /);\nconst localParticipant = room.localParticipant;\n    ,\n  }}\n  exampleOrder=\"Mux,LiveKit\"\n  args={{ Mux: { lang: 'text' }, LiveKit: { lang: 'text' }}}\n/>\n\nWhen calling join() using the Mux Spaces SDK any participants already in the room will\ntrigger a ParticipantJoined event on the space object, but with LiveKit's SDK the existing\nparticipants will not trigger ParticipantConnected events.\nInstead of listening to an event you will need to trigger any handling of the existing\nparticipants by retrieving the list from room.participants.\n\nThere are only minor differences between Mux's participant objects and LiveKit's.\n\n| Mux | LiveKit |\n|-----|---------|\n| connectionId | sid (Server ID) |\n| id | identity |\n| displayName | name |\n| role | permisions |\n| status | N/A |\n\nTracks are one of the areas where there's a conceptual difference between Mux Spaces & LiveKit.\nMux has a single RemoteTrack class which may or may not be currently subscribed.\nLiveKit separates out the concept of the tracks that a participant is publishing from the\ntracks to which a LocalParticipant is subscribed. RemoteTrackPublication is object received\nwhen a RemoteParticipant publishes a track.\nA LiveKit RemoteTrack is the object available when the local participant is subscribed to\nthat publication. The parameters for events around tracks can contain both a RemoteTrack &\na RemoteTrackPublication, depending on what you're code depends on you may need one or both\nof these objects.\n\nSpaceEvent to RoomEvent\n\n| Mux | LiveKit |\n|-----|---------|\n| ActiveSpeakersChanged | ActiveSpeakersChanged |\n| LocalParticipantReconnectFailed | N/A |\n| LocalParticipantReconnecting | N/A |\n| ParticipantDisplayNameChanged | ParticipantNameChanged |\n| ParticipantLeft | ParticipantDisconnected |\n| ParticipantTrackPublished | TrackPublished |\n| ParticipantTrackUnmuted | TrackMuted |\n| ParticipantTrackUnsubscribed | TrackUnsubscribed |\n| BroadcastStateChanged | RecordingStatusChanged |\n| LocalParticipantReconnected | Reconnected |\n| ParticipantCustomEventPublished | DataReceived |\n| ParticipantJoined | ParticipantConnected |\n| ParticipantTrackMuted | TrackMuted |\n| ParticipantTrackSubscribed | TrackSubscribed |\n| ParticipantTrackUnpublished | TrackUnpublished |\n\nParticipantEvent\n\n| Mux | LiveKit |\n|-----|---------|\n| CustomEventPublished | DataReceived |\n| StartedSpeaking | IsSpeakingChanged(speaking: true) |\n| TrackMuted | TrackMuted |\n| TrackSubscribed | TrackSubscribed |\n| TrackUnpublished | TrackUnpublished |\n| DisplayNameChanged | ParticipantNameChanged |\n| StoppedSpeaking | IsSpeakingChanged(speaking: false) |\n| TrackPublished | TrackPublished |\n| TrackUnmuted | TrackUnmuted |\n| TrackUnsubscribed | TrackUnsubscribed |\n\n| Kind | Mux | LiveKit |\n|------|-----|---------|\n| Function | getUserMedia | createLocalTracks |\n| Function | getDisplayMedia | createLocalScreenTracks |\n| Function | getLocalTracksFromMediaStream | new LocalVideoTrack or new LocalAudioTrack |\n| Enum | AcrScore | LiveKit does not have the concept of reporting user provided ACR scores. |\n| Enum | ParticipantRole | LiveKit does not have roles, instead it has granular permissions: ParticipantPermission |\n| Enum | SpaceEvent | RoomEvent |\n| Enum | TrackEvent | TrackEvent |\n| Enum | TrackSource | Track.Source |\n| Enum | ParticipantEvent | ParticipantEvent |\n| Enum | ParticipantStatus | N/A. Use the ParticipantEvents to determine status |\n| Enum | SubscriptionMode | RoomConnectOptions.autoSubscribe |\n| Enum | TrackKind | Track.Kind |\n| Interface | CreateLocalMediaOptions | CreateLocalTrackOptions |\n| Interface | SpaceOptionsParams | RoomOptions |\n| Interface | LocalTrackOptions | AudioCaptureOptions or VideoCaptureOptions |\n| Class | LocalParticipant | LocalParticipant |\n| Class | RemoteTrack | RemoteTrack & RemoteTrackPublication |\n| Class | Track | Track |\n| Class | LocalTrack | LocalTrack & LocalTrackPublication |\n| Class | RemoteParticipant | RemoteParticipant |\n| Class | Space | Room |\n| Type Alias | ActiveSpeaker | N/A. LiveKit only identifies the participant in active speaker events not the track |\n| Type Alias | CustomEvent | Data messages |"
  },
  {
    "id": "130-_guides/developer/start-live-streaming",
    "title": "Start live streaming",
    "path": "_guides/developer/start-live-streaming.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/start-live-streaming",
    "content": "Whether you’re looking to build “Twitch for X”, online classrooms, a news & sports broadcasting platform or something the world’s never seen before, the Mux Live Streaming API  makes it easy to build live video into your own software. With a simple API call you get everything you need to push a live stream and play it back at high quality for a global audience.\n\n  For a guided example of how to make API Requests from your local environment, see the guide and watch this video tutorial:  Make API Requests.\n\nThe Mux Video API uses a token key pair that consists of a Token ID and Token Secret for authentication. If you haven't already, generate a new Access Token in the Access Token settings of your Mux account dashboard.\n\nThe access token should have Mux Video Read and Write permissions.\n\nAccess Tokens also belong to an Environment. Be sure to use the same Environment when using Mux Video and Mux Data together, so the data from Mux Data can be used to optimize your Mux Video streams.\n\nDetailed API Reference\n\nThe Live Stream object in the Mux API is a record of a live stream of video that will be pushed to Mux. To create your first Live Stream, POST request to the /live-streams endpoint.\n\nYou can either replace ${MUX_TOKEN_ID} and ${MUX_TOKEN_SECRET} with your own access token details or make sure to export those environment variables with the correct values first.\n\n<CodeExamples\n  product=\"video\"\n  example=\"createLiveStream\"\n/>\n\nThe response will include a Playback ID and a Stream Key.\n\n- Playback IDs for a Live Stream can be used the same way as Playback IDs for an Asset. You can use it to play video, get images from a video or build timeline hover previews with your player.\n- The Stream Key is a secret that can be used along with Mux's RTMP Server URL (see table below) to configure RTMP streaming software.\n\n  The Stream Key should be treated as a private key for live streaming. Anyone with the key can use it to stream video to the Live Stream it belongs to, so make sure your users know to keep it safe. If you lose control of a stream key, you can either delete the Live Stream or reset the stream key\n\n\n```json\n{\n  \"data\": {\n    \"id\": \"QrikEQpEXp3RvklQSHyHSYOakQkXlRId\",\n    \"stream_key\": \"super-secret-stream-key\",\n    \"status\": \"idle\",\n    \"playback_ids\": [\n      {\n        \"policy\": \"public\",\n        \"id\": \"OJxPwQuByldIr02VfoXDdX6Ynl01MTgC8w02\"\n      }\n    ],\n    \"created_at\": \"1527110899\"\n  }\n}\n```\n\n\nMux also allows you to set a few additional options on your live stream. When enabled, you can support more use cases.\n\n| Option | Description |\n|--------|-------------|\n| \"latency_mode\": \"reduced\" | Mux live streams have an option for \"reduced latency\". When \"latency_mode\": \"reduced\" is enabled, we treat your stream a little differently to minimize glass-to-glass latency. The latency reduces to about 10-15 seconds compared to 30 seconds typically without enabling this option. For more details, please refer to the Live Stream Latency guide. |\n| \"latency_mode\": \"low\" | Similar to \"reduced\" latency option, \"latency_mode\": \"low\" live streams reduce the glass-to-glass latency to as low as 5 seconds but the latency can vary depending on your viewer's geographical location and internet connectivity. For more details, please refer to the Live Stream Latency guide. |\n| audio_only | Mux live streams is ready for Audio specific use cases too. For example, you can host Live Podcasts or broadcast Radio Shows. When audio_only is enabled, we only process the audio track, even dropping the video track if broadcast. |\n\nA live stream can only be configured as \"reduced latency\" or \"low latency\" or standard latency.\n\nYou can find more details about the options on the Create Live Stream.\n\nMux supports live streaming using the RTMP protocol, which is supported by most broadcast software/hardware as well as open source software for mobile applications.\n\nYour users or your client app will need software that can push an RTMP stream. That software will be configured using the Stream Key from the prior step along with Mux's RTMP Server URL. Mux supports both RTMP and RTMPS:\n\n| RTMP Server URL |  Description | Common Applications |\n|---|---|---|\n| rtmp://global-live.mux.com:5222/app | Mux's standard RTMP entry point. Compatible with the majority of streaming applications and services. |Open Source RTMP SDKs, most app-store streaming applications. |\n| rtmps://global-live.mux.com:443/app | Mux's secure RTMPS entry point. Compatible with less streaming applications, but offers a higher level of security. | OBS, Wirecast, Streamaxia RTMP SDKs |\n\nLearn more about:\n Additional regional ingest URLs for when you want control over the geographic region receiving your user's livestream\n How to configure broadcast software for when users will be using their own streaming software, e.g. Twitch live streamers\n* How to live stream from a mobile app for when users will live stream using your mobile app\n\n  Mux's RTMP server URL uses port number 5222 and not the standard RTMP port number 1935.  If your encoder does not provide a method to change the port number, please contact our support team with your encoder details.\n\nMux Video also supports Secure Reliable Transport (SRT) for receiving live streams. If you want to live stream with a protocol other than RTMP or SRT, let us know!\n\nThe broadcast software will describe how to start and stop an RTMP session. Once the session begins, the software will start pushing live video to Mux and the Live Stream will change its status to active indicating it is receiving the RTMP stream and is playable using the Playback ID.\n\nBroadcasting Webhooks\n\nWhen a Streamer begins sending video and the Live Stream changes status, your application can respond by using Webhooks. There are a few related events that Mux will send. Your application may benefit from some or none of these events, depending on the specific user experience you want to provide.\n\n| Event | Description |\n|-------|-------------|\n| video.live_stream.connected | The Streamer's broadcasting software/hardware has successfully connected with Mux servers. Video is not yet being recorded and is not yet playable. |\n| video.live_stream.disconnected | The Streamer's broadcasting software/hardware has disconnected from Mux servers, either intentionally or unintentionally because of a network drop. |\n| video.live_stream.recording | Video is being recorded and prepared for playback. The recording of the live stream (the Active Asset) will include video sent after this point. If your UI has a red \"recording\" light, this would be the event that turns it on. |\n| video.live_stream.active | The Live Stream is now playable using the Live Stream's Playback ID or the Active Asset's Playback ID |\n| video.live_stream.idle | The Streamer's broadcasting software/hardware previously disconnected from Mux servers and the reconnect_window has now expired. The recording of the live stream (the Active Asset) will now be considered complete. The next time video is streamed using the same Stream Key it will create a new Asset for the recording. |\n| video.asset.live_stream_completed | This event is fired by the Active Asset when the Live Stream enters the idle state and the Active Asset is considered complete. The Asset's playback URL will switch to being an \"on-demand\" (not live) video. |\n\nTo play back a live stream, use the PLAYBACK_ID that was returned when you created the Live Stream along with stream.mux.com to create an HTTP Live Streaming (HLS) playback URL.\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8\n```\n\n\n<CodeExamples\n  product=\"video\"\n  example=\"hlsPlaybackLive\"\n  exampleOrder=\"html,react,embed,swift,android\"\n/>\n\nSee the playback guide for more information about how to integrate with a video player.\n\nAfter you have everything working integrate Mux Data with your player for monitoring playback performance.\n\nWhen the Streamer is finished they will stop the broadcast software/hardware, which will disconnect from the Mux servers. After the reconnect_window time (if any) runs out, the Live Stream will transition to a status of idle.\n\n  Mux automatically disconnects clients after 12 hours. Contact us if you require longer live streams.\n\nAfter you have live streams created in your Mux environment, you may find some of these other endpoints handy:\n\n- Create a live stream\n- List live streams\n- Retrieve a live stream\n- Delete a live stream\n- Create a live stream playback ID\n- Delete a live stream playback ID\n- Reset a stream key for a live stream\n- Signal a live stream is finished\n- Disable a live stream\n- Enable a live stream\n- Create a live stream simulcast target\n- Delete a live stream simulcast target\n- Retrieve a live stream simulcast target\n\nMore Video methods and descriptions are available at the API Docs.\n\n  <GuideCard\n    title=\"Play your live stream\"\n    description=\"Set up your iOS application, Android application or web application to start playing your Mux assets\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/play-your-videos\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Integrate Mux Data\"\n    description=\"Add the Mux Data SDK to your player and start collecting playback performance metrics.\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/track-your-video-performance\"},\n    ]}\n  />"
  },
  {
    "id": "131-_guides/developer/stream-live-to-3rd-party-platforms",
    "title": "Stream live to 3rd party platforms",
    "path": "_guides/developer/stream-live-to-3rd-party-platforms.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/stream-live-to-3rd-party-platforms",
    "content": "With the Simulcasting feature, developers can enable their users publish live streams on social platforms.\n\nThe Mux Video API makes it easy for developers to build live streaming into their applications. Combined with simulcasting, existing features like Persistent Stream Keys and Automatic Live Stream Recording together provide a way to connect with a number of social sharing apps.\n\nWhat Simulcasting can help you do:\n Forward a live stream on to social networks like YouTube, Facebook, and Twitch\n Let users publish user-generated live streams on social platforms\n Connect with a number of social sharing apps\n\nOther domains may use varying terminology to refer to the same general process including:\n\n Restreaming\n Live Syndication\n Rebroadcasting\n RTMP Passthrough\n Multistreams - a term used by Crowdcast\n\nMux Simulcasting works with any arbitrary RTMP server. That means Mux will support Simulcast Targets from any platform that supports the RTMP or RTMPS protocol.\n\nTargets that are supported include but are not limited to the following:\n Facebook Live\n YouTube Live\n Twitch\n Crowdcast\n Vimeo\n\nUnfortunately the following Targets are not supported:\n Instagram (you can only go live from the Instagram app)\n\nUse the Mux API to add simulcasting to a live stream.\n\nThe first step is to add a Simulcasting Target. You can do this when the Live Stream object is first created, or anytime afterward. Note that Simulcast Targets can only be added while the Live Stream object is not active.\n\nHere is an example of adding a Simulcasting Target for each additional platform the stream should be published to:\n\n\n```text\nPOST https://api.mux.com/video/v1/live-streams\n```\n\n\n\n```text\n{\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"new_asset_settings\": {\n    \"playback_policies\": [\n      \"public\"\n    ]\n  },\n  \"simulcast_targets\" : [\n    {\n      \"url\" : \"rtmp://a.rtmp.youtube.com/live2\",\n      \"stream_key\" : \"12345\",\n      \"passthrough\" : \"YouTube Example\"\n    },\n    {\n      \"url\" : \"rtmps://live-api-s.facebook.com:443/rtmp/\",\n      \"stream_key\" : \"12345\",\n      \"passthrough\" : \"Facebook Example\"\n    }\n  ]\n}\n```\n\n\nAs defined in the Simulcast Targets API Reference, RTMP credentials consist of two parts:\n a url , which is the RTMP hostname including the application name for the third party live streaming service\n a stream_key, which is the password that represents a stream identifier for the third party live streaming service to simulcast the parent live stream to.\n\nNote that stream keys are sensitive and should be treated with caution the same way you would with an API key or a password.\n\nNew to live streaming? In this blog post we provide a step-by-step outline how to use Twitch, YouTube, or Facebook for getting RTMP credentials.\n\nNot sure what settings to use?\nAs for settings, a recommendation for your end users is 4,000 kbps at 720p resolution with 2s keyframe intervals. However, this post also provides an in-depth explanation for choosing personalized settings.\n\nHelp Your Users be in 5 Places at Once: Your Guide to Simulcasting\n\nPricing\n\nSimulcasting has an added cost on top of live streaming, but like all of our pricing, you only pay for what you use.\n\nSee the Pricing Page for details.\n\nAvailability\n\nThere's a limit of 6 simulcasts/restreams per live stream. Let us know if you have a use case that requires more.\n\nBlog Posts about Simulcasting\n\nWe have several blog posts that cover more topics about simulcasting products, if you want to read more:\n\n Seeing double? Let your users simulcast (aka restream) to any social platform\n Help Your Users be in 5 Places at Once: Your Guide to Simulcasting"
  },
  {
    "id": "132-_guides/developer/stream-recordings-of-live-streams",
    "title": "Stream recordings of live streams",
    "path": "_guides/developer/stream-recordings-of-live-streams.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/stream-recordings-of-live-streams",
    "content": "When playing back a live stream, Mux offers you two options for historical playback. Both options are available at any time; you can switch between the two at will.\n\n1. Non-DVR mode - keep all users \"live\". Only a small portion of your live stream (approximately 30 seconds) will be exposed to your viewers through your player.\n2. DVR mode - allow your users to scrub back to the beginning of the live stream whenever they want in your player.\n\nThe 3 Mux concepts we need to understand here are:\n\n Live streams: This is the top level live streaming resource. Your stream key maps back to a single live stream. Live streams are reusable. Each Live stream has one or more playback IDs associated with it.\n Assets: Assets are videos on demand. In Mux, assets get created by either: direct uploads, creating an asset with an input URL, or from recordings of live streams. Each Asset has one or more playback IDs associated with it.\n\n Playback IDs: Playback IDs are the resource that controls playback. A playback ID may point to either a live stream OR an asset and it can be either public or signed. More information on signed playback IDs is here. A playback ID is the identifier that you use in a stream.mux.com URL of the form: https://stream.mux.com/{\"{\"}PLAYBACK_ID{\"}\"}.m3u8.\n\nDVR mode vs. non-DVR mode\n\nIn non-DVR Mode, all users viewing the live stream will be viewing the most recent content. The player will have access to approximately the most recent 30 seconds of content.\n\nIn order to use non-DVR mode, construct your playback URL with the playback ID _associated with the live stream_.\n\nMost uses of live streaming opt for non-DVR mode and, if you are unsure about which to use, we recommend that you stick with non-DVR mode.\n\nWhen using DVR mode, the player will have access to your stream's content going all the way back to the beginning of the live stream.\n\nMux does not recommend DVR mode for live streams longer than four hours. If you expect long live streams, you should use non-DVR mode.\n\nIf you choose to use DVR mode, then you should construct your playback URL using the playback ID _associated with the live stream's active_asset_id_.\n\nAssets created from live streams\n\nMux will automatically start creating an asset in the background when you begin broadcasting to your live stream. This asset has two purposes:\n\n You can use the asset directly in order to enable DVR mode playback.\n* When the live stream is over, you can use the asset to play back the recording of the live stream.\n\nSince assets are automatically created from every live stream and live streams can be re-used as many times as you want, Mux creates a new asset every time a live stream begins broadcasting. A single live stream can end up producing an indefinite number of assets.\n\nThe lifecycle of events produced by a Mux live stream is as below.\n\n| Step | Event | Description |\n|------|-------|-------------|\n| 1 | Initial State | Live stream begins in status idle |\n| 2 | video.live_stream.connected | The encoder has connected. At this point in time the live stream will have a new active_asset_id. The active_asset_id is the ID that points to a new asset that Mux is creating for this live stream. |\n| 3 | video.asset.created | The asset corresponding to the active_asset_id from step 2 gets created. This asset has a live_stream_id that points back to the live stream it was created from. This asset does not have any content yet, it is a placeholder that will be getting content from the ingested live stream. |\n| 4 | video.live_stream.recording | Mux has started recording the incoming content. The live stream's status will still be idle at this point. |\n| 5 | video.live_stream.active | The live stream's state has transitioned active. When in non-DVR mode, the live stream's playback ID can now be used to build a playback URL on stream.mux.com. |\n| 6 | video.asset.ready | The asset (active_asset_id) from step 2 and 3 will be \"ready\" at around the same time that the live stream is \"active\". This asset only has about 10 seconds worth of content at this point. The duration on this asset reflects the current playable duration. If you are using DVR mode, it is at this point that you can use the active_asset_id to build a playback URL on stream.mux.com. |\n| 7 | video.live_stream.disconnected | The encoder has disconnected, and the live stream status is still active. Please note that live streams that do not use the \"latency_mode\": \"reduced\" option will enter a reconnect window (defaulting to a duration of 60 seconds) after disconnecting. The encoder can re-connect within this reconnect window and, in doing so, pick back up where it left off with the same active_asset_id. For more information, please consult handling live stream disconnects. |\n| 8 | video.live_stream.idle | After the encoder has stayed disconnected for the duration of the reconnect window, the live stream will transition back to status idle. This live stream will no longer have an active asset associated with it, but for ease of use this event will include the active_asset_id of the asset that is just ending. The next time an encoder connects this lifecycle with start back at step 1 with a new active_asset_id. |\n| 9 | video.asset.live_stream_completed | This event fires at the same time as the live stream transitions back to idle. This event tells you that the asset is finalized. The duration of the asset will now be the full, finalized duration; you can use the playback ID in your player to play the recording of the live stream. |\n\nPlease note that some of these webhook events correspond to the live_stream resource and others correspond to the asset.\n\nMore information about configuring and using webhooks can be found in the webhooks guide."
  },
  {
    "id": "133-_guides/developer/stream-simulated-live",
    "title": "Stream simulated live",
    "path": "_guides/developer/stream-simulated-live.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/stream-simulated-live",
    "content": "- Pre-Recorded Live\n  - Scheduled Live\n  - Playout Service\n  - Simulated Live from VOD\n  - Psuedo-live\n  - Live Linear Channel\n\nYou may have a pre-recorded video and want to use Mux to broadcast it as if it were live.\n\nFor now, Mux does not support Simulated Live streaming directly as a feature. As a work-around, this guide provides a few options to implement your own Simulated Live streaming solution.\n\nSimulated Live streaming is a common strategy to ensure reliability. For example, if your platform has groups of users watching content simultaneously, you will want to employ one of the following strategies.\n\n  You should be familiar with how live streaming works:\n  1. Create a live stream with the Mux API\n  2. Get the unique stream key for that live stream\n  3. Put the server URL and stream key into an encoder (OBS, Wirecast, etc.)\n  4. Use the Playback ID to view your live stream in any player that supports HLS\n\nThe most straightforward and reliable option we recommend is to use a third party service built for Simulated Live streaming. The service will allow you to upload videos and send out an RTMP stream at a scheduled time.\n\nUpload your video to the service, enter in the Mux rtmp ingest server details, and schedule the time you want it to \"go live\".\n\nFor example, restream.io offers this guide to get started with pre-recorded videos. Note that there is a cost associated with this option.\n\nThe second option we recommend is to build your own server that is capable of uploading video and sending an RTMP stream to Mux.\n\nTo do this, run encoder software that can ingest a video file and sends output to a Mux RTMP ingest URL. Software you might use to build a server include ffmpeg or GStreamer.\n\nIf you are going with this \"home-rolling\" route, your program should:\n\n- Handle network blips gracefully. Even if your server is running in a reliable cloud like AWS or Google, networking between commercial data centers may experience interruptions.\n\n- Handle disconnects. In particular, ffmpeg does not have any built in disconnect handling so if you use that software you should make sure you have a solution to handle them.\n\n- Hold up to rigorous testing. Test the program with different types of content and long running streams. Make sure what you built is reliable before you use it in production.\n\nThe final option is to skip the backend live streaming setup, use an on-demand video, and make it \"appear live\" in your UI. This is a work-around we have seen success with.\n\nTo simulate a Live Stream in the UI you could:\n\n- Hide the timeline of the player so that users can't seek back and forth\n- Have the client make requests to the server to check server-time and use the server-time to keep the playhead synced to the \"current live\" time\n- Show a red dot that gives the impression to the user \"this is live\"\n\nProvide your feedback\n\nWe'd love to hear what is working and what isn't working, so if you are using one of these solutions (or some other solution), please send your ideas.\n\nIf you are interested in Simulated Live streaming as a Mux feature, let us know about your use case and specific needs!"
  },
  {
    "id": "134-_guides/developer/stream-videos-in-4k",
    "title": "Stream videos in 4K",
    "path": "_guides/developer/stream-videos-in-4k.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/stream-videos-in-4k",
    "content": "Introduction to 4K\n\nMux Video supports ingesting, storing, and delivering on-demand video assets in high resolutions up to and including 4K (2160p). At this time, 2K and 4K output is not supported for Mux Live Streaming. Live Streams will accept 2K and 4K input, but the output will be capped to 1080p (and will be billed as 1080p).\n\nMuch premium video content is created in 4K, but more recently user-generated content is often in 4K as well, as mobile devices are increasingly capable of producing 4K video.\n\nMux Video also supports 2K and 2.5K video on-demand video assets.\n\nCreate a 4K asset\n\nTo ingest, store, and deliver an asset in 4K, you'll need to set the new max_resolution_tier attribute on your create-asset API call.\n\n\n```json\n// POST /video/v1/assets\n{\n\t\"inputs\": [\n\t\t{\n\t\t\t\"url\": \"https://storage.googleapis.com/muxdemofiles/mux-4k.mp4\"\n\t\t}\n\t],\n\t\"playback_policies\": [\n\t\t\"public\"\n\t],\n\t\"video_quality\": \"basic\",\n\t\"max_resolution_tier\": \"2160p\"\n}\n```\n\n\nThis field controls the maximum resolution that we'll encode, store, and deliver your media in. We do not to automatically ingest content at 4K so that you can avoid unexpectedly high ingest bills. If you send us 4K content today and don't set max_resolution_tier, nothing changes in your bill.\n\nThis also allows you to build applications where some of your content creators are able to upload 4K content while others remain capped at 1080p.\n\nAnd of course you can use 4K with Direct Uploads, too; you just need to set the same \"max_resolution_tier\": \"2160p\" field in the new_asset_settings of your create-direct-upload API call.\n\n\n```json\n// POST /video/v1/uploads\n{\n  \"new_asset_settings\": {\n    \"playback_policies\": [\n      \"public\"\n    ],\n    \"video_quality\": \"basic\",\n    \"max_resolution_tier\": \"2160p\"\n  },\n  \"cors_origin\": \"*\"\n}\n```\n\n\nPlay your assets in 4K\n\nFor assets with 4K enabled at ingest, we'll automatically add 2K and 4K renditions to your HLS Playback URLs. Mux uses high-bitrate H.264 for delivering 4K content, which is supported on a wide range of devices, like Mux Player shown below.\n\nWhile we've tested playback and built device detection rules that should protect you against unexpected playback failures, you should always test playback on your own device footprint before enabling 4K widely on your platform.\n\nLimiting playback resolution below 4K\n\nOf course, you might not want all of your viewers to be able to view your content in 4K. Lots of streaming platforms choose to only offer 4K playback to their high subscription tiers. You can implement this by controlling playback resolution with the max_resolution query parameter on your playback URLs, as shown below.\n\n\n```\nhttps://stream.mux.com/${PLAYBACK_ID}.m3u8?max_resolution=1080p\n```\n\n\nPreparing 4K inputs\n\nMux uses just-in-time (JIT) encoding to make sure your assets are available as soon as possible after you create them, and this includes 4K assets.\n\nMost of the usual restrictions for standard inputs still apply when you're using 4K, but there are a few different restrictions you should be aware of:\n\n The input must have a maximum dimension of 4096 pixels\n The input must have a maximum keyframe interval of 10 seconds\n The input must be 20 Mbps or less\n The input must have a frame rate between 5 fps and 60 fps\n\nYou can find full details of the standard input specification for 1080p and 4K content in our documentation.\n\nStream 2K and 2.5K content\n\nMux Video also supports 2K and 2.5K (1440p) content. If you want your asset processed as 2/2.5K, you just need to set \"max_resolution_tier\": \"1440p\" in your create asset (or create direct upload) calls instead."
  },
  {
    "id": "135-_guides/developer/track-autoplaying-videos",
    "title": "Track autoplaying videos",
    "path": "_guides/developer/track-autoplaying-videos.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/track-autoplaying-videos",
    "content": "If you are autoplaying videos with any web based players that use the video element then make sure you read this guide so that Mux can accurately track your videos' startup time. This applies to video elements with the autoplay attribute and anytime you are calling play() on a video element (this includes all HTML5 players like VideoJS, JWPlayer, Shaka player, etc.).\n\nBrowser vendors are frequently changing their policies when autoplay is allowed and not allowed, so your application should be prepared to deal with both scenarios, and we want to make sure we're tracking your views and errors accurately.\n\nIncrease your chance of autoplay working\n\nThere's a few conditions that will increase your chance of autoplay working.\n\n Your video is muted with the muted attribute.\n The user has interacted with the page with a click or a tap.\n (Chrome - desktop) The user’s Media Engagement Index threshold has been crossed. Chrome keeps track of how often a user consumes media on a site and if a user has played a lot of media on this site then Chrome will probably allow autoplay.\n (Chrome - mobile) The user has added the site to their home screen.\n* (Safari) Device is not in power-saving mode.\n\nEven if autoplay works when you test it out, you can never rely on it working for every one of your users. Your application must be prepared for autoplay to fail.\n\nAvoid the autoplay attribute\n\nWhen you use the autoplay attribute (it looks like `, you (and Mux) have no way to know if the browser blocked or didn't block autoplay.\n\nThe issue is that when using the autoplay attribute the video element sometimes does not send the play event when it should, which can result in incorrect Video Startup Time measurements.\n\nTo avoid this issue, use video.play()` instead, which returns a promise and allows you to know if playback played successfully or not. If autoplay worked, the promise will resolve, if autoplay did not work then the promise will reject with an error. The great thing about this approach is that you can choose what to do with the error.\n\nFor example: you can report the error to your own error tracking tools or update the UI to reflect this error. Note that Mux's custom error tracking is for tracking fatal errors, so you wouldn't want to report an autoplay failure to Mux because then it will be considered a fatal error.\n\n\n```js\nconst video = document.querySelector('#my-video');\nmux.monitor(\n  /*\n    see the web-integration-guide HTML5 to set this up\n  */\n);\n\nvideo.play().then(function () {\n  // autoplay was successful!\n}).catch(function (error) {\n  // do something if you want to handle or track this error\n});\n```\n\n\nFor further reading, see the mux blog post about this topic."
  },
  {
    "id": "136-_guides/developer/understand-metric-definitions",
    "title": "Understand metric definitions",
    "path": "_guides/developer/understand-metric-definitions.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/understand-metric-definitions",
    "content": "Engagement and Quality of Experience metrics are tracked during each playback attempt and a value for each metric is assigned to the view that is generated. Metrics reports aggregate the values from individual, completed views that match a specified filter to calculate the metric for analysis.\n\nEach report is defined by the metric being analyzed, the time range, and a filter that can focus the report on a specific subset of views. Engagement metrics use the start time of each view for determining if it should be included in a time range. Quality of Experience metrics are aggregated based on the end time of each view. Views are only included in a metric calculation if they have a valid value for the metric.\n\nViews and Watch Time\n\nViews and Watch Time are key metrics that are often shown along with other engagement or Quality of Experience metrics in your Mux dashboard.\n\nDefinition of a View\n\nIn Mux Data, a \"View\" is an attempt (successful or not) to play a video. A view is created when a viewer clicks play or if playback is started programmatically. If the user taps play, the video starts to load and fails, that counts as a single view. If a user taps play, starts watching the video, pauses, then resumes within 60 minutes, that counts as a single view.\n\nEach view is tracked until playback is explicitly ended or 60 minutes after playback stops. Playback can be explicitly ended by the SDK or if a viewer navigates off the page with the video being played.\n\nA single video can be watched multiple times in a single view by looping or seeking to the start of the video. If you see more views than expected in your dashboard or see duplicate views check on the code that initializes the Mux Data SDK to make sure you are initializing it once per playback attempt.\n\nAfter a view stops receiving playback events for 60 seconds, it is considered complete and is available in Metrics and exported via streaming exports. Playback events will be added to views if playback resumes within 60 minutes. After 60 minutes of inactivity, the view is finalized and new playback events will create a new view.\n\nHow Watch Time is calculated\n\nWatch Time is not currently an aggregated metric in Mux Data but is used in some of the metrics calculations. The Watch Time for a view is the cumulative amount of time the user spent watching or attempting to watch the video. This metric includes actively playing content, starting up, rebuffering, and seeking. It is similar to Playing Time, which is an aggregated metric available for analysis, but Watch Time also includes the time spent rebuffering.\n\nIf user watches for 90 seconds, has 4 seconds of rebuffering, spends 2 seconds seeking by rewinding and then watches 60 more seconds that would total 156 seconds of watch time (90 + 4 + 2 + 60).\n\nIf a user watches a 2 minute video at 2x speed, Watch Time will be 1 minute (assuming no buffering, seeking, startup time). This is because Watch Time is measuring how much time has elapsed during playback, not how much video duration was watched.\n\nMetrics\n\nMux has engagement metrics to track viewership and five top-level metrics to measure quality of experience. Detailed definitions and formulas can be found on these metric guide pages:\n\n Viewer Engagement\n Overall Viewer Experience\n Playback Success\n Startup Time\n Smoothness\n Video Quality\n\nThese metrics are available in the Mux Data Dashboard and via the Mux Data API. They can be used by your team to track KPIs and optimize the viewing experience for your end users.\n\nThis is what the metrics look like on the Mux Data Dashboard:\n\n<Image\n  alt=\"Mux top 6 metrics\"\n  width={321}\n  height={800}\n  src=\"/docs/images/top-6-metrics.png\"\n/>\n\nIn order to get the most value out of the metrics measured by Mux, make sure your data is actionable by providing valuable metadata for each view. Use this in conjunction with filters to segment data metrics."
  },
  {
    "id": "137-_guides/developer/upload-files-directly",
    "title": "Upload files directly",
    "path": "_guides/developer/upload-files-directly.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/upload-files-directly",
    "content": "Overview\n\nDirect Uploads allow you to provide an authenticated upload URL to your client applications so content can be uploaded directly to Mux without needing any intermediary steps. You still get to control who gets an authenticated URL, how long it's viable, and, of course, the Asset settings used when the upload is complete.\n\nThe most common use-case for Direct Uploads is in client applications, such as native mobile apps and the browser, but you could also use them to upload directly from your server or in a command line tool. Any time you don't feel the need to store the original on your own, just generate a signed URL and push the content directly.\n\nLet's start by walking through the simplest use case of getting a file directly into Mux.\n\nUpload a file directly into Mux\n\n1. Create an authenticated URL\n\nThe first step is creating a new Direct Upload with the Mux Asset settings you want. The Mux API will return an authenticated URL that you can use directly in your client apps, as well as an ID specific to that Direct Upload so you can check the status later via the API.\n\n<CodeExamples\n  product=\"video\"\n  example=\"createUpload\"\n/>\n\n2. Use the URL to upload in your client\n\nOnce you've got an upload object, you'll use the authenticated URL it includes to make a PUT request that includes the file in the body. The URL is resumable, which means if it's a _really_ large file you can send your file in pieces and pause/resume at will.\n\n<CodeExamples\n  product=\"video\"\n  example=\"uploadFile\"\n/>\n\nIf you were following along with these examples, you should find new Assets in the Mux Dashboard with the settings you specified in the original upload create request, but the video you uploaded in the second step!\n\nIf the upload doesn't work via cURL, be sure that you've put quotes around the upload URL.\n\nUsing Direct Uploads in your application\n\nThe examples above are a great way to upload a one-off file into Mux, but let's talk about how this workflow looks in your actual application. Typically you're going to want to do a few things:\n\n- Authenticate the request that gives the user a signed URL so random people don't start ingesting Assets into your Mux account.\n- Save information in your application about the file when the user creates the upload, such as who uploaded it and when, details about the video like title, tags, etc.\n- Make sure the Asset that's ultimately created from that upload is associated with that information.\n\nJust like Assets, Direct Uploads have their own events, and then the Asset created off the upload has the usual events as well. When you receive the video.upload.asset_created event you'll find an asset_id key that you could use in your application to tie the Asset back to the upload, but that gets tricky if your application misses events or they come out of order. To keep things simple, we like to use the passthrough key when creating an Asset. Let's look at how the passthrough workflow would work in a real application.\n\nWe provide SDKs for Android, iOS, iPadOS, and web frontend that handle difficult parts of the upload process, such has handling large files and preprocessing video for size and cost. Once your backend has created an authenticated URL for the upload, you you can give it to one of our Upload SDKs to reliably process and upload the the video.\n\nFor more information, check out our upload SDK guides:\n- Upload directly from an Android app\n- Upload directly from iOS or iPadOS\n- Upload directly from your Web App\n\nwith-mux-video is a full open-source example application that uses direct uploads\n\nnpx create-next-app --example with-mux-video with-mux-video-app\n\nAnother open-source example application is stream.new. GitHub repo link: muxinc/stream.new\n\ngit clone git@github.com:muxinc/stream.new.git\n\nBoth of these example applications use Next.js, UpChunk, Mux Direct Uploads and Mux playback.\n\nCreating an /upload route in the application\n\nIn the route we build to create and return a new Direct Upload, we'll first create a new object in our application that includes a generated ID and all the additional information we want about that Asset. _Then_ we'll create the Direct Upload and include that generated ID in the passthrough field.\n\n\n```node\nconst { json, send } = require('micro');\nconst uuid = require('uuid/v1');\n\n// This assumes you have MUX_TOKEN_ID and MUX_TOKEN_SECRET\n// environment variables.\nconst mux = new Mux();\n\n// All the 'db' references here are going to be total pseudocode.\nconst db = yourDatabase();\n\nmodule.exports = async (req, res) => {\n  const id = uuid();\n  // Go ahead and grab any info you want from the request body.\n  const assetInfo = await json(req);\n\n  // Create a new upload using the Mux SDK.\n  const upload = await mux.video.uploads.create({\n    // Set the CORS origin to your application.\n    cors_origin: 'https://your-app.com',\n\n    // Specify the settings used to create the new Asset after\n    // the upload is complete\n    new_asset_settings: {\n      passthrough: id,\n      playback_policy: ['public'],\n      video_quality: 'basic'\n    }\n  });\n\n  db.put(id, {\n    // save the upload ID in case we need to update this based on\n    // 'video.upload' webhook events.\n    uploadId: upload.id,\n    metadata: assetInfo,\n    status: 'waiting_for_upload',\n  });\n\n   // Now send back that ID and the upload URL so the client can use it!\n  send(res, 201, { id, url: upload.url });\n}\n```\n\n\nExcellent! Now we've got a working endpoint to create new Mux uploads that we can use in our Node app or deploy as a serverless function. Next we need to make sure we have an endpoint that handles the Mux webhooks when they come back.\n\n\n```node\nconst { json, send } = require('micro');\n\n// More db pseudocode.\nconst db = yourDatabase();\n\nmodule.exports = async (req, res) => {\n  // We'll grab the request body again, this time grabbing the event\n  // type and event data so we can easily use it.\n  const { type: eventType, data: eventData } = await json(req);\n\n  switch (eventType) {\n    case 'video.asset.created': {\n      // This means an Asset was successfully created! We'll get\n      // the existing item from the DB first, then update it with the\n      // new Asset details\n      const item = await db.get(eventData.passthrough);\n      // Just in case the events got here out of order, make sure the\n      // asset isn't already set to ready before blindly updating it!\n      if (item.asset.status !== 'ready') {\n        await db.put(item.id, {\n          ...item,\n          asset: eventData,\n        });\n      }\n      break;\n    };\n    case 'video.asset.ready': {\n      // This means an Asset was successfully created! This is the final\n      // state of an Asset in this stage of its lifecycle, so we don't need\n      // to check anything first.\n        const item = await db.get(eventData.passthrough);\n      await db.put(item.id, {\n        ...item,\n        asset: eventData,\n        });\n      break;\n    };\n    case 'video.upload.cancelled': {\n      // This fires when you decide you want to cancel an upload, so you\n      // may want to update your internal state to reflect that it's no longer\n      // active.\n      const item = await db.findByUploadId(eventData.passthrough);\n      await db.put(item.id, { ...item, status: 'cancelled_upload' });\n    }\n    default:\n      // Mux sends webhooks for *lots* of things, but we'll ignore those for now\n      console.log('some other event!', eventType, eventData);\n  }\n}\n```\n\n\nGreat! Now we've got our application listening for events from Mux, then updating our DB to reflect the relevant changes. You could also do cool things in the webhook handler like send your customers events via Server-Sent Events or WebSockets.\n\nHandle large files with UpChunk\n\nIn general, just making a PUT request with the file in the body is going to work fine for most client applications and content. When the files start getting a little bigger, you can stretch that by making sure to stream the file from the disk into the request. With a reliable connection, that can take you to gigabytes worth of video, but if that request fails, you or your customer are going to have to start the whole thing over again.\n\nIn those scenarios where you have really big files and potentially need to pause/restart a transfer, you can chunk up the file and use the resumable features of the upload endpoint! If you're doing it in a browser we wrote UpChunk to help, but the process isn't nearly as scary as it sounds.\n\nInstalling UpChunk\n\nWith NPM\n\n```shell\nnpm install --save @mux/upchunk\n```\n\n\nWith yarn\n\n```shell\nyarn add @mux/upchunk\n```\n\n\nWith CDN\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/upchunk@2\"></script>\n```\n\n\nUsing UpChunk\n<CodeExamples\n  product=\"video\"\n  example=\"usingUpchunk\"\n/>\n\nAlternatives to UpChunk\n\n- Split the file into chunks that are a multiple of 256KB (256  1024 bytes). For example, if you wanted to have 20MB chunks, you'd want each one to be 20,971,520 bytes (20  1024  1024). The exception is the final chunk, which can just be the remainder of the file. Bigger chunks will be a faster upload, but think about each one as its own upload in the sense of needing to restart that one if it fails, but needing to upload fewer chunks can be faster.\n- Set a couple of headers:\n    - Content-Length: the size of the current chunk you're uploading.\n    - Content-Range: what bytes you're currently uploading. For example, if you've got a 10,000,000 byte file and you're uploading in ~1MB chunks, this header would look like Content-Range: bytes 0-1048575/10000000 for the first chunk.\n- Now use a PUT request like we were for \"normal\" uploads, just with those additional headers and each individual chunk as the body.\n- If the server responds with a 308, you're good to continue uploading! It will respond with as 200 OK or 201 Created when the upload is completed.\n\nUpload streamed data as it becomes available\n\nWhen dealing with streaming data where the total file size is unknown until the end—such as live recordings or streaming AI generated data—you can upload the data to Mux in chunks as it becomes available.\n\nThis approach has several benefits:\n\n- No need to know the total file size upfront\n- Reduced memory usage on the client, because you're uploading chunks and releasing them instead of buffering the entire file in memory\n- Faster uploads, because you're uploading chunks in parallel with the client instead of waiting for the entire file to be recorded\n\nExample: MediaRecorder\n\nWhen recording media directly from a user's device using the MediaRecorder API, the total file size is unknown until the recording is complete. To handle this, you can upload the media data to Mux in chunks as it becomes available, without needing to know the total size up front.\n\nLet's look at an example of how to do this with a web app. First, we'll set up the MediaRecorder to capture media data in chunks. Each chunk will be passed to the uploadChunk function, which will upload it to Mux.\n\nYou can find a complete example repository demonstrating this approach in our examples repo.\n\nStart by declaring some global variables to track recording state and upload progress.\n\n```javascript\n// Global variables to track recording state and upload progress\nlet mediaRecorder;\nlet mediaStream;\nlet nextByteStart = 0;\nconst CHUNK_SIZE = 8 * 1024 * 1024; // 8MB chunks - must be multiple of 256KB\nconst maxRetries = 3; // Number of upload retry attempts\nconst lockName = 'uploadLock'; // Used by Web Locks API for sequential uploads\nlet activeUploads = 0; // Track number of chunks currently uploading\nlet isFinalizing = false; // Flag to prevent new uploads during finalization\n```\n\n\nNext, configure the MediaRecorder to capture media data in chunks.\n\n\n```javascript\nasync function startRecording() {\n  // Request access to user's media devices\n  mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: true });\n\n  // Use a widely supported MIME type for maximum compatibility\n  const mimeType = 'video/webm';\n\n  // Initialize MediaRecorder with optimal settings\n  mediaRecorder = new MediaRecorder(mediaStream, {\n    mimeType,\n    videoBitsPerSecond: 5000000, // 5 Mbps video bitrate\n    audioBitsPerSecond: 128000   // 128 kbps audio bitrate\n  });\n\n  // Buffer to accumulate media data until we have enough for a chunk\n  let buffer = new Blob([], { type: mimeType });\n  let bufferSize = 0;\n\n  // Handle incoming media data\n  mediaRecorder.ondataavailable = async (event) => {\n    // Only process if we have data and aren't in the finalization phase\n    if (event.data.size > 0 && !isFinalizing) {\n      // Combine the new data with our existing buffer\n      // We use a Blob to efficiently handle large binary data\n      // The type must match what we specified when creating the MediaRecorder\n      buffer = new Blob([buffer, event.data], { type: mimeType });\n      bufferSize += event.data.size;\n\n      // Keep processing chunks as long as we have enough data\n      // This ensures we maintain a consistent chunk size of 8MB (CHUNK_SIZE)\n      // which is required by Mux's direct upload API\n      while (bufferSize >= CHUNK_SIZE) {\n        // Extract exactly CHUNK_SIZE bytes from the start of our buffer\n        const chunk = buffer.slice(0, CHUNK_SIZE);\n\n        // Keep the remainder in the buffer for the next chunk\n        buffer = buffer.slice(CHUNK_SIZE);\n        bufferSize -= CHUNK_SIZE;\n\n        // Upload this chunk, passing false for isFinalChunk since we're still recording\n        // nextByteStart tracks where in the overall file this chunk belongs\n        await uploadChunk(chunk, nextByteStart, false);\n\n        // Increment our position tracker by the size of the chunk we just uploaded\n        nextByteStart += chunk.size;\n      }\n      // Any remaining data stays in the buffer until we get more from ondataavailable\n    }\n  };\n\n  // Start recording, getting data every 500ms\n  mediaRecorder.start(500);\n}\n```\n\n\nUploaded chunks need to be delivered in multiples of 256KB (256  1024 bytes). Since the chunks provided by the MediaRecorder API can be smaller than that, you'll need to collect them in a buffer until you have an aggregate chunk that is at least 256KB in size. 8MB is a good size for a chunk, so we'll use that as our chunk size in this example.\n\nWhen the recording is complete, call the stopRecording function to upload the final chunk and clean up the MediaRecorder.\n\n\n```javascript\nasync function stopRecording() {\n  // Only proceed if we have an active mediaRecorder\n  if (mediaRecorder && mediaRecorder.state !== 'inactive') {\n    // Stop recording new data\n    mediaRecorder.stop();\n    // Set flag to prevent new uploads from starting during finalization\n    isFinalizing = true;\n\n    // Wait for any in-progress chunk uploads to complete\n    // Check every 100ms until all uploads are done\n    while (activeUploads > 0) {\n      await new Promise(resolve => setTimeout(resolve, 100));\n    }\n\n    // If there's any remaining data in the buffer that hasn't been uploaded yet\n    // Upload it as the final chunk (isFinalChunk = true)\n    if (buffer.size > 0) {\n      await uploadChunk(buffer, nextByteStart, true);\n      nextByteStart += buffer.size;\n    }\n\n    // Clean up by stopping all media tracks (camera, mic etc)\n    if (mediaStream) {\n      mediaStream.getTracks().forEach(track => track.stop());\n    }\n\n    // Reset finalization flag now that we're done\n    isFinalizing = false;\n  }\n}\n```\n\n\nWithin the uploadChunk function, perform a PUT request to the authenticated Mux upload URL. Use the Content-Range header to indicate the byte range of the chunk being uploaded. Since the total file size is unknown, use * as the total size until the final chunk is uploaded.\n\n\n```javascript\nasync function uploadChunk(chunk, byteStart, isFinalChunk) {\n  // Calculate the end byte position for this chunk by adding chunk size to start position\n  // Subtract 1 since byte ranges are inclusive (e.g. bytes 0-499 is 500 bytes)\n  const byteEnd = byteStart + chunk.size - 1;\n\n  // For the total size in the Content-Range header:\n  // - If this is the final chunk, use the actual total size (byteEnd + 1)\n  // - Otherwise use '*' since we don't know the final size yet\n  const totalSize = isFinalChunk ? byteEnd + 1 : '*';\n\n  // Set required headers for resumable upload:\n  // - Content-Length: Size of this chunk in bytes\n  // - Content-Range: Byte range being uploaded in format \"bytes START-END/TOTAL\"\n  const headers = {\n    'Content-Length': chunk.size.toString(),\n    'Content-Range': `bytes ${byteStart}-${byteEnd}/${totalSize}`,\n  };\n\n  let attempt = 0;\n  let success = false;\n\n  // Use Web Locks API to enforce sequential uploads\n  await navigator.locks.request(lockName, async () => {\n    activeUploads++;\n    while (attempt < maxRetries && !success) {\n      try {\n        const response = await fetch('MUX_DIRECT_UPLOAD_URL_HERE', {\n          method: 'PUT',\n          headers,\n          body: chunk\n        });\n\n        if (response.ok || response.status === 308) {\n          success = true;\n        } else {\n          throw new Error(`Upload failed with status: ${response.status}`);\n        }\n      } catch (error) {\n        attempt++;\n        if (attempt < maxRetries) {\n          await new Promise(resolve => setTimeout(resolve, attempt * 1000)); // Exponential backoff\n        } else {\n          throw error;\n        }\n      }\n    }\n    activeUploads--;\n  });\n\n  return success;\n}\n```\n\n\nIn the provided example, the navigator.locks.request method is used to enforce sequential chunk uploads. This is necessary because if the MediaRecorder is stopped, the ondataavailable event can trigger multiple times simultaneously, which would cause multiple concurrent uploads if not properly synchronized. If you attempt to upload the final chunk before the previous uploads have completed, the upload will fail.\n\nThe final chunk is indicated by the isFinalChunk parameter, which is passed to the uploadChunk function. When isFinalChunk is true, the function will upload the remaining data in the buffer as the final chunk and modify the totalSize to reflect the total amount of data that was uploaded."
  },
  {
    "id": "138-_guides/developer/upload-video-directly-from-android",
    "title": "Upload video directly from an Android app",
    "path": "_guides/developer/upload-video-directly-from-android.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/upload-video-directly-from-android",
    "content": "Direct Uploads allow you to provide an authenticated upload URL to your client applications so content can be uploaded directly to Mux without needing any intermediate steps. You still get to control who gets an authenticated URL, how long it's viable, and, of course, the Asset settings used when the upload is complete.\n\nThe Android Upload SDK allows a client application to upload video files from an Android device to Mux Video. The upload can be paused before completion and resume where it left off, even after process death.\n\nLet's start by uploading a video directly into Mux from an Android application. The code from these examples can be found in our upload example app\n\nGradle setup\n\nTo integrate the Mux Upload SDK into your Android app, you first have to add it to your project, then create a MuxUpload object using an upload URL your app can fetch from a trusted server. Once you create the MuxUpload, you can start it with start().\n\nA working example can be found alongside our source code here.\n\nAdd Mux's maven repository to your project\n\nAdd our maven repository to your project's repositories block. Depending on your setup, you may need to do this either the settings.gradle under dependencyResolutionManagement or your project's build.gradle.\n\n<CodeExamples\n  examples={{\n    gradle_kts:\n// In your repositories block\nmaven {\n  url = uri(\"https://muxinc.jfrog.io/artifactory/default-maven-release-local\")\n}\n    ,\n    gradle_groovy:\n// In your repositories block\nmaven {\n  url \"https://muxinc.jfrog.io/artifactory/default-maven-release-local\"\n}\n    ,\n  }}\n  exampleOrder=\"gradle_kts,gradle_groovy\"\n/>\n\nAdd the Upload SDK to your app's dependencies\n\nAdd the upload SDK to your app's dependencies block in its build.gradle file.\n\n<CodeExamples\n  examples={{\n    gradle_kts:\n// in your app's dependencies\nimplementation(\"com.mux.video:upload:0.4.1\")\n    ,\n    gradle_groovy:\n// in your app's dependencies\nimplementation \"com.mux.video:upload:0.4.1\"\n    ,\n  }}\n  exampleOrder=\"gradle_kts,gradle_groovy\"\n/>\n\nUpload a video\n\nIn order to securely upload a video, you will need to create a PUT URL for your video. Once you have created the upload URL, return it to the Android client then use the MuxUpload class to upload the file to Mux.\n\nGetting an Upload URL to Mux Video\n\nIn order to upload a new video to Mux, you must first create a new Direct Upload to receive the file. The Direct Upload will contain a resumable PUT url for your Android client to use while uploading the video file.\n\nYou should not create your Direct Uploads directly from your app. Instead, refer to the Direct Upload Guide to create them securely on your server backend.\n\nCreating and starting your MuxUpload\n\nTo perform the upload from your Android app, you can use the MuxUpload class. At the simplest, you need to build your MuxUpload via its Builder, then add your listeners and start() the upload.\n\n<CodeExamples\n  examples={{\n    kotlin:\n/*\n  @param myUploadUri PUT URL fetched from a trusted environment\n  @param myVideoFile File where the local video is stored. The app must have permission to read this file\n/\nfun beginUpload(myUploadUrl: Uri, myVideoFile: File) {\n  val upl = MuxUpload.Builder(myUploadUrl, myVideoFile).build()\n  upl.addProgressListener { innerUploads.postValue(uploadList) }\n  upl.addResultListener {\n    if (it.isSuccess) {\n      notifyUploadSuccess()\n    } else {\n      notifyUploadFail()\n    }\n  }\n  upl.start()\n}\n    ,\n    java:\n/*\n  @param myUploadUri PUT URL fetched from a trusted environment\n  @param myVideoFile File where the local video is stored. The app must have permission to read this file\n/\npublic void beginUpload(Uri uploadUrl, File videoFile) {\n  MuxUpload upload = new MuxUpload.Builder(uploadUri, videoFile).build();\n  upload.setProgressListener(progress -> {\n    handleProgress(progress);\n  });\n  upload.setResultListener(result -> {\n    if (UploadResult.isSuccessful(progressResult)) {\n      handleSuccess(UploadResult.getFinalProgress(progressResult));\n    } else {\n      handleFailure(UploadResult.getError(progressResult));\n    }\n  });\n  upload.start();\n}\n    ,\n  }}\n  exampleOrder=\"kotlin,java\"\n/>\n\nResume uploads after network loss or process death\n\nThe upload SDK will keep track of uploads that are in progress. When your app starts, you can restart them using MuxUploadManager. For more information on managing, pausing, and resuming uploads, see the next section of this guide.\n\n<CodeExamples\n  examples={{\n    kotlin:\n// You can do this anywhere, but it's really effective to do early in app startup\nMuxUploadManager.resumeAllCachedJobs()\n    ,\n    java:\n// You can do this anywhere, but it's really effective to do early in app startup\nMuxUploadManager.INSTANCE.resumeAllCachedJobs()\n    ,\n  }}\n  exampleOrder=\"kotlin,java\"\n/>\n\nUpload from a coroutine\n\nIf you're using Kotlin coroutines, you don't have to rely on the listener API to receive notifications when an upload succeeds or fails. If you prefer, you can use awaitSuccess in your coroutine.\n\n\n```kotlin\nsuspend fun uploadFromCoroutine(videoFile: File): Result<UploadStatus> {\n  val uploadUrl = withContext(Dispatchers.IO) {\n    getUploadUrl()  // via call to your backend server, see the guide above\n  }\n  val upload = MuxUpload.Builder(uploadUrl, videoFile).build()\n  // Set up your listener here too\n  return upload.awaitSuccess()\n}\n```\n\n\nResuming and managing Uploads\n\nMuxUploads are managed globally while they are in-progress. Your upload can safely continue while your user does other things in your app. Optionally, you can listen for progress updates for these uploads in, eg, a foreground Service with a system notification, or a progress view in another Fragment.\n\nFind Uploads already in progress\n\nMuxUploads are managed internally by the SDK, and you don't have to hold onto a reference to your MuxUpload in order for the upload to complete. You can get a MuxUpload object for any file currently uploading using MuxUploadManager\n\nThis example listens for progress updates. You can also pause() or cancel() your uploads this way if desired.\n\n<CodeExamples\n  examples={{\n    kotlin:\nfun listenToUploadInProgress(videoFile: File) {\n  val upload = MuxUploadManager.findUploadByFile(videoFile)\n  upload?.setProgressListener { handleProgress(it) }\n}\n    ,\n    java:\npublic void listenToUploadInProgress(File videoFile) {\n  MuxUpload uploadInProgress = MuxUploadManager.INSTANCE.findUploadByFile(videoFile);\n  if (uploadInProgress != null) {\n    uploadInProgress.setProgressListener(progress -> handleProgress(progress));\n  }\n}\n    ,\n  }}\n  exampleOrder=\"kotlin,java\"\n/>\n\nAdvanced\n\nSetting a Maximum resolution\n\nIf desired, you may choose a maximum resolution for the content being uploaded. You may wish to scale down the video files that are too large for your asset tier, for instance. This can save data costs for your users and it ensures that your assets are available to play as soon as possible.\n\nThe Mux Upload SDK scales down any input video larger than 4k (3840x2160 or 2160x3840) by default. You can choose to scale them down further to save on user data, or if you're targeting a basic video quality asset.\n\nDisable Input Standardization\n\n  The setting described here will only affect local changes to your input. Mux Video will still convert any non-standard inputs to a standard format during ingestion.\n\nThe Upload SDK is capable of processing input videos in order to optimize them for use with Mux Video. This behavior can be disabled if it isn't desired, although this may result in extra processing on Mux's servers. We don't recommend disabling standardization unless you are experiencing issues.\n\n<CodeExamples\n  examples={{\n    kotlin:\nfun beginUpload(myUploadUrl: Uri, myVideoFile: File) {\n  val upl = MuxUpload.Builder(myUploadUrl, myVideoFile)\n    .standarizationRequested(false) // disable input processing\n    .build()\n  // add listeners etc\n  upl.start()\n}\n    ,\n    java:\npublic void beginUpload(Uri uploadUrl, File videoFile) {\n  MuxUpload upload = new MuxUpload.Builder(uploadUri, videoFile)\n      .standarizationRequested(false) // disable input processing\n      .build();\n  // add listeners etc\n  upload.start();\n}\n    ,\n  }}\n  exampleOrder=\"kotlin,java\"\n/>\n\nRelease notes\n\nCurrent release\n\n1.0.0\nNew:\n 4k and 720p input standardization\n Background-Uploading example in sample app\n\nFixes:\n fix: currentStatus always reports READY\n fix: upload success reported as failure in some cases\n\nPrevious releases\n\n0.5.0\nNew:\n Audio transcoding\n\nImprovements:\n Improved performance reporting\n\n0.4.2\nNew\n feat: Add UploadResult class for java users to interpret Result\n\nFixes\n Fix: Some methods on MuxUpload.Builder don't return Builder\n Fix: the application context shouldn't be visible\n Fix: Transcoding errors handled incorrectly\n\n0.4.1\n\nNew\n feat: Add API for listening to and retrieving the status of an upload\n feat: Add Input Standardization, to process videos device-side\n\nFixes\n fix: Metrics events not properly redirected\n\nKnown Issues\n There's no notification/callback for the result of input standardization\n\n0.4.0\n\nImprovements\n\n doc: Finish out the public KDoc\n doc: Improve KDocs and add logo\n nfc: Hide some internal classes from java. This should not affect anyone using the SDK\n\nFixes\n fix: pausing uploads shouldn't create errors\n\n0.3.1\n\nImprovements\n fix: Restarts broken due to invalid progress data\n\n0.3.0\n\nBreaking\n breaking: Remove extraneous MIME type and Retry Time Builder fields. Configuring these did nothing\n\nUpdates\n update: Add the ability to resume all failed or paused uploads\n\nImprovements\n Greatly improved the example app\n\n0.2.0\n\nImprovements\n fix: Hide some constructors to prevent unintended use by java callers\n feat: Add Performance Metrics Tracking\n\n0.1.0\n\n🥳 First beta release of the Mux Android SDK\n\nFeatures\n Upload multiple files at once\n Pause and resume uploads, even after process death\n* Observe upload progress from anywhere in your app without extra code"
  },
  {
    "id": "139-_guides/developer/upload-video-directly-from-ios-or-ipados",
    "title": "Upload video directly from iOS or iPadOS",
    "path": "_guides/developer/upload-video-directly-from-ios-or-ipados.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/upload-video-directly-from-ios-or-ipados",
    "content": "Direct Uploads allow you to upload content from your client applications directly to Mux without needing any intermediary steps using an authenticated URL.\n\nThis guide will help you install the Upload SDK from Mux. The Upload SDK is designed to handle common tasks required to upload large video files, like file chunking and networking. By using the Upload SDK, your application will also become able to pause and resume uploads across restarts, report upload progress, and make adjustments that minimize processing time when your upload is ingested by Mux.\n\nThe Upload SDK is supported on iOS 14 and iPadOS 14, or higher. macOS is not supported at this time.\n\nYour application can also handle uploads on its own using built-in URLSession and file system APIs. We encourage you to check out the Upload SDK implementation as an example to follow along.\n\nInstall the SDK\n\nLet's start by installing the SDK. We'll use the Swift Package Manager. Step-by-step guide on using Swift Package Manager in Xcode.\n\nOpen your applications project in Xcode. In the Xcode menu bar select File > Add Packages. In the top-right corner of the modal window that opens enter the SDK repository URL which is https://github.com/muxinc/swift-upload-sdk.\n\nBy default Xcode will fetch the latest version of the SDK available on the main branch. If you need a specific package version or to restrict the range of package versions used in your application, select a different Dependency Rule. Here's an overview of the different SPM Dependency Rules and their semantics.\n\nClick on Add Package to begin resolving and downloading the SDK package. When completed, select your application target as the destination for the MuxUploadSDK package product. To use the SDK in your application, import it's module: import MuxUploadSDK.\n\nUpload content from your application\n\nGetting an authenticated URL from Mux Video\n\nYou must create a new Direct Upload to upload a new video to Mux.\n\nThe Direct Upload will contain an authenticated PUT url that's unique to your upload. Your application will upload video to this url.\n\nDirect Uploads are resumable and if your application application started an upload and needed to pause it, use the same url to resume the upload.\n\nWe recommend that you avoid creating Direct Uploads outside of a trusted environment such as a backend server. Your application can request a new authenticated URL from your server when it needs one. You can also hardcode a pre-made URL in an internal build of your application for a one-time test.\n\nCreate and start your direct upload\n\nOnce your application has an authenticated direct upload URL, you're ready to start uploading!\n\nYour application will use the authenticated url to construct a PUT request. The body of the request will contain your video data. The DirectUpload API in the Upload SDK handles these operations for you.\n\nInitialize a DirectUpload with your authenticated URL and a local video file URL. We'll also set the progress handler callback to log the upload progress to the console. In a later example you'll learn how to customize how an upload behaves.\n\n<CodeExamples\n  examples={{\n    swift:\n\n    // The url found in the response after creating a direct upload\n    let authenticatedURL: URL = / fetch from trusted environment /\n\n    // In this example we're uploading a video input file saved locally inside the application sandbox\n    let videoInputURL: URL = / URL to a video available locally /\n\n    let directUpload = DirectUpload(\n      uploadURL: authenticatedURL,\n      inputFileURL: videoInputURL\n    )\n\n    // Let's log the progress to the console\n    directUpload.progressHandler = { state in\n      print(\"Uploaded \\(state.progress.completedUnitCount) / \\(state.progress.totalUnitCount)\")\n    }\n\n    // Then start the direct upload\n    directUpload.start()\n    ,\n  }}\n  exampleOrder=\"swift\"\n/>\n\nTactics for handling large files\n\nChunking uploads\n\nSmaller videos can be uploaded with a single request. We recommend breaking up larger videos into chunks and treating them as separate uploads.\n\nThe Upload SDK handles the required networking and file chunking operations for you regardless of file size. By default the SDK splits your video into 8MB chunks when necessary. To change the chunk size your application will initialize its own DirectUploadOptions and pass the custom size as chunkSizeInBytes. Be sure to convert any quantities expressed in kilobytes or megabytes to bytes first.\n\nInitialize a DirectUpload and pass the custom options you've created as the options parameter. A default set of options will be used if options isn't set when initializing a DirectUpload.\n\n<CodeExamples\n  examples={{\n    swift:\n\n    let authenticatedURL: URL = / fetch from trusted environment /\n    let videoInputURL: URL = / URL to a video available locally /\n\n    // Construct custom upload options to upload a file in 6MB chunks\n    let chunkSizeInBytes = 6  1024  1024\n    let options = DirectUploadOptions(\n      chunkSizeInBytes: chunkSizeInBytes\n    )\n\n    // Initialize a DirectUpload with custom options\n    let directUpload = DirectUpload(\n      uploadURL: authenticatedURL,\n      inputFileURL: videoInputURL,\n      options: options\n    )\n\n    // Let's log the upload progress to the console\n    directUpload.progressHandler = { state in\n      print(\"Uploaded \\(state.progress.completedUnitCount) / \\(state.progress.totalUnitCount)\")\n    }\n\n    // Then start the direct upload\n    directUpload.start()\n    ,\n  }}\n  exampleOrder=\"swift\"\n/>\n\nSmaller chunk sizes result in more requests while larger chunk sizes lead to fewer requests that take longer to complete. We recommend using a smaller chunk size on unstable or lossy networks.\n\nWhat happens if an upload request fails?\n\nWhen the SDK becomes aware of a failed upload PUT request, it will automatically retry it. By default the SDK will retry uploading each chunk up to 3 times before the upload is deemed to have failed. This limit can be altered by your application by initializing its own DirectUploadOptions with a custom value for retryLimitPerChunk. Then initialize a DirectUpload with the custom options as the option argument.\n\n<CodeExamples\n  examples={{\n    swift:\n\n    let authenticatedURL: URL = / fetch from trusted environment /\n    let videoInputURL: URL = / URL to a video available locally /\n\n    // Construct custom upload options with a higher per-chunk retry limit\n    let options = DirectUploadOptions(\n      retryLimitPerChunk: 5\n    )\n\n    // Initialize a DirectUpload that will retry each chunk\n    // request up to 5 times\n    let directUpload = DirectUpload(\n      uploadURL: authenticatedURL,\n      inputFileURL: videoInputURL,\n      options: options\n    )\n\n    // Then start the direct upload\n    directUpload.start()\n    ,\n  }}\n  exampleOrder=\"swift\"\n/>\n\nPause and resume uploads\n\nYour application might become suspended or terminated in the middle of a long-running upload. You can avoid losing the progress completed so far by pausing the upload and resuming it when the app becomes active again.\n\n<CodeExamples\n  examples={{\n    swift:\n\n    class UploadCoordinator {\n      func handleApplicationWillTerminate() {\n        UploadManager.shared.allManagedUploads().forEach { upload in\n          upload.pause()\n        }\n      }\n\n      func handleApplicationDidBecomeActive() {\n        UploadManager.shared.resumeAllUploads()\n      }\n    }\n    ,\n  }}\n  exampleOrder=\"swift\"\n/>\n\nA direct upload can be resumed as long as it remains in a waiting status and hasn't yet transitioned to a timed_out status. You can customize this length of time by setting the timeout value in the create direct upload request to a value between 1 minute and 7 days. If no value is set the upload times out 1 hour after being created.\n\nNeed a playable asset as fast as possible?\n\nThe APIs around this feature are not final.\n\nAfter your direct upload is completed, Mux Video will convert the uploaded input into a playable asset.\n\nSome types of inputs require additional processing time during ingestion before becoming ready for playback. By default the Upload SDK reduces the processing time by adjusting upload inputs locally to a faster-to-process format when needed. More details on how audio and video input formats relate to new asset processing time available here.\n\nSetting a maximum resolution\n\nThe SDK can adjust the resolution of your video input locally before it is uploaded to Mux. By default the SDK will adjust the input resolution to 1920 x 1080 for any inputs that are larger.\n\nYou can also reduce the maximum resolution further to 1280 x 720. Initialize a new DirectUploadOptions and set .preset1280x720 as InputStandardization.maximumResolution.\n\n<CodeExamples\n  examples={{\n    swift:\n\n    let authenticatedURL: URL = / fetch from trusted environment /\n    let videoInputURL: URL = / URL to a video available locally /\n\n    // Reduce the maximum resolution to 1280 x 720\n    let options = DirectUploadOptions(\n      inputStandardization: .init(maximumResolution: .preset1280x720)\n    )\n\n    // Initialize a DirectUpload with custom options\n    let directUpload = DirectUpload(\n      uploadURL: authenticatedURL,\n      inputFileURL: videoInputURL,\n      options: options\n    )\n\n    // Then start the direct upload\n    directUpload.start()\n    ,\n  }}\n  exampleOrder=\"swift\"\n/>\n\nSkipping input adjustments\n\n  The setting described here will only affect local changes to your input. Mux Video will still convert any non-standard inputs to a standard format during ingestion.\n\nIn most cases your application won't need to bypass these adjustments. When necessary they can be skipped by initializing DirectUploadOptions and passing .skipped for inputStandardization, then passing those to the options argument when initializing a new DirectUpload like you've customized other options before.\n\n<CodeExamples\n  examples={{\n    swift:\n\n    let authenticatedURL: URL = / fetch from trusted environment /\n    let videoInputURL: URL = / URL to a video available locally /\n\n    // Skip adjustments to your input locally\n    let options = DirectUploadOptions(\n      inputStandardization: .skipped\n    )\n\n    // Initialize a DirectUpload with that skips input standardization\n    // and uploads your video as-is\n    let directUpload = DirectUpload(\n      uploadURL: authenticatedURL,\n      inputFileURL: videoInputURL,\n      options: options\n    )\n\n    // Then start the direct upload\n    directUpload.start()\n    ,\n  }}\n  exampleOrder=\"swift\"\n/>\n\nRelease notes\n\nCurrent release\n\n1.0.0\n\nImprovements\n Direct uploads are cancelable while inputs are standardized on the client\n Video inputs can be standardized to 2160p (4K) resolution\n Upload source AVAsset has the correct URL\n\nKnown Issues\n When checking if a video input file is standard or not, the SDK compares an averaged bitrate to a resolution-dependent limit. If different parts of the video input have varying input, the video may require further processing by Mux upon ingestion.\n\n0.7.0\n\nNew\n Add macOS deployment target\n\nImprovements\n Fix memory leak occurring when uploading large files\n\n0.6.0\n\nNew\n Add Foundation Measurement API for chunk size\n\nBreaking\n Rename Version to SemanticVersion for explicitness in API\n\nImprovements\n Remove UIKit dependency from SDK\n Backfill missing inline API docs\n\n0.5.0\n\nNew\n Add an overload initializer for DirectUploadOptions\n\nBreaking\n Remove prefix use in public APIs and respell Upload as DirectUpload\n\nPrevious releases\n\n0.4.0\n\nAPI Changes\n Deprecation: MuxUpload.init(uploadURL:videoFileURL:chunkSize:retriesPerChunk:) has been deprecated and will be removed in a future SDK version. Use init(uploadURL:inputFileURL:options:) instead\n Breaking Change: MuxUpload.startTime now returns an optional value\n Breaking Change: MuxUpload.Status has been renamed to MuxUpload.TransportStatus\n Add: UploadOptions struct to contain all available MuxUpload options\n Add: Options to request or to skip input standardization\n Add: MuxUpload initializer APIs that accept AVAsset or PHAsset\n Add: MuxUpload.InputStatus enum to represent the current state of the upload and change handler\n\nNew\n Support for on-device input standardization, create a playable asset from your direct upload faster. When input standardization is requested from the SDK, input video is converted to a standard range of values on a best-effort basis\n\nFixes\n Prevent integer overflow when calculating chunk request content ranges\n Prevent crash from chunk worker force unwrap\n Remove public methods from internal SDK classes\n Prevent removal of result handler properties when passing MuxUpload via UploadManager\n\n0.3.0\n\nAPI Changes\n MuxUpload's initializer no longer requires a MIME type or Retry Time. These are calculated internally\n Added methods for querying the UploadManager for the list of currenty-active uploads, and listening for changes to the list\n Add opt-out for upload statistics\n\nImprovements\n Add a much-improved example app\n\n0.2.1\n\nImprovements\n Track upload statistics\n\nFixes\n Resumed Uploads start at the beginning of the file\n\n0.2.0\n\nImprovements\n* Remove Alamofire Dependency\n\n0.1.0\n\nOur first release of Mux's Swift Upload SDK!! 🎉 💯\n\nThis public beta release includes chunked, pause-able, resume-able video uploads for Mux Video. You can upload from anywhere in your app as well as query the upload state from anywhere in your app regardless of your app architecture. Uploads can be resumed even after your app restarted after a shutdown."
  },
  {
    "id": "140-_guides/developer/uploader-web-core-functionality",
    "title": "Core functionality of Mux Uploader",
    "path": "_guides/developer/uploader-web-core-functionality.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/uploader-web-core-functionality",
    "content": "Mux Video integration\n\nMux Uploader is built for working with Mux's Direct Uploads API and workflow. Add your upload\nURL as Mux Uploader's endpoint to use it.\n\nMux Uploader uses UpChunk under the hood to handle large files by splitting them into small chunks before uploading them.\n\nControls and UI\n\nMux Uploader provides a feature-rich, dynamic UI that changes based on the current state of your media upload.\nThese can be broken down into:\n\n| State | Attribute | Description |\n| ----- | --------- | ----------- |\n| Initial | (none) | State before a media file has been selected for upload |\n| In Progress | upload-in-progress | State while media chunks are being uploaded |\n| Completed | upload-complete | State after the media has successfully finished uploading all chunks |\n| Error | upload-error | State whenever an error occurs that results in a failure to fully upload the media |\n\nInitial State\n\nThe initial state by default will show both a drag and drop region and a file select button to select your file for upload.\nBy default, it looks like this:\n\nIn Progress State\n\nUnder normal conditions, the in progress state will indicate the ongoing uploading progress as both a numeric percentage and\na progress bar. It will look something like this:\n\nPausing\n\nIn addition, you can opt into pausing, in which case the UI\nwill look like one of these, depending on if you are unpaused, pausing (after the current chunk finishes uploading), or paused.\n\n<MultiImage\n  images={[\n    { src: \"/docs/images/mux-uploader-web-pause.png\", width: 710, height: 173 },\n    { src: \"/docs/images/mux-uploader-web-pausing.png\", width: 710, height: 173 },\n    { src: \"/docs/images/mux-uploader-web-resume.png\", width: 710, height: 173 },\n  ]}\n/>\n\nOffline\n\nFinally, if you unfortunately end up loosing internet connection while uploading is in progress, you'll see this:\n\nCompleted State\n\nOnce uploading has completed, Mux Uploader will present the following status:\n\nError State\n\nAnd in the unfortunate case where you encounter an error, by default you'll see the error message and a retry button:\n\nIf you want to explore different ways to customize the UI for these different states,\ncheck out our documentation on customizing Mux Uploader's look and feel.\n\nError handling\n\nMux Uploader will monitor for unrecoverable errors and surface them via the UI, giving the\nuser the opportunity to retry the upload. Mux Uploader monitors both HTTP-status based errors\n(e.g. 4xx, 5xx statuses) and file processing errors like exceeding maximum file size limits. See our optional configuration options below for more ways to work around some of these errors.\n\nIn addition, before surfacing an HTTP-based error, Mux Uploader will automatically retry the request 5 times.\n\nYou may also listen for these errors via the uploaderror event, discussed in the section below.\n\nUsing events\n\nAll of Mux Uploader's core UI behaviors and functionality are driven by specific events. These fall into two\ncategories:\n\n1. user-driven update events (e.g. notifying Mux Uploader which file to upload or to retry uploading after an error)\n2. state-driven informational events (e.g. notifying subcomponents or anyone else listening about the upload progress or that an error occurred)\n\nFor example, you can listen for the progress event to receive details on how far along your file upload is.\n\n\n```js\n  const muxUploader = document.querySelector('mux-uploader');\n\n  muxUploader.addEventListener('progress', function (e) {\n    console.log(`My upload is ${e.detail}% complete!`)\n  });\n```\n\n\nWhen the upload is complete, you'll see 100% on the progress bar and the success event will fire.\n\nIf an error occurs during the upload, an uploaderror event will fire.\n\nExample HTML Usage\n\n\n```html\n<mux-uploader endpoint=\"https://my-authenticated-url/storage?your-url-params\"></mux-uploader>\n\n<script>\n  const muxUploader = document.querySelector('mux-uploader');\n\n  muxUploader.addEventListener('success', function () {\n    // Handle upload success\n  });\n\n  muxUploader.addEventListener('uploaderror', function () {\n    // Handle upload error\n  });\n</script>\n```\n\n\nExample React Usage\n\n\n```jsx\nimport MuxUploader from \"@mux/mux-uploader-react\";\n\nexport default function App() {\n  return (\n    <MuxUploader\n      endpoint=\"https://my-authenticated-url/storage?your-url-params\"\n      onSuccess={() => {\n        // Handle upload success\n      }}\n      onUploadError={() => {\n        // Handle upload error\n      }}\n    />\n  );\n}\n```\n\n\nConfigure Upload Details\n\nIn addition to various UI customization and behaviors, Mux Uploader exposes the following attributes / properties for configuring details\nabout the file upload itself:\n\n| Attribute / Property | Description |\n| --- | --- |\n| max-file-size / maxFileSize | The largest size, in kB, allowed for upload |\n| chunk-size / chunkSize | The size of each upload chunk, in kB. Useful for advanced optimization based on known network conditions or file details. |\n| dynamic-chunk-size / dynamicChunkSize | A boolean that tells Mux Uploader to automatically adapt its chunk size larger or smaller based on network conditions. |\n| use-large-file-workaround / useLargeFileWorkaround | A boolean that enables a less memory efficient way of loading and chunking files for environments that don't reliably handle ReadableStream for large files. This can occur on e.g. Safari browsers with files >= 4GB. NOTE: This fallback will only be used if and when attempts to use ReadableStream fails. |\n\nFull API reference\n\nAny features or settings not mentioned above can be found in our full API reference\ncovering all of the available events, attributes, properties, slots, CSS parts, and CSS variables available on Mux Uploader and all of its subcomponents."
  },
  {
    "id": "141-_guides/developer/uploader-web-customize-look-and-feel",
    "title": "Customize the look and feel of Mux Uploader",
    "path": "_guides/developer/uploader-web-customize-look-and-feel.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/uploader-web-customize-look-and-feel",
    "content": "Configure UI features\n\nThe basic use case of Mux Uploader includes many UI features which may be enabled or disabled by default.\nYou can toggle many of these via attributes/properties.\n\nEnable pausing\n\nFor larger video files, you may want to allow your users to pause and resume an upload. You can enable this in the UI using\nthe pausable attribute, property, or React prop.\n\nBecause Mux Uploader uploads the file in chunks, it will wait to complete uploading the current chunk before pausing. To indicate this,\nthe pause button will actually have 3 states:\n\n1. Pause - indicates the upload is not currently paused, but can be by pressing the button.\n2. Pausing - indicates that the upload will pause once the current chunk upload finishes. The button will be disabled in this case.\n3. Resume - indicates the upload is currently paused, but can be resumed by pressing the button.\n\nBelow are examples of what this looks like in the UI.\n\n<MultiImage\n  images={[\n    { src: \"/docs/images/mux-uploader-web-pause.png\", width: 710, height: 173 },\n    { src: \"/docs/images/mux-uploader-web-pausing.png\", width: 710, height: 173 },\n    { src: \"/docs/images/mux-uploader-web-resume.png\", width: 710, height: 173 },\n  ]}\n/>\n\nDisable Retrying\n\nIf for some reason your video upload fails, Mux Uploader will allow a user to retry via the UI. You can disable this using the\nno-retry attribute or noRetry property in the web component, or just noRetry prop in React.\n\nBelow are examples of what this looks like in the UI.\n\n<MultiImage\n  images={[\n    { src: \"/docs/images/mux-uploader-web-retry.png\", width: 710, height: 160 },\n    { src: \"/docs/images/mux-uploader-web-no-retry.png\", width: 710, height: 141 },\n  ]}\n/>\n\nDisable Drag & Drop\n\nMux Uploader makes drag and drop available for your video files by default. You can disable this using the\nno-drop attribute or noDrop property in the web component, or just noDrop prop in React.\n\nBelow are examples of what this looks like in the UI.\n\n<MultiImage\n  images={[\n    { src: \"/docs/images/mux-uploader-web-drop.png\", width: 502, height: 210 },\n    { src: \"/docs/images/mux-uploader-web-no-drop.png\", width: 710, height: 50 },\n  ]}\n/>\n\nNote: There are two likely cases where you may want to disable drag and drop on Mux Uploader:\n\n1. You still want to support drag and drop, but your page or application design needs the drop zone component somewhere different.\nMux Uploader supports this by allowing you to use its subcomponents directly.\n2. You want to use Mux Uploader with all of its features baked in but drag and drop doesn't make sense for your designs. Because\nthings like the upload progress UI requires more space for its display, you'll probably also want to\nuse CSS to customize Mux Uploader.\n\nDisable other UI subcomponents or features\n\nMux Uploader also provides attributes and properties to disable:\n\n- The upload progress UI (no-progress / noProgress for the web component attribute / property, noProgress for the React prop)\n- The upload status UI (e.g. when the upload is complete or when an error occurs) (no-status / noStatus for the web component attribute / property, noStatus for the React prop)\n\nSince removing these UI elements might result in a poor user experience, you may want to use Mux Uploader's subcomponents directly for a more bespoke design when doing so.\n\nOverride the file selector with slots\n\nBecause Mux Uploader is a web component, it lets you provide your\nown file select element simply by adding it as a child and using the named slot\nslot=\"file-select\" attribute or property.\n\nThis is really handy if, for example, you already have a .btn class or similar that styles buttons in your application. For example:\n\nThe same applies to the React version of the component, `, as it's just a wrapper around the web component:\n\nStyle with CSS\n\nThe Mux Uploader element, , can be styled and positioned with CSS just like you would any other HTML element. For example:\n\nBecause Mux Uploader React is a wrapper around the HTML element, the same applies to it as well:\n\n- Mux Uploader relies on certain styles for its layout, so take care when overriding them. For example: flexbox is used by default to layout\nits subcomponents so it might be best to prefer display: inline-flex instead of potentially changing it to inline or inline-block.\n- Because Mux Uploader is a complex component made up of various sub-components, your mileage may vary on simply relying\non CSS to style the component. In these more advanced cases of styling, you may want to explore using CSS variables or\nusing the Mux Uploader subcomponents directly.\n\nUse CSS variables for additional styling\n\nIn addition to styling with standard CSS, Mux Uploader exposes some additional styles via CSS variables.\nThis allows you to tweak some of the \"under the hood\" subcomponents' styles simply. These include:\n\n| Name                            | CSS Property       | Default Value               | Description                                     |\n| ------------------------------- | ------------------ | --------------------------- | ----------------------------------------------- |\n| --overlay-background-color    | background-color | rgba(226, 253, 255, 0.95) | background color of the drop overlay            |\n| --progress-bar-fill-color     | background       | 000000                   | color for progress bar                          |\n| --progress-percentage-display | display          | block                     | display value for text percentage progress UI   |\n| --progress-radial-fill-color  | stroke           | black                     | stroke color for radial progress (experimental) |\n\nBuilding off of the prior examples, you can use these just like you would other CSS variables:\n\nAnd for React:\n\nUse uploader attributes for state-driven styling\n\nMux Uploader uses read-only properties and attributes to manage and advertise different state changes during the upload process.\n\nThese are:\n\n| State | Description |\n| --- | --- |\n| (none) | Upload has not yet begun |\n| upload-in-progress | Upload is currently in progress. NOTE: This includes while the upload is paused. |\n| upload-complete | Upload has completed. |\n| upload-error` | An error occurred while attempting to upload. |\n\nThese allow you to use attribute selectors\nif you want state-driven, dynamic styling via CSS.\n\nHere's a basic example of these in action that builds off of the prior examples:\n\nNOTE: Because Mux Uploader React is a thin wrapper around the Mux Uploader web component, you can use these exact same CSS selectors\nin your React application. Alternatively, some frameworks, like Tailwind CSS, have built-in support for arbitrary\nattribute selectors. For an example of this in use, see the section below.\n\nStyling in React\n\nIf you're using React to build your application, there are some common patterns used in React that are less likely to be relevant for\nthe web component version. Below are a couple of these.\n\nUsing CSS modules\n\nOne common pattern for styling in React is to use CSS-in-JS, for example, using CSS modules:\n\nUsing Tailwind CSS\n\nAnother common approach to styling React applications is using Tailwind CSS. Here's an example for Mux Uploader\napproximating the previous examples, including CSS variables via\narbitrary properties and attribute selectors via\narbitrary variants:"
  },
  {
    "id": "142-_guides/developer/uploader-web-integrate-in-your-webapp",
    "title": "Integrate Mux Uploader into your web application",
    "path": "_guides/developer/uploader-web-integrate-in-your-webapp.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/uploader-web-integrate-in-your-webapp",
    "content": "Install Mux Uploader\n\nMux Uploader has 2 packages:\n\n- @mux/mux-uploader: the web component, compatible with all frontend frameworks\n- @mux/mux-uploader-react: the React component, for usage in React\n\nBoth are built with TypeScript and can be installed either via npm, yarn or the hosted option on jsdelivr.\n\nNPM\n\n\n```shell\nnpm install @mux/mux-uploader@latest #or @mux/mux-uploader-react@latest\n```\n\n\nYarn\n\n\n```shell\nyarn add @mux/mux-uploader@latest #or @mux/mux-uploader-react@latest\n```\n\n\nHosted\n\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-uploader\"></script>\n<!--\nor src=\"https://cdn.jsdelivr.net/npm/@mux/mux-uploader-react\"\n-->\n```\n\n\nProviding attributes\n\nThe only required value to use Mux uploader is endpoint.\n\nExamples\n\nHTML element\n\nUsing in HTML just requires adding the hosted ` tag to your page and then adding the ` element where you need it.\n\nReact\n\nFor our React implementation, you can use it just like you would any other React component.\n\nSvelte\n\nBecause Svelte supports web components, it doesn't need a separate wrapper component like React. View the SveltKit example in the\nMux Elements repo for a fully functioning example.\n\n\n```html\n<script context=\"module\" lang=\"ts\">\n  export const prerender = true;\n</script>\n\n<script lang=\"ts\">\n  // this prevents the custom elements from being redefined when the REPL is updated and reloads, which throws an error\n  // this means that any changes to the custom element won't be picked up without saving and refreshing the REPL\n  // const oldRegister = customElements.define;\n  // customElements.define = function(name, constructor, options) {\n  // \tif (!customElements.get(name)) {\n  // \t\toldRegister(name, constructor, options);\n  // \t}\n  // }\n  // import { page } from '$app/stores';\n  import { onMount } from \"svelte\";\n  onMount(async () => {\n    await import(\"@mux/mux-uploader\");\n  });\n</script>\n\n<mux-uploader endpoint=\"https://httpbin.org/put\" />\n```\n\n\nVue\n\nBecause Vue supports web components, it doesn't need a separate wrapper component like React. View the Vue example in the Mux Elements repo for a fully functioning example.\n\n\n```html\n<script setup lang=\"ts\">\n  import \"@mux/mux-uploader\";\n</script>\n\n<template>\n  <main>\n    <mux-uploader endpoint=\"https://httpbin.org/put\" />\n  </main>\n</template>\n```\n\n\n  <GuideCard\n    title=\"Customize the look and feel\"\n    description=\"Customize Mux Uploader to match your brand\"\n    links={[\n      {\n        title: \"Read the guide\",\n        href: \"/docs/guides/uploader-web-customize-look-and-feel\",\n      },\n    ]}\n  />"
  },
  {
    "id": "143-_guides/developer/uploader-web-use-subcomponents-directly",
    "title": "Compose custom UIs with subcomponents",
    "path": "_guides/developer/uploader-web-use-subcomponents-directly.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/uploader-web-use-subcomponents-directly",
    "content": "Although Mux Uploader is a single component that's easy to drop into your web application, it's actually built using several subcomponents\n\"under the hood.\" If your application design or desired user experience requires more customization, you can use the individual web components that come packaged with Mux Uploader to build out a custom upload UI that meets your needs.\n\nTo use this approach, add an id attribute to your ` element with a unique value.\n\nYou can then associate the  element with any of the packaged components by adding a mux-uploader=\"\" attribute to each component and setting it to the id that you gave to the  element.\n\nHere's a simple example for the web component:\n\n\n```html\n<!-- add a mux-uploader tag with an id attribute and hide it with CSS -->\n<mux-uploader id=\"my-uploader\" style=\"display: none;\"></mux-uploader>\n\n<!-- ...then, somewhere else in your app, add a reference back to it -->\n<mux-uploader-file-select mux-uploader=\"my-uploader\">\n  <button slot=\"file-select\">Pick a video</button>\n</mux-uploader-file-select>\n```\n\n\nHere's one for React:\n\n\n```jsx\nimport MuxUploader, { MuxUploaderFileSelect } from \"@mux/mux-uploader-react\";\n\nexport default function App() {\n  return (\n    <MuxUploader id=\"my-uploader\" style={{ display: \"none\"}} />\n\n    {/* ...then, somewhere else in your app, add a reference back to it */}\n    <MuxUploaderFileSelect mux-uploader=\"my-uploader\">\n      <button slot=\"file-select\">Pick a video</button>\n    </mux-uploader-file-select>\n  );\n}\n```\n\n\nBecause all of these are web components, you can use CSS to style them or\nany of their slotted children (discussed below).\n\nSubcomponents\n\nFile Select\n\nThe file select subcomponent is what tells Mux Uploader to open the file selection browser. The web component is\n, and the React component is .\n\nYou can further customize it by slotting in your own  or other component in the file-select slot.\n\nHere's an example:\n\nDrop\n\nThe drop subcomponent is what implements the drag and drop API\nand tells Mux Uploader the relevant details about the file.\nThe web component is , and the React component is .\n\nMux Uploader Drop provides a few slots for customization.\n\n- heading - By default this is a  with the text \"Drop a video file here to upload\".\n- separator - By default this is a  containing the text \"or\" placed between the heading and any additional children.\n- (default) - Any additional children that don't have a specified slot will show up below the two previous slots.\n\nHere's an example that puts all of these together, including CSS:\n\nIn addition, Mux Uploader Drop has attributes/properties for optionally showing an overlay whenever a file is\ndragged over it. These are on by default in Mux Uploader, and are:\n\n- overlay - A boolean attribute / property / React prop for enabling the overlay UI.\n- overlay-text (overlayText property and React prop) - Allows you to provide custom text to show on the overlay.\n\nIf you'd like to further customize the overlay with a different background color, you can use the\n--overlay-background-color CSS variable (which is also available when using Mux Uploader directly)\n\nHere's an example of these in action:\n\nCustom Drop\nYou can even implement your own drag and drop completely separate from  and as long as you dispatch a custom file-ready with the file in the detail property then  will handle the upload upon receiving the event.\n\n\n```html\n<script>\n  const muxUploader = document.querySelector(\"mux-uploader\");\n\n  // Dispatch custom event to trigger upload\n  muxUploader.dispatchEvent(\n    new CustomEvent(\"file-ready\", {\n      composed: true,\n      bubbles: true,\n      detail: file,\n    })\n  );\n</script>\n```\n\n\nProgress\n\nThe progress subcomponent is what visualizes progress of your upload. In fact, it is used twice \"under the hood\" by the default :\nonce for showing the %, and once for showing the progress bar.\nThe web component is , and the React component is .\n\nIn addition, Mux Uploader Progress exposes the type attribute / property / React prop for choosing the particular kind of visualization you'd prefer. The\navailable type values are:\n\n- percentage (default) - Show as a numeric % in text\n- bar - Show as a progress bar\n- radial (_Experimental_) - Show as a radial/circular progress indicator\n\nEach of these types also has CSS variables available for further customization:\n\npercentage:\n\n- --progress-percentage-display - Applies to the display of the underlying percentage element (default: block).\n\nbar:\n\n- --progress-bar-height - Applies to the height of the progress bar (default: 4px).\n- --progress-bar-fill-color - Applies to the color of the progress bar's progress indication (default: black).\n\nradial:\n\n- --progress-radial-fill-color - Applies to the color of the radial progress indication (default: black).\n\nHere's an example of these in action:\n\nStatus\n\nThe status subcomponent is what indicates when the upload is completed, or an error has occurred, or when you're offline.\nThe web component is , and the React component is .\n\nHere's an example with a bit of CSS customization, using Mux Uploader's state attributes\non the status component for additional state-driven styling:\n\nRetry\n\nThe retry subcomponent that is displayed when an error has occurred to retry uploading and will notify Mux Uploader to retry when clicked.\nThe web component is , and the React component is .\n\nHere's a simple example:\n\nPause\n\nThe pause subcomponent that is displayed while an upload is in progress and will notify Mux Uploader to either pause or resume uploading\nwhen clicked, depending on the current uploading state.\nThe web component is , and the React component is `.\n\nHere's a simple example:\n\nAdvanced use cases\n\nHere are some more examples of working with the subcomponents directly, using multiple subcomponents together to demonstrate the versatility\nand composability of using the various subcomponents together in either React or vanilla HTML.\n\nReact CSS modules\n\nJust like you can do with the \"batteries\" usage of Mux Uploader, you can use CSS-in-JS\nto handle styling of your subcomponents in React. Here's an example of how you can style Mux Uploader using CSS modules:\n\nReact Tailwind CSS\n\nAlso like Mux Uploader, you can use Tailwind CSS for your subcomponent styling. Here's an example in React:\n\nUploader Page\n\nIn this example, we use the Mux Uploader Drop component as the parent for a full page upload experience, with the various subcomponents as descendants\nwith their own customization for a more bespoke look and feel:"
  },
  {
    "id": "144-_guides/developer/use-a-custom-domain-for-streaming",
    "title": "Use your own custom domain",
    "path": "_guides/developer/use-a-custom-domain-for-streaming.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/use-a-custom-domain-for-streaming",
    "content": "Use your own domain name for live ingest\n\nCNAME-ing, short for \"Canonical Naming\", is a configuration that allows you to change the default domain name we provide.\n\nAdd a CNAME to your domain's DNS settings, and configure it to point to global-live.mux.com. After a short amount of time you should be able use your own domain name for ingest.\n\nMux supports both RTMP, RTMPS and SRT ingestion. RTMP and SRT support custom domains by configuring the CNAME record to point at the relevant ingest URL's domain (such as global-live.mux.com, or a regional live ingest URL). Custom domains will not work with RTMPS.\n\nPlease reach out to our support team with additional details of your requirements.\n\nHere are a few popular domain services with CNAME-ing instructions. If your domain service is not listed, try searching their support resources.\n\n- Cloudflare\n- Google Domains\n- AWS Route 53\n- GoDaddy\n\nNote that the CNAME doesn't have to be global-live, it can be anything you want it to be.\n\nAfter configuring your DNS settings it may take a few hours before the new configuration works, depending on your DNS provider.\n\nHere are a few examples of RTMPS and RTMP CNAME URLs before and after they are changed to custom domains:\n\n\n```text\n# RTMPS examples\nrtmps://global-live.mux.com:443/app\n# RTMP examples\nrtmp://global-live.mux.com:5222/app\nrtmp://your-cname.your-site.com:5222/app\n```\n\n\nUse your own domain for delivering videos and images\n\nFor delivery, a custom domain allows you to play videos or deliver images from your domain rather than stream.mux.com or images.mux.com. Use your own domain for delivery, such as media.mycustomdomain.com\n\nWhy might you be interested in this feature? If you want to have a consistent brand presence across all your assets, sandbox your videos, or have a need to be allowlisted. If you are interested in this feature, please reach out to your Mux Account team.\n\nAvailability\n\nCustom domains for playback is available for our customers with an annual contract with Mux. If you do not have an annual contract with Mux you can add-on this feature for the price of $100 per month. Please reach out to our Support Team to get set up."
  },
  {
    "id": "145-_guides/developer/use-srt-to-live-stream",
    "title": "Use SRT to live stream",
    "path": "_guides/developer/use-srt-to-live-stream.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/use-srt-to-live-stream",
    "content": "SRT is a modern, common alternative to RTMP and is designed for high-quality, reliable point-to-point video transmission over unreliable networks.\n\nThe Mux Video SRT feature also supports using HEVC (h.265) as the live stream input codec, reducing inbound bitrate requirements.\n\nSRT is supported by a wide range of free and commercial video encoders.\n\nAuthentication for SRT is a little different than with RTMP, and requires two pieces of information:\n\n1. streamid This is the same stream_key attribute you know & love from RTMP\n2. passphrase This is a new piece of information exposed in the Live Streams API called srt_passphrase. You'll need to use this when your encoder asks you for a passphrase.\n\nAll new and existing live streams now expose the srt_passphrase field.\n\nYou can get this field through the API using the Get Live Stream API call:\n\n\n```json\n// GET https://api.mux.com/video/v1/live-streams/{LIVE_STREAM_ID}\n{\n  // [...]\n  \"stream_key\": \"abc-123-def-456\",\n  \"srt_passphrase\": \"GHI789JKL101112\",\n  // [...]\n}\n```\n\n\nYou can also see the SRT connection details from the dashboard of any live stream:\n\nConfigure your encoder\n\nDepending on the encoder you're using, the exact path to setting the SRT configuration will vary.\n\nSome encoders accept all configuration parameters in the form of an SRT URL, in which case you'll need to construct an SRT URL as below, substituting the stream_key and srt_passphrase.\n\n\n```\nsrt://global-live.mux.com:6001?streamid={stream_key}&passphrase={srt_passphrase}\n```\n\n\nMux's global SRT ingest urls will connect you to the closest ingest region. While these ingest URLs typically provide optimal performance, you can also select a specific region using our regional ingest URLs..\n\nCommon Configuration values\n\nOther encoders will break out the SRT configuration as multiple fields, you should fill them out as below:\n\n| Field | Value |\n| --- | --- |\n| Hostname / URL / Port | srt://global-live.mux.com:6001 |\n| Stream ID | Use the stream_key from your live stream. |\n| Passphrase | Use the srt_passphrase field from your live stream. |\n| Mode | Should be set to caller if required. |\n| Encryption Key Size / Length | Set to 128 if expressed as “bits”, or 16 if expressed as “pbkeylen” |\n\nTuning\n\nYou may need some of the tuning settings below.\n\n| Field | Value | Notes |\n| --- | --- | --- |\n| Latency | 500 is generally a safe starting value | Set to at least 4 x the RTT to global-live.mux.com  |\n| Bandwidth | 25% is generally a safe starting value | Set to the percentage of overhead you have available in your internet connection for bursts of retransmission. For example, if you have a 5Mbps internet connection, and you set your encoder's target bitrate to 4Mbps, a value of 25% would be appropriate, as it would allow the encoder to burst to 5Mbps for retransmission purposes. |\n\nStream!\n\nIf you've configured your encoder correctly, you should be all set to connect your encoder and start streaming. You can then check you see the live stream in your Mux Dashboard.\n\nYou will see all the usual state transitions, events, and webhooks that you'd expect when connecting from an RTMP source.\n\nExample Encoder Configuration\n\nOBS\n\nOBS accepts the SRT endpoint as a single URL, and should be structured as shown below:\n\n_Stream Key should be left empty as both the Stream ID and the Passphrase are being set in the URL field._\n\nVideon\n\nVideon encoders need each parameter to be configured separately, as shown below:\n\nWirecast\n\nWirecast needs each parameter to be configured separately, as shown below:\n\nLarix Broadcaster on iOS and Android\n\nLarix Broadcaster also needs each parameter to be configured separately, as shown below:\n\nFFmpeg\n\nFFmpeg takes an SRT URL with the parameters on the URL, for example:\n\n\n```shell\nffmpeg \\\n  -f lavfi -re -i testsrc=size=1920x1080:rate=30 \\\n  -f lavfi -i \"sine=frequency=1000:duration=3600\" \\\n  -c:v libx264 -x264-params keyint=120:scenecut=0 \\\n  -preset superfast -b:v 5M -maxrate 6M -bufsize 3M -threads 4 \\\n  -c:a aac \\\n  -f mpegts 'srt://global-live.mux.com:6001?streamid={stream_key}&passphrase={srt_passphrase}'\n```\n\n\nGstreamer\n\nGstreamer takes an SRT URL with the parameters on the URL, for example:\n\n\n```shell\ngst-launch-1.0 -v videotestsrc ! queue ! video/x-raw, height=1080, width=1920 \\\n  ! videoconvert ! x264enc tune=zerolatency ! video/x-h264, profile=main \\\n  ! ts. audiotestsrc ! queue ! avenc_aac ! mpegtsmux name=ts \\\n  ! srtsink uri='srt://global-live.mux.com:6001?streamid={stream_key}&passphrase={srt_passphrase}'\n```\n\n\nWhen sending a live stream for ingest over SRT, Mux supports HEVC (h.265) as the contribution codec.\n\nUsing HEVC generally allows you to reduce the inbound bitrate of your live stream without sacrificing quality. The amount you can reduce the bitrate by will vary depending on the encoder that you're using, but generally this would be between 30% and 50%.\n\nYou can also now simulcast to SRT destinations for streams that are sent to Mux over SRT.\n\nYou can also simulcast streams that were sent over SRT to RTMP destinations.\n\nTo configure a simulcast destination as SRT, you can simply pass the SRT URL in the url field when creating a Simulcast Target, as shown below:\n\n\n```json\nPOST /video/v1/live-streams/{LIVE_STREAM_ID}/simulcast-targets\n\n{\n  \"url\" : \"srt://my-srt-server.example.com:6001?streamid=streamid&passphrase=passphrase\",\n  \"passthrough\" : \"My SRT Destination\"\n}\n```\n\n\nSimulcasting and HEVC over SRT\n\nWhen simulcasting an inbound SRT stream sent over HEVC, Mux does not currently transcode the output stream, so you need to be confident that the simulcast destination supports the HEVC codec.\n\nBelow is a current list of the codecs and protocols supported by common simulcast destinations:\n\n| Platform | Protocols | Codecs |\n| --- | --- | --- |\n| Facebook | RTMP(S) | h.264 |\n| X (Twitter) | RTMP(S), HLS Pull | h.264 |\n| YouTube | RTMP(S), HLS Pull, SRT (Closed Beta) | h.264, HEVC, AV1 |\n| Twitch / IVS | RTMP(S) | h.264 |\n\nSimulcast retains source codec\n\nSee simulcasting notes above.\n\nCross-protocol and cross-codec reconnects\n\nWe do not support switching ingest protocols or codecs within a reconnect window.  If you want to reuse the same Live Stream with different protocols you'll need to wait for the reconnect period to expire or call the Complete Live Stream API.\n\nEmbedded Captions\n\nEmbedded captions (608) are not supported. Auto-generated captions can be used with SRT live streams.\n\nMulti-track audio\n\nWhile we support multiple audio tracks in an SRT stream, we recommend against sending more than one, as there's no mechanism to configure which will be used. Mux will choose the first audio stream listed in the PMT; other audio streams will be dropped.\n\nFeedback\n\nWe'd love to hear your feedback as you use SRT. If you run into issues or have feedback, please contact Mux Support, and we'll get back to you."
  },
  {
    "id": "146-_guides/developer/use-video-quality-levels",
    "title": "Use different video quality levels",
    "path": "_guides/developer/use-video-quality-levels.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/use-video-quality-levels",
    "content": "We recently renamed encoding tiers to video quality levels. Read the blog for more details.\n\nIntroducing video quality levels\n\nMux Video supports encoding content with three different video quality levels. The video quality level informs the quality, cost, and available platform features for the asset.\n\nBasic\n\nThe basic video quality level uses a reduced encoding ladder, with a lower target video quality, suitable for simpler video use cases.\n\nThere is no charge for video encoding when using basic quality.\n\nPlus\n\nThe plus video quality level encodes your video at a consistent high-quality level. Assets encoded with the plus quality use an AI-powered per-title encoding technology that boosts bitrates for high-complexity content, ensuring high-quality video, while reducing bitrates for lower-complexity content to save bandwidth without sacrificing on quality.\n\nThe plus quality level incurs a cost per video minute of encoding.\n\nPremium\n\nThe premium video quality level uses the same AI-powered per-title encoding technology as plus, but is tuned to optimize for the presentation of premium media content, where the highest video quality is required, including use cases like live sports, or studio movies.\n\nThe premium quality level incurs a higher cost per video minute of encoding, storage, and delivery.\n\nSet a video quality level when creating an asset\n\nThe video quality of an asset is controlled by setting the video_quality attribute on your create-asset API call, so to create an asset with the basic quality level, you should set \"video_quality\": \"basic\" as shown below.\n\n\n```json\n// POST /video/v1/assets\n{\n\t\"inputs\": [\n\t\t{\n\t\t\t\"url\": \"https://storage.googleapis.com/muxdemofiles/mux.mp4\"\n\t\t}\n\t],\n\t\"playback_policies\": [\n\t\t\"public\"\n\t],\n\t\"video_quality\": \"basic\"\n}\n```\n\n\nAnd of course you can also select the video_quality within Direct Uploads, too; you just need to set the same \"video_quality\": \"basic\" field in the new_asset_settings of your create-direct-upload API call.\n\n\n```json\n// POST /video/v1/uploads\n{\n  \"new_asset_settings\": {\n    \"playback_policies\": [\n      \"public\"\n    ],\n    \"video_quality\": \"basic\"\n  },\n  \"cors_origin\": \"*\"\n}\n```\n\n\nSet the video quality when creating a live stream\n\nTo set the video_quality for a live stream, you just need to set the \"video_quality\" field within the new_asset_settings configuration of your create-live-stream API call to \"plus\" or \"premium\", as shown below.\n\n\n```json\n// POST /video/v1/live-streams\n{\n  \"playback_policies\": [\n    \"public\"\n  ],\n  \"new_asset_settings\": {\n    \"playback_policies\": [\n      \"public\"\n    ],\n    \"video_quality\": \"plus\"\n  }\n}\n```\n\n\nAll on-demand assets created from the live stream will also inherit the given quality level. Live streams can currently only use the plus or premium video quality levels.\n\nSupported features\n\nAssets using different video quality levels have different features or limits available to them. Refer to the below table for more details:\n\n| Feature | Basic | Plus | Premium |\n| :-- | :-- | :-- | :-- |\n| JIT encoding | ✅ | ✅ | ✅ |\n| Multi CDN delivery | ✅ | ✅ | ✅ |\n| Mux Data included | ✅ | ✅ | ✅ |\n| Mux Player included | ✅ | ✅ | ✅ |\n| Thumbnails, Gifs, Storyboards | ✅ | ✅ | ✅ |\n| Watermarking | ✅ | ✅ | ✅ |\n| Signed playback IDs and playback restrictions | ✅ | ✅ | ✅ |\n| On-Demand | ✅ | ✅ | ✅ |\n| Master Access | ✅ | ✅  | ✅ |\n| Audio-only Assets | ✅ | ✅ | ✅ |\n| Auto-generated captions | ✅ | ✅ | ✅ |\n| Clipping to a new asset| ✅ | ✅ | ✅ |\n| Multi-track audio | ✅ | ✅ | ✅ |\n| Live Streaming | ❌ | ✅ |  ✅ |\n| Adaptive bitrate ladder | Reduced | Standard | Extended |\n| Maximum streaming resolution | 2160p (4K) | 2160p (4K) | 2160p (4K) |\n| MP4 support \\ | ✅  | ✅ | ✅ |\n| DRM  | ❌ | ✅ | ✅ |\n\nExamples for comparison\n\n| Encoding tier | Content complexity | Playback page |\n| :-- | :-- | :-- |\n| basic | Simple | moodeng - basic |\n| basic | Complex | waterfall - basic |\n| plus | Simple | moodeng - plus |\n| plus | Complex | waterfall - plus |\n| premium | Simple | moodeng - premium |\n| premium | Complex | waterfall - premium |\n\n\\ MP4 pricing depends on the video quality level of your asset. Learn more."
  },
  {
    "id": "147-_guides/developer/web-autoplay-your-videos",
    "title": "Autoplay your videos",
    "path": "_guides/developer/web-autoplay-your-videos.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/developer/web-autoplay-your-videos",
    "content": "If you are autoplaying videos with any web based players that use the video element it will help to understand how browsers handle autoplay so that you can provide the best experience for your users. This applies to video elements with the autoplay attribute and anytime you are calling play() on a video element (this includes all HTML5 players like VideoJS, JWPlayer, Shaka player, etc.).\n\nBrowser vendors are frequently changing their policies when autoplay is allowed and not allowed, so your application should be prepared to deal with both scenarios, and we want to make sure we're tracking your views and errors accurately.\n\nMux Player has some extra options for helping with autoplay that do some of the following recommendations for you. Check out the Mux Player autoplay guide for details.\n\nIncrease your chance of autoplay working\n\nThere's a few conditions that will increase your chance of autoplay working.\n\n Your video is muted with the muted attribute.\n The user has interacted with the page with a click or a tap.\n (Chrome - desktop) The user’s Media Engagement Index threshold has been crossed. Chrome keeps track of how often a user consumes media on a site and if a user has played a lot of media on this site then Chrome will probably allow autoplay.\n (Chrome - mobile) The user has added the site to their home screen.\n* (Safari) Device is not in power-saving mode.\n\nEven if autoplay works when you test it out, you can never rely on it working for every one of your users. Your application must be prepared for autoplay to fail.\n\nAvoid the autoplay attribute\n\nWhen you use the autoplay attribute on a ` element (it looks like ), you have no way to know if the browser blocked or didn't block autoplay.\n\nIt is recommended to use video.play()` instead, which returns a promise and allows you to know if playback played successfully or not. If autoplay worked, the promise will resolve, if autoplay did not work then the promise will reject with an error. The great thing about this approach is that you can choose what to do with the error.\n\nFor example: you can report the error to your own error tracking tools or update the UI to reflect this error. Note that Mux's custom error tracking is for tracking fatal errors, so you wouldn't want to report an autoplay failure to Mux because then it will be considered a fatal error.\n\n\n```js\nconst video = document.querySelector('#my-video');\n\nvideo.play().then(function () {\n  // autoplay was successful!\n}).catch(function (error) {\n  // do something if you want to handle or track this error\n});\n```\n\n\nFor further reading, see the mux blog post about this topic."
  },
  {
    "id": "148-_guides/examples/ai-generated-chapters",
    "title": "Generating video chapters with AI",
    "path": "_guides/examples/ai-generated-chapters.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/examples/ai-generated-chapters",
    "content": "This guide uses @mux/ai, our open-source library that provides prebuilt workflows for common video AI tasks. It works with your favorite LLM provider (OpenAI, Anthropic, or Google). Check out the GitHub repository for more details!\n\nIf you're using a player that supports visualizing chapters during playback, like Mux Player does, you can automatically generate chapter markers using AI. The @mux/ai library makes this straightforward by handling all the complexity of fetching transcripts, formatting prompts, and parsing AI responses.\n\nPrerequisites\n\nBefore starting, make sure you have:\n- A Mux account with API credentials (token ID and token secret)\n- An API key for your preferred AI provider (OpenAI, Anthropic, or Google)\n- Node.js installed\n- Videos with captions enabled (human-generated captions are best, but auto-generated captions work great too)\n\nInstallation\n\n\n```bash\nnpm install @mux/ai\n```\n\n\nConfiguration\n\nSet your environment variables:\n\n\n```bash\n# Required\nMUX_TOKEN_ID=your_mux_token_id\nMUX_TOKEN_SECRET=your_mux_token_secret\n# You only need the API key for the provider you're using\nOPENAI_API_KEY=your_openai_api_key # OR\nANTHROPIC_API_KEY=your_anthropic_api_key # OR\nGOOGLE_GENERATIVE_AI_API_KEY=your_google_api_key\n```\n\n\nBasic usage\n\nBackend: Generate chapters\n\n\n```javascript\nimport { generateChapters } from \"@mux/ai/workflows\";\n\n// Generate chapters for a video\nconst result = await generateChapters(\"your-mux-asset-id\", \"en\", {\n  provider: \"openai\" // or \"anthropic\" or \"google\"\n});\n```\n\n\nThe function returns chapters in the exact format Mux Player expects:\n\n\n```json\n{\n  \"chapters\": [\n    { \"startTime\": 0, \"title\": \"Introduction\" },\n    { \"startTime\": 15, \"title\": \"Setting Up the Live Stream\" },\n    { \"startTime\": 29, \"title\": \"Adding Functionality with HTML and JavaScript\" },\n    { \"startTime\": 41, \"title\": \"Identifying Favorite Scene for Clipping\" }\n  ]\n}\n```\n\n\nFrontend: Add chapters to player\n\nOnce you have the chapters from your backend, you can add them to Mux Player:\n\n\n```javascript\nconst player = document.querySelector('mux-player');\nplayer.addChapters(result.chapters);\n```\n\n\nProvider options\n\n@mux/ai supports three AI providers:\n\n- OpenAI (default): Uses gpt-5-mini model - Fast and cost-effective\n- Anthropic: Uses claude-sonnet-4-5 model - Great for nuanced understanding\n- Google: Uses gemini-2.5-flash model - Balance of speed and quality\n\nYou can override the default model:\n\n\n```javascript\nconst result = await generateChapters(\"your-mux-asset-id\", \"en\", {\n  provider: \"openai\",\n  model: \"gpt-4o\" // Use a different model\n});\n```\n\n\nCustom prompts\n\nYou can override specific parts of the prompt to tune the output:\n\n\n```javascript\nconst result = await generateChapters(\"your-mux-asset-id\", \"en\", {\n  provider: \"anthropic\",\n  promptOverrides: {\n    system: \"You are a professional video editor. Create concise, engaging chapter titles.\",\n    instructions: \"Generate 5-8 chapters with titles under 50 characters each.\"\n  }\n});\n```\n\n\nWebhook integration\n\nFor automated chapter generation when videos are uploaded, you should trigger the call to generate chapters from the video.asset.track.ready webhook:\n\n\n```javascript\nexport async function handleWebhook(req, res) {\n  const event = req.body;\n\n  if (event.type === 'video.asset.track.ready' &&\n      event.data.type === 'text' &&\n      event.data.language_code === 'en') {\n    const result = await generateChapters(event.data.asset_id, \"en\");\n    await db.saveChapters(event.data.asset_id, result.chapters);\n  }\n}\n```\n\n\nVisualizing in Mux Player\n\nOnce you have chapters, you can display them in Mux Player:\n\n\n```javascript\nconst player = document.querySelector('mux-player');\nplayer.addChapters(result.chapters);\n```\n\n\nHere's an interactive example:\n\n<InteractiveCodeExample\n  product=\"player\"\n  example=\"aiChapters\"\n/>\n\nHow it works\n\nUnder the hood, @mux/ai handles:\n1. Fetching the video transcript from Mux using the asset ID\n2. Formatting the transcript for the AI provider\n3. Sending optimized prompts to generate chapter markers\n4. Parsing and validating the AI response\n5. Converting timestamps to the format Mux Player expects\n\nMux features used\n\n- Auto-generated captions - @mux/ai fetches these automatically\n- Mux Player - For displaying the generated chapters\n\nBest practices\n\n- Enable captions: Human-generated captions provide the best results, but auto-generated captions work great too\n- Choose the right provider: OpenAI's gpt-5-mini is cost-effective for most use cases\n- Validate output: While @mux/ai validates JSON structure, review chapter quality for your use case\n- Cache results: Store generated chapters in your database to avoid regenerating them\n\nResources\n\n- @mux/ai GitHub Repository\n- @mux/ai Workflows Documentation\n- Mux Auto-generated Captions\n- Mux Player Web Component"
  },
  {
    "id": "149-_guides/examples/ai-moderation",
    "title": "AI Moderation",
    "path": "_guides/examples/ai-moderation.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/examples/ai-moderation",
    "content": "This guide uses @mux/ai, our open-source library that provides prebuilt workflows for common video AI tasks. It works with your favorite LLM provider (OpenAI, Anthropic, or Google). Check out the GitHub repository for more details!\n\nOverview\n\nThis guide demonstrates how to automatically screen video content for inappropriate material using AI. The @mux/ai library handles all the complexity of extracting thumbnails, analyzing them with moderation APIs, and returning actionable results. If content exceeds your defined thresholds for sexual or violent content, you can automatically remove access to protect your platform.\n\nThis approach provides an automated first line of defense against inappropriate content, helping you maintain content standards at scale without manual review of every upload.\n\nPrerequisites\n\nBefore starting this guide, make sure you have:\n- A Mux account with API credentials (token ID and token secret)\n- An API key for OpenAI or Hive (depending on your chosen provider)\n- Node.js installed\n- Basic familiarity with webhooks and async JavaScript\n\nInstallation\n\n\n```bash\nnpm install @mux/ai\n```\n\n\nConfiguration\n\nSet your environment variables:\n\n\n```bash\n# Required\nMUX_TOKEN_ID=your_mux_token_id\nMUX_TOKEN_SECRET=your_mux_token_secret\n# You only need the API key for the provider you're using\nOPENAI_API_KEY=your_openai_api_key # OR\nHIVE_API_KEY=your_hive_api_key\n```\n\n\nBasic usage\n\n\n```javascript\nimport { getModerationScores } from \"@mux/ai/workflows\";\n\nconst result = await getModerationScores(\"your-mux-asset-id\", {\n  provider: \"openai\", // or \"hive\"\n  thresholds: {\n    sexual: 0.7,   // Flag content with 70%+ confidence\n    violence: 0.8  // Flag content with 80%+ confidence\n  }\n});\n\nconsole.log(result.exceedsThreshold); // true if content flagged\nconsole.log(result.maxScores.sexual);  // Highest sexual content score\nconsole.log(result.maxScores.violence); // Highest violence score\n```\n\n\nThe function analyzes multiple thumbnails from your video and returns:\n\n\n```javascript\n{\n  \"assetId\": \"your-asset-id\",\n  \"exceedsThreshold\": false,\n  \"maxScores\": {\n    \"sexual\": 0.12,\n    \"violence\": 0.05\n  },\n  \"thresholds\": {\n    \"sexual\": 0.7,\n    \"violence\": 0.8\n  },\n  \"thumbnailScores\": [\n    { \"sexual\": 0.12, \"violence\": 0.05, \"error\": false },\n    { \"sexual\": 0.08, \"violence\": 0.03, \"error\": false }\n    // ... more thumbnails\n  ]\n}\n```\n\n\nProvider options\n\n@mux/ai supports two moderation providers:\n\n- OpenAI (default): Uses omni-moderation-latest model - Multi-modal moderation with vision support\n- Hive: Visual moderation using Hive's specialized content safety models\n\n\n```javascript\n// Using OpenAI (default)\nconst result = await getModerationScores(\"your-mux-asset-id\", {\n  provider: \"openai\"\n});\n\n// Using Hive\nconst result = await getModerationScores(\"your-mux-asset-id\", {\n  provider: \"hive\"\n});\n```\n\n\nConfiguring thresholds\n\nThresholds use a 0-1 scale where higher values mean stricter moderation:\n\n\n```javascript\nconst result = await getModerationScores(\"your-mux-asset-id\", {\n  thresholds: {\n    sexual: 0.7,   // Flag content with 70%+ confidence of sexual content\n    violence: 0.8  // Flag content with 80%+ confidence of violence\n  }\n});\n```\n\n\nAdjust these based on your content policies and user base. Lower thresholds catch more content but may increase false positives.\n\nWebhook integration\n\nFor automated moderation when videos are uploaded, you should trigger the call to get moderation scores from the video.asset.ready webhook:\n\n\n```javascript\nexport async function handleWebhook(req, res) {\n  const event = req.body;\n\n  if (event.type === 'video.asset.ready') {\n    const result = await getModerationScores(event.data.id, { thresholds: { sexual: 0.7, violence: 0.8 } });\n    if (result.exceedsThreshold) {\n      await mux.video.assets.deletePlaybackId(event.data.id, event.data.playback_ids[0].id);\n    }\n  }\n}\n```\n\n\nHow it works\n\nUnder the hood, @mux/ai handles:\n1. Thumbnail extraction: Selects representative frames based on video duration\n   - Videos under 50 seconds: 5 evenly-spaced thumbnails\n   - Longer videos: One thumbnail every 10 seconds\n2. Concurrent analysis: Sends all thumbnails to the moderation API in parallel\n3. Score aggregation: Tracks the highest scores across all thumbnails\n4. Threshold evaluation: Compares max scores against your configured thresholds\n5. Error handling: Gracefully handles API failures and returns partial results\n\nMux features used\n\n- Mux Thumbnail API - Extracts frames for moderation analysis\n- Webhooks - Trigger moderation automatically\n\nBest practices\n\n- Maintain a database of automated moderation actions to fine-tune thresholds\n- Add notifications to users or moderators when content is flagged\n- Implement manual review queues for borderline content\n- Use transcriptions or captions for additional moderation\n- Be mindful of AI API rate limits and implement moderation queueing if needed\n\nResources\n\n- @mux/ai GitHub Repository\n- @mux/ai Workflows Documentation\n- Mux Webhooks\n- OpenAI Moderation API\n- Mux Thumbnail API"
  },
  {
    "id": "150-_guides/examples/ai-recommendation-engine",
    "title": "Building a video recommendation engine with AI",
    "path": "_guides/examples/ai-recommendation-engine.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/examples/ai-recommendation-engine",
    "content": "This guide uses @mux/ai, our open-source library that provides prebuilt workflows for common video AI tasks. It works with your favorite LLM provider (OpenAI, Anthropic, or Google). Check out the GitHub repository for more details!\n\nYou can build a content-based recommendation system that suggests similar videos by converting video transcripts into AI embeddings and performing vector similarity search. The @mux/ai library makes this straightforward by handling transcript fetching, chunking, and embedding generation.\n\nOverview\n\nThe core concept is to convert text (your video transcripts) into high-dimensional vectors (embeddings) that capture semantic meaning. Videos with similar content will have embeddings that are close together in vector space, allowing you to find and recommend similar content.\n\nPrerequisites\n\nBefore starting, make sure you have:\n- A Mux account with API credentials (token ID and token secret)\n- An API key for OpenAI or Google (the providers that support embeddings)\n- A vector database (Pinecone, Supabase with pgvector, etc.)\n- Node.js installed\n- Videos with captions enabled (human-generated captions are best, but auto-generated captions work great too)\n\nInstallation\n\n\n```bash\nnpm install @mux/ai\n```\n\n\nConfiguration\n\nSet your environment variables:\n\n\n```bash\n# Required\nMUX_TOKEN_ID=your_mux_token_id\nMUX_TOKEN_SECRET=your_mux_token_secret\n# You only need the API key for the provider you're using\nOPENAI_API_KEY=your_openai_api_key # OR\nGOOGLE_GENERATIVE_AI_API_KEY=your_google_api_key\n```\n\n\nBasic usage\n\n\n```javascript\nimport { generateVideoEmbeddings } from \"@mux/ai/workflows\";\n\nconst result = await generateVideoEmbeddings(\"your-mux-asset-id\", {\n  provider: \"openai\",  // or \"google\"\n  languageCode: \"en\"\n});\n\n// Use the averaged embedding for video-level search\nconsole.log(result.averagedEmbedding);\n// Array of 1536 numbers (for OpenAI's text-embedding-3-small)\n\n// Or use individual chunks for timestamp-accurate search\nconsole.log(result.chunks.length);\nconsole.log(result.chunks[0].embedding);\n```\n\n\nThe function returns:\n\n\n```javascript\n{\n  \"assetId\": \"your-asset-id\",\n  \"averagedEmbedding\": [0.123, -0.456, ...],  // Single vector representing the whole video\n  \"chunks\": [\n    {\n      \"chunkId\": \"chunk_0\",\n      \"embedding\": [0.234, -0.567, ...],\n      \"metadata\": {\n        \"tokenCount\": 450,\n        \"startTime\": 0,\n        \"endTime\": 30.5,\n        \"text\": \"Welcome to our tutorial...\"\n      }\n    }\n    // ... more chunks\n  ],\n  \"metadata\": {\n    \"totalChunks\": 12,\n    \"totalTokens\": 5432,\n    \"embeddingDimensions\": 1536,\n    \"languageCode\": \"en\"\n  }\n}\n```\n\n\nProvider options\n\n@mux/ai supports two embedding providers:\n\n- OpenAI (default): Uses text-embedding-3-small model (default 1536 dimensions) - Fast and cost-effective\n- Google: Uses text-embedding-004 model (768 dimensions) - Alternative option\n\n\n```javascript\n// Using OpenAI (default)\nconst result = await generateVideoEmbeddings(\"your-mux-asset-id\", {\n  provider: \"openai\"\n});\n\n// Using Google\nconst result = await generateVideoEmbeddings(\"your-mux-asset-id\", {\n  provider: \"google\"\n});\n\n// Override the default model\nconst result = await generateVideoEmbeddings(\"your-mux-asset-id\", {\n  provider: \"openai\",\n  model: \"text-embedding-3-large\"  // 3072 dimensions, higher quality\n});\n```\n\n\nChunking strategies\n\nFor long videos, transcripts are split into chunks to fit within embedding model token limits. Chunking strategy affects the granularity of your search results:\n\n- Token-based chunking: Splits text by token count, maximizing information density. Best for general video-level recommendations.\n- VTT-based chunking: Preserves caption boundaries and timing metadata. Best when you need timestamp-accurate search or want to recommend specific video segments.\n\n\n```javascript\n// Token-based chunking (default)\nconst result = await generateVideoEmbeddings(\"your-mux-asset-id\", {\n  chunkingStrategy: {\n    type: \"token\",\n    maxTokens: 500,\n    overlap: 100  // Tokens of overlap between chunks\n  }\n});\n\n// VTT-based chunking (preserves caption boundaries)\nconst result = await generateVideoEmbeddings(\"your-mux-asset-id\", {\n  chunkingStrategy: {\n    type: \"vtt\",\n    maxTokens: 500,\n    overlapCues: 2  // Number of caption cues to overlap\n  }\n});\n```\n\n\nStoring embeddings in a vector database\n\nUsing Pinecone\n\n\n```javascript\nimport { Pinecone } from '@pinecone-database/pinecone';\nimport { generateVideoEmbeddings } from \"@mux/ai/workflows\";\n\nconst pinecone = new Pinecone({ apiKey: process.env.PINECONE_API_KEY });\nconst index = pinecone.index('video-recommendations');\n\n// Generate and store embeddings\nconst result = await generateVideoEmbeddings(\"your-mux-asset-id\");\n\n// Store the averaged embedding for video-level search\nawait index.upsert([{\n  id: \"your-mux-asset-id\",\n  values: result.averagedEmbedding,\n  metadata: {\n    title: \"Video Title\",\n    duration: 300,\n    totalChunks: result.metadata.totalChunks\n  }\n}]);\n```\n\n\nUsing Supabase with pgvector\n\n\n```javascript\nimport { createClient } from '@supabase/supabase-js';\nimport { generateVideoEmbeddings } from \"@mux/ai/workflows\";\n\nconst supabase = createClient(\n  process.env.SUPABASE_URL,\n  process.env.SUPABASE_KEY\n);\n\n// Generate embeddings\nconst result = await generateVideoEmbeddings(\"your-mux-asset-id\");\n\n// Store in Supabase\nawait supabase.from('video_embeddings').insert({\n  asset_id: \"your-mux-asset-id\",\n  embedding: result.averagedEmbedding,\n  metadata: result.metadata\n});\n```\n\n\nFinding similar videos\n\nOnce embeddings are stored, use vector similarity search:\n\n\n```javascript\n// Generate embedding for the query video\nconst queryResult = await generateVideoEmbeddings(queryAssetId);\n\n// Search for similar videos in Pinecone\nconst searchResults = await index.query({\n  vector: queryResult.averagedEmbedding,\n  topK: 5,  // Return 5 most similar videos\n  includeMetadata: true\n});\n\n// Display recommendations\nsearchResults.matches.forEach(match => {\n  console.log(`Similar video: ${match.id}`);\n  console.log(`Similarity score: ${match.score}`);\n});\n```\n\n\nWebhook integration\n\nFor automated embedding generation when videos are uploaded, you should trigger the call to generate video embeddings from the video.asset.track.ready webhook:\n\n\n```javascript\nexport async function handleWebhook(req, res) {\n  const event = req.body;\n\n  if (event.type === 'video.asset.track.ready' &&\n      event.data.type === 'text' &&\n      event.data.language_code === 'en') {\n    const result = await generateVideoEmbeddings(event.data.asset_id);\n    await vectorDB.upsert({ id: event.data.asset_id, embedding: result.averagedEmbedding });\n  }\n}\n```\n\n\nHow it works\n\nUnder the hood, @mux/ai handles:\n1. Fetching transcript: Downloads the VTT file from Mux\n2. Chunking: Splits long transcripts into manageable pieces\n3. Token counting: Ensures chunks fit within model limits\n4. Batch processing: Sends chunks to the embedding API efficiently\n5. Averaging: Computes a single vector for the whole video\n6. Metadata tracking: Preserves timing and token information\n\nMux features used\n\n- Auto-generated captions - Source transcripts for embeddings\n\nBest practices\n\n- Enable captions: Human-generated captions provide the best results, but auto-generated captions work great too\n- Choose appropriate chunking: Token-based for most cases, VTT-based for caption-aligned chunks\n- Use averaged embeddings for video-level search: Faster and simpler for basic recommendations\n- Use chunk embeddings for precise matching: Better for finding specific segments within videos\n- Consistent embedding model: Always use the same model for queries and storage\n- Set quality thresholds: Only recommend videos with similarity scores above a minimum threshold\n\nVector database options\n\nHere are a few popular options for storing embeddings:\n\n- Pinecone: Managed vector database, easy to use\n- Supabase with pgvector: PostgreSQL extension, good for existing Postgres users\n- Weaviate: Open-source vector database\n- Milvus: Scalable vector database\n- Qdrant: High-performance vector search\n\nResources\n\n- @mux/ai GitHub Repository\n- @mux/ai Workflows Documentation\n- Mux Auto-generated Captions\n- OpenAI Embeddings\n- Pinecone Documentation\n- Supabase pgvector Guide"
  },
  {
    "id": "151-_guides/examples/ai-summarizing-and-tagging",
    "title": "Summarizing and tagging videos with AI",
    "path": "_guides/examples/ai-summarizing-and-tagging.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/examples/ai-summarizing-and-tagging",
    "content": "This guide uses @mux/ai, our open-source library that provides prebuilt workflows for common video AI tasks. It works with your favorite LLM provider (OpenAI, Anthropic, or Google). Check out the GitHub repository for more details!\n\nAutomatically generating video metadata like titles, descriptions, and tags helps you build better search experiences, improve content discovery, and save time on manual content curation. The @mux/ai library makes this straightforward by analyzing video transcripts and storyboard images to generate metadata.\n\nPrerequisites\n\nBefore starting, make sure you have:\n- A Mux account with API credentials (token ID and token secret)\n- An API key for your preferred AI provider (OpenAI, Anthropic, or Google)\n- Node.js installed\n- Videos with captions enabled (human-generated captions are best, but auto-generated captions work great too)\n\nInstallation\n\n\n```bash\nnpm install @mux/ai\n```\n\n\nConfiguration\n\nSet your environment variables:\n\n\n```bash\n# Required\nMUX_TOKEN_ID=your_mux_token_id\nMUX_TOKEN_SECRET=your_mux_token_secret\n# You only need the API key for the provider you're using\nOPENAI_API_KEY=your_openai_api_key # OR\nANTHROPIC_API_KEY=your_anthropic_api_key # OR\nGOOGLE_GENERATIVE_AI_API_KEY=your_google_api_key\n```\n\n\nBasic usage\n\n\n```javascript\nimport { getSummaryAndTags } from \"@mux/ai/workflows\";\n\nconst result = await getSummaryAndTags(\"your-mux-asset-id\", {\n  tone: \"professional\" // or \"normal\" or \"sassy\"\n});\n\nconsole.log(result.title);\n// \"How to Build a Video Platform in 2025\"\n\nconsole.log(result.description);\n// \"Learn the fundamentals of building a modern video platform...\"\n\nconsole.log(result.tags);\n// [\"video streaming\", \"web development\", \"tutorial\", \"javascript\"]\n```\n\n\nTone options\n\nYou can control the style of generated content with the tone option:\n\n\n```javascript\n// Professional tone - formal and business-appropriate\nconst professional = await getSummaryAndTags(\"your-mux-asset-id\", {\n  tone: \"professional\"\n});\n\n// Normal tone - balanced and conversational (default)\nconst normal = await getSummaryAndTags(\"your-mux-asset-id\", {\n  tone: \"normal\"\n});\n\n// Sassy tone - playful and engaging\nconst sassy = await getSummaryAndTags(\"your-mux-asset-id\", {\n  tone: \"sassy\"\n});\n```\n\n\nHere's some example titles for each tone, based on the same demo video of Mux's thumbnail API:\n- Normal: Effortless Thumbnails & GIFs with Mux API\n- Sassy: Developer Snags Thumbnails and GIFs with Mux API\n- Professional: Mux API Simplifies Video Thumbnail and GIF Creation\n\nProvider options\n\n@mux/ai supports three AI providers:\n\n- OpenAI (default): Uses gpt-5-mini model - Fast and cost-effective\n- Anthropic: Uses claude-sonnet-4-5 model - Great for nuanced understanding\n- Google: Uses gemini-2.5-flash model - Balance of speed and quality\n\n\n```javascript\nconst result = await getSummaryAndTags(\"your-mux-asset-id\", {\n  provider: \"anthropic\", // or \"openai\" or \"google\"\n  model: \"claude-opus-4-5\" // Optional: override default model\n});\n```\n\n\nIncluding transcript\n\nBy default, @mux/ai analyzes both the storyboard images and transcript. Storyboard images are always included, but you can optionally exclude the transcript:\n\n\n```javascript\n// Exclude transcript (faster, uses only visual analysis)\nconst result = await getSummaryAndTags(\"your-mux-asset-id\", {\n  includeTranscript: false\n});\n```\n\n\nCustom prompts\n\nYou can override specific parts of the prompt to tune the output:\n\n\n```javascript\nconst result = await getSummaryAndTags(\"your-mux-asset-id\", {\n  promptOverrides: {\n    system: \"You are a video content specialist focused on technical tutorials.\",\n    instructions: \"Create a title under 60 characters and exactly 5 tags focused on technical concepts.\"\n  }\n});\n```\n\n\nWebhook integration\n\nFor automated metadata generation when videos are uploaded, you should trigger the call to get the summary and tags from the video.asset.track.ready webhook:\n\n\n```javascript\nexport async function handleWebhook(req, res) {\n  const event = req.body;\n\n  if (event.type === 'video.asset.track.ready' &&\n      event.data.type === 'text' &&\n      event.data.language_code === 'en') {\n    const result = await getSummaryAndTags(event.data.asset_id, { tone: \"professional\" });\n    await db.updateVideo(event.data.asset_id, { title: result.title, description: result.description, tags: result.tags });\n  }\n}\n```\n\n\nUse cases\n\nOnce you have automatically generated metadata, you can:\n\n- Improve search and discovery: Use titles, descriptions, and tags to build better search experiences with tools like Algolia or Elasticsearch\n- Content filtering: Allow users to filter videos by auto-generated tags\n- Analytics and insights: Track content trends across your video library by analyzing tag distributions\n\nHow it works\n\nUnder the hood, @mux/ai handles:\n1. Fetching storyboard images for visual analysis\n2. Optionally fetching the video transcript from Mux\n3. Sending optimized multimodal prompts to the AI provider\n4. Parsing and validating the structured response\n5. Returning clean, ready-to-use metadata\n\nMux features used\n\n- Storyboard images - Always used for visual analysis\n- Auto-generated captions - Optionally included for additional context\n\nBest practices\n\n- Enable captions: Human-generated captions provide the best results, but auto-generated captions work great too\n- Choose appropriate tone: Match the tone to your brand voice\n- Validate critical metadata: Review auto-generated titles for high-visibility content\n- Cache results: Store generated metadata to avoid regenerating it\n- Consider cost vs. quality: gpt-5-mini is cost-effective for most use cases\n\nResources\n\n- @mux/ai GitHub Repository\n- @mux/ai Workflows Documentation\n- Mux Auto-generated Captions\n- Mux Storyboard Images"
  },
  {
    "id": "152-_guides/examples/ai-translation-dubbing",
    "title": "Automatic translation and dubbing with AI",
    "path": "_guides/examples/ai-translation-dubbing.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/examples/ai-translation-dubbing",
    "content": "This guide uses @mux/ai, our open-source library that provides prebuilt workflows for common video AI tasks. It works with your favorite LLM provider (OpenAI, Anthropic, or Google). Check out the GitHub repository for more details!\n\nWhile Mux's auto-generated captions can produce transcripts in the original language, you may want to translate and dub the audio itself into different languages. The @mux/ai library integrates with ElevenLabs' dubbing API to automatically create translated audio tracks and add them to your videos as multi-track audio.\n\nPrerequisites\n\nBefore starting, make sure you have:\n- A Mux account with API credentials (token ID and token secret)\n- An ElevenLabs API key with dubbing access\n- An S3-compatible storage bucket (required for audio file hosting during upload)\n- Node.js installed\n\nInstallation\n\n\n```bash\nnpm install @mux/ai\n```\n\n\nConfiguration\n\nSet your environment variables:\n\n\n```bash\n# Required for Mux\nMUX_TOKEN_ID=your_mux_token_id\nMUX_TOKEN_SECRET=your_mux_token_secret\n# Required for ElevenLabs dubbing\nELEVENLABS_API_KEY=your_elevenlabs_api_key\n# Required for uploading dubbed audio back to Mux\nS3_ENDPOINT=https://your-s3-endpoint.com\nS3_REGION=auto\nS3_BUCKET=your-bucket-name\nS3_ACCESS_KEY_ID=your-access-key\nS3_SECRET_ACCESS_KEY=your-secret-key\n```\n\n\nEnabling audio static renditions\n\nThe @mux/ai library automatically requests audio-only static renditions if they don't already exist on your asset. However, you can pre-emptively enable them when creating videos to avoid waiting for rendition generation during the dubbing workflow.\n\nTo enable when creating a video:\n\n\n```javascript\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux();\n\nconst asset = await mux.video.assets.create({\n  input: \"https://example.com/video.mp4\",\n  playback_policy: ['public'],\n  static_renditions: [\n    { resolution: 'audio-only' }  // Enable audio.m4a rendition\n  ]\n});\n```\n\n\nOr add to an existing asset:\n\n\n```javascript\nawait mux.video.assets.createStaticRendition(\"your-mux-asset-id\", {\n  resolution: 'audio-only'\n});\n```\n\n\nBasic usage\n\n\n```javascript\nimport { translateAudio } from \"@mux/ai/workflows\";\n\n// Dub video audio to Spanish\nconst result = await translateAudio(\n  \"your-mux-asset-id\",\n  \"es\"  // target language (source language is auto-detected)\n);\n\nconsole.log(result.uploadedTrackId);\n// The new Mux audio track ID for the dubbed audio\n\nconsole.log(result.dubbingId);\n// ElevenLabs dubbing ID for tracking\n\nconsole.log(result.targetLanguageCode);  // \"es\"\n```\n\n\nThe function automatically:\n1. Fetches the audio.m4a static rendition from Mux\n2. Sends it to ElevenLabs for dubbing (source language auto-detected)\n3. Waits for the dubbing to complete\n4. Uploads the dubbed audio to your S3 bucket\n5. Creates a new audio track on your Mux asset\n6. Returns the new track ID\n\nLanguage support\n\nThe library uses ISO 639-1 language codes. Common target languages include:\n\n\n```javascript\nawait translateAudio(\"your-mux-asset-id\", \"es\");  // Spanish\nawait translateAudio(\"your-mux-asset-id\", \"fr\");  // French\nawait translateAudio(\"your-mux-asset-id\", \"de\");  // German\nawait translateAudio(\"your-mux-asset-id\", \"ja\");  // Japanese\nawait translateAudio(\"your-mux-asset-id\", \"zh\");  // Chinese\nawait translateAudio(\"your-mux-asset-id\", \"pt\");  // Portuguese\nawait translateAudio(\"your-mux-asset-id\", \"it\");  // Italian\n// etc.\n```\n\n\nThe source language is automatically detected by ElevenLabs. You only need to specify the target language.\n\nSpeaker detection\n\nYou can specify the number of speakers for better dubbing quality:\n\n\n```javascript\n// Auto-detect number of speakers (default)\nconst result = await translateAudio(\"your-mux-asset-id\", \"es\", {\n  numSpeakers: 0\n});\n\n// Specify exact number of speakers\nconst result = await translateAudio(\"your-mux-asset-id\", \"es\", {\n  numSpeakers: 2  // For videos with 2 distinct speakers\n});\n```\n\n\nDownload without uploading\n\nIf you want to handle the upload yourself or just get the dubbed audio file:\n\n\n```javascript\nconst result = await translateAudio(\"your-mux-asset-id\", \"es\", {\n  uploadToMux: false\n});\n\nconsole.log(result.presignedUrl);\n// URL to download the dubbed audio file for manual review before uploading to Mux\n```\n\n\nWebhook integration\n\nFor automated dubbing when videos are uploaded, you should trigger the call to translate audio from the video.asset.static_rendition.ready webhook:\n\n\n```javascript\nexport async function handleWebhook(req, res) {\n  const event = req.body;\n\n  if (event.type === 'video.asset.static_rendition.ready') {\n    const result = await translateAudio(event.data.id, \"es\");\n    await db.saveDubbedTrack(event.data.id, result.uploadedTrackId);\n  }\n}\n```\n\n\nPlaying multi-language content\n\nMux Player (and most other common video players), automatically detects multiple audio tracks and shows an audio selector. Users can switch between audio languages using the audio menu in the player controls.\n\nHow it works\n\nUnder the hood, @mux/ai handles:\n1. Fetching source audio: Downloads the audio.m4a static rendition from Mux\n2. ElevenLabs dubbing: Submits the audio to ElevenLabs with language parameters\n3. Polling: Waits for the dubbing job to complete (can take several minutes)\n4. Download: Retrieves the dubbed audio file\n5. S3 upload: Uploads the dubbed file to your S3 bucket with a presigned URL\n6. Mux track creation: Creates a new audio track on your asset\n\nMux features used\n\n- Audio-only static renditions - Source audio for dubbing\n- Multi-track audio - Adding dubbed tracks\n- Webhooks - Trigger dubbing automatically\n- Mux Player - Play videos with language-selectable audio\n\nBest practices\n\n- Enable audio-only renditions: Required for the dubbing workflow\n- Sequential processing: Process one language at a time to avoid rate limits\n- Error handling: Dubbing can fail or take time; implement retries and timeouts\n- Cost management: Dubbing is more expensive than caption translation and takes several minutes per video\n- Quality review: AI dubbing quality varies - voices may not match the original tone, lip sync can be off, and nuances like humor or cultural references may be lost. Consider human review for important or high-visibility content\n- Set user expectations: Add labels like \"Auto-dubbed\" in your UI to indicate the content is AI-generated\n\nVideo demo\n\nHere's an example of AI-dubbed audio in action:\n\nResources\n\n- @mux/ai GitHub Repository\n- @mux/ai Workflows Documentation\n- ElevenLabs Dubbing API\n- Mux Multi-track Audio\n- Mux Static Renditions"
  },
  {
    "id": "153-_guides/examples/ai-translation-subtitles",
    "title": "Automatic subtitle translations with AI",
    "path": "_guides/examples/ai-translation-subtitles.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/examples/ai-translation-subtitles",
    "content": "This guide uses @mux/ai, our open-source library that provides prebuilt workflows for common video AI tasks. It works with your favorite LLM provider (OpenAI, Anthropic, or Google). Check out the GitHub repository for more details!\n\nMux uses OpenAI's Whisper model to create auto-generated captions, which must be generated in the same language as your source audio. To make your content accessible globally, you can use AI to translate captions into other languages. The @mux/ai library makes this straightforward by handling caption fetching, translation, and re-uploading to Mux.\n\nPrerequisites\n\nBefore starting, make sure you have:\n- A Mux account with API credentials (token ID and token secret)\n- An API key for your preferred AI provider (OpenAI, Anthropic, or Google)\n- An S3-compatible storage bucket (required for caption file hosting during upload)\n- Node.js installed\n- Videos with captions enabled (human-generated captions are best, but auto-generated captions work great too)\n\nInstallation\n\n\n```bash\nnpm install @mux/ai\n```\n\n\nConfiguration\n\nSet your environment variables:\n\n\n```bash\n# Required for Mux\nMUX_TOKEN_ID=your_mux_token_id\nMUX_TOKEN_SECRET=your_mux_token_secret\n# You only need the API key for the provider you're using\nOPENAI_API_KEY=your_openai_api_key # OR\nANTHROPIC_API_KEY=your_anthropic_api_key # OR\nGOOGLE_GENERATIVE_AI_API_KEY=your_google_api_key\n# Required for uploading translated captions back to Mux\nS3_ENDPOINT=https://your-s3-endpoint.com\nS3_REGION=auto\nS3_BUCKET=your-bucket-name\nS3_ACCESS_KEY_ID=your-access-key\nS3_SECRET_ACCESS_KEY=your-secret-key\n```\n\n\nBasic usage\n\n\n```javascript\nimport { translateCaptions } from \"@mux/ai/workflows\";\n\n// Translate English captions to Spanish\nconst result = await translateCaptions(\n  \"your-mux-asset-id\",\n  \"en\",  // source language\n  \"es\",  // target language\n  {\n    provider: \"anthropic\" // or \"openai\" or \"google\"\n  }\n);\n\nconsole.log(result.uploadedTrackId);\n// The new Mux track ID for the translated captions\n```\n\n\nThe function automatically:\n1. Fetches the source captions from Mux\n2. Translates them using your chosen AI provider\n3. Uploads the translated VTT file to your S3 bucket\n4. Creates a new caption track on your Mux asset\n5. Returns the new track ID\n\nLanguage support\n\n@mux/ai uses ISO 639-1 language codes and automatically converts them to full language names. It supports all standard language codes, but the translation capability of your chosen AI provider may vary.\n\n\n```javascript\n// Common translations\nawait translateCaptions(\"your-mux-asset-id\", \"en\", \"es\");  // English → Spanish\nawait translateCaptions(\"your-mux-asset-id\", \"en\", \"fr\");  // English → French\nawait translateCaptions(\"your-mux-asset-id\", \"en\", \"de\");  // English → German\nawait translateCaptions(\"your-mux-asset-id\", \"en\", \"ja\");  // English → Japanese\nawait translateCaptions(\"your-mux-asset-id\", \"en\", \"zh\");  // English → Chinese\nawait translateCaptions(\"your-mux-asset-id\", \"en\", \"ar\");  // English → Arabic\n// etc.\n```\n\n\nProvider options\n\n@mux/ai supports three AI providers:\n\n- OpenAI (default): Uses gpt-5-mini model - Fast and cost-effective\n- Anthropic: Uses claude-sonnet-4-5 model - Excellent for nuanced translations\n- Google: Uses gemini-2.5-flash model - Balance of speed and quality\n\n\n```javascript\nconst result = await translateCaptions(\"your-mux-asset-id\", \"en\", \"es\", {\n  provider: \"anthropic\",\n  model: \"claude-opus-4-5\" // Optional: override default model\n});\n```\n\n\nTranslate without uploading\n\nIf you want to handle the upload yourself or just get the translated file:\n\n\n```javascript\nconst result = await translateCaptions(\"your-mux-asset-id\", \"en\", \"es\", {\n  uploadToMux: false\n});\n\nconsole.log(result.presignedUrl);\n// URL to download the translated VTT file for review before uploading to Mux\n```\n\n\nWebhook integration\n\nFor automated translation when videos are uploaded, you should trigger the call to translate captions from the video.asset.track.ready webhook for your source language:\n\n\n```javascript\nexport async function handleWebhook(req, res) {\n  const event = req.body;\n\n  if (event.type === 'video.asset.track.ready' &&\n      event.data.type === 'text' &&\n      event.data.language_code === 'en') {\n    const result = await translateCaptions(event.data.asset_id, \"en\", \"es\");\n    await db.saveTranslationTrack(event.data.asset_id, result.uploadedTrackId);\n  }\n}\n```\n\n\nUsing with Mux Player\n\nMux Player automatically detects multiple caption tracks and shows a language selector:\n\n\n```html\n<mux-player\n  playback-id=\"your-playback-id\"\n  metadata-video-title=\"My Video\"\n></mux-player>\n```\n\n\nUsers can switch between languages using the captions menu in the player controls.\n\nComplete example\n\nHere's a complete webhook handler that translates captions:\n\n\n```javascript\nimport express from 'express';\nimport { translateCaptions } from \"@mux/ai/workflows\";\n\nconst app = express();\napp.use(express.json());\n\napp.post('/webhook', async (req, res) => {\n  const event = req.body;\n\n  if (event.type === 'video.asset.track.ready' &&\n      event.data.type === 'text' &&\n      event.data.language_code === 'en') {\n\n    const assetId = event.data.asset_id;\n\n    try {\n      // Translate to Spanish\n      const result = await translateCaptions(assetId, \"en\", \"es\");\n\n      console.log(`Spanish captions created: ${result.uploadedTrackId}`);\n\n      res.status(200).json({ success: true });\n    } catch (error) {\n      console.error('Translation error:', error);\n      res.status(500).json({ error: error.message });\n    }\n  } else {\n    res.status(200).json({ message: 'Event ignored' });\n  }\n});\n\napp.listen(3000, () => {\n  console.log('Webhook server running on port 3000');\n});\n```\n\n\nHow it works\n\nUnder the hood, @mux/ai handles:\n1. Fetching source captions: Downloads the VTT file from Mux\n2. Translation: Sends the captions to your chosen AI provider with optimized prompts\n3. VTT preservation: Maintains timing information and formatting\n4. S3 upload: Uploads the translated file to your S3 bucket with a presigned URL\n5. Mux track creation: Creates a new caption track on your asset\n6. Cleanup: Optionally cleans up temporary files\n\nMux features used\n\n- Auto-generated captions - Source captions for translation\n- Webhooks - Trigger translations automatically\n- Mux Player - Display translated captions with language switching\n\nBest practices\n\n- Validate translations and review quality: AI translations are generally accurate but may miss context-specific nuances - for critical content, consider human review\n- Handle errors gracefully: Translation may fail for very long videos or stability issues with LLMs\n- Consider costs: Translating to many languages increases LLM costs\n\nResources\n\n- @mux/ai GitHub Repository\n- @mux/ai Workflows Documentation\n- Mux Auto-generated Captions\n- Mux Player Language Switching\n- ISO 639-1 Language Codes"
  },
  {
    "id": "154-_guides/examples/ai-workflows",
    "title": "Use Mux in AI Workflows",
    "path": "_guides/examples/ai-workflows.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/examples/ai-workflows",
    "content": "The workflows below are all powered by @mux/ai, our open-source library that provides prebuilt workflows for common video AI tasks. It works with your favorite LLM provider (OpenAI, Anthropic, or Google). Check out the GitHub repository for more details!\n\n  <GuideCard\n    imageSrc=\"/docs/images/ai-chapters@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"AI Chapters\"\n    description=\"Automatically generate chapters for your video using AI.\"\n    links={[\n      {\n        title: \"View the Guide →\",\n        href: \"/docs/examples/ai-generated-chapters\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/ai-translation@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"AI Dubbing\"\n    description=\"Automatically dub your video into different languages.\"\n    links={[\n      {\n        title: \"View the Guide →\",\n        href: \"/docs/examples/ai-translation-dubbing\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/ai-summarizing@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"AI Summarization\"\n    description=\"Automatically summarize your video using AI.\"\n    links={[\n      {\n        title: \"View the Guide →\",\n        href: \"/docs/examples/ai-summarizing-and-tagging\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/ai-subtitle-translations@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"AI Subtitle Translation\"\n    description=\"Automatically convert Mux's auto-generated captions into another language by leveraging the power of an LLM.\"\n    links={[\n      {\n        title: \"View the Guide →\",\n        href: \"/docs/examples/ai-translation-subtitles\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/ai-recommendation-engine@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"AI Recommendation Engine\"\n    description=\"Nearest neighbor search for similar videos\"\n    links={[\n      {\n        title: \"View the Guide →\",\n        href: \"/docs/examples/ai-recommendation-engine\",\n      },\n    ]}\n  />\n  <GuideCard\n    imageSrc=\"/docs/images/ai-moderation@2x.png\"\n    imageWidth={536}\n    imageHeight={300}\n    title=\"AI Moderation\"\n    description=\"Automatically moderate video content using AI to detect violence or nudity.\"\n    links={[\n      {\n        title: \"View the Guide →\",\n        href: \"/docs/examples/ai-moderation\",\n      },\n    ]}\n  />"
  },
  {
    "id": "155-_guides/examples/moderate-video-content",
    "title": "Moderate video content",
    "path": "_guides/examples/moderate-video-content.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/examples/moderate-video-content",
    "content": "If your platform accepts user-generated content in any form, you know that people will upload everything and anything. For video this can be particularly high stakes, with the potential for users to upload anything from popular media content to inappropriate footage.\n\nWhile large platforms may staff big teams of Trust & Safety specialists, you don't need an army to implement content moderation strategies of your own. Below we've rounded up a number of technical and operational strategies that Mux customers can use to keep their content libraries healthy.\n\nSecure Video Playback\n\nMux's secure video playback tools can help make it more difficult for bad actors to use your videos for their own purposes.\n\nWhen first testing out Mux, it's common to set a video's playback policy to public so you can easily view the video via its public URL. Once testing is done, we recommend that UGC platforms switch to using signed playback policies to help curb abuse. These allow you to use a JWT to time-limit requests for your content and to set playback restrictions specifying which referring domains can serve your content.\n\nHigh Delivery Webhook\n\nFor certain platforms, we currently offer an internal feature that sends notifications via webhook when we detect high delivery traffic on an asset. This can be helpful to catch unauthorized content quickly, before it results in increased spend or risk to your platform. To get this feature enabled for your account, contact Support.\n\nAlert Forwarding\n\nOur Trust & Safety team contacts all administrators on your account in the event of account usage or content that violates our Terms of Service. Our team may take actions that include the deletion of assets, disabling of live streams, and in rare cases disabling of environments. Because bad actors will often repeatedly upload the same unauthorized content, we recommend making sure these messages reach you right away so you can take appropriate actions to address the source (e.g., closing the user's account).\n\nTo ensure emails from our team get escalated, add an email group or paging service email as an admin on your Mux account. (For example, see PagerDuty's docs on email routing.)\n\nVideo Content Moderation\n\nAs our own engineers have blogged about, you either die an MVP or live long enough to build content moderation. A basic content moderation flow should take some information about the video asset (a sample of still frames, the transcript of its audio track, a copy of its metadata) and evaluate it based on algorithmic rules to escalate potentially troublesome content. For a peek at how Mux has iterated on our own approach, check out this talk that one of our experts gave at Demuxed 2023.\n\nFor info on the tools Mux offers to help you retrieve relevant data, check out these docs & blogs:\n- Get images from a video\n- Add auto-generated captions to your videos and use transcripts\n- Create timeline hover previews (helpful for human reviewers)\n- No-code partner integration blog\n\nMany customers grab images from their content via Mux APIs to feed into third-party services that can provide object detection and specialized content classification. While we recommend relying primarily on thumbnails, we also support MP4 downloads for those services that prefer a video. The results coming out of these services can be used as the trigger for automated workflows that end up in your own Slack channel or on platforms like Pagerduty or Opsgenie. Through those flows, you can action simple cases automatically and escalate edge cases to a human reviewer. You can use a tool like n8n to build these workflows with no-code blocks.\n\nMux Data\n\nIf high risk content is ending up in a page where you control the player, you can integrate Mux Data to get a lot of visibility into viewing sessions and track engagement (including the unwanted kind).\n\nAggregating these Views will help you gain insights into the types of platforms & devices being used to stream your content.\n\nIf you're using Mux Data's Media tier, you can also take advantage of two additional features:\n- Once Views are appearing in your Dashboard, you can set up alerting based on concurrent viewership. These alerts can be tuned and filtered, so you only get notifications for platforms or users you're interested in. Even more, you can create your own custom dimensions to supplement the built-in metrics.\n- And if you need to analyze your data outside of the Mux Dashboard, you can export it via CSV files or Streaming Exports.\n\nOne thing worth noting: the High Delivery Webhook's \"delivery rate\" is different than the \"Views\" tracked by Mux Data. Both can be used for telemetry, but they are looking at different parts of the video pipeline.\n\nContent Policy\n\nOne simple way to address issues with user-provided content is to make sure your content policies are clear. These rules can be in your Terms of Service, Acceptable Use Policy, Community Guidelines, or a separate content policy.\n\nConsider covering the following common topics (you're even welcome to copy this and make it your own):\n- You represent and warrant that:\n  - You will provide and maintain accurate account information.\n  - You will ensure that you have the necessary licenses, rights, and permissions to upload your content and host it on our service (including any rights to third-party music, images, or footage included in your content).\n  - You won't use our service for unlawful purposes or in any way that would violate applicable laws, rules, and regulations.\n  - You won't upload any content that infringes on anyone's copyright, trademark, or other intellectual property rights.\n- You won't upload any content that is:\n  - false or misleading, including content that constitutes impersonation or defamation\n  - violent, harmful, illegal, or dangerous, including content harmful to children\n  - hateful, abusive, offensive, racist, sexist, or otherwise inappropriate\n  - graphic, sexually explicit, or mature in nature\n  - You agree not to use our service in a way that could create an undue burden or impact service to other users.\n  - You agree not to circumvent any security or moderation features of our service.\n  - If we find any violations of applicable law, our legal terms, or our policies, you acknowledge that we may take action at our discretion, including removing content and restricting or terminating your account.\n\nYou can also share details of how you'll enforce the policy, such as a strikes-based system.\n\nFor some examples of artful content policies, check out Patreon, Strava, and Crowdcast. If you have a legal advisor, make sure to discuss any obligations that may apply to your company (e.g., under DMCA) and include coverage of those.\n\nContact Mechanisms\n\nWhile your platform will need its own active measures for content moderation, you can also incorporate third-party reporting into your approach. At minimum, you should have an email address specifically for complaints, such as copyright@yourdomain.com or abuse@yourdomain.com, but you can also build a simple intake form that will create a support ticket in your system. Make sure incoming messages will be routed to someone with training on how to handle them appropriately. Evaluate whether your contact info should be listed in the US DMCA Agent Directory.\n\nYou can also implement in-product reporting capabilities that allow other users to report a video that may violate your content policies.\n\nThis is another good place to consult your legal advisor, as some copyright safe harbor laws include specific requirements around contact details and response turnaround times to keep yourself free from liability.\n\nUser Signup Flow\n\nWhen users sign up for an account on your platform, you likely collect a short list of details (e.g., email) while keeping things as simple/frictionless as possible. If your platform is seeing patterns of abuse, consider altering this flow to disincentivize signups/posting by bad actors:\n- Collect additional personal information (e.g., full name) to increase the sense of accountability\n- Send a verification link to their email to verify its authenticity before allowing users to post videos\n- Add a buffer of time before new users can post videos or start a live stream\n- Add a viewership limit to videos posted by users who have joined within the last day\n- If your service is paid but includes a free trial, require entry of payment info before the free trial begins"
  },
  {
    "id": "156-_guides/examples/synchronize-video-playback",
    "title": "Synchronize video playback",
    "path": "_guides/examples/synchronize-video-playback.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/examples/synchronize-video-playback",
    "content": "Introduction to video playback synchronization\n\nYou may have encountered many video streaming products and services enabling the following experiences:\n Plan a watch party where each viewer is watching the video at the exact moment at the same time.\n  And when one viewer pauses the video, the video playback pauses for every viewer at the same time at the exact moment.\n Synchronize video playback with other components like chats, activity feeds, fitness stats collection, etc.\n\nYou can build similar and possibly many more interactive experiences like those mentioned above by aligning your web page\nor application components using a common source of truth, i.e., epoch time.\nThe underlying assumption to achieve synchronization is that your viewer's device remains synced to an NTP server.\n\nMux records the epoch time of each frame received for the live stream and includes that timing information in\nthe HLS Manifest as EXT-X-PROGRAM-DATE-TIME (aka PDT) tag.\nThe PDT tag value is represented in ISO 8601 format.\nThis tag is added every few seconds with monotonically increasing epoch time representing the next frame's recorded epoch time.\n\nBelow is an example of the HLS rendition (2nd level) manifest with repeating PDT tags for every 2s of the\nlive stream recorded:\n\n```text\n#EXTM3U\n#EXT-X-VERSION:7\n#EXT-X-TARGETDURATION:2\n#EXT-X-MAP:URI=\"https://chunk-gce-us-east1-production.cfcdn.mux.com/v1/chunk/3aJUOua6jsMHYybcqXRBpcXH82aCYXTu02TPTKHzIokndAPmz300ZThlCZbeNAy1t73003iytFZNJdjcvjTsOrCVTaGZgQ9J00uU/18446744073709551615.m4s?skid=default&signature=NjBmMjFkODBfYWVhMjIyZTdmMDU0ZmI0YWU2ZWJkZTJiYTY4MzhmYWQzNWQ2YzMyMTVlYjdjNmM0NzZiZjBmZGU0ODU1MTUyNQ==\"\n#EXT-X-PLAYLIST-TYPE:VOD\n\n#EXT-X-PROGRAM-DATE-TIME:2021-06-28T17:53:25.533+00:00\n#EXTINF:2,\nhttps://chunk-gce-us-east1-production.cfcdn.mux.com/v1/chunk/3aJUOua6jsMHYybcqXRBpcXH82aCYXTu02TPTKHzIokndAPmz300ZThlCZbeNAy1t73003iytFZNJdjcvjTsOrCVTaGZgQ9J00uU/0.m4s?skid=default&signature=NjBmMjFkODBfOWJkMzMyMTc5YzgwY2VmMTdlYzIwODgzZGI2NWFiMThiM2U1NDM0NzM0NDZhMmQwOThhZmI0NDQ5OWY5N2VmMA==\n\n#EXT-X-PROGRAM-DATE-TIME:2021-06-28T17:53:27.533+00:00\n#EXTINF:2,\nhttps://chunk-gce-us-east1-production.cfcdn.mux.com/v1/chunk/3aJUOua6jsMHYybcqXRBpcXH82aCYXTu02TPTKHzIokndAPmz300ZThlCZbeNAy1t73003iytFZNJdjcvjTsOrCVTaGZgQ9J00uU/1.m4s?skid=default&signature=NjBmMjFkODBfMjA1ZWNmYzgzYWRhMzNjMTY5YmEyYmM2NzE4MDk5N2I1MWE3NzhjODlhNGIzNWI3NGIwNTA5ZTIxOWQyNjI5OQ==\n\n#EXT-X-PROGRAM-DATE-TIME:2021-06-28T17:53:29.533+00:00\n#EXTINF:2,\nhttps://chunk-gce-us-east1-production.cfcdn.mux.com/v1/chunk/3aJUOua6jsMHYybcqXRBpcXH82aCYXTu02TPTKHzIokndAPmz300ZThlCZbeNAy1t73003iytFZNJdjcvjTsOrCVTaGZgQ9J00uU/2.m4s?skid=default&signature=NjBmMjFkODBfZTIyOTA5YWFjZjMzYTY4MzQ4YWEzZDBiNDkyODk1NTg2ODE2M2YwZjI3NmY2MTVhOTM5MTA2MzQ4ODIyNTNkOQ==\n\n#EXT-X-PROGRAM-DATE-TIME:2021-06-28T17:53:31.533+00:00\n#EXTINF:2,\nhttps://chunk-gce-us-east1-production.cfcdn.mux.com/v1/chunk/3aJUOua6jsMHYybcqXRBpcXH82aCYXTu02TPTKHzIokndAPmz300ZThlCZbeNAy1t73003iytFZNJdjcvjTsOrCVTaGZgQ9J00uU/3.m4s?skid=default&signature=NjBmMjFkODBfNDRkZTNhYTE5M2RhYTA4MTA4MWFkODc0YzgyMDcyMGMwODFmZWIxOGRiNWM4YzJhMTM0YTNiNGRhYmYyMWE1Nw==\n\n#EXT-X-ENDLIST\n```\n\n\nHow to get epoch time value\n\nEvery modern video player exposes an API to get EXT-X-PROGRAM-DATE-TIME tag value.\nYour application can synchronize video playback to other components using this epoch time.\nAn example demonstrating how to implement synchronization:\n Watch this Demuxed 2018 presentation by Seth Maddison on\n  How to Synchronize your Watches: Cross-platform stream synchronization of HLS and DASH\n\nSupported Video Players\nThe list below shows the various video players providing API to get EXT-X-PROGRAM-DATE-TIME tag value.\nIf your player isn't listed here, please reach out.\n Mux Player\n hls.js\n JW Player\n THEOplayer\n Bitmovin\n React Native\n Apple AVPlayer\n Android ExoPlayer\n\nIf your application wants to synchronize viewers playing videos on different devices, your application can\nsubscribe to communication channels for receiving and sending epoch time values. Many cloud-based or other\ncommercial products developed using WebSockets are available for implementing such a communication channel.\n\nAdd exclude_pdt parameter\n\nBy default, HLS playback using stream.mux.com/{PLAYBACK_ID}.m3u8 URL always adds EXT-X-PROGRAM-DATE-TIME tag with\nrecorded epoch time value. If you add the exclude_pdt=true parameter to the playback URL, then Mux will exclude this tag\nfrom the HLS rendition manifest.\n\nThere are few reasons to exclude the HLS tag:\n Video Player, like React Native, updates the current play position time value with the EXT-X-PROGRAM-DATE-TIME tag value.\nSo if your application expects a zero-based play position time, the viewer could experience playback issues when the video\nplayer starts reporting epoch time instead.\n* Your application is using a legacy video player or a player version without support for this HLS tag.\n\nUsing signed URLs\nMux videos have two types of playback policy, public or signed. If your playback_id is signed,\nthen all query parameters, including exclude_pdt need to be added to the claims body.\n\nTake a look at the signed URLs guide for details.\n\nFAQs\n\nIs the epoch time available with on-demand video?\n\nYes. Mux records epoch time for all live streams. So, the HLS manifest includes the epoch time every few seconds\nwith the EXT-X-PROGRAM-DATE-TIME tag value when the live stream is active, or for the on-demand playback of the\nlive stream recording.\n\nThe epoch time is not available in the HLS manifest when the input is a video file.\n\nCan I retrieve the epoch time through the API?\n\nYes. The asset resource object includes\nrecording_times which represents the live stream start epoch time and the duration recorded.\nYou can store the live stream timing information using therecording_times\nfor managing the live stream's status information."
  },
  {
    "id": "157-_guides/frameworks/astro",
    "title": "Add high-performance video to your Astro application",
    "path": "_guides/frameworks/astro.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/astro",
    "content": "When should you use Mux with Astro?\nWhen adding video to your Astro app, you'll encounter some common hurdles. First, videos are large. Storing them in your public directory can lead to excessive bandwidth consumption and poor Git repository performance. Next, it's important to compress and optimize your videos for the web. Then, as network conditions change, you might want to adapt the quality of your video to ensure a smooth playback experience for your users. Finally, you may want to integrate additional features like captions, thumbnails, and analytics.\n\nYou might consider using Mux's APIs and components to handle these challenges, and more.\n\nUse the API to build your video workflow\n\nIf you're looking to build your own video workflow that enables uploading, playback, and more in your application, you can use the Mux API and components like Mux Player and Mux Uploader.\n\nExample: allowing users to upload video to your app\nOne reason you might want to build your own video workflow is when you want to allow users to upload video to your app.\n\n  Much of the work described here is done on the server and is unique for every user. Make sure your Astro app is in SSR mode before you begin.\n\nLet's start by adding a new page where users can upload videos. This will involve using the Mux Uploader component, which will upload videos to a Mux Direct Uploads URL.\n\nFirst, install the Astro version of Mux Uploader:\n\n\n```bash\nnpm install @mux/mux-uploader-astro\n```\n\n\nIn the code sample below, we'll create an upload URL using the Mux Node SDK and the Direct Uploads URL API. We'll pass that URL to the native Astro ` component, which will handle uploading for us.\n\n\n```astro filename=src/pages/index.astro\n---\nimport Layout from '../layouts/Layout.astro';\nimport Mux from \"@mux/mux-node\";\nimport MuxUploader from \"@mux/mux-uploader-astro\";\n\nconst mux = new Mux({\n  tokenId: import.meta.env.MUX_TOKEN_ID,\n  tokenSecret: import.meta.env.MUX_TOKEN_SECRET\n});\n\nconst upload = await mux.video.uploads.create({\n  new_asset_settings: {\n    playback_policy: ['public'],\n    video_quality: 'basic',\n  },\n  cors_origin: '*',\n});\n---\n\n<Layout title=\"Upload a video to Mux\">\n  <MuxUploader endpoint={upload.url} />\n</Layout>\n```\n\n\nIn production, you'll want to apply additional security measures to your upload URL. Consider protecting the route with authentication to prevent unauthorized users from uploading videos. Also, use cors_origin and consider playback_policy to further restrict where uploads can be performed and who can view uploaded videos.\n\nNext, we'll create an API endpoint that will listen for Mux webhooks. When we receive the notification that the video has finished uploading and is ready for playback, we'll add the video's metadata to our database.\n\n\n```ts filename=src/pages/mux-webhook.json.ts\nimport type { APIRoute } from 'astro';\nimport mux from '../lib/mux';\n\nexport const POST: APIRoute = async ({ request }) => {\n  const body = await request.text();\n  // mux.webhooks.unwrap will validate that the given payload was sent by Mux and parse the payload.\n  // It will also provide type-safe access to the payload.\n  // Generate MUX_WEBHOOK_SIGNING_SECRET in the Mux dashboard\n  // https://dashboard.mux.com/settings/webhooks\n  const event = mux.webhooks.unwrap(\n    body,\n    request.headers,\n    process.env.MUX_WEBHOOK_SIGNING_SECRET\n  );\n\n  // you can also unwrap the payload yourself:\n  // const event = await request.json();\n  switch (event.type) {\n    case 'video.upload.asset_created':\n      // we might use this to know that an upload has been completed\n      // and we can save its assetId to our database\n      break;\n    case 'video.asset.ready':\n      // we might use this to know that a video has been encoded\n      // and we can save its playbackId to our database\n      break;\n    // there are many more Mux webhook events\n    // check them out at https://www.mux.com/docs/webhook-reference\n    default:\n      break;\n  }\n\n  return new Response(JSON.stringify({ message: 'ok' }), {\n    headers: {\n      'Content-Type': 'application/json',\n    },\n  });\n};\n```\n\n\nFinally, let's make a playback page. We retrieve the video metadata from our database, and play it by passing its playbackId to Mux Player.\n\nFirst, install the Astro version of Mux Player:\n\n\n```bash\nnpm install @mux/mux-player-astro\n```\n\n\nNow create your playback page using the native Astro  component:\n\n\n```astro filename=src/pages/playback/[playbackId].astro\n---\nimport Layout from '../../layouts/Layout.astro';\nimport MuxPlayer from \"@mux/mux-player-astro\";\n\nconst { playbackId } = Astro.params;\n---\n\n<Layout>\n  <MuxPlayer\n    playbackId={playbackId}\n    metadata={{video_title: 'My Video'}}\n  />\n</Layout>\n```\n\n\nAnd we've got upload and playback. Nice!\n\nRetrieving asset data with the Mux Node SDK\n\nYou can use the Mux Node SDK to retrieve information about your videos and pass that data to your Astro components. This is useful for displaying video metadata like title, duration, and upload date.\n\n\n```bash\nnpm install @mux/mux-node\n```\n\n\nHere's an example of fetching video asset data and using it in your component:\n\n\n```astro filename=src/pages/video/[assetId].astro\n---\nimport Layout from '../../layouts/Layout.astro';\nimport Mux from \"@mux/mux-node\";\nimport MuxPlayer from \"@mux/mux-player-astro\";\n\nconst mux = new Mux({\n  tokenId: import.meta.env.MUX_TOKEN_ID,\n  tokenSecret: import.meta.env.MUX_TOKEN_SECRET,\n});\n\nconst { assetId } = Astro.params;\nconst asset = await mux.video.assets.retrieve(assetId);\n\nconst playbackId = asset.playback_ids?.find((id) => id.policy === \"public\")?.id;\nconst videoTitle = asset?.meta?.title;\nconst createdAt = Number(asset?.created_at);\nconst duration = Number(asset?.duration);\n\nconst date = new Date(createdAt * 1000).toDateString();\nconst time = new Date(Math.round(duration) * 1000).toISOString().substring(14, 19);\n---\n\n<Layout>\n  <h1>My Video Page</h1>\n  <p>Title: {videoTitle}</p>\n  <p>Upload Date: {date}</p>\n  <p>Length: {time}</p>\n\n  <MuxPlayer\n    playbackId={playbackId}\n    metadata={{video_title: videoTitle}}\n  />\n</Layout>\n```\n\n\nUsing Mux video element\n\nIf you prefer a simpler alternative to Mux Player that provides browser support for HLS playback with automatic Mux Data analytics, you can use the ` web component:\n\n\n```bash\nnpm install @mux/mux-video\n```\n\n\n\n```astro filename=src/components/SimpleVideoPlayer.astro\n<script>import '@mux/mux-video'</script>\n\n<mux-video\n  playback-id=\"FOTbeIxKeMPzyhrob722wytaTGI02Y3zbV00NeFQbTbK00\"\n  metadata-video-title=\"My Astro Video\"\n  controls\n  disable-tracking\n></mux-video>\n```\n\n\nEvent handling for uploads\n\nYou can listen for upload events and handle them with client-side scripts. Here's an example of handling upload events:\n\n\n```astro filename=src/pages/upload-with-events.astro\n---\nimport Layout from '../layouts/Layout.astro';\nimport Mux from \"@mux/mux-node\";\nimport MuxUploader from \"@mux/mux-uploader-astro\";\n\nconst mux = new Mux({\n  tokenId: import.meta.env.MUX_TOKEN_ID,\n  tokenSecret: import.meta.env.MUX_TOKEN_SECRET\n});\n\nconst upload = await mux.video.uploads.create({\n  new_asset_settings: {\n    playback_policy: ['public'],\n    video_quality: 'basic',\n  },\n  cors_origin: '*',\n});\n---\n\n<Layout title=\"Upload with Event Handling\">\n  <MuxUploader\n    id=\"my-uploader\"\n    endpoint={upload.url}\n    pausable\n    maxFileSize={50000}\n  />\n\n  <script>\n    import type { MuxUploaderElement } from '@mux/mux-uploader-astro';\n\n    const uploader = document.getElementById('my-uploader') as MuxUploaderElement;\n\n    uploader.addEventListener('uploadstart', (event) => {\n      console.log('Upload started!', event.detail);\n    });\n\n    uploader.addEventListener('success', (event) => {\n      console.log('Upload successful!', event.detail);\n    });\n\n    uploader.addEventListener('uploaderror', (event) => {\n      console.error('Upload error!', event.detail);\n    });\n\n    uploader.addEventListener('progress', (event) => {\n      console.log('Upload progress: ', event.detail);\n    });\n  </script>\n</Layout>\n```\n\n\nWhat's next? You can integrate with your CMS. You can optimize your loading experience. Or get started with the example project below:\n\nExample projects\n\n  <GuideCard\n    title=\"muxinc/examples/astro-uploader-and-player\"\n    description={<>\n      This is a bare-bones starter application with Astro that uses:\n\n        Mux Direct Uploads and Mux Uploader\n        Mux Video + Mux Data\n        Mux Player\n\n    }\n    links={[\n      {\n        title: \"View project →\",\n        href: \"https://github.com/muxinc/examples/tree/main/astro-uploader-and-player\",\n      },\n    ]}\n  />"
  },
  {
    "id": "158-_guides/frameworks/laravel",
    "title": "Add high-performance video to your Laravel application",
    "path": "_guides/frameworks/laravel.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/laravel",
    "content": "Laravel is one of the most popular PHP frameworks for building a website but doesn't have a built-in path for integrating video.\n\nMux is a video API for developers that makes it easy to upload and manage your library of video and audio content. We'll handle the video end-to-end for you from upload, encoding, generating thumbnails and captions, right through to playback and customising the player experience.\n\nHere we've outlined some techniques and libraries you can use to make integrating with Mux as smooth as possible.\n\nListening for webhooks\n\nEverything that happens to your videos on Mux triggers a webhook that notifies you of the change. This can include an asset being ready for playback, a live streaming connecting, an asset being deleted, and many others.\n\nRead our webhook guide for learning about how to get setup for handling webhooks generally.\n\nIn Laravel you would setup a route that looks like this:\n\n\n```php\n// routes/api.php\nuse App\\Http\\Controllers\\WebhookController;\n\nRoute::post('webhook/endpoint', [WebhookController::class, 'handle']);\n```\n\n\nWhich references this WebhookController:\n\n\n```php\n// app/Http/Controllers/WebhookController.php\nnamespace App\\Http\\Controllers;\n\nuse Illuminate\\Http\\Request;\n\nclass WebhookController extends Controller\n{\n    public function handle(Request $request)\n    {\n        // Process webhook payload here\n        // Save the asset ID and playback ID to your database\n        return response()->json(['success' => true]);\n    }\n}\n```\n\n\nThis controller will be in charge of storing references to your videos that have successfully been uploaded and processed. It will also be notified if an upload fails for any reason, you might want to store this state too so it can be shown to users if needed.\n\nYou should store at least the Asset ID and Playback ID in your database so that you can use them to embed the videos for playback in your page templates. You will use the Asset ID whenever you need to interact with the asset with the Mux API and you will need the Playback ID for playback on the front-end.\n\nUploading from the front-end with Direct Uploads\n\nDirect Uploads allow you to upload a video from the browser to your Mux account. To start, call the Mux API to generate an upload URL that is provided to the front-end.\n\nWe can use the Mux PHP library to make it easier to create these upload URLs:\n\n\n```php\n$createAssetRequest = new MuxPhp\\Models\\CreateAssetRequest([\"playback_policy\" => [MuxPhp\\Models\\PlaybackPolicy::_PUBLIC]]);\n$createUploadRequest = new MuxPhp\\Models\\CreateUploadRequest([\"new_asset_settings\" => $createAssetRequest]);\n$upload = $uploadsApi->createDirectUpload($createUploadRequest);\n\nprint \"Upload URL:\" $upload->getData()->getUrl();\n```\n\n\nYou'll want to add this script to one of your API routes, and return the upload URL instead of printing it.\nOn the front-end, you can use Mux Uploader, a web component that gives you a simple UI to make uploading a video easier.\nOn the front-end using Mux Uploader, you would use the Upload URL for the endpoint attribute:\n\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-uploader\"></script>\n\n<mux-uploader endpoint=\"{direct_upload_url}\"></mux-uploader>\n```\n\n\nVideo playback\n\nIf your webhook is already storing Playback IDs in your database, you can play back videos on the front-end using Mux Player. Your blade template for this might look like:\n\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-player\" defer></script>\n\n<!-- The `metadata-` attributes are optional  -->\n<mux-player\n  playback-id=\"{{ $playbackId }}\"\n  metadata-video-title=\"{{ $title }}\"\n  metadata-viewer-user-id=\"{{ $userId }}\"\n></mux-player>\n```\n\n\nMux Player comes with lots of features and customisability out of the box.\n\nThe controller for this page might look something like this:\n\n\n```php\n<?php\nnamespace App\\Http\\Controllers;\n\nuse Illuminate\\Http\\Request;\n\nclass PlaybackController extends Controller\n{\n    public function show($videoId)\n    {\n        // Fetch the video from the database and set\n        // $playbackId\n        // $title\n\n        // Get user (replace with your actual authentication logic)\n        $userId = auth()->id();\n\n        return view('playback', [\n            'playbackId' => $playbackId,\n            'title' => $title,\n            'userId' => $userId,\n        ]);\n    }\n}\n```\n\n\nCommunity contributions and libraries\n\nmux-php-laravel\n\nmux-php-laravel is a library that will help you setup defaults for working with Mux easier in your Laravel project.\n\nStatamic Mux\n\nStatamic is a popular CMS built on top of Laravel. There is a community Mux integration for making it easier to get your videos into Mux using the CMS."
  },
  {
    "id": "159-_guides/frameworks/next-js",
    "title": "Add high-performance video to your Next.js application",
    "path": "_guides/frameworks/next-js.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/next-js",
    "content": "Mux is available as a native integration through the Vercel Marketplace. Visit the Vercel documentation for specific guidance related to getting up and running with Mux on Vercel.\n\nWhen should you use Mux with Next.js?\nWhen adding video to your Next.js app, you'll encounter some common hurdles. First, videos are large. Storing them in your public directory can lead to excessive bandwidth consumption and poor Git repository performance. Next, it's important to compress and optimize your videos for the web. Then, as network conditions change, you might want to adapt the quality of your video to ensure a smooth playback experience for your users. Finally, you may want to integrate additional features like captions, thumbnails, and analytics.\n\nYou might consider using Mux's APIs and components to handle these challenges, and more.\n\nQuickly drop in a video with next-video\n\nnext-video is a React component, maintained by Mux, for adding video to your Next.js application. It extends both the ` element and your Next app with features to simplify video uploading, storage, and playback.\n\nTo get started...\n1. Run the install script: npx -y next-video init. This will install the next-video package, update your next.config.js and TypeScript configuration, and create a /videos folder in your project.\n2. Add a video to your /videos folder. Mux will upload, store, and optimize it for you.\n3. Add the component to your app:\n\n```jsx\nimport Video from 'next-video';\nimport myVideo from '/videos/my-video.mp4';\n\nexport default function Page() {\n return <Video src={myVideo} />;\n}\n```\n\n\nCheck out the next-video docs to learn more.\n\nUse the API and our components for full control\n\nIf you're looking to build your own video workflow that enables uploading, playback, and more in your application, you can use the Mux API and components like Mux Player and Mux Uploader.\n\nExample: allowing users to upload video to your app\nOne reason you might want to build your own video workflow is when you want to allow users to upload video to your app.\n\nLet's start by adding a new page where users can upload videos. This will involve using the Mux Uploader component, which will upload videos to a Mux Direct Uploads URL.\n\nIn the code sample below, we'll create an upload URL using the Mux Node SDK and the Direct Uploads URL API. We'll pass that URL to the Mux Uploader component, which will handle uploading for us.\n\nIn production, you'll want to apply additional security measures to your upload URL. Consider protecting the route with authentication to prevent unauthorized users from uploading videos. Also, use cors_origin and consider playback_policy to further restrict where uploads can be performed and who can view uploaded videos.\n\nNext, we'll create an API endpoint that will listen for Mux webhooks. When we receive the notification that the video has finished uploading and is ready for playback, we'll add the video's metadata to our database.\n\nFinally, let's make a playback page. We retrieve the video metadata from our database, and play it by passing its playbackId` to Mux Player:\n\nAnd we've got upload and playback. Nice!\n\nWhat's next? You can integrate with your CMS. You can optimize your loading experience. Or get started with an example project below:\n\nExample projects\n\n  <GuideCard\n    title=\"Video Course Starter Kit\"\n    description={If you’re a developer you’ve probably seen and used platforms like Egghead, LevelUp Tutorials, Coursera, etc. This is your starter kit to build something like that with Next.js + Mux. Complete with Github OAuth, the ability to create courses, adding video lessons, progress tracking for viewers.}\n    links={[\n      {\n        title: \"View project →\",\n        href: \"https://github.com/muxinc/video-course-starter-kit\",\n      },\n    ]}\n  />\n  <GuideCard\n    title=\"with-mux-video\"\n    description={<>\n      This is a bare-bones starter application with Next.js that uses:\n\n        Mux Direct Uploads\n        Mux Video + Mux Data\n        Mux Player\n\n    }\n    links={[\n      {\n        title: \"View project →\",\n        href: \"https://github.com/vercel/next.js/tree/931eee87be8af86bd95336deade5870ad5e04669/examples/with-mux-video\",\n      },\n    ]}\n  />\n  <GuideCard\n    title=\"stream.new\"\n    description={<>\n      Stream.new is an open source Next.js application that does:\n\n        Mux Direct Uploads\n        Content Moderation with Google Vision or Hive.ai (Read more)\n\n    }\n    links={[\n      {\n        title: \"View project →\",\n        href: \"https://github.com/muxinc/stream.new\",\n      },\n    ]}\n  />"
  },
  {
    "id": "160-_guides/frameworks/react-native-api-reference",
    "title": "API Reference for React Native",
    "path": "_guides/frameworks/react-native-api-reference.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-api-reference",
    "content": "API Reference for React Native\n\nThis guide covers the most common Mux API operations you'll use when building a React Native app. For complete API documentation, see the Video API Reference.\n\nNever call Mux APIs directly from React Native. All API calls must go through your backend server. Never expose Mux API credentials in client-side code.\n\nCommon Architecture Pattern\n\n\n```\nReact Native App ←→ Your Backend ←→ Mux API\n```\n\n\nYour backend acts as a proxy, handling authentication and making secure Mux API calls. React Native sends requests to your backend, which then communicates with Mux.\n\nAsset Management\n\nCreate Asset from URL\n\nWhen to use: Ingesting AI-generated videos or content from external URLs (like Slop Social's AI workflow).\n\nReact Native perspective: Your app triggers the backend to ingest a video URL, then listens for webhook/realtime updates when ready.\n\n\n```javascript\n// Backend code (Node.js with Mux SDK)\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux({\n  tokenId: process.env.MUX_TOKEN_ID,\n  tokenSecret: process.env.MUX_TOKEN_SECRET,\n});\n\n// Backend endpoint\napp.post('/api/ingest-video', async (req, res) => {\n  const { videoUrl, userId } = req.body;\n\n  const asset = await mux.video.assets.create({\n    input: [{ url: videoUrl }],\n    playback_policy: ['public'], // or ['signed'] for private\n    mp4_support: 'standard', // optional: enable MP4 downloads\n  });\n\n  // Save to database\n  await db.videos.create({\n    userId,\n    muxAssetId: asset.id,\n    status: 'preparing',\n  });\n\n  res.json({ assetId: asset.id });\n});\n```\n\n\n\n```tsx\n// React Native code\nconst ingestAIVideo = async (videoUrl: string) => {\n  const response = await fetch('https://your-api.com/api/ingest-video', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({ videoUrl }),\n  });\n\n  const { assetId } = await response.json();\n  return assetId;\n};\n```\n\n\nAPI Reference: Create Asset\n\n---\n\nCreate Direct Upload URL\n\nWhen to use: User is uploading a video from their device (camera or library).\n\nReact Native perspective: Request upload URL from backend, then upload file directly to Mux from device.\n\n\n```javascript\n// Backend code\napp.post('/api/generate-upload-url', async (req, res) => {\n  const { userId } = req.body;\n\n  const upload = await mux.video.uploads.create({\n    cors_origin: '*', // Set to your app's origin in production\n    new_asset_settings: {\n      playback_policy: ['public'],\n    },\n  });\n\n  // Save upload ID to associate with user\n  await db.uploads.create({\n    userId,\n    muxUploadId: upload.id,\n    uploadUrl: upload.url,\n  });\n\n  res.json({\n    uploadUrl: upload.url,\n    uploadId: upload.id,\n  });\n});\n```\n\n\n\n```tsx\n// React Native code\nimport * as FileSystem from 'expo-file-system';\n\nconst uploadVideo = async (videoUri: string) => {\n  // Step 1: Get upload URL\n  const response = await fetch('https://your-api.com/api/generate-upload-url', {\n    method: 'POST',\n  });\n  const { uploadUrl, uploadId } = await response.json();\n\n  // Step 2: Upload video\n  await FileSystem.uploadAsync(uploadUrl, videoUri, {\n    httpMethod: 'PUT',\n    uploadType: FileSystem.FileSystemUploadType.BINARY_CONTENT,\n  });\n\n  return uploadId;\n};\n```\n\n\nAPI Reference: Create Direct Upload\n\n---\n\nGet Asset Details\n\nWhen to use: Checking asset status, getting playback IDs, or retrieving video metadata.\n\nReact Native perspective: Backend polls asset status or responds to webhook, then updates database. React Native reads from database or backend endpoint.\n\n\n```javascript\n// Backend code\napp.get('/api/asset/:assetId', async (req, res) => {\n  const { assetId } = req.params;\n\n  const asset = await mux.video.assets.retrieve(assetId);\n\n  res.json({\n    id: asset.id,\n    status: asset.status, // 'preparing', 'ready', 'errored'\n    playbackIds: asset.playback_ids,\n    duration: asset.duration,\n    aspectRatio: asset.aspect_ratio,\n  });\n});\n```\n\n\n\n```tsx\n// React Native code\nconst getAssetStatus = async (assetId: string) => {\n  const response = await fetch(`https://your-api.com/api/asset/${assetId}`);\n  const asset = await response.json();\n\n  if (asset.status === 'ready') {\n    const playbackId = asset.playbackIds[0].id;\n    return playbackId;\n  }\n\n  return null;\n};\n```\n\n\nAPI Reference: Get Asset\n\n---\n\nDelete Asset\n\nWhen to use: User deletes their video or content moderation removes a video.\n\nReact Native perspective: App requests deletion from backend, backend calls Mux API.\n\n\n```javascript\n// Backend code\napp.delete('/api/asset/:assetId', async (req, res) => {\n  const { assetId } = req.params;\n  const { userId } = req.user; // From auth middleware\n\n  // Verify user owns this asset\n  const video = await db.videos.findOne({ muxAssetId: assetId, userId });\n  if (!video) {\n    return res.status(403).json({ error: 'Unauthorized' });\n  }\n\n  // Delete from Mux\n  await mux.video.assets.delete(assetId);\n\n  // Delete from database\n  await db.videos.delete({ muxAssetId: assetId });\n\n  res.json({ success: true });\n});\n```\n\n\n\n```tsx\n// React Native code\nconst deleteVideo = async (assetId: string) => {\n  await fetch(`https://your-api.com/api/asset/${assetId}`, {\n    method: 'DELETE',\n  });\n};\n```\n\n\nAPI Reference: Delete Asset\n\n---\n\nPlayback\n\nGet Playback URL\n\nWhen to use: Every time you need to play a video in React Native.\n\nReact Native perspective: Simple - just construct the URL from the playback ID.\n\n\n```tsx\n// React Native code - Public playback\nconst playbackId = 'EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs';\nconst playbackUrl = `https://stream.mux.com/${playbackId}.m3u8`;\n\n<Video source={{ uri: playbackUrl }} />\n```\n\n\nFor private videos, use signed playback IDs:\n\n\n```javascript\n// Backend code - Generate signed URL\nimport Mux from '@mux/mux-node';\n\napp.get('/api/video/:videoId/playback-url', async (req, res) => {\n  const { videoId } = req.params;\n  const { userId } = req.user;\n\n  const video = await db.videos.findOne({ id: videoId });\n\n  // Check if user has access\n  if (video.isPrivate && !userHasAccess(userId, videoId)) {\n    return res.status(403).json({ error: 'Unauthorized' });\n  }\n\n  const token = Mux.JWT.signPlaybackId(video.playbackId, {\n    keyId: process.env.MUX_SIGNING_KEY_ID,\n    keySecret: process.env.MUX_SIGNING_KEY_SECRET,\n    expiration: '7d',\n  });\n\n  const signedUrl = `https://stream.mux.com/${video.playbackId}.m3u8?token=${token}`;\n\n  res.json({ playbackUrl: signedUrl });\n});\n```\n\n\n\n```tsx\n// React Native code\nconst getPlaybackUrl = async (videoId: string) => {\n  const response = await fetch(`https://your-api.com/api/video/${videoId}/playback-url`);\n  const { playbackUrl } = await response.json();\n  return playbackUrl;\n};\n```\n\n\nAPI Reference: Playback IDs | Secure Playback Guide\n\n---\n\nGet Thumbnail URL\n\nWhen to use: Showing video thumbnails in feeds or before playback.\n\nReact Native perspective: Construct thumbnail URL directly - no API call needed.\n\n\n```tsx\n// React Native code\nconst playbackId = 'EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs';\n\n// Basic thumbnail\nconst thumbnailUrl = `https://image.mux.com/${playbackId}/thumbnail.jpg`;\n\n// With options\nconst thumbnailWithOptions = `https://image.mux.com/${playbackId}/thumbnail.jpg?width=640&height=360&time=5`;\n\n<Image source={{ uri: thumbnailUrl }} />\n```\n\n\nParameters:\n- width - Thumbnail width (default: 640)\n- height - Thumbnail height (default: 360)\n- time - Time offset in seconds (default: 0)\n- fit_mode - How to fit image: smartcrop, preserve, crop\n\nAPI Reference: Thumbnail API Guide\n\n---\n\nAnalytics (Mux Data)\n\nGet View Count\n\nWhen to use: Displaying view counts in video feeds.\n\nReact Native perspective: Backend fetches from Mux Data API, React Native displays the count.\n\n\n```javascript\n// Backend code\nimport Mux from '@mux/mux-node';\n\napp.get('/api/video/:videoId/views', async (req, res) => {\n  const { videoId } = req.params;\n\n  const response = await mux.data.metrics.breakdown('views', {\n    filters: [`video_id:${videoId}`],\n    timeframe: ['30:days'], // Last 30 days\n  });\n\n  const viewCount = response.total_row_count || 0;\n\n  res.json({ views: viewCount });\n});\n```\n\n\n\n```tsx\n// React Native code\nconst useViewCount = (videoId: string) => {\n  const [views, setViews] = useState(0);\n\n  useEffect(() => {\n    fetch(`https://your-api.com/api/video/${videoId}/views`)\n      .then(r => r.json())\n      .then(data => setViews(data.views));\n  }, [videoId]);\n\n  return views;\n};\n\n// Usage\nfunction VideoCard({ video }: Props) {\n  const views = useViewCount(video.id);\n\n  return (\n    <View>\n      <Video source={{ uri: video.playbackUrl }} />\n      <Text>{views.toLocaleString()} views</Text>\n    </View>\n  );\n}\n```\n\n\nAPI Reference: Data API Reference\n\n---\n\nGet Real-time Viewers\n\nWhen to use: Showing \"X people watching now\" for live or popular videos.\n\nReact Native perspective: Backend generates signed viewer count token, React Native polls for updates.\n\n\n```javascript\n// Backend code\napp.get('/api/video/:playbackId/live-viewers', async (req, res) => {\n  const { playbackId } = req.params;\n\n  const token = Mux.JWT.signViewerCounts(playbackId, {\n    keyId: process.env.MUX_SIGNING_KEY_ID,\n    keySecret: process.env.MUX_SIGNING_KEY_SECRET,\n    type: 'video',\n  });\n\n  const statsResponse = await fetch(`https://stats.mux.com/counts?token=${token}`);\n  const data = await statsResponse.json();\n\n  res.json({ liveViewers: data.current_viewers || 0 });\n});\n```\n\n\n\n```tsx\n// React Native code\nconst useLiveViewers = (playbackId: string) => {\n  const [viewers, setViewers] = useState(0);\n\n  useEffect(() => {\n    const fetchViewers = async () => {\n      const response = await fetch(`https://your-api.com/api/video/${playbackId}/live-viewers`);\n      const { liveViewers } = await response.json();\n      setViewers(liveViewers);\n    };\n\n    fetchViewers();\n    const interval = setInterval(fetchViewers, 10000); // Every 10 seconds\n\n    return () => clearInterval(interval);\n  }, [playbackId]);\n\n  return viewers;\n};\n```\n\n\nAPI Reference: Real-time Viewer Counts\n\n---\n\nWebhooks\n\nHandling Webhooks\n\nWhen to use: Get notified when assets are ready, errored, or other events occur.\n\nReact Native perspective: Backend receives webhooks, updates database. React Native listens to database changes (Supabase Realtime, Firebase, etc.).\n\n\n```javascript\n// Backend webhook handler\nimport Mux from '@mux/mux-node';\n\napp.post('/webhooks/mux', async (req, res) => {\n  const signature = req.headers['mux-signature'];\n\n  // Verify webhook signature\n  try {\n    Mux.Webhooks.verifyHeader(\n      JSON.stringify(req.body),\n      signature,\n      process.env.MUX_WEBHOOK_SECRET\n    );\n  } catch (error) {\n    return res.status(400).send('Invalid signature');\n  }\n\n  const event = req.body;\n\n  // Handle different event types\n  if (event.type === 'video.asset.ready') {\n    const asset = event.data;\n\n    await db.videos.update({\n      where: { muxAssetId: asset.id },\n      data: {\n        status: 'ready',\n        playbackId: asset.playback_ids[0].id,\n        duration: asset.duration,\n      },\n    });\n  }\n\n  if (event.type === 'video.asset.errored') {\n    const asset = event.data;\n\n    await db.videos.update({\n      where: { muxAssetId: asset.id },\n      data: {\n        status: 'errored',\n        error: asset.errors?.messages?.[0] || 'Unknown error',\n      },\n    });\n  }\n\n  res.sendStatus(200);\n});\n```\n\n\n\n```tsx\n// React Native code - Listen to database changes\nimport { supabase } from './supabase';\n\nuseEffect(() => {\n  const subscription = supabase\n    .channel(`video-${videoId}`)\n    .on('postgres_changes', {\n      event: 'UPDATE',\n      schema: 'public',\n      table: 'videos',\n      filter: `id=eq.${videoId}`,\n    }, (payload) => {\n      if (payload.new.status === 'ready') {\n        setVideo(payload.new);\n        setIsReady(true);\n      }\n    })\n    .subscribe();\n\n  return () => subscription.unsubscribe();\n}, [videoId]);\n```\n\n\nAPI Reference: Webhooks Guide\n\nCommon webhook events:\n- video.asset.ready - Asset is ready for playback\n- video.asset.errored - Asset processing failed\n- video.asset.created - New asset created\n- video.asset.deleted - Asset deleted\n- video.upload.asset_created - Direct upload completed\n- video.upload.cancelled - Direct upload cancelled\n- video.upload.errored - Direct upload failed\n\n---\n\nSDKs and Packages\n\nBackend SDKs\n\nMux Node SDK (Recommended for most backends)\n\n```bash\nnpm install @mux/mux-node\n```\n\n\n\n```javascript\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux({\n  tokenId: process.env.MUX_TOKEN_ID,\n  tokenSecret: process.env.MUX_TOKEN_SECRET,\n});\n```\n\n\nOther backend SDKs:\n- Python SDK\n- Ruby SDK\n- Go SDK\n- PHP SDK\n\nReact Native Packages\n\nreact-native-video (Video playback)\n\n```bash\nnpm install react-native-video\n```\n\n\n@mux/mux-data-react-native-video (Analytics)\n\n```bash\nnpm install @mux/mux-data-react-native-video\n```\n\n\n@react-native-community/netinfo (Network detection)\n\n```bash\nnpm install @react-native-community/netinfo\n```\n\n\nexpo-file-system (File uploads for Expo)\n\n```bash\nnpx expo install expo-file-system\n```\n\n\n---\n\nAuthentication & Security\n\nAPI Token Management\n\nNever put Mux credentials in React Native code. API tokens must remain on your backend server.\n\n\n```javascript\n// ✅ CORRECT - Backend only\nconst mux = new Mux({\n  tokenId: process.env.MUX_TOKEN_ID, // Server environment variable\n  tokenSecret: process.env.MUX_TOKEN_SECRET,\n});\n\n// ❌ WRONG - Never in React Native\nconst MUX_TOKEN_ID = 'abc123'; // DON'T DO THIS\n```\n\n\nSigning Keys for Playback\n\nFor private videos, use JWT signing:\n\n\n```javascript\n// Backend - Generate signed URL\nconst token = Mux.JWT.signPlaybackId(playbackId, {\n  keyId: process.env.MUX_SIGNING_KEY_ID,\n  keySecret: process.env.MUX_SIGNING_KEY_SECRET,\n  expiration: '7d',\n});\n```\n\n\nLearn more: Secure Video Playback\n\n---\n\nRate Limits\n\nMux API has rate limits:\n- General API: 100 requests per second per account\n- Data API: Different limits based on endpoint\n\nIf you hit rate limits, implement backoff logic:\n\n\n```javascript\n// Backend - Retry with exponential backoff\nasync function muxApiCallWithRetry(apiCall, maxRetries = 3) {\n  for (let i = 0; i < maxRetries; i++) {\n    try {\n      return await apiCall();\n    } catch (error) {\n      if (error.status === 429 && i < maxRetries - 1) {\n        const delay = Math.pow(2, i) * 1000; // 1s, 2s, 4s\n        await new Promise(resolve => setTimeout(resolve, delay));\n      } else {\n        throw error;\n      }\n    }\n  }\n}\n```\n\n\n---\n\nNext Steps\n\n  <GuideCard\n    title=\"Video API Reference\"\n    description=\"Complete API documentation for all Mux Video endpoints\"\n    links={[\n      {title: \"View API docs\", href: \"/docs/api-reference/video\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Data API Reference\"\n    description=\"Complete API documentation for Mux Data analytics\"\n    links={[\n      {title: \"View API docs\", href: \"/docs/api-reference/data\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Troubleshooting\"\n    description=\"Common issues and solutions for React Native + Mux\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/troubleshooting\"},\n    ]}\n  />"
  },
  {
    "id": "161-_guides/frameworks/react-native-async-processing",
    "title": "Handle async video processing",
    "path": "_guides/frameworks/react-native-async-processing.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-async-processing",
    "content": "Video processing is asynchronous - whether you're uploading from a device or ingesting from a URL, there's always a delay while Mux processes the video. This guide shows you how to handle this gracefully in React Native.\n\nWhy video processing is async\n\nAfter you upload a video or create an asset from a URL, Mux needs time to:\n\n1. Download the video (if from URL)\n2. Transcode it into multiple formats and qualities\n3. Generate thumbnails and storyboards\n4. Prepare it for adaptive bitrate streaming\n\nThis can take anywhere from a few seconds (short videos) to several minutes (long, high-resolution videos).\n\nAsset states\n\nMux assets go through several states:\n\n| State | Meaning | Action |\n|-------|---------|--------|\n| preparing | Video is being processed | Show loading UI |\n| ready | Video is ready to play | Display video player |\n| errored | Processing failed | Show error message |\n\nThere are other intermediate states, but these are the main ones you'll need to handle in your app.\n\nGetting notified when videos are ready\n\nYour backend receives webhook notifications from Mux when asset states change. Your React Native app then needs to know about these changes. There are three main patterns:\n\nPattern comparison\n\n| Pattern | Best For | Pros | Cons |\n|---------|----------|------|------|\n| Realtime Database | Production apps | Instant updates, efficient | Requires realtime infrastructure |\n| Polling | Simple apps, prototypes | Easy to implement | Server load, delayed updates |\n| Push Notifications | Long processes (>60s) | Works when app backgrounded | Requires notification permissions |\n\n---\n\nPattern 1: Realtime database (recommended)\n\nThe best approach for production apps is to use a realtime database like Supabase or Firebase. Your backend updates the database via webhooks, and React Native subscribes to changes.\n\nArchitecture\n\n\n```\nMux → Webhook → Your Backend → Database\n                                   ↓\n                              Realtime Update\n                                   ↓\n                           React Native App\n```\n\n\nBackend: Handle Mux webhook\n\nSee the uploading videos guide for the complete webhook handler. Here's the key part:\n\n\n```javascript\n// Backend: Webhook handler\nexport async function handleMuxWebhook(req, res) {\n  // Verify signature (see main docs)\n  const event = req.body;\n\n  if (event.type === 'video.asset.ready') {\n    const { id, playback_ids, duration } = event.data;\n\n    // Update your database\n    await db.videos.update({\n      where: { muxAssetId: id },\n      data: {\n        status: 'ready',\n        playbackId: playback_ids[0].id,\n        duration,\n        updatedAt: new Date(),\n      },\n    });\n    // Database realtime will notify subscribed clients automatically\n  }\n\n  res.json({ received: true });\n}\n```\n\n\nReact Native: Subscribe to changes (Supabase)\n\n\n```tsx\nimport React, { useEffect, useState } from 'react';\nimport { View, Text, ActivityIndicator, StyleSheet, Image } from 'react-native';\nimport { supabase } from './lib/supabase';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\ninterface Video {\n  id: string;\n  status: 'processing' | 'ready' | 'failed';\n  playbackId: string | null;\n  duration: number | null;\n}\n\ninterface VideoStatusProps {\n  videoId: string;\n}\n\nexport default function VideoStatus({ videoId }: VideoStatusProps) {\n  const [video, setVideo] = useState<Video | null>(null);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    // Fetch initial video state\n    const fetchVideo = async () => {\n      const { data, error } = await supabase\n        .from('videos')\n        .select('*')\n        .eq('id', videoId)\n        .single();\n\n      if (data) {\n        setVideo(data);\n        setLoading(false);\n      }\n    };\n\n    fetchVideo();\n\n    // Subscribe to realtime updates\n    const subscription = supabase\n      .channel(`video-${videoId}`)\n      .on(\n        'postgres_changes',\n        {\n          event: 'UPDATE',\n          schema: 'public',\n          table: 'videos',\n          filter: `id=eq.${videoId}`,\n        },\n        (payload) => {\n          console.log('Video updated:', payload.new);\n          setVideo(payload.new as Video);\n        }\n      )\n      .subscribe();\n\n    return () => {\n      subscription.unsubscribe();\n    };\n  }, [videoId]);\n\n  if (loading) {\n    return (\n      <View style={styles.container}>\n        <ActivityIndicator size=\"large\" />\n      </View>\n    );\n  }\n\n  if (video?.status === 'failed') {\n    return (\n      <View style={styles.container}>\n        <Text style={styles.errorText}>\n          Video processing failed. Please try again.\n        </Text>\n      </View>\n    );\n  }\n\n  if (video?.status === 'processing' || !video?.playbackId) {\n    return (\n      <View style={styles.container}>\n        <ActivityIndicator size=\"large\" color=\"#007AFF\" />\n        <Text style={styles.statusText}>Processing your video...</Text>\n        <Text style={styles.subText}>This usually takes 30-60 seconds</Text>\n      </View>\n    );\n  }\n\n  return <VideoPlayer playbackId={video.playbackId} />;\n}\n\nfunction VideoPlayer({ playbackId }: { playbackId: string }) {\n  const [showPoster, setShowPoster] = useState(true);\n  const posterUrl = `https://image.mux.com/${playbackId}/thumbnail.png?time=0`;\n\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.play();\n    }\n  );\n\n  return (\n    <View style={styles.videoContainer}>\n      <VideoView\n        player={player}\n        style={styles.video}\n        nativeControls\n        contentFit=\"contain\"\n        onFirstFrameRender={() => setShowPoster(false)}\n      />\n      {showPoster && (\n        <Image\n          source={{ uri: posterUrl }}\n          style={[styles.video, styles.poster]}\n          resizeMode=\"cover\"\n        />\n      )}\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n    justifyContent: 'center',\n    alignItems: 'center',\n    padding: 20,\n  },\n  videoContainer: {\n    position: 'relative',\n    width: '100%',\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  poster: {\n    position: 'absolute',\n    top: 0,\n    left: 0,\n  },\n  statusText: {\n    fontSize: 16,\n    marginTop: 15,\n    color: '#333',\n  },\n  subText: {\n    fontSize: 14,\n    marginTop: 5,\n    color: '#666',\n  },\n  errorText: {\n    fontSize: 16,\n    color: '#ff0000',\n    textAlign: 'center',\n  },\n});\n```\n\n\nReact Native: Subscribe to changes (Firebase)\n\n\n```tsx\nimport React, { useEffect, useState } from 'react';\nimport { View, ActivityIndicator, StyleSheet } from 'react-native';\nimport firestore from '@react-native-firebase/firestore';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nexport default function VideoStatus({ videoId }: { videoId: string }) {\n  const [status, setStatus] = useState<'processing' | 'ready' | 'failed'>('processing');\n  const [playbackId, setPlaybackId] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Subscribe to Firestore document changes\n    const unsubscribe = firestore()\n      .collection('videos')\n      .doc(videoId)\n      .onSnapshot((documentSnapshot) => {\n        const data = documentSnapshot.data();\n        if (data) {\n          setStatus(data.status);\n          if (data.status === 'ready') {\n            setPlaybackId(data.playbackId);\n          }\n        }\n      });\n\n    return () => unsubscribe();\n  }, [videoId]);\n\n  if (status === 'processing' || !playbackId) {\n    return <ActivityIndicator size=\"large\" />;\n  }\n\n  return <VideoPlayer playbackId={playbackId} />;\n}\n\nfunction VideoPlayer({ playbackId }: { playbackId: string }) {\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.play();\n    }\n  );\n\n  return (\n    <VideoView\n      player={player}\n      style={styles.video}\n      nativeControls\n    />\n  );\n}\n\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n});\n```\n\n\n  Setup required: Both Supabase and Firebase require configuration. See Supabase Realtime docs or Firebase Firestore docs for setup instructions.\n\n---\n\nPattern 2: Polling from React Native\n\nIf you don't have realtime infrastructure, you can poll your backend for status updates. This is simpler but less efficient.\n\n  Polling creates unnecessary server load and provides slower updates compared to realtime databases. Use this only for prototypes or simple apps.\n\n\n```tsx\nimport React, { useEffect, useState, useRef } from 'react';\nimport { View, Text, ActivityIndicator, StyleSheet } from 'react-native';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\ninterface VideoPollerProps {\n  videoId: string;\n  pollInterval?: number; // milliseconds\n}\n\nexport default function VideoPoller({\n  videoId,\n  pollInterval = 3000, // Poll every 3 seconds\n}: VideoPollerProps) {\n  const [status, setStatus] = useState<'processing' | 'ready' | 'failed'>('processing');\n  const [playbackId, setPlaybackId] = useState<string | null>(null);\n  const [attempts, setAttempts] = useState(0);\n  const maxAttempts = 60; // Stop after 3 minutes (60 * 3s)\n  const intervalRef = useRef<NodeJS.Timeout | null>(null);\n\n  useEffect(() => {\n    const checkVideoStatus = async () => {\n      try {\n        const response = await fetch(\n          `https://your-api.com/videos/${videoId}/status`\n        );\n        const data = await response.json();\n\n        if (data.status === 'ready') {\n          setStatus('ready');\n          setPlaybackId(data.playbackId);\n          // Stop polling\n          if (intervalRef.current) {\n            clearInterval(intervalRef.current);\n          }\n        } else if (data.status === 'failed') {\n          setStatus('failed');\n          if (intervalRef.current) {\n            clearInterval(intervalRef.current);\n          }\n        } else {\n          setAttempts((prev) => prev + 1);\n        }\n      } catch (error) {\n        console.error('Failed to check video status:', error);\n      }\n    };\n\n    // Initial check\n    checkVideoStatus();\n\n    // Start polling\n    intervalRef.current = setInterval(() => {\n      if (attempts >= maxAttempts) {\n        // Timeout - stop polling\n        if (intervalRef.current) {\n          clearInterval(intervalRef.current);\n        }\n        setStatus('failed');\n      } else {\n        checkVideoStatus();\n      }\n    }, pollInterval);\n\n    return () => {\n      if (intervalRef.current) {\n        clearInterval(intervalRef.current);\n      }\n    };\n  }, [videoId, attempts, pollInterval, maxAttempts]);\n\n  if (status === 'failed') {\n    return (\n      <View style={styles.container}>\n        <Text style={styles.errorText}>\n          Video processing failed or timed out.\n        </Text>\n      </View>\n    );\n  }\n\n  if (status === 'processing' || !playbackId) {\n    return (\n      <View style={styles.container}>\n        <ActivityIndicator size=\"large\" color=\"#007AFF\" />\n        <Text style={styles.statusText}>\n          Processing... ({Math.floor((attempts * pollInterval) / 1000)}s)\n        </Text>\n      </View>\n    );\n  }\n\n  return <VideoPlayer playbackId={playbackId} />;\n}\n\nfunction VideoPlayer({ playbackId }: { playbackId: string }) {\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.play();\n    }\n  );\n\n  return (\n    <VideoView\n      player={player}\n      style={styles.video}\n      nativeControls\n    />\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n    justifyContent: 'center',\n    alignItems: 'center',\n    padding: 20,\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  statusText: {\n    fontSize: 16,\n    marginTop: 10,\n    color: '#666',\n  },\n  errorText: {\n    fontSize: 16,\n    color: '#ff0000',\n    textAlign: 'center',\n  },\n});\n```\n\n\nPolling best practices\n\n1. Set a maximum number of attempts - Don't poll forever\n2. Use reasonable intervals - 3-5 seconds is typical\n3. Stop polling when done - Clean up intervals on unmount\n4. Handle errors gracefully - Network issues happen\n5. Show elapsed time - Help users understand progress\n\n---\n\nPattern 3: Push notifications\n\nFor longer processing times (AI video generation can take 30-120 seconds), push notifications ensure users are notified even if they navigate away or background the app.\n\nSetup Expo Notifications\n\n\n```bash\nnpx expo install expo-notifications expo-device expo-constants\n```\n\n\nRequest notification permissions\n\n\n```tsx\nimport * as Notifications from 'expo-notifications';\nimport * as Device from 'expo-device';\nimport { Platform } from 'react-native';\n\nasync function registerForPushNotificationsAsync() {\n  let token;\n\n  if (Platform.OS === 'android') {\n    await Notifications.setNotificationChannelAsync('default', {\n      name: 'default',\n      importance: Notifications.AndroidImportance.MAX,\n    });\n  }\n\n  if (Device.isDevice) {\n    const { status: existingStatus } = await Notifications.getPermissionsAsync();\n    let finalStatus = existingStatus;\n\n    if (existingStatus !== 'granted') {\n      const { status } = await Notifications.requestPermissionsAsync();\n      finalStatus = status;\n    }\n\n    if (finalStatus !== 'granted') {\n      alert('Failed to get push token for push notification!');\n      return;\n    }\n\n    token = (await Notifications.getExpoPushTokenAsync()).data;\n  }\n\n  return token;\n}\n```\n\n\nSend notification when video is ready (backend)\n\n\n```javascript\n// Backend: After video is ready\nasync function notifyUserVideoReady(userId, videoId, playbackId) {\n  // Get user's push token from your database\n  const user = await db.users.findUnique({ where: { id: userId } });\n\n  if (user.pushToken) {\n    await fetch('https://exp.host/--/api/v2/push/send', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        to: user.pushToken,\n        title: 'Your video is ready! 🎉',\n        body: 'Tap to watch your AI-generated video',\n        data: { videoId, playbackId },\n      }),\n    });\n  }\n}\n```\n\n\nHandle notification tap (React Native)\n\n\n```tsx\nimport { useEffect, useRef } from 'react';\nimport { useNavigation } from '@react-navigation/native';\nimport * as Notifications from 'expo-notifications';\n\nexport function useNotificationHandler() {\n  const navigation = useNavigation();\n  const notificationListener = useRef<any>();\n  const responseListener = useRef<any>();\n\n  useEffect(() => {\n    // Handle notification when app is foregrounded\n    notificationListener.current = Notifications.addNotificationReceivedListener(\n      (notification) => {\n        console.log('Notification received:', notification);\n      }\n    );\n\n    // Handle notification tap\n    responseListener.current = Notifications.addNotificationResponseReceivedListener(\n      (response) => {\n        const { videoId } = response.notification.request.content.data;\n\n        // Navigate to video screen\n        navigation.navigate('Video', { videoId });\n      }\n    );\n\n    return () => {\n      Notifications.removeNotificationSubscription(notificationListener.current);\n      Notifications.removeNotificationSubscription(responseListener.current);\n    };\n  }, [navigation]);\n}\n```\n\n\n  Push notifications require additional setup including APNs (iOS) and FCM (Android) configuration. See Expo Notifications docs for details.\n\n---\n\nUI patterns for processing states\n\nLoading with progress indicator\n\n\n```tsx\nimport React, { useState, useEffect } from 'react';\nimport { View, Text, ActivityIndicator, StyleSheet } from 'react-native';\nimport { LinearGradient } from 'expo-linear-gradient';\n\nexport function ProcessingIndicator({ estimatedTime = 60 }: { estimatedTime?: number }) {\n  const [elapsedTime, setElapsedTime] = useState(0);\n\n  useEffect(() => {\n    const interval = setInterval(() => {\n      setElapsedTime((prev) => prev + 1);\n    }, 1000);\n\n    return () => clearInterval(interval);\n  }, []);\n\n  const progress = Math.min((elapsedTime / estimatedTime) * 100, 95);\n\n  return (\n    <View style={styles.container}>\n      <ActivityIndicator size=\"large\" color=\"#007AFF\" />\n      <Text style={styles.title}>Generating your video</Text>\n      <Text style={styles.subtitle}>This usually takes {estimatedTime}s</Text>\n\n      <View style={styles.progressBar}>\n        <View style={[styles.progressFill, { width: `${progress}%` }]} />\n      </View>\n\n      <Text style={styles.time}>{elapsedTime}s elapsed</Text>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    padding: 40,\n    alignItems: 'center',\n  },\n  title: {\n    fontSize: 18,\n    fontWeight: 'bold',\n    marginTop: 20,\n  },\n  subtitle: {\n    fontSize: 14,\n    color: '#666',\n    marginTop: 5,\n  },\n  progressBar: {\n    width: '100%',\n    height: 4,\n    backgroundColor: '#e0e0e0',\n    borderRadius: 2,\n    marginTop: 20,\n    overflow: 'hidden',\n  },\n  progressFill: {\n    height: '100%',\n    backgroundColor: '#007AFF',\n  },\n  time: {\n    fontSize: 12,\n    color: '#999',\n    marginTop: 10,\n  },\n});\n```\n\n\nSuccess animation\n\n\n```tsx\nimport React, { useEffect } from 'react';\nimport { View, Text, StyleSheet } from 'react-native';\nimport Animated, {\n  useSharedValue,\n  useAnimatedStyle,\n  withSpring,\n  withSequence,\n} from 'react-native-reanimated';\n\nexport function SuccessAnimation() {\n  const scale = useSharedValue(0);\n\n  useEffect(() => {\n    scale.value = withSequence(\n      withSpring(1.2, { damping: 2 }),\n      withSpring(1)\n    );\n  }, []);\n\n  const animatedStyle = useAnimatedStyle(() => ({\n    transform: [{ scale: scale.value }],\n  }));\n\n  return (\n    <View style={styles.container}>\n      <Animated.View style={[styles.checkmark, animatedStyle]}>\n        <Text style={styles.checkmarkText}>✓</Text>\n      </Animated.View>\n      <Text style={styles.text}>Video ready!</Text>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    alignItems: 'center',\n    padding: 20,\n  },\n  checkmark: {\n    width: 80,\n    height: 80,\n    borderRadius: 40,\n    backgroundColor: '#4CAF50',\n    justifyContent: 'center',\n    alignItems: 'center',\n  },\n  checkmarkText: {\n    fontSize: 48,\n    color: '#fff',\n  },\n  text: {\n    fontSize: 18,\n    fontWeight: 'bold',\n    marginTop: 15,\n  },\n});\n```\n\n\nError with retry\n\n\n```tsx\nimport React from 'react';\nimport { View, Text, TouchableOpacity, StyleSheet } from 'react-native';\n\ninterface ErrorStateProps {\n  message: string;\n  onRetry: () => void;\n}\n\nexport function ErrorState({ message, onRetry }: ErrorStateProps) {\n  return (\n    <View style={styles.container}>\n      <Text style={styles.icon}>⚠️</Text>\n      <Text style={styles.title}>Processing Failed</Text>\n      <Text style={styles.message}>{message}</Text>\n\n      <TouchableOpacity style={styles.button} onPress={onRetry}>\n        <Text style={styles.buttonText}>Try Again</Text>\n      </TouchableOpacity>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    padding: 40,\n    alignItems: 'center',\n  },\n  icon: {\n    fontSize: 48,\n  },\n  title: {\n    fontSize: 20,\n    fontWeight: 'bold',\n    marginTop: 10,\n  },\n  message: {\n    fontSize: 14,\n    color: '#666',\n    textAlign: 'center',\n    marginTop: 10,\n  },\n  button: {\n    backgroundColor: '#007AFF',\n    paddingHorizontal: 30,\n    paddingVertical: 12,\n    borderRadius: 8,\n    marginTop: 20,\n  },\n  buttonText: {\n    color: '#fff',\n    fontSize: 16,\n    fontWeight: 'bold',\n  },\n});\n```\n\n\nComplete workflow example\n\nPutting it all together - AI video generation with async handling:\n\n\n```tsx\nimport React, { useState, useEffect } from 'react';\nimport { View, TextInput, TouchableOpacity, Text, StyleSheet, Image } from 'react-native';\nimport { supabase } from './lib/supabase';\nimport { useVideoPlayer, VideoView } from 'expo-video';\nimport { ProcessingIndicator } from './ProcessingIndicator';\nimport { SuccessAnimation } from './SuccessAnimation';\nimport { ErrorState } from './ErrorState';\n\nexport default function AIVideoGenerator() {\n  const [prompt, setPrompt] = useState('');\n  const [videoId, setVideoId] = useState<string | null>(null);\n  const [status, setStatus] = useState<'idle' | 'generating' | 'processing' | 'ready' | 'failed'>('idle');\n  const [playbackId, setPlaybackId] = useState<string | null>(null);\n  const [error, setError] = useState<string | null>(null);\n\n  useEffect(() => {\n    if (!videoId) return;\n\n    // Subscribe to video status updates\n    const subscription = supabase\n      .channel(`video-${videoId}`)\n      .on(\n        'postgres_changes',\n        {\n          event: 'UPDATE',\n          schema: 'public',\n          table: 'videos',\n          filter: `id=eq.${videoId}`,\n        },\n        (payload) => {\n          const video = payload.new;\n          setStatus(video.status);\n\n          if (video.status === 'ready') {\n            setPlaybackId(video.playback_id);\n          } else if (video.status === 'failed') {\n            setError(video.error || 'Video generation failed');\n          }\n        }\n      )\n      .subscribe();\n\n    return () => {\n      subscription.unsubscribe();\n    };\n  }, [videoId]);\n\n  const generateVideo = async () => {\n    if (!prompt.trim()) return;\n\n    setStatus('generating');\n    setError(null);\n\n    try {\n      const response = await fetch('https://your-api.com/generate-video', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ prompt }),\n      });\n\n      const data = await response.json();\n      setVideoId(data.videoId);\n      setStatus('processing');\n    } catch (err) {\n      setStatus('failed');\n      setError('Failed to start video generation');\n    }\n  };\n\n  const reset = () => {\n    setPrompt('');\n    setVideoId(null);\n    setStatus('idle');\n    setPlaybackId(null);\n    setError(null);\n  };\n\n  if (status === 'ready' && playbackId) {\n    return (\n      <View style={styles.container}>\n        <SuccessAnimation />\n        <VideoPlayer playbackId={playbackId} />\n        <TouchableOpacity style={styles.button} onPress={reset}>\n          <Text style={styles.buttonText}>Generate Another</Text>\n        </TouchableOpacity>\n      </View>\n    );\n  }\n\n  if (status === 'failed') {\n    return (\n      <ErrorState\n        message={error || 'Something went wrong'}\n        onRetry={reset}\n      />\n    );\n  }\n\n  if (status === 'generating' || status === 'processing') {\n    return (\n      <View style={styles.container}>\n        <ProcessingIndicator estimatedTime={60} />\n      </View>\n    );\n  }\n\n  return (\n    <View style={styles.container}>\n      <Text style={styles.title}>Generate AI Video</Text>\n      <TextInput\n        style={styles.input}\n        placeholder=\"Describe your video...\"\n        value={prompt}\n        onChangeText={setPrompt}\n        multiline\n        numberOfLines={4}\n      />\n      <TouchableOpacity\n        style={[styles.button, !prompt.trim() && styles.buttonDisabled]}\n        onPress={generateVideo}\n        disabled={!prompt.trim()}\n      >\n        <Text style={styles.buttonText}>Generate</Text>\n      </TouchableOpacity>\n    </View>\n  );\n}\n\nfunction VideoPlayer({ playbackId }: { playbackId: string }) {\n  const [showPoster, setShowPoster] = useState(true);\n  const posterUrl = `https://image.mux.com/${playbackId}/thumbnail.png?time=0`;\n\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.play();\n    }\n  );\n\n  return (\n    <View style={styles.videoContainer}>\n      <VideoView\n        player={player}\n        style={styles.video}\n        nativeControls\n        contentFit=\"contain\"\n        onFirstFrameRender={() => setShowPoster(false)}\n      />\n      {showPoster && (\n        <Image\n          source={{ uri: posterUrl }}\n          style={[styles.video, styles.poster]}\n          resizeMode=\"cover\"\n        />\n      )}\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n    padding: 20,\n  },\n  title: {\n    fontSize: 24,\n    fontWeight: 'bold',\n    marginBottom: 20,\n  },\n  input: {\n    borderWidth: 1,\n    borderColor: '#ddd',\n    borderRadius: 8,\n    padding: 15,\n    fontSize: 16,\n    minHeight: 120,\n    textAlignVertical: 'top',\n  },\n  button: {\n    backgroundColor: '#007AFF',\n    padding: 15,\n    borderRadius: 8,\n    alignItems: 'center',\n    marginTop: 15,\n  },\n  buttonDisabled: {\n    backgroundColor: '#ccc',\n  },\n  buttonText: {\n    color: '#fff',\n    fontSize: 16,\n    fontWeight: 'bold',\n  },\n  videoContainer: {\n    position: 'relative',\n    width: '100%',\n    marginVertical: 20,\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  poster: {\n    position: 'absolute',\n    top: 0,\n    left: 0,\n  },\n});\n```\n\n\nBest practices\n\n1. Always clean up subscriptions - Prevent memory leaks\n2. Show meaningful progress - Elapsed time, estimated time remaining\n3. Handle edge cases - What if the user navigates away?\n4. Set timeouts - Don't wait forever (max 3-5 minutes)\n5. Provide feedback - Loading states, success animations, error messages\n6. Allow cancellation - Let users cancel long operations\n7. Test on slow networks - Video processing + slow network = long waits\n\n  For more details on webhook setup and verification, see the listen for webhooks guide in the main Mux documentation."
  },
  {
    "id": "162-_guides/frameworks/react-native-best-practices",
    "title": "Best Practices & Optimization",
    "path": "_guides/frameworks/react-native-best-practices.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-best-practices",
    "content": "Best Practices & Optimization\n\nThis guide covers production best practices for building high-quality video experiences with Mux in React Native. Follow these patterns to ensure your app is performant, secure, and accessible.\n\nPerformance Optimization\n\nVideo Preloading Strategies\n\nPreload the next video's metadata without downloading the entire video. HLS handles adaptive streaming automatically, so focus on reducing startup time.\n\n\n```tsx\nimport { useEffect, useRef } from 'react';\nimport Video from 'react-native-video';\n\nfunction PreloadManager({ videos, currentIndex }: Props) {\n  const nextVideoRef = useRef<Video>(null);\n\n  useEffect(() => {\n    // Preload next video by mounting a hidden Video component\n    // This initializes the HLS connection without auto-playing\n  }, [currentIndex]);\n\n  return (\n    <>\n      {/* Current video (visible) */}\n      <Video\n        source={{ uri: videos[currentIndex].playbackUrl }}\n        style={styles.video}\n      />\n\n      {/* Preload next video (hidden) */}\n      {currentIndex + 1 < videos.length && (\n        <Video\n          ref={nextVideoRef}\n          source={{ uri: videos[currentIndex + 1].playbackUrl }}\n          style={{ display: 'none' }}\n          paused={true}\n          playInBackground={false}\n        />\n      )}\n    </>\n  );\n}\n```\n\n\nDon't preload more than 1-2 videos at a time. The HLS protocol handles adaptive bitrate streaming automatically, so you don't need to download entire videos in advance.\n\nMemory Management in FlatLists\n\nProperly configure FlatList to avoid memory issues with video feeds:\n\n\n```tsx\nimport { FlatList, Dimensions } from 'react-native';\n\nconst SCREEN_HEIGHT = Dimensions.get('window').height;\n\n<FlatList\n  data={videos}\n  renderItem={({ item, index }) => (\n    <VideoItem\n      video={item}\n      isVisible={index === currentIndex}\n    />\n  )}\n  // Memory optimization\n  windowSize={3} // Render 3 screens worth of content (1 above, current, 1 below)\n  maxToRenderPerBatch={2} // Render 2 items per batch\n  removeClippedSubviews={true} // Remove off-screen views\n  initialNumToRender={1} // Only render first item initially\n\n  // Improve scroll performance\n  getItemLayout={(data, index) => ({\n    length: SCREEN_HEIGHT,\n    offset: SCREEN_HEIGHT * index,\n    index,\n  })}\n\n  // Proper key extraction\n  keyExtractor={(item) => item.id}\n/>\n```\n\n\nAvoiding Re-renders\n\nUse React.memo and proper dependency arrays to prevent unnecessary re-renders:\n\n\n```tsx\nimport React, { memo } from 'react';\n\ninterface VideoItemProps {\n  video: Video;\n  isActive: boolean;\n  onLike: (videoId: string) => void;\n}\n\nconst VideoItem = memo(({ video, isActive, onLike }: VideoItemProps) => {\n  // This component will only re-render if props change\n  return (\n    <Video\n      source={{ uri: video.playbackUrl }}\n      paused={!isActive}\n    />\n  );\n}, (prevProps, nextProps) => {\n  // Custom comparison function\n  return (\n    prevProps.video.id === nextProps.video.id &&\n    prevProps.isActive === nextProps.isActive\n  );\n});\n\nexport default VideoItem;\n```\n\n\nVideo components are expensive to render. Always use React.memo for VideoItem components in lists to prevent unnecessary re-renders when sibling items change.\n\nCleanup Video References\n\nProperly cleanup video references to prevent memory leaks:\n\n\n```tsx\nimport { useRef, useEffect } from 'react';\n\nfunction VideoPlayer({ videoUrl, paused }: Props) {\n  const videoRef = useRef<Video>(null);\n\n  useEffect(() => {\n    return () => {\n      // Cleanup when component unmounts\n      if (videoRef.current) {\n        videoRef.current = null;\n      }\n    };\n  }, []);\n\n  return (\n    <Video\n      ref={videoRef}\n      source={{ uri: videoUrl }}\n      paused={paused}\n    />\n  );\n}\n```\n\n\nNetwork Optimization\n\nCellular vs WiFi Detection\n\nAdapt video quality or warn users when on cellular:\n\n\n```tsx\nimport NetInfo from '@react-native-community/netinfo';\nimport { useState, useEffect } from 'react';\n\nfunction useNetworkType() {\n  const [networkType, setNetworkType] = useState<string>('unknown');\n\n  useEffect(() => {\n    const unsubscribe = NetInfo.addEventListener(state => {\n      setNetworkType(state.type);\n    });\n\n    return () => unsubscribe();\n  }, []);\n\n  return networkType;\n}\n\nfunction VideoPlayer({ videoUrl }: Props) {\n  const networkType = useNetworkType();\n  const [showWarning, setShowWarning] = useState(false);\n\n  useEffect(() => {\n    if (networkType === 'cellular') {\n      setShowWarning(true);\n    }\n  }, [networkType]);\n\n  return (\n    <>\n      {showWarning && (\n        <Callout type=\"info\">\n          You're on cellular data. Video streaming may use significant data.\n        </Callout>\n      )}\n      <Video source={{ uri: videoUrl }} />\n    </>\n  );\n}\n```\n\n\nAdaptive Bitrate (ABR)\n\nHLS automatically handles adaptive bitrate streaming. Mux will serve the appropriate quality based on network conditions. Don't force quality settings - let Mux and HLS handle it.\n\nWhen using react-native-video, the player automatically adapts quality:\n\n\n```tsx\n<Video\n  source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }}\n  // NO NEED to set quality manually - HLS handles it\n  resizeMode=\"contain\"\n/>\n```\n\n\nBattery Optimization\n\nPause Videos When App Backgrounds\n\nStop video playback when the app goes to background:\n\n\n```tsx\nimport { useEffect, useState } from 'react';\nimport { AppState } from 'react-native';\n\nfunction useAppState() {\n  const [appState, setAppState] = useState(AppState.currentState);\n\n  useEffect(() => {\n    const subscription = AppState.addEventListener('change', nextAppState => {\n      setAppState(nextAppState);\n    });\n\n    return () => subscription.remove();\n  }, []);\n\n  return appState;\n}\n\nfunction VideoPlayer({ videoUrl }: Props) {\n  const appState = useAppState();\n  const [paused, setPaused] = useState(false);\n\n  useEffect(() => {\n    // Pause when app goes to background\n    if (appState === 'background' || appState === 'inactive') {\n      setPaused(true);\n    }\n  }, [appState]);\n\n  return (\n    <Video\n      source={{ uri: videoUrl }}\n      paused={paused}\n    />\n  );\n}\n```\n\n\nReduce Re-renders\n\nMinimize component re-renders to save CPU and battery:\n\n\n```tsx\nimport { useMemo, useCallback } from 'react';\n\nfunction VideoFeed({ videos }: Props) {\n  // Memoize expensive computations\n  const sortedVideos = useMemo(() => {\n    return videos.sort((a, b) => b.createdAt - a.createdAt);\n  }, [videos]);\n\n  // Memoize callbacks to prevent child re-renders\n  const handleLike = useCallback((videoId: string) => {\n    // Like logic\n  }, []);\n\n  return (\n    <FlatList\n      data={sortedVideos}\n      renderItem={({ item }) => (\n        <VideoItem video={item} onLike={handleLike} />\n      )}\n    />\n  );\n}\n```\n\n\nError Handling Patterns\n\nRetry Logic for Network Failures\n\nImplement exponential backoff for failed video loads:\n\n\n```tsx\nimport { useState, useEffect } from 'react';\n\nfunction useVideoWithRetry(videoUrl: string, maxRetries = 3) {\n  const [error, setError] = useState<string | null>(null);\n  const [retryCount, setRetryCount] = useState(0);\n  const [currentUrl, setCurrentUrl] = useState(videoUrl);\n\n  const handleError = (err: any) => {\n    if (retryCount < maxRetries) {\n      // Exponential backoff: 1s, 2s, 4s\n      const delay = Math.pow(2, retryCount) * 1000;\n\n      setTimeout(() => {\n        setRetryCount(prev => prev + 1);\n        // Force reload by adding cache-busting parameter\n        setCurrentUrl(`${videoUrl}?retry=${retryCount + 1}`);\n      }, delay);\n    } else {\n      setError('Failed to load video after multiple attempts');\n    }\n  };\n\n  return { currentUrl, error, handleError, retryCount };\n}\n\nfunction VideoPlayer({ videoUrl }: Props) {\n  const { currentUrl, error, handleError, retryCount } = useVideoWithRetry(videoUrl);\n\n  if (error) {\n    return <ErrorView message={error} />;\n  }\n\n  return (\n    <>\n      <Video\n        source={{ uri: currentUrl }}\n        onError={handleError}\n      />\n      {retryCount > 0 && (\n        <Text style={styles.retryText}>\n          Retrying... ({retryCount}/3)\n        </Text>\n      )}\n    </>\n  );\n}\n```\n\n\nFallback UI for Errors\n\nAlways provide clear error states:\n\n\n```tsx\nfunction ErrorView({ message, onRetry }: Props) {\n  return (\n    <View style={styles.errorContainer}>\n      <Text style={styles.errorIcon}>⚠️</Text>\n      <Text style={styles.errorTitle}>Unable to play video</Text>\n      <Text style={styles.errorMessage}>{message}</Text>\n      {onRetry && (\n        <TouchableOpacity style={styles.retryButton} onPress={onRetry}>\n          <Text style={styles.retryButtonText}>Tap to retry</Text>\n        </TouchableOpacity>\n      )}\n    </View>\n  );\n}\n```\n\n\nLogging Errors\n\nLog video errors for debugging:\n\n\n```tsx\nimport { Platform } from 'react-native';\n\nfunction VideoPlayer({ video }: Props) {\n  const handleError = (error: any) => {\n    // Log to your error tracking service\n    console.error('Video playback error:', {\n      videoId: video.id,\n      playbackId: video.playbackId,\n      platform: Platform.OS,\n      error: error.error,\n      timestamp: new Date().toISOString(),\n    });\n\n    // Show user-friendly error\n    setError('Unable to play video');\n  };\n\n  return (\n    <Video\n      source={{ uri: video.playbackUrl }}\n      onError={handleError}\n    />\n  );\n}\n```\n\n\nAccessibility\n\nCaptions and Subtitles\n\nAlways provide captions for accessibility. Mux supports WebVTT captions:\n\n\n```tsx\n<Video\n  source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }}\n  textTracks={[\n    {\n      title: 'English Subtitles',\n      language: 'en',\n      type: 'text/vtt',\n      uri: `https://stream.mux.com/${playbackId}/text/en.vtt`,\n    },\n  ]}\n  selectedTextTrack={{ type: 'title', value: 'English Subtitles' }}\n/>\n```\n\n\nLearn how to add captions to your Mux videos in the Captions and Subtitles guide.\n\nScreen Reader Support\n\nProvide descriptive labels for screen readers:\n\n\n```tsx\nimport { View, Text } from 'react-native';\n\n<View accessible={true} accessibilityLabel={`Video by ${username}: ${title}`}>\n  <Video\n    source={{ uri: videoUrl }}\n    accessible={true}\n    accessibilityLabel=\"Video player\"\n    accessibilityHint=\"Double tap to play or pause\"\n  />\n  <Text accessibilityRole=\"text\">{title}</Text>\n</View>\n```\n\n\nAudio Descriptions\n\nFor videos with important visual information, consider audio descriptions:\n\n\n```tsx\n<Video\n  source={{ uri: videoUrl }}\n  audioOnly={false}\n  textTracks={[\n    {\n      title: 'English Subtitles',\n      language: 'en',\n      type: 'text/vtt',\n      uri: subtitleUrl,\n    },\n    {\n      title: 'Audio Description',\n      language: 'en',\n      type: 'text/vtt',\n      uri: audioDescriptionUrl,\n    },\n  ]}\n/>\n```\n\n\nSecurity\n\nUse Signed URLs for Private Content\n\nNever expose private videos with public playback IDs. Use signed playback IDs instead:\n\n\n```tsx\n// Backend: Generate signed URL\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux();\n\nfunction generateSignedUrl(playbackId: string, userId: string) {\n  const token = Mux.JWT.signPlaybackId(playbackId, {\n    keyId: process.env.MUX_SIGNING_KEY_ID!,\n    keySecret: process.env.MUX_SIGNING_KEY_SECRET!,\n    expiration: '1h', // Token expires in 1 hour\n    params: {\n      aud: userId, // Tie token to specific user\n    },\n  });\n\n  return `https://stream.mux.com/${playbackId}.m3u8?token=${token}`;\n}\n\n// React Native: Use signed URL\n<Video source={{ uri: signedUrl }} />\n```\n\n\nNever expose Mux API keys, signing keys, or secrets in React Native code. Always generate signed URLs on your backend and send them to the client.\n\nLearn more in the Secure Video Playback guide.\n\nNever Expose API Keys in Client Code\n\nAll Mux API calls should go through your backend:\n\n\n```tsx\n// ❌ NEVER DO THIS\nimport Mux from '@mux/mux-node';\nconst mux = new Mux({\n  tokenId: 'YOUR_TOKEN_ID', // NEVER in client code!\n  tokenSecret: 'YOUR_TOKEN_SECRET', // NEVER in client code!\n});\n\n// ✅ DO THIS INSTEAD\nasync function createUploadUrl() {\n  const response = await fetch('https://your-api.com/generate-upload-url', {\n    method: 'POST',\n    headers: {\n      'Authorization': `Bearer ${userAuthToken}`,\n    },\n  });\n  return response.json();\n}\n```\n\n\nTesting\n\nTest on Real Devices\n\nAlways test video playback on real devices, not just simulators:\n\n- iOS Simulator: Works but may have performance differences\n- Android Emulator: Often has video codec issues\n- Real iOS device: Test on iPhone (different screen sizes)\n- Real Android device: Test on multiple manufacturers (Samsung, Google, etc.)\n\nTest on Slow Networks\n\nUse network throttling to test on poor connections:\n\n\n```tsx\n// In development, test with React Native debugger network throttling\n// Or use Charles Proxy to simulate slow networks\n\nfunction VideoPlayer({ videoUrl }: Props) {\n  const [isBuffering, setIsBuffering] = useState(false);\n\n  return (\n    <>\n      <Video\n        source={{ uri: videoUrl }}\n        onBuffer={({ isBuffering }) => setIsBuffering(isBuffering)}\n      />\n      {isBuffering && (\n        <View style={styles.bufferingOverlay}>\n          <ActivityIndicator size=\"large\" />\n          <Text>Buffering...</Text>\n        </View>\n      )}\n    </>\n  );\n}\n```\n\n\nTest scenarios:\n- 3G network (slow)\n- WiFi with high latency\n- Switching between WiFi and cellular\n- Network interruption and recovery\n\nTest Video Error States\n\nManually test error scenarios:\n\n\n```tsx\nfunction TestErrorScenarios() {\n  const scenarios = [\n    {\n      name: 'Invalid playback ID',\n      url: 'https://stream.mux.com/invalid.m3u8',\n    },\n    {\n      name: 'Network timeout',\n      url: 'https://stream.mux.com/EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs.m3u8?timeout=1',\n    },\n  ];\n\n  return scenarios.map(scenario => (\n    <TestCase key={scenario.name} scenario={scenario} />\n  ));\n}\n```\n\n\nDebugging\n\nCommon Issues and Solutions\n\nVideo won't play:\n- ✅ Check if asset is in ready state (not preparing)\n- ✅ Verify playback ID is correct\n- ✅ Check network connectivity\n- ✅ Test on real device (simulator may have codec issues)\n\nPlayback errors:\n- ✅ Check HLS URL format: https://stream.mux.com/${playbackId}.m3u8\n- ✅ Verify CORS headers (if using signed playback)\n- ✅ Check if asset has been deleted\n\nPerformance issues:\n- ✅ Reduce windowSize in FlatList\n- ✅ Use React.memo for VideoItem components\n- ✅ Check for memory leaks with React DevTools\n- ✅ Profile with Xcode Instruments (iOS) or Android Profiler\n\nUpload failures:\n- ✅ Check file size (Mux supports up to 500GB but mobile apps should limit)\n- ✅ Verify network stability\n- ✅ Implement retry logic with exponential backoff\n- ✅ Check upload URL hasn't expired\n\nUsing Mux Data for Debugging\n\nMux Data provides insights into playback issues:\n\n\n```tsx\nimport muxReactNativeVideo from '@mux/mux-data-react-native-video';\n\nconst MuxVideo = muxReactNativeVideo(Video);\n\n<MuxVideo\n  source={{ uri: videoUrl }}\n  muxOptions={{\n    application_name: 'MyApp',\n    data: {\n      env_key: MUX_DATA_ENV_KEY,\n      video_id: videoId,\n      video_title: videoTitle,\n      // Add debug metadata\n      player_init_time: Date.now(),\n      player_version: '1.0.0',\n    },\n  }}\n/>\n```\n\n\nCheck the Mux Dashboard for:\n- Video startup time\n- Buffering events\n- Error rates\n- Playback failures\n- Quality of experience metrics\n\nReact Native Debugger with Video\n\nWhen debugging, be aware that video playback may behave differently with remote debugging enabled:\n\n\n```tsx\nimport { Platform } from 'react-native';\n\nconst IS_DEBUGGING = __DEV__ && Platform.OS === 'ios';\n\nfunction VideoPlayer({ videoUrl }: Props) {\n  useEffect(() => {\n    if (IS_DEBUGGING) {\n      console.log('Video debugging enabled:', {\n        url: videoUrl,\n        platform: Platform.OS,\n      });\n    }\n  }, [videoUrl]);\n\n  return <Video source={{ uri: videoUrl }} />;\n}\n```\n\n\nVideo performance in the iOS Simulator with remote debugging enabled is significantly slower than on a real device. Always test performance on actual hardware.\n\nProduction Checklist\n\nBefore launching your app, verify:\n\nPerformance\n- [ ] Videos play smoothly on 3G networks\n- [ ] FlatList doesn't cause memory issues with 100+ videos\n- [ ] App doesn't drain battery excessively\n- [ ] Videos pause when app backgrounds\n- [ ] No memory leaks in video components\n\nError Handling\n- [ ] Network failures show clear error messages\n- [ ] Retry logic works for transient failures\n- [ ] Invalid playback IDs handled gracefully\n- [ ] Errors logged to tracking service\n\nAccessibility\n- [ ] Captions available for videos\n- [ ] Screen reader support for video controls\n- [ ] Proper ARIA labels on interactive elements\n\nSecurity\n- [ ] No API keys in client code\n- [ ] Private videos use signed playback IDs\n- [ ] Signed URLs have appropriate expiration times\n- [ ] User authentication checked before video access\n\nTesting\n- [ ] Tested on iOS (multiple screen sizes)\n- [ ] Tested on Android (multiple manufacturers)\n- [ ] Tested on slow networks\n- [ ] Tested error scenarios\n- [ ] Tested with screen reader\n\nAnalytics\n- [ ] Mux Data integrated for all videos\n- [ ] Custom metadata includes user_id, video_id\n- [ ] Dashboard metrics reviewed regularly\n\nNext Steps\n\n  <GuideCard\n    title=\"Troubleshooting & FAQ\"\n    description=\"Solutions to common issues and frequently asked questions about React Native + Mux\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/troubleshooting\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Example App\"\n    description=\"Complete reference implementation with all features demonstrated\"\n    links={[\n      {title: \"See the example\", href: \"/docs/guides/react-native/example-app\"},\n    ]}\n  />"
  },
  {
    "id": "163-_guides/frameworks/react-native-example-app",
    "title": "Complete Example App",
    "path": "_guides/frameworks/react-native-example-app.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-example-app",
    "content": "Complete Example App: Slop Social\n\nThis guide walks through Slop Social, a complete reference implementation that demonstrates all the patterns covered in this documentation. Slop Social is an AI-generated video social media app with Instagram Stories-style video playback.\n\nOverview\n\nSlop Social is a React Native app where users:\n1. Generate videos using AI prompts\n2. Videos are automatically uploaded to Mux\n3. Browse AI-generated videos in a Stories-style vertical feed\n4. See engagement metrics (views, likes)\n5. Interact with videos (like, comment, share)\n\nGitHub Repository: github.com/mux/slop-social _(example link)_\n\nWhat's Demonstrated\n\nThis example app showcases every pattern from the React Native + Mux documentation:\n\nVideo Playback\n- ✅ HLS streaming with react-native-video\n- ✅ Stories/Reels vertical swipe interface\n- ✅ Auto-play on scroll\n- ✅ Custom video controls\n- ✅ Fullscreen support\n- ✅ Loading and error states\n\nUpload & Processing\n- ✅ Upload videos from URL (AI-generated)\n- ✅ Direct upload from device (camera/library)\n- ✅ Async processing with webhooks\n- ✅ Real-time status updates (Supabase Realtime)\n- ✅ Progress indicators\n\nAnalytics\n- ✅ Mux Data integration\n- ✅ View counts\n- ✅ Real-time viewer counts\n- ✅ Engagement metrics\n\nProduction Best Practices\n- ✅ Performance optimization\n- ✅ Error handling and retry logic\n- ✅ Memory management in lists\n- ✅ Network detection\n- ✅ Accessibility features\n\nArchitecture\n\n\n```\n┌─────────────────┐\n│  React Native   │\n│   (Expo App)    │\n└────────┬────────┘\n         │\n         ├─ Video Playback ──────► Mux Stream (stream.mux.com)\n         │\n         ├─ API Requests ─────────► Backend (Supabase Edge Functions)\n         │                              │\n         │                              ├─ Mux API (create assets, uploads)\n         │                              ├─ AI Service (Fal.ai)\n         │                              └─ Webhooks (video.asset.ready)\n         │\n         └─ Realtime Updates ──────► Supabase Realtime DB\n```\n\n\nTech Stack\n\nFrontend:\n- React Native (Expo)\n- TypeScript\n- react-native-video (playback)\n- @mux/mux-data-react-native-video (analytics)\n- react-native-gesture-handler (interactions)\n- react-native-reanimated (animations)\n\nBackend:\n- Supabase (database, auth, realtime, edge functions)\n- Node.js (edge functions runtime)\n\nVideo:\n- Mux (video hosting, streaming, analytics)\n- Fal.ai (AI video generation)\n\nKey Features\n\n1. Stories Feed (screens/StoriesFeed.tsx)\n\nThe main feature - Instagram Stories-style vertical video feed:\n\n\n```tsx\nimport { FlatList, Dimensions } from 'react-native';\nimport { StoryItem } from '../components/StoryItem';\n\nconst SCREEN_HEIGHT = Dimensions.get('window').height;\n\nexport function StoriesFeed() {\n  const [videos, setVideos] = useState<Video[]>([]);\n  const [currentIndex, setCurrentIndex] = useState(0);\n\n  // Load videos from API\n  useEffect(() => {\n    loadVideos();\n  }, []);\n\n  // Track which video is visible\n  const onViewableItemsChanged = useRef(({ viewableItems }) => {\n    if (viewableItems.length > 0) {\n      setCurrentIndex(viewableItems[0].index);\n    }\n  }).current;\n\n  return (\n    <FlatList\n      data={videos}\n      renderItem={({ item, index }) => (\n        <StoryItem\n          video={item}\n          isActive={index === currentIndex}\n        />\n      )}\n      pagingEnabled\n      snapToInterval={SCREEN_HEIGHT}\n      snapToAlignment=\"start\"\n      decelerationRate=\"fast\"\n      showsVerticalScrollIndicator={false}\n      windowSize={3}\n      removeClippedSubviews\n      onViewableItemsChanged={onViewableItemsChanged}\n      viewabilityConfig={{\n        itemVisiblePercentThreshold: 80,\n      }}\n      getItemLayout={(data, index) => ({\n        length: SCREEN_HEIGHT,\n        offset: SCREEN_HEIGHT * index,\n        index,\n      })}\n    />\n  );\n}\n```\n\n\nDemonstrates:\n- Full-screen vertical paging\n- Visibility tracking for auto-play\n- Memory optimization\n- Performance best practices\n\n---\n\n2. Story Item (components/StoryItem.tsx)\n\nIndividual video with overlay UI:\n\n\n```tsx\nimport Video from 'react-native-video';\nimport { VideoOverlay } from './VideoOverlay';\nimport { GestureDetector, Gesture } from 'react-native-gesture-handler';\nimport muxReactNativeVideo from '@mux/mux-data-react-native-video';\n\nconst MuxVideo = muxReactNativeVideo(Video);\n\nexport function StoryItem({ video, isActive }: Props) {\n  const [paused, setPaused] = useState(!isActive);\n  const [liked, setLiked] = useState(false);\n\n  // Auto-play when active\n  useEffect(() => {\n    setPaused(!isActive);\n  }, [isActive]);\n\n  // Gesture handlers\n  const singleTap = Gesture.Tap()\n    .numberOfTaps(1)\n    .onEnd(() => setPaused(prev => !prev));\n\n  const doubleTap = Gesture.Tap()\n    .numberOfTaps(2)\n    .onEnd(() => handleLike());\n\n  const taps = Gesture.Exclusive(doubleTap, singleTap);\n\n  return (\n    <View style={styles.container}>\n      <GestureDetector gesture={taps}>\n        <MuxVideo\n          source={{ uri: video.playbackUrl }}\n          style={styles.video}\n          paused={paused}\n          resizeMode=\"cover\"\n          repeat\n          muxOptions={{\n            application_name: 'Slop Social',\n            data: {\n              env_key: MUX_DATA_ENV_KEY,\n              video_id: video.id,\n              video_title: video.title,\n              viewer_user_id: currentUserId,\n            },\n          }}\n        />\n      </GestureDetector>\n\n      <VideoOverlay\n        video={video}\n        liked={liked}\n        onLike={handleLike}\n        onComment={handleComment}\n        onShare={handleShare}\n      />\n\n      {liked && <LikeAnimation />}\n    </View>\n  );\n}\n```\n\n\nDemonstrates:\n- Mux Data integration for analytics\n- Gesture detection (tap to pause, double-tap to like)\n- Auto-play based on visibility\n- Video overlays\n\n---\n\n3. AI Video Generation (hooks/useAIVideoGeneration.ts)\n\nComplete workflow for generating videos with AI:\n\n\n```tsx\nimport { useState } from 'react';\n\nexport function useAIVideoGeneration() {\n  const [status, setStatus] = useState<'idle' | 'generating' | 'uploading' | 'processing' | 'ready'>('idle');\n  const [progress, setProgress] = useState(0);\n  const [error, setError] = useState<string | null>(null);\n\n  const generateVideo = async (prompt: string) => {\n    try {\n      // Step 1: Call AI service\n      setStatus('generating');\n      const response = await fetch(`${API_URL}/generate-video`, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ prompt }),\n      });\n      const { videoUrl, videoId } = await response.json();\n\n      // Step 2: Backend uploads to Mux\n      setStatus('uploading');\n      await fetch(`${API_URL}/ingest-video`, {\n        method: 'POST',\n        body: JSON.stringify({ videoUrl, videoId }),\n      });\n\n      // Step 3: Listen for processing completion\n      setStatus('processing');\n      await waitForVideoReady(videoId);\n\n      setStatus('ready');\n      return videoId;\n\n    } catch (err) {\n      setError(err.message);\n      setStatus('idle');\n      throw err;\n    }\n  };\n\n  return { generateVideo, status, progress, error };\n}\n```\n\n\nDemonstrates:\n- Complete AI video workflow\n- Upload from URL pattern\n- Status tracking through multiple stages\n- Error handling\n\n---\n\n4. Realtime Updates (hooks/useVideoStatus.ts)\n\nListen for video processing updates via Supabase Realtime:\n\n\n```tsx\nimport { useEffect, useState } from 'react';\nimport { supabase } from '../lib/supabase';\n\nexport function useVideoStatus(videoId: string) {\n  const [video, setVideo] = useState<Video | null>(null);\n  const [isReady, setIsReady] = useState(false);\n\n  useEffect(() => {\n    // Initial fetch\n    const fetchVideo = async () => {\n      const { data } = await supabase\n        .from('videos')\n        .select('*')\n        .eq('id', videoId)\n        .single();\n\n      setVideo(data);\n      setIsReady(data.status === 'ready');\n    };\n\n    fetchVideo();\n\n    // Subscribe to changes\n    const subscription = supabase\n      .channel(`video-${videoId}`)\n      .on('postgres_changes', {\n        event: 'UPDATE',\n        schema: 'public',\n        table: 'videos',\n        filter: `id=eq.${videoId}`,\n      }, (payload) => {\n        const updatedVideo = payload.new as Video;\n        setVideo(updatedVideo);\n        setIsReady(updatedVideo.status === 'ready');\n      })\n      .subscribe();\n\n    return () => {\n      subscription.unsubscribe();\n    };\n  }, [videoId]);\n\n  return { video, isReady };\n}\n```\n\n\nDemonstrates:\n- Realtime database subscriptions\n- Async processing handling\n- Status updates from webhooks\n\n---\n\n5. Upload from Device (screens/UploadScreen.tsx)\n\nAllow users to upload videos from camera or library:\n\n\n```tsx\nimport * as ImagePicker from 'expo-image-picker';\nimport * as FileSystem from 'expo-file-system';\n\nexport function UploadScreen() {\n  const [uploading, setUploading] = useState(false);\n  const [progress, setProgress] = useState(0);\n\n  const uploadVideo = async () => {\n    // Step 1: Pick video\n    const result = await ImagePicker.launchImageLibraryAsync({\n      mediaTypes: ImagePicker.MediaTypeOptions.Videos,\n      allowsEditing: true,\n      quality: 1,\n    });\n\n    if (result.canceled) return;\n\n    setUploading(true);\n\n    try {\n      // Step 2: Get upload URL from backend\n      const response = await fetch(`${API_URL}/generate-upload-url`, {\n        method: 'POST',\n      });\n      const { uploadUrl, uploadId } = await response.json();\n\n      // Step 3: Upload to Mux\n      const uploadResult = await FileSystem.uploadAsync(\n        uploadUrl,\n        result.assets[0].uri,\n        {\n          httpMethod: 'PUT',\n          uploadType: FileSystem.FileSystemUploadType.BINARY_CONTENT,\n        }\n      );\n\n      if (uploadResult.status === 200) {\n        // Step 4: Wait for processing\n        await waitForUploadComplete(uploadId);\n        navigation.navigate('Home');\n      }\n\n    } catch (error) {\n      Alert.alert('Upload failed', error.message);\n    } finally {\n      setUploading(false);\n    }\n  };\n\n  return (\n    <View style={styles.container}>\n      <Button title=\"Upload Video\" onPress={uploadVideo} />\n      {uploading && (\n        <View style={styles.uploadProgress}>\n          <ActivityIndicator size=\"large\" />\n          <Text>Uploading... {Math.round(progress * 100)}%</Text>\n        </View>\n      )}\n    </View>\n  );\n}\n```\n\n\nDemonstrates:\n- Direct upload flow\n- File picker integration\n- Upload progress tracking\n- Error handling\n\n---\n\n6. View Analytics (components/VideoStats.tsx)\n\nDisplay engagement metrics:\n\n\n```tsx\nimport { useVideoAnalytics } from '../hooks/useVideoAnalytics';\n\nexport function VideoStats({ videoId }: Props) {\n  const { views, liveViewers } = useVideoAnalytics(videoId);\n\n  return (\n    <View style={styles.stats}>\n      <View style={styles.stat}>\n        <Text style={styles.statIcon}>👁</Text>\n        <Text style={styles.statValue}>\n          {views.toLocaleString()} views\n        </Text>\n      </View>\n\n      {liveViewers > 0 && (\n        <View style={styles.stat}>\n          <View style={styles.liveDot} />\n          <Text style={styles.statValue}>\n            {liveViewers} watching now\n          </Text>\n        </View>\n      )}\n    </View>\n  );\n}\n\n// Custom hook\nfunction useVideoAnalytics(videoId: string) {\n  const [views, setViews] = useState(0);\n  const [liveViewers, setLiveViewers] = useState(0);\n\n  useEffect(() => {\n    // Fetch total views\n    fetch(`${API_URL}/video/${videoId}/views`)\n      .then(r => r.json())\n      .then(data => setViews(data.views));\n\n    // Poll for live viewers\n    const interval = setInterval(async () => {\n      const response = await fetch(`${API_URL}/video/${videoId}/live-viewers`);\n      const data = await response.json();\n      setLiveViewers(data.liveViewers);\n    }, 10000);\n\n    return () => clearInterval(interval);\n  }, [videoId]);\n\n  return { views, liveViewers };\n}\n```\n\n\nDemonstrates:\n- Mux Data API integration\n- View count display\n- Real-time viewer tracking\n- Polling pattern\n\n---\n\nBackend Structure\n\nSupabase Edge Functions\n\ngenerate-video - Trigger AI video generation\n\n```typescript\n// supabase/functions/generate-video/index.ts\nimport { serve } from 'https://deno.land/std@0.168.0/http/server.ts';\n\nserve(async (req) => {\n  const { prompt, userId } = await req.json();\n\n  // Call AI service (Fal.ai)\n  const response = await fetch('https://fal.run/fal-ai/video-gen', {\n    method: 'POST',\n    headers: {\n      'Authorization': `Key ${Deno.env.get('FAL_KEY')}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ prompt }),\n  });\n\n  const { video_url } = await response.json();\n\n  return new Response(\n    JSON.stringify({ videoUrl: video_url }),\n    { headers: { 'Content-Type': 'application/json' } }\n  );\n});\n```\n\n\ningest-video - Upload video URL to Mux\n\n```typescript\n// supabase/functions/ingest-video/index.ts\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux({\n  tokenId: Deno.env.get('MUX_TOKEN_ID')!,\n  tokenSecret: Deno.env.get('MUX_TOKEN_SECRET')!,\n});\n\nserve(async (req) => {\n  const { videoUrl, videoId } = await req.json();\n\n  const asset = await mux.video.assets.create({\n    input: [{ url: videoUrl }],\n    playback_policy: ['public'],\n  });\n\n  // Save to database\n  await supabase.from('videos').insert({\n    id: videoId,\n    mux_asset_id: asset.id,\n    status: 'preparing',\n  });\n\n  return new Response(JSON.stringify({ assetId: asset.id }));\n});\n```\n\n\nwebhooks - Handle Mux webhooks\n\n```typescript\n// supabase/functions/webhooks/index.ts\nimport Mux from '@mux/mux-node';\n\nserve(async (req) => {\n  const signature = req.headers.get('mux-signature');\n  const body = await req.text();\n\n  // Verify webhook\n  Mux.Webhooks.verifyHeader(\n    body,\n    signature,\n    Deno.env.get('MUX_WEBHOOK_SECRET')!\n  );\n\n  const event = JSON.parse(body);\n\n  if (event.type === 'video.asset.ready') {\n    const asset = event.data;\n\n    await supabase\n      .from('videos')\n      .update({\n        status: 'ready',\n        playback_id: asset.playback_ids[0].id,\n        duration: asset.duration,\n      })\n      .eq('mux_asset_id', asset.id);\n  }\n\n  return new Response('OK');\n});\n```\n\n\nDemonstrates:\n- Serverless functions (Deno Deploy)\n- Mux SDK usage\n- Webhook handling\n- Database updates\n\n---\n\nDatabase Schema\n\n\n```sql\n-- Videos table\ncreate table videos (\n  id uuid primary key default uuid_generate_v4(),\n  user_id uuid references auth.users(id),\n  mux_asset_id text unique,\n  playback_id text,\n  status text check (status in ('preparing', 'ready', 'errored')),\n  title text,\n  prompt text, -- AI generation prompt\n  duration float,\n  aspect_ratio text,\n  thumbnail_url text,\n  view_count integer default 0,\n  like_count integer default 0,\n  created_at timestamp with time zone default now()\n);\n\n-- Likes table\ncreate table likes (\n  id uuid primary key default uuid_generate_v4(),\n  user_id uuid references auth.users(id),\n  video_id uuid references videos(id),\n  created_at timestamp with time zone default now(),\n  unique(user_id, video_id)\n);\n\n-- Realtime setup\nalter publication supabase_realtime add table videos;\n```\n\n\n---\n\nHow to Run Locally\n\nPrerequisites\n\n- Node.js 18+\n- Expo CLI (npm install -g expo-cli)\n- Mux account (mux.com)\n- Supabase account (supabase.com)\n- Fal.ai account (fal.ai)\n\nStep 1: Clone Repository\n\n\n```bash\ngit clone https://github.com/mux/slop-social.git\ncd slop-social\nnpm install\n```\n\n\nStep 2: Environment Variables\n\nCreate .env file:\n\n\n```bash\n# Mux (Dashboard → Settings → API Access Tokens)\nMUX_TOKEN_ID=your_mux_token_id\nMUX_TOKEN_SECRET=your_mux_token_secret\nMUX_SIGNING_KEY_ID=your_signing_key_id\nMUX_SIGNING_KEY_SECRET=your_signing_key_secret\nMUX_WEBHOOK_SECRET=your_webhook_secret\n\n# Mux Data (Dashboard → Settings → Data)\nEXPO_PUBLIC_MUX_DATA_ENV_KEY=your_mux_data_env_key\n\n# Supabase (Dashboard → Settings → API)\nEXPO_PUBLIC_SUPABASE_URL=https://xxx.supabase.co\nEXPO_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key\nSUPABASE_SERVICE_ROLE_KEY=your_service_role_key\n\n# Fal.ai\nFAL_API_KEY=your_fal_api_key\n\n# API URL (local or deployed)\nEXPO_PUBLIC_API_URL=http://localhost:54321/functions/v1\n```\n\n\nStep 3: Set Up Supabase\n\n\n```bash\n# Install Supabase CLI\nnpm install -g supabase\n\n# Login\nsupabase login\n\n# Link project\nsupabase link --project-ref your-project-ref\n\n# Push database schema\nsupabase db push\n\n# Deploy edge functions\nsupabase functions deploy generate-video\nsupabase functions deploy ingest-video\nsupabase functions deploy webhooks\n```\n\n\nStep 4: Configure Mux Webhooks\n\nIn Mux Dashboard → Settings → Webhooks:\n\nWebhook URL: https://your-project.supabase.co/functions/v1/webhooks\n\nEvents:\n- video.asset.ready\n- video.asset.errored\n- video.upload.asset_created\n\nCopy the webhook secret to your .env file.\n\nStep 5: Run the App\n\n\n```bash\n# Start Expo dev server\nnpm start\n\n# Run on iOS simulator\nnpm run ios\n\n# Run on Android emulator\nnpm run android\n\n# Or scan QR code in Expo Go app\n```\n\n\nStep 6: Test the Flow\n\n1. Sign up / log in\n2. Tap \"Generate Video\"\n3. Enter a prompt (e.g., \"A cat playing piano\")\n4. Wait for AI generation and Mux processing\n5. Video appears in your Stories feed\n6. Swipe up/down to navigate\n7. Tap to pause, double-tap to like\n\n---\n\nProject Structure\n\n\n```\nslop-social/\n├── src/\n│   ├── screens/\n│   │   ├── StoriesFeed.tsx          # Main feed (vertical swipe)\n│   │   ├── GenerateScreen.tsx       # AI video generation\n│   │   ├── UploadScreen.tsx         # Upload from device\n│   │   └── ProfileScreen.tsx        # User profile & videos\n│   ├── components/\n│   │   ├── StoryItem.tsx            # Individual video item\n│   │   ├── VideoOverlay.tsx         # UI overlay (likes, comments)\n│   │   ├── VideoPlayer.tsx          # Reusable video player\n│   │   ├── VideoStats.tsx           # View counts, analytics\n│   │   └── LikeAnimation.tsx        # Like animation effect\n│   ├── hooks/\n│   │   ├── useAIVideoGeneration.ts  # AI generation flow\n│   │   ├── useVideoStatus.ts        # Realtime status updates\n│   │   ├── useVideoAnalytics.ts     # Mux Data integration\n│   │   └── useVideoUpload.ts        # Direct upload flow\n│   └── lib/\n│       ├── supabase.ts              # Supabase client\n│       └── api.ts                   # API client\n├── supabase/\n│   ├── functions/\n│   │   ├── generate-video/          # AI video generation\n│   │   ├── ingest-video/            # Upload to Mux\n│   │   ├── webhooks/                # Mux webhook handler\n│   │   └── analytics/               # View counts API\n│   └── migrations/\n│       └── 001_initial_schema.sql   # Database schema\n├── App.tsx                          # Root component\n├── app.json                         # Expo config\n└── package.json\n```\n\n\n---\n\nKey Learnings\n\nWhat Works Well\n\n✅ Stories UI is engaging - Vertical swipe is intuitive and familiar\n✅ Mux handles video complexity - No need to worry about formats, codecs, or streaming\n✅ Webhooks + Realtime = Great UX - Users see updates immediately\n✅ Mux Data provides insights - View counts and analytics out of the box\n✅ Upload from URL is perfect for AI - Seamless integration with AI video services\n\nCommon Pitfalls Avoided\n\n❌ Don't render all videos at once - Use FlatList windowSize\n❌ Don't forget React.memo - Prevents expensive re-renders\n❌ Don't expose API keys - Always use backend proxy\n❌ Don't skip error states - Videos fail, networks drop - handle it\n❌ Don't test only in simulator - Real devices perform differently\n\n---\n\nNext Steps\n\nExtend the Example\n\nIdeas for additional features:\n\n- Comments - Add comment threads to videos\n- User profiles - Show all videos from a user\n- Search - Search videos by prompt/tags\n- Notifications - Push notifications for likes/comments\n- Filters - Apply filters to AI-generated videos\n- Duets - Side-by-side video responses\n- Live streaming - Go live with Mux Live Stream API\n\nDeploy to Production\n\n1. Build production app\n\n```bash\n   eas build --platform ios\n   eas build --platform android\n   ```\n\n\n2. Deploy backend\n   - Supabase edge functions auto-deploy on push\n\n3. Configure Mux for production\n   - Set up proper webhook endpoints\n   - Use signed playback IDs for private content\n   - Review encoding tier (baseline vs standard)\n\n4. Submit to app stores\n\n```bash\n   eas submit --platform ios\n   eas submit --platform android\n   ```\n\n\n---\n\nAdditional Resources\n\n  <GuideCard\n    title=\"Quickstart\"\n    description=\"Start from the beginning with the 5-minute quickstart\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/quickstart\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Best Practices\"\n    description=\"Optimize your production video app\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/best-practices\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Troubleshooting\"\n    description=\"Common issues and how to solve them\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/troubleshooting\"},\n    ]}\n  />\n  <GuideCard\n    title=\"GitHub Repository\"\n    description=\"View the complete source code\"\n    links={[\n      {title: \"View on GitHub\", href: \"https://github.com/mux/slop-social\"},\n    ]}\n  />"
  },
  {
    "id": "164-_guides/frameworks/react-native-live-streaming",
    "title": "Live Streaming",
    "path": "_guides/frameworks/react-native-live-streaming.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-live-streaming",
    "content": "Live Streaming\n\nThis guide covers how to integrate Mux live streaming into your React Native app. You'll learn how to play live streams (simple!) and explore options for broadcasting live video from mobile devices.\n\nGood news: Playing live streams in React Native is exactly the same as playing on-demand videos. If you can play a video, you can play a live stream!\n\nFor complete live streaming concepts and backend setup, see the Live Streaming Guide.\n\nOverview\n\nMux Live Stream allows you to broadcast live video to viewers in real-time. Common use cases:\n- Live events and conferences\n- Live Q&A sessions\n- Live shopping streams\n- Gaming streams\n- Real-time video interactions\n\nArchitecture:\n\n```\nBroadcaster (RTMP) → Mux Live Stream → HLS Playback → React Native App\n```\n\n\nCreating Live Streams\n\nLive streams are created on your backend using the Mux API. React Native apps consume the playback URL.\n\n\n```javascript\n// Backend code (Node.js)\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux({\n  tokenId: process.env.MUX_TOKEN_ID,\n  tokenSecret: process.env.MUX_TOKEN_SECRET,\n});\n\n// Create live stream\napp.post('/api/live-stream/create', async (req, res) => {\n  const { userId, title } = req.body;\n\n  const liveStream = await mux.video.liveStreams.create({\n    playback_policy: ['public'], // or ['signed'] for private\n    new_asset_settings: {\n      playback_policy: ['public'], // Record stream as VOD\n    },\n    reconnect_window: 60, // Allow reconnection within 60 seconds\n    reduced_latency: false, // Set true for low-latency streaming\n  });\n\n  // Save to database\n  await db.liveStreams.create({\n    id: liveStream.id,\n    userId,\n    title,\n    streamKey: liveStream.stream_key,\n    playbackId: liveStream.playback_ids[0].id,\n    status: 'idle',\n  });\n\n  res.json({\n    streamId: liveStream.id,\n    streamKey: liveStream.stream_key, // Keep secret! Only share with broadcaster\n    playbackId: liveStream.playback_ids[0].id,\n    rtmpUrl: `rtmps://global-live.mux.com:443/app/${liveStream.stream_key}`,\n  });\n});\n```\n\n\nKeep stream keys secret! Only share them with the broadcaster. Anyone with the stream key can broadcast to your live stream.\n\nAPI Reference: Create Live Stream\n\n---\n\nPlaying Live Streams\n\nPlaying a live stream in React Native is identical to playing a VOD video:\n\n\n```tsx\nimport Video from 'react-native-video';\n\nfunction LiveStreamPlayer({ playbackId }: Props) {\n  const playbackUrl = `https://stream.mux.com/${playbackId}.m3u8`;\n\n  return (\n    <Video\n      source={{ uri: playbackUrl }}\n      style={styles.video}\n      controls={true}\n      resizeMode=\"contain\"\n      // Tell react-native-video this is a live stream\n      streamType=\"live\"\n    />\n  );\n}\n\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n});\n```\n\n\nThat's it! HLS handles all the complexity of live streaming automatically.\n\n---\n\nLive Stream States\n\nLive streams have different states that affect playback:\n\n\n```tsx\nimport { useState, useEffect } from 'react';\n\ntype LiveStreamStatus = 'idle' | 'active' | 'disconnected';\n\nfunction useLiveStreamStatus(streamId: string) {\n  const [status, setStatus] = useState<LiveStreamStatus>('idle');\n\n  useEffect(() => {\n    // Poll backend for stream status\n    const checkStatus = async () => {\n      const response = await fetch(`${API_URL}/live-stream/${streamId}/status`);\n      const { status } = await response.json();\n      setStatus(status);\n    };\n\n    checkStatus();\n    const interval = setInterval(checkStatus, 5000); // Check every 5 seconds\n\n    return () => clearInterval(interval);\n  }, [streamId]);\n\n  return status;\n}\n\nfunction LiveStreamPlayer({ streamId, playbackId }: Props) {\n  const status = useLiveStreamStatus(streamId);\n\n  if (status === 'idle') {\n    return (\n      <View style={styles.waitingContainer}>\n        <Text style={styles.waitingText}>Stream will start soon...</Text>\n        <ActivityIndicator size=\"large\" />\n      </View>\n    );\n  }\n\n  if (status === 'disconnected') {\n    return (\n      <View style={styles.disconnectedContainer}>\n        <Text style={styles.disconnectedText}>\n          Stream temporarily disconnected. Reconnecting...\n        </Text>\n      </View>\n    );\n  }\n\n  // Status is 'active'\n  return (\n    <View style={styles.container}>\n      <Video\n        source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }}\n        style={styles.video}\n        streamType=\"live\"\n      />\n      <View style={styles.liveBadge}>\n        <View style={styles.liveDot} />\n        <Text style={styles.liveText}>LIVE</Text>\n      </View>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  liveBadge: {\n    position: 'absolute',\n    top: 16,\n    left: 16,\n    flexDirection: 'row',\n    alignItems: 'center',\n    backgroundColor: 'rgba(255, 0, 0, 0.8)',\n    paddingHorizontal: 12,\n    paddingVertical: 6,\n    borderRadius: 4,\n  },\n  liveDot: {\n    width: 8,\n    height: 8,\n    borderRadius: 4,\n    backgroundColor: 'white',\n    marginRight: 6,\n  },\n  liveText: {\n    color: 'white',\n    fontWeight: 'bold',\n    fontSize: 12,\n  },\n});\n```\n\n\nBackend endpoint to check live stream status:\n\n\n```javascript\n// Backend code\napp.get('/api/live-stream/:streamId/status', async (req, res) => {\n  const { streamId } = req.params;\n\n  const liveStream = await mux.video.liveStreams.retrieve(streamId);\n\n  res.json({\n    status: liveStream.status, // 'idle', 'active', 'disconnected'\n    isActive: liveStream.status === 'active',\n  });\n});\n```\n\n\n---\n\nLive Stream with Viewer Count\n\nShow real-time viewer counts:\n\n\n```tsx\nimport { useLiveViewers } from '../hooks/useVideoAnalytics';\n\nfunction LiveStreamPlayer({ streamId, playbackId }: Props) {\n  const liveViewers = useLiveViewers(playbackId);\n\n  return (\n    <View style={styles.container}>\n      <Video\n        source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }}\n        style={styles.video}\n        streamType=\"live\"\n      />\n\n      <View style={styles.topOverlay}>\n        <View style={styles.liveBadge}>\n          <View style={styles.liveDot} />\n          <Text style={styles.liveText}>LIVE</Text>\n        </View>\n\n        <View style={styles.viewerCount}>\n          <Text style={styles.viewerIcon}>👁</Text>\n          <Text style={styles.viewerText}>\n            {liveViewers.toLocaleString()} watching\n          </Text>\n        </View>\n      </View>\n    </View>\n  );\n}\n```\n\n\nLearn more: Real-time Viewer Counts\n\n---\n\nLow-Latency Streaming\n\nFor interactive use cases (live Q&A, auctions), enable low-latency mode:\n\n\n```javascript\n// Backend code - Create low-latency stream\nconst liveStream = await mux.video.liveStreams.create({\n  playback_policy: ['public'],\n  reduced_latency: true, // Enable low-latency mode (3-5s vs 10-15s)\n});\n```\n\n\n\n```tsx\n// React Native - Same playback code, lower latency automatically\n<Video\n  source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }}\n  streamType=\"live\"\n/>\n```\n\n\nLow-latency streaming reduces latency from ~10-15 seconds to ~3-5 seconds. However, it may increase buffering on poor networks. Choose based on your use case.\n\n---\n\nDVR Mode (Seeking in Live Streams)\n\nAllow viewers to scrub backwards in live streams:\n\n\n```tsx\nfunction LiveStreamPlayer({ playbackId }: Props) {\n  const videoRef = useRef<Video>(null);\n  const [currentTime, setCurrentTime] = useState(0);\n  const [seekableDuration, setSeekableDuration] = useState(0);\n\n  return (\n    <View>\n      <Video\n        ref={videoRef}\n        source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }}\n        streamType=\"live\"\n        onProgress={(data) => {\n          setCurrentTime(data.currentTime);\n          setSeekableDuration(data.seekableDuration);\n        }}\n      />\n\n      {/* DVR controls */}\n      <View style={styles.controls}>\n        <Slider\n          value={currentTime}\n          maximumValue={seekableDuration}\n          onSlidingComplete={(value) => {\n            videoRef.current?.seek(value);\n          }}\n        />\n\n        <TouchableOpacity\n          onPress={() => {\n            // Jump to live edge\n            videoRef.current?.seek(seekableDuration);\n          }}\n        >\n          <Text style={styles.liveButton}>Go to LIVE</Text>\n        </TouchableOpacity>\n      </View>\n    </View>\n  );\n}\n```\n\n\n---\n\nBroadcasting from React Native\n\nBroadcasting live video from React Native is more complex than playback. Options:\n\nOption 1: Use External RTMP Apps (Recommended)\n\nThe simplest approach is to direct users to dedicated RTMP streaming apps:\n\n\n```tsx\nimport { Linking, Alert } from 'react-native';\n\nfunction StartBroadcastButton({ rtmpUrl, streamKey }: Props) {\n  const startBroadcast = () => {\n    Alert.alert(\n      'Start Broadcasting',\n      'To broadcast, you need an RTMP streaming app.',\n      [\n        {\n          text: 'Download Larix',\n          onPress: () => {\n            // Larix Broadcaster (iOS/Android)\n            Linking.openURL('https://softvelum.com/larix/');\n          },\n        },\n        {\n          text: 'Copy Stream Info',\n          onPress: () => {\n            // Copy RTMP details to clipboard\n            Clipboard.setString(`RTMP URL: ${rtmpUrl}\\nStream Key: ${streamKey}`);\n          },\n        },\n        { text: 'Cancel' },\n      ]\n    );\n  };\n\n  return (\n    <Button title=\"Start Broadcasting\" onPress={startBroadcast} />\n  );\n}\n```\n\n\nRecommended RTMP apps:\n- Larix Broadcaster (iOS/Android) - Free, professional features\n- Streamlabs (iOS/Android) - Gaming-focused, with overlays\n- OBS Mobile (iOS) - Open source streaming\n\nOption 2: WebRTC Broadcasting (Advanced)\n\nFor in-app broadcasting without external apps, use WebRTC:\n\n\n```tsx\nimport { RTCView, mediaDevices } from 'react-native-webrtc';\nimport { MuxWebRTCClient } from '@mux/webrtc-client'; // Hypothetical package\n\nfunction InAppBroadcaster({ streamId }: Props) {\n  const [localStream, setLocalStream] = useState<MediaStream | null>(null);\n\n  const startBroadcast = async () => {\n    // Get camera and mic access\n    const stream = await mediaDevices.getUserMedia({\n      video: {\n        facingMode: 'user',\n        width: 1280,\n        height: 720,\n      },\n      audio: true,\n    });\n\n    setLocalStream(stream);\n\n    // Connect to Mux via WebRTC (requires custom implementation)\n    // Note: Mux doesn't have official WebRTC ingest yet\n    // This would require a media server bridge (Janus, Jitsi, etc.)\n  };\n\n  return (\n    <View style={styles.container}>\n      {localStream && (\n        <RTCView\n          streamURL={localStream.toURL()}\n          style={styles.preview}\n        />\n      )}\n      <Button title=\"Start Broadcast\" onPress={startBroadcast} />\n    </View>\n  );\n}\n```\n\n\nWebRTC broadcasting to Mux requires a media server bridge. Mux accepts RTMP/RTMPS input. To broadcast via WebRTC, you need a media server (like Janus or Jitsi) that converts WebRTC to RTMP. This is an advanced setup.\n\nOption 3: Native Modules (Most Advanced)\n\nBridge native RTMP broadcasting libraries:\n\niOS: Use libraries like HaishinKit or LFLiveKit\nAndroid: Use rtmp-rtsp-stream-client-java\n\nThis requires building React Native native modules, which is beyond the scope of this guide. See the Native SDKs guide for bridging patterns.\n\n---\n\nLive to VOD (Recording)\n\nMux automatically records live streams as VOD assets:\n\n\n```javascript\n// Backend - Create stream with recording enabled\nconst liveStream = await mux.video.liveStreams.create({\n  playback_policy: ['public'],\n  new_asset_settings: {\n    playback_policy: ['public'], // VOD will be public\n  },\n});\n\n// After stream ends, check for created asset\napp.post('/webhooks/mux', async (req, res) => {\n  const event = req.body;\n\n  if (event.type === 'video.live_stream.recording') {\n    const assetId = event.data.asset_id;\n\n    // Save the VOD asset\n    await db.videos.create({\n      liveStreamId: event.data.id,\n      muxAssetId: assetId,\n      status: 'ready',\n      type: 'vod',\n    });\n  }\n\n  res.sendStatus(200);\n});\n```\n\n\n\n```tsx\n// React Native - Play recorded stream\nfunction RecordedStream({ assetId }: Props) {\n  const [playbackId, setPlaybackId] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Fetch playback ID from backend\n    fetch(`${API_URL}/asset/${assetId}`)\n      .then(r => r.json())\n      .then(data => setPlaybackId(data.playbackId));\n  }, [assetId]);\n\n  if (!playbackId) {\n    return <LoadingView />;\n  }\n\n  return (\n    <Video\n      source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }}\n      controls\n    />\n  );\n}\n```\n\n\n---\n\nComplete Live Stream Example\n\nHere's a full example showing live stream playback with status handling:\n\n\n```tsx\nimport React, { useState, useEffect } from 'react';\nimport { View, Text, ActivityIndicator, StyleSheet } from 'react-native';\nimport Video from 'react-native-video';\n\ninterface LiveStreamProps {\n  streamId: string;\n  playbackId: string;\n}\n\ntype StreamStatus = 'idle' | 'active' | 'disconnected';\n\nexport function LiveStreamPlayer({ streamId, playbackId }: LiveStreamProps) {\n  const [status, setStatus] = useState<StreamStatus>('idle');\n  const [viewers, setViewers] = useState(0);\n\n  // Poll for stream status\n  useEffect(() => {\n    const checkStatus = async () => {\n      try {\n        const response = await fetch(`${API_URL}/live-stream/${streamId}/status`);\n        const data = await response.json();\n        setStatus(data.status);\n      } catch (error) {\n        console.error('Failed to fetch stream status:', error);\n      }\n    };\n\n    checkStatus();\n    const interval = setInterval(checkStatus, 5000);\n\n    return () => clearInterval(interval);\n  }, [streamId]);\n\n  // Poll for live viewers\n  useEffect(() => {\n    if (status !== 'active') return;\n\n    const fetchViewers = async () => {\n      try {\n        const response = await fetch(`${API_URL}/live-stream/${streamId}/viewers`);\n        const data = await response.json();\n        setViewers(data.viewers);\n      } catch (error) {\n        console.error('Failed to fetch viewers:', error);\n      }\n    };\n\n    fetchViewers();\n    const interval = setInterval(fetchViewers, 10000);\n\n    return () => clearInterval(interval);\n  }, [streamId, status]);\n\n  // Render waiting state\n  if (status === 'idle') {\n    return (\n      <View style={styles.centerContainer}>\n        <ActivityIndicator size=\"large\" color=\"#007AFF\" />\n        <Text style={styles.statusText}>Stream will start soon...</Text>\n      </View>\n    );\n  }\n\n  // Render disconnected state\n  if (status === 'disconnected') {\n    return (\n      <View style={styles.centerContainer}>\n        <Text style={styles.statusText}>Stream temporarily disconnected</Text>\n        <Text style={styles.subText}>Reconnecting...</Text>\n      </View>\n    );\n  }\n\n  // Render active stream\n  return (\n    <View style={styles.container}>\n      <Video\n        source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }}\n        style={styles.video}\n        streamType=\"live\"\n        resizeMode=\"contain\"\n      />\n\n      {/* Live badge */}\n      <View style={styles.liveBadge}>\n        <View style={styles.liveDot} />\n        <Text style={styles.liveText}>LIVE</Text>\n      </View>\n\n      {/* Viewer count */}\n      {viewers > 0 && (\n        <View style={styles.viewerCount}>\n          <Text style={styles.viewerIcon}>👁</Text>\n          <Text style={styles.viewerText}>\n            {viewers.toLocaleString()}\n          </Text>\n        </View>\n      )}\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n    backgroundColor: '#000',\n  },\n  centerContainer: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n    backgroundColor: '#000',\n    justifyContent: 'center',\n    alignItems: 'center',\n  },\n  video: {\n    width: '100%',\n    height: '100%',\n  },\n  statusText: {\n    color: '#fff',\n    fontSize: 18,\n    fontWeight: '600',\n    marginTop: 16,\n  },\n  subText: {\n    color: '#999',\n    fontSize: 14,\n    marginTop: 8,\n  },\n  liveBadge: {\n    position: 'absolute',\n    top: 16,\n    left: 16,\n    flexDirection: 'row',\n    alignItems: 'center',\n    backgroundColor: 'rgba(255, 0, 0, 0.9)',\n    paddingHorizontal: 12,\n    paddingVertical: 6,\n    borderRadius: 4,\n  },\n  liveDot: {\n    width: 8,\n    height: 8,\n    borderRadius: 4,\n    backgroundColor: '#fff',\n    marginRight: 6,\n  },\n  liveText: {\n    color: '#fff',\n    fontWeight: 'bold',\n    fontSize: 12,\n    letterSpacing: 0.5,\n  },\n  viewerCount: {\n    position: 'absolute',\n    top: 16,\n    right: 16,\n    flexDirection: 'row',\n    alignItems: 'center',\n    backgroundColor: 'rgba(0, 0, 0, 0.6)',\n    paddingHorizontal: 12,\n    paddingVertical: 6,\n    borderRadius: 4,\n  },\n  viewerIcon: {\n    fontSize: 16,\n    marginRight: 4,\n  },\n  viewerText: {\n    color: '#fff',\n    fontSize: 14,\n    fontWeight: '600',\n  },\n});\n```\n\n\n---\n\nBest Practices\n\nFor Playback\n\n✅ Handle all stream states - idle, active, disconnected\n✅ Show \"LIVE\" badge - Make it clear this is live content\n✅ Display viewer count - Creates social proof\n✅ Test on real devices - Live streams require good network\n✅ Add buffering indicators - Live streams may buffer more than VOD\n\nFor Broadcasting\n\n✅ Recommend dedicated apps - Better UX than in-app solutions\n✅ Keep stream keys secure - Never expose in client code\n✅ Test network requirements - Live upload needs stable upload bandwidth\n✅ Provide clear instructions - Broadcasting is complex for users\n✅ Monitor stream health - Alert broadcaster if connection is poor\n\n---\n\nNext Steps\n\n  <GuideCard\n    title=\"Live Streaming Guide\"\n    description=\"Complete guide to Mux Live Stream features and concepts\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/live-streaming\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Real-time Viewer Counts\"\n    description=\"Display live viewer counts for your streams\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/get-real-time-viewer-count\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Native SDKs\"\n    description=\"Bridge native broadcasting libraries for advanced use cases\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/native-sdks\"},\n    ]}\n  />"
  },
  {
    "id": "165-_guides/frameworks/react-native-mux-data-analytics",
    "title": "Track video analytics with Mux Data",
    "path": "_guides/frameworks/react-native-mux-data-analytics.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-mux-data-analytics",
    "content": "Mux Data provides analytics for your video playback, helping you understand video performance and user engagement. This guide shows you how to integrate Mux Data with React Native and display metrics like view counts in your app.\n\n  Learn about Mux Data's full capabilities in the main documentation. This guide focuses on React Native integration.\n\nWhat Mux Data tracks\n\nMux Data automatically collects metrics about video playback:\n\n- Performance: Video startup time, buffering events, playback failures\n- Engagement: Play rate, watch time, viewer drop-off\n- Quality of Experience (QoE): Video quality scores, rebuffering ratio\n- Audience: Unique viewers, concurrent viewers, geographic data\n\nAll of this data is available in the Mux dashboard and via the Data API.\n\nSetup: Create a Mux Data environment\n\nBefore integrating, create a Data environment in your Mux dashboard:\n\n1. Go to Settings → Data Environments\n2. Create a new environment (e.g., \"Production\" or \"Slop Social\")\n3. Copy the Environment Key - you'll need this for integration\n\n  Environment keys are public and safe to use in your React Native app. They're different from API tokens, which should never be exposed in client-side code.\n\n---\n\nIntegrate Mux Data with react-native-video\n\nMux provides a wrapper for react-native-video that automatically tracks playback metrics.\n\nInstall the Mux Data SDK\n\n\n```bash\nnpm install @mux/mux-data-react-native-video\n```\n\n\nWrap your Video component\n\n\n```tsx\nimport React from 'react';\nimport { StyleSheet, Platform } from 'react-native';\nimport { Video } from 'react-native-video';\nimport muxReactNativeVideo from '@mux/mux-data-react-native-video';\n\n// Create the wrapped video component\nconst MuxVideo = muxReactNativeVideo(Video);\n\ninterface MuxVideoPlayerProps {\n  playbackId: string;\n  videoId: string;\n  videoTitle: string;\n  userId?: string;\n}\n\nexport default function MuxVideoPlayer({\n  playbackId,\n  videoId,\n  videoTitle,\n  userId,\n}: MuxVideoPlayerProps) {\n  return (\n    <MuxVideo\n      source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }}\n      style={styles.video}\n      controls\n      resizeMode=\"contain\"\n      // Mux Data configuration\n      muxOptions={{\n        application_name: Platform.OS === 'ios' ? 'Slop Social iOS' : 'Slop Social Android',\n        application_version: '1.0.0',\n        data: {\n          env_key: 'YOUR_MUX_DATA_ENV_KEY', // Get from Mux dashboard\n          video_id: videoId,\n          video_title: videoTitle,\n          viewer_user_id: userId,\n          player_name: 'React Native Video',\n          player_version: '6.0.0',\n        },\n      }}\n    />\n  );\n}\n\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n});\n```\n\n\nCustom metadata\n\nYou can track custom metadata to segment and analyze your data:\n\n\n```tsx\n<MuxVideo\n  source={{ uri: videoUrl }}\n  muxOptions={{\n    application_name: 'Slop Social',\n    application_version: '1.0.0',\n    data: {\n      env_key: process.env.MUX_DATA_ENV_KEY,\n\n      // Video metadata\n      video_id: videoId,\n      video_title: videoTitle,\n      video_series: 'AI Generated',\n      video_duration: duration,\n\n      // Viewer metadata\n      viewer_user_id: userId,\n      viewer_user_name: username,\n\n      // Player metadata\n      player_name: 'React Native Video',\n      player_version: '6.0.0',\n\n      // Custom metadata (use for filtering)\n      custom_1: 'portrait', // video orientation\n      custom_2: aiModel, // e.g., 'fal-ai', 'runway'\n      custom_3: category, // e.g., 'animals', 'nature'\n    },\n  }}\n/>\n```\n\n\n  Using Expo Video? Mux Data support for Expo Video is limited. The react-native-video integration is currently the recommended approach. Check the Mux Data documentation for updates.\n\n---\n\nView metrics in the Mux dashboard\n\nOnce integrated, view your analytics at dashboard.mux.com:\n\n- Overview: High-level metrics (plays, viewing hours, QoE scores)\n- Views: Individual viewing sessions with detailed metrics\n- Videos: Per-video performance breakdown\n- Viewers: Unique and concurrent viewer counts\n- Errors: Playback failures and error rates\n\nYou can filter by any custom metadata you've set (video_id, viewer_user_id, custom fields).\n\n  Explore the Mux Data dashboard guide for details on interpreting metrics.\n\n---\n\nDisplay view counts in your app\n\nTo show view counts and engagement metrics in your React Native app, use the Mux Data API. Since API credentials should never be exposed in client code, proxy requests through your backend.\n\nBackend: Fetch view count\n\n\n```javascript\n// Backend: Node.js + Mux SDK\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux({\n  tokenId: process.env.MUX_TOKEN_ID,\n  tokenSecret: process.env.MUX_TOKEN_SECRET,\n});\n\n// API endpoint: GET /api/videos/:videoId/views\nexport async function getVideoViews(req, res) {\n  const { videoId } = req.params;\n\n  try {\n    // Query Mux Data API for views filtered by video_id\n    const response = await mux.data.metrics.breakdown('views', {\n      filters: [`video_id:${videoId}`],\n      timeframe: ['30:days'], // Last 30 days\n    });\n\n    const viewCount = response.total_row_count || 0;\n\n    res.json({ videoId, viewCount });\n  } catch (error) {\n    console.error('Failed to fetch view count:', error);\n    res.status(500).json({ error: 'Failed to fetch views' });\n  }\n}\n```\n\n\n  The Data API has a rate limit of 5 requests per second. Cache results when possible to avoid hitting limits. See the Data API reference for details.\n\nReact Native: Display view count\n\n\n```tsx\nimport React, { useEffect, useState } from 'react';\nimport { View, Text, StyleSheet } from 'react-native';\n\ninterface ViewCountProps {\n  videoId: string;\n}\n\nexport function ViewCount({ videoId }: ViewCountProps) {\n  const [viewCount, setViewCount] = useState<number | null>(null);\n  const [loading, setLoading] = useState(true);\n\n  useEffect(() => {\n    const fetchViewCount = async () => {\n      try {\n        const response = await fetch(\n          `https://your-api.com/videos/${videoId}/views`\n        );\n        const data = await response.json();\n        setViewCount(data.viewCount);\n      } catch (error) {\n        console.error('Failed to fetch view count:', error);\n      } finally {\n        setLoading(false);\n      }\n    };\n\n    fetchViewCount();\n  }, [videoId]);\n\n  if (loading || viewCount === null) {\n    return null;\n  }\n\n  return (\n    <View style={styles.container}>\n      <Text style={styles.count}>\n        {formatViewCount(viewCount)} views\n      </Text>\n    </View>\n  );\n}\n\nfunction formatViewCount(count: number): string {\n  if (count >= 1000000) {\n    return `${(count / 1000000).toFixed(1)}M`;\n  }\n  if (count >= 1000) {\n    return `${(count / 1000).toFixed(1)}K`;\n  }\n  return count.toString();\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    paddingVertical: 5,\n  },\n  count: {\n    fontSize: 14,\n    color: '#666',\n    fontWeight: '500',\n  },\n});\n```\n\n\n---\n\nDisplay real-time viewers\n\nShow how many people are watching a video right now.\n\nBackend: Get real-time viewer count\n\n\n```javascript\n// Backend: Node.js + Mux SDK\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux({\n  tokenId: process.env.MUX_TOKEN_ID,\n  tokenSecret: process.env.MUX_TOKEN_SECRET,\n});\n\n// For signed URLs, you need signing keys\nconst signingKeyId = process.env.MUX_SIGNING_KEY_ID;\nconst signingKeySecret = process.env.MUX_SIGNING_PRIVATE_KEY;\n\n// API endpoint: GET /api/videos/:playbackId/live-viewers\nexport async function getLiveViewers(req, res) {\n  const { playbackId } = req.params;\n\n  try {\n    // Generate signed token for viewer counts\n    const token = Mux.JWT.signViewerCounts(playbackId, {\n      keyId: signingKeyId,\n      keySecret: signingKeySecret,\n      type: 'video',\n    });\n\n    // Fetch real-time viewer count\n    const response = await fetch(`https://stats.mux.com/counts?token=${token}`);\n    const data = await response.json();\n\n    const liveViewers = data.data?.[0]?.views || 0;\n\n    res.json({ playbackId, liveViewers });\n  } catch (error) {\n    console.error('Failed to fetch live viewers:', error);\n    res.status(500).json({ error: 'Failed to fetch live viewers' });\n  }\n}\n```\n\n\n  Real-time viewer counts require Mux Data signing keys. Create them in your Mux dashboard settings.\n\nReact Native: Display live viewers\n\n\n```tsx\nimport React, { useEffect, useState } from 'react';\nimport { View, Text, StyleSheet } from 'react-native';\n\ninterface LiveViewersProps {\n  playbackId: string;\n  refreshInterval?: number; // milliseconds\n}\n\nexport function LiveViewers({\n  playbackId,\n  refreshInterval = 15000, // Refresh every 15 seconds\n}: LiveViewersProps) {\n  const [liveViewers, setLiveViewers] = useState<number>(0);\n\n  useEffect(() => {\n    const fetchLiveViewers = async () => {\n      try {\n        const response = await fetch(\n          `https://your-api.com/videos/${playbackId}/live-viewers`\n        );\n        const data = await response.json();\n        setLiveViewers(data.liveViewers);\n      } catch (error) {\n        console.error('Failed to fetch live viewers:', error);\n      }\n    };\n\n    fetchLiveViewers();\n\n    const interval = setInterval(fetchLiveViewers, refreshInterval);\n\n    return () => clearInterval(interval);\n  }, [playbackId, refreshInterval]);\n\n  if (liveViewers === 0) {\n    return null;\n  }\n\n  return (\n    <View style={styles.container}>\n      <View style={styles.dot} />\n      <Text style={styles.text}>\n        {liveViewers} {liveViewers === 1 ? 'viewer' : 'viewers'} watching\n      </Text>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flexDirection: 'row',\n    alignItems: 'center',\n    paddingVertical: 5,\n  },\n  dot: {\n    width: 8,\n    height: 8,\n    borderRadius: 4,\n    backgroundColor: '#ff0000',\n    marginRight: 6,\n  },\n  text: {\n    fontSize: 12,\n    color: '#666',\n    fontWeight: '500',\n  },\n});\n```\n\n\n  Don't poll the real-time viewers endpoint more frequently than every 15-30 seconds. More frequent requests won't provide meaningfully different results and may hit rate limits.\n\n---\n\nComplete video card with analytics\n\nCombine view counts and live viewers in a video card:\n\n\n```tsx\nimport React from 'react';\nimport { View, Text, StyleSheet, TouchableOpacity } from 'react-native';\nimport { MuxVideo } from './MuxVideoPlayer';\nimport { ViewCount } from './ViewCount';\nimport { LiveViewers } from './LiveViewers';\n\ninterface VideoCardProps {\n  videoId: string;\n  playbackId: string;\n  title: string;\n  username: string;\n  userId?: string;\n  onPress?: () => void;\n}\n\nexport default function VideoCard({\n  videoId,\n  playbackId,\n  title,\n  username,\n  userId,\n  onPress,\n}: VideoCardProps) {\n  return (\n    <TouchableOpacity style={styles.container} onPress={onPress}>\n      <MuxVideo\n        playbackId={playbackId}\n        videoId={videoId}\n        videoTitle={title}\n        userId={userId}\n      />\n\n      <View style={styles.info}>\n        <Text style={styles.title} numberOfLines={2}>\n          {title}\n        </Text>\n        <Text style={styles.username}>@{username}</Text>\n\n        <View style={styles.stats}>\n          <ViewCount videoId={videoId} />\n          <LiveViewers playbackId={playbackId} />\n        </View>\n      </View>\n    </TouchableOpacity>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    marginBottom: 20,\n  },\n  info: {\n    padding: 15,\n  },\n  title: {\n    fontSize: 16,\n    fontWeight: 'bold',\n    marginBottom: 5,\n  },\n  username: {\n    fontSize: 14,\n    color: '#666',\n    marginBottom: 10,\n  },\n  stats: {\n    flexDirection: 'row',\n    alignItems: 'center',\n    gap: 15,\n  },\n});\n```\n\n\n---\n\nCustom hook for video analytics\n\nCreate a reusable hook for fetching video analytics:\n\n\n```tsx\nimport { useEffect, useState } from 'react';\n\ninterface VideoAnalytics {\n  viewCount: number;\n  liveViewers: number;\n  loading: boolean;\n  error: string | null;\n}\n\nexport function useVideoAnalytics(\n  videoId: string,\n  playbackId: string,\n  options?: {\n    enableLiveViewers?: boolean;\n    refreshInterval?: number;\n  }\n): VideoAnalytics {\n  const [viewCount, setViewCount] = useState(0);\n  const [liveViewers, setLiveViewers] = useState(0);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState<string | null>(null);\n\n  const enableLiveViewers = options?.enableLiveViewers ?? true;\n  const refreshInterval = options?.refreshInterval ?? 30000;\n\n  useEffect(() => {\n    const fetchAnalytics = async () => {\n      try {\n        // Fetch view count\n        const viewsResponse = await fetch(\n          `https://your-api.com/videos/${videoId}/views`\n        );\n        const viewsData = await viewsResponse.json();\n        setViewCount(viewsData.viewCount);\n\n        // Fetch live viewers if enabled\n        if (enableLiveViewers) {\n          const liveResponse = await fetch(\n            `https://your-api.com/videos/${playbackId}/live-viewers`\n          );\n          const liveData = await liveResponse.json();\n          setLiveViewers(liveData.liveViewers);\n        }\n\n        setLoading(false);\n      } catch (err) {\n        setError('Failed to load analytics');\n        setLoading(false);\n      }\n    };\n\n    fetchAnalytics();\n\n    // Refresh live viewers periodically\n    if (enableLiveViewers) {\n      const interval = setInterval(fetchAnalytics, refreshInterval);\n      return () => clearInterval(interval);\n    }\n  }, [videoId, playbackId, enableLiveViewers, refreshInterval]);\n\n  return { viewCount, liveViewers, loading, error };\n}\n```\n\n\nUsage:\n\n\n```tsx\nfunction VideoScreen({ videoId, playbackId }: Props) {\n  const { viewCount, liveViewers, loading } = useVideoAnalytics(\n    videoId,\n    playbackId\n  );\n\n  return (\n    <View>\n      <MuxVideo playbackId={playbackId} videoId={videoId} />\n      {!loading && (\n        <View>\n          <Text>{viewCount} views</Text>\n          {liveViewers > 0 && (\n            <Text>{liveViewers} watching now</Text>\n          )}\n        </View>\n      )}\n    </View>\n  );\n}\n```\n\n\n---\n\nCache view counts\n\nTo reduce API calls and improve performance, cache view counts in your database:\n\nUpdate view counts periodically (backend)\n\n\n```javascript\n// Backend: Scheduled job (runs every hour)\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux({\n  tokenId: process.env.MUX_TOKEN_ID,\n  tokenSecret: process.env.MUX_TOKEN_SECRET,\n});\n\nasync function updateAllViewCounts() {\n  const videos = await db.videos.findMany({\n    where: { status: 'ready' },\n  });\n\n  for (const video of videos) {\n    try {\n      const response = await mux.data.metrics.breakdown('views', {\n        filters: [`video_id:${video.id}`],\n        timeframe: ['30:days'],\n      });\n\n      const viewCount = response.total_row_count || 0;\n\n      await db.videos.update({\n        where: { id: video.id },\n        data: { viewCount, viewCountUpdatedAt: new Date() },\n      });\n    } catch (error) {\n      console.error(`Failed to update views for ${video.id}:`, error);\n    }\n\n    // Rate limit: wait 250ms between requests (4 req/sec)\n    await new Promise((resolve) => setTimeout(resolve, 250));\n  }\n}\n```\n\n\nThen fetch from your database instead of Mux API:\n\n\n```typescript\n// React Native\nconst response = await fetch(`https://your-api.com/videos/${videoId}`);\nconst video = await response.json();\nconst viewCount = video.viewCount; // From database, not Mux API\n```\n\n\n  Mux Data retains views for 30 days (or 90 days on higher tiers). For longer-term view counts, regularly export data to your database. See data retention and exports for details.\n\n---\n\nDebugging with Mux Data\n\nUse Mux Data to debug playback issues:\n\nIdentify problem videos\n\n\n```javascript\n// Backend: Find videos with high error rates\nconst response = await mux.data.metrics.breakdown('video-startup-failure-percentage', {\n  group_by: 'video_id',\n  timeframe: ['7:days'],\n  order_direction: 'desc',\n  limit: 10,\n});\n\n// Videos with most playback failures\nconst problematicVideos = response.data;\n```\n\n\nCheck individual viewing sessions\n\nIn the Mux dashboard:\n1. Go to Data → Views\n2. Filter by video_id or viewer_user_id\n3. Click on a session to see detailed metrics\n4. Look for errors, buffering events, quality issues\n\nThis helps you understand if issues are:\n- Video-specific (encoding problem)\n- User-specific (network/device issue)\n- Platform-specific (iOS vs Android)\n\n---\n\nBest practices\n\n1. Always set custom metadata\n\n\n```tsx\n<MuxVideo\n  muxOptions={{\n    data: {\n      env_key: MUX_ENV_KEY,\n      video_id: videoId, // Required for filtering\n      viewer_user_id: userId, // Required for per-user analytics\n      video_title: title, // Helpful for dashboard\n      // Add more metadata as needed\n    },\n  }}\n/>\n```\n\n\n2. Use consistent IDs\n\n- video_id should match your database ID\n- viewer_user_id should match your auth system\n- Use the same IDs across playback and Data API queries\n\n3. Cache expensive queries\n\n- View counts change slowly - cache for 5-15 minutes\n- Real-time viewers can update every 15-30 seconds\n- Store aggregated metrics in your database\n\n4. Rate limit awareness\n\n- Data API: 5 requests/second max\n- Viewer counts: Don't poll more than every 15-30 seconds\n- Batch queries when possible\n\n5. Monitor QoE scores\n\nTrack Quality of Experience scores to ensure good playback:\n- 90-100: Excellent\n- 75-90: Good\n- Below 75: Needs investigation\n\n  Learn more about Quality of Experience (QoE) scores in the main docs.\n\n---\n\nNext Steps\n\n  <GuideCard\n    title=\"Build a Stories UI\"\n    description=\"Create an Instagram Stories or TikTok-style vertical video feed with analytics\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/stories-reels-ui\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Video playback deep dive\"\n    description=\"Learn advanced player patterns and error handling techniques\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/video-playback\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Best practices\"\n    description=\"Optimize your React Native video app for production\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/best-practices\"},\n    ]}\n  />"
  },
  {
    "id": "166-_guides/frameworks/react-native-native-sdks",
    "title": "Bridging Native Mux SDKs",
    "path": "_guides/frameworks/react-native-native-sdks.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-native-sdks",
    "content": "Bridging Native Mux SDKs\n\nThis guide covers when and how to bridge native Mux SDKs (iOS/Android) into your React Native app. Most developers won't need this - JavaScript solutions work great for 95% of use cases. But if you need advanced features or maximum performance, native bridging is an option.\n\nStart with JavaScript first. Only consider native bridging if you have specific needs that can't be met with react-native-video and the patterns in this documentation.\n\nWhen to Use Native SDKs\n\nConsider native Mux SDKs when you need:\n\nAdvanced Features\n- DRM (Digital Rights Management) - Full FairPlay (iOS) and Widevine (Android) support\n- Advanced analytics - Native Mux Data integration with more detailed metrics\n- Picture-in-picture - Better PiP support than JavaScript solutions\n- Background playback - Robust background audio/video\n- Offline playback - Download and play DRM-protected content offline\n\nPerformance\n- Lower overhead - Native video rendering without JavaScript bridge\n- Better memory management - Native memory handling for large video apps\n- Smoother playback - Fewer dropped frames on older devices\n\nNative Features\n- AirPlay (iOS) - Seamless AirPlay integration\n- Cast (Android) - Chromecast support\n- System controls - Native lock screen controls\n- Closed captions - Native caption rendering\n\nWhen NOT to Use Native SDKs\n\n❌ Don't use native SDKs if:\n- Your JavaScript solution works fine\n- You don't need DRM\n- You want to avoid native development complexity\n- Your team lacks iOS/Android experience\n- You want easier maintenance and updates\n\n✅ Stick with react-native-video if:\n- Basic playback meets your needs\n- You're using public or signed playback (no DRM)\n- You want simpler codebases\n- You need to ship quickly\n- Cross-platform consistency is important\n\n95% of React Native video apps work great with react-native-video. Only invest in native bridging if you have specific requirements that justify the added complexity.\n\n---\n\nAvailable Native SDKs\n\nMux Player iOS\n\nFeatures:\n- Native AVPlayer with Mux optimizations\n- Full DRM support (FairPlay)\n- Picture-in-picture\n- AirPlay\n- Native Mux Data integration\n\nGitHub: github.com/muxinc/mux-player-ios\n\nInstallation (if bridging):\n\n```ruby\n# ios/Podfile\npod 'MuxPlayerSwift', '~> 2.0'\n```\n\n\n---\n\nMux Player Android\n\nFeatures:\n- Native ExoPlayer with Mux optimizations\n- Full DRM support (Widevine)\n- Picture-in-picture\n- Chromecast support\n- Native Mux Data integration\n\nGitHub: github.com/muxinc/mux-player-android\n\nInstallation (if bridging):\n\n```gradle\n// android/app/build.gradle\ndependencies {\n    implementation 'com.mux:stats-muxplayer:1.0.0'\n}\n```\n\n\n---\n\nMux Uploader iOS\n\nFeatures:\n- Chunked uploads with resume capability\n- Background uploads\n- Client-side transcoding\n- Progress tracking\n\nGitHub: github.com/muxinc/mux-uploader-ios\n\n---\n\nMux Uploader Android\n\nFeatures:\n- Chunked uploads with resume capability\n- Background uploads\n- Progress tracking\n\nGitHub: github.com/muxinc/mux-uploader-android\n\n---\n\nCreating a Native Module\n\nBridging native Mux SDKs requires creating React Native native modules. Here's a high-level overview:\n\nArchitecture\n\n\n```\nJavaScript (React Native)\n    ↕ (Bridge)\nNative Module (Objective-C/Swift or Java/Kotlin)\n    ↓\nNative Mux SDK (iOS/Android)\n```\n\n\nExample: Bridging Mux Player iOS\n\nStep 1: Create Native Module (ios/MuxPlayerModule.swift)\n\n\n```swift\nimport Foundation\nimport MuxPlayerSwift\nimport React\n\n@objc(MuxPlayerModule)\nclass MuxPlayerModule: RCTEventEmitter {\n\n  var player: MuxPlayer?\n\n  @objc\n  func initializePlayer(\n    _ playbackId: String,\n    resolver: @escaping RCTPromiseResolveBlock,\n    rejecter: @escaping RCTPromiseRejectBlock\n  ) {\n    DispatchQueue.main.async {\n      // Initialize Mux Player\n      let playerView = MuxPlayerView()\n      playerView.playbackId = playbackId\n\n      self.player = playerView.player\n\n      // Set up event listeners\n      self.setupPlayerListeners()\n\n      resolver([\"success\": true])\n    }\n  }\n\n  @objc\n  func play(\n    _ resolver: @escaping RCTPromiseResolveBlock,\n    rejecter: @escaping RCTPromiseRejectBlock\n  ) {\n    player?.play()\n    resolver([\"playing\": true])\n  }\n\n  @objc\n  func pause(\n    _ resolver: @escaping RCTPromiseResolveBlock,\n    rejecter: @escaping RCTPromiseRejectBlock\n  ) {\n    player?.pause()\n    resolver([\"playing\": false])\n  }\n\n  private func setupPlayerListeners() {\n    // Listen for player events and send to JavaScript\n    NotificationCenter.default.addObserver(\n      self,\n      selector: #selector(playerDidFinishPlaying),\n      name: .AVPlayerItemDidPlayToEndTime,\n      object: player?.currentItem\n    )\n  }\n\n  @objc\n  private func playerDidFinishPlaying() {\n    sendEvent(withName: \"onVideoEnd\", body: [:])\n  }\n\n  // Required for RCTEventEmitter\n  override func supportedEvents() -> [String]! {\n    return [\"onVideoEnd\", \"onProgress\", \"onError\"]\n  }\n\n  override static func requiresMainQueueSetup() -> Bool {\n    return true\n  }\n}\n```\n\n\nStep 2: Bridge to JavaScript (ios/MuxPlayerModule.m)\n\n\n```objc\n#import <React/RCTBridgeModule.h>\n#import <React/RCTEventEmitter.h>\n\n@interface RCT_EXTERN_MODULE(MuxPlayerModule, RCTEventEmitter)\n\nRCT_EXTERN_METHOD(\n  initializePlayer:(NSString *)playbackId\n  resolver:(RCTPromiseResolveBlock)resolve\n  rejecter:(RCTPromiseRejectBlock)reject\n)\n\nRCT_EXTERN_METHOD(\n  play:(RCTPromiseResolveBlock)resolve\n  rejecter:(RCTPromiseRejectBlock)reject\n)\n\nRCT_EXTERN_METHOD(\n  pause:(RCTPromiseResolveBlock)resolve\n  rejecter:(RCTPromiseRejectBlock)reject\n)\n\n@end\n```\n\n\nStep 3: Create React Native Component\n\n\n```tsx\n// MuxPlayer.tsx\nimport { NativeModules, NativeEventEmitter, requireNativeComponent } from 'react-native';\n\nconst { MuxPlayerModule } = NativeModules;\nconst MuxPlayerView = requireNativeComponent('MuxPlayerView');\n\ninterface MuxPlayerProps {\n  playbackId: string;\n  onVideoEnd?: () => void;\n  onProgress?: (progress: number) => void;\n  onError?: (error: Error) => void;\n}\n\nexport function MuxPlayer({ playbackId, onVideoEnd, onProgress, onError }: MuxPlayerProps) {\n  useEffect(() => {\n    // Initialize player\n    MuxPlayerModule.initializePlayer(playbackId);\n\n    // Set up event listeners\n    const eventEmitter = new NativeEventEmitter(MuxPlayerModule);\n\n    const endListener = eventEmitter.addListener('onVideoEnd', () => {\n      onVideoEnd?.();\n    });\n\n    const progressListener = eventEmitter.addListener('onProgress', (event) => {\n      onProgress?.(event.currentTime);\n    });\n\n    const errorListener = eventEmitter.addListener('onError', (event) => {\n      onError?.(new Error(event.message));\n    });\n\n    return () => {\n      endListener.remove();\n      progressListener.remove();\n      errorListener.remove();\n    };\n  }, [playbackId]);\n\n  return (\n    <MuxPlayerView\n      style={{ width: '100%', height: 300 }}\n      playbackId={playbackId}\n    />\n  );\n}\n\n// Export native methods\nexport const MuxPlayerAPI = {\n  play: () => MuxPlayerModule.play(),\n  pause: () => MuxPlayerModule.pause(),\n};\n```\n\n\nStep 4: Use in React Native\n\n\n```tsx\nimport { MuxPlayer, MuxPlayerAPI } from './MuxPlayer';\n\nexport function VideoScreen() {\n  const playbackId = 'EcHgOK9coz5K4rjSwOkoE7Y7O01201YMIC200RI6lNxnhs';\n\n  return (\n    <View>\n      <MuxPlayer\n        playbackId={playbackId}\n        onVideoEnd={() => console.log('Video ended')}\n        onProgress={(time) => console.log('Progress:', time)}\n      />\n\n      <Button title=\"Play\" onPress={() => MuxPlayerAPI.play()} />\n      <Button title=\"Pause\" onPress={() => MuxPlayerAPI.pause()} />\n    </View>\n  );\n}\n```\n\n\n---\n\nBridging Complexity\n\nCreating native bridges involves:\n\niOS (Swift/Objective-C)\n- ✅ Swift/Objective-C knowledge required\n- ✅ Understanding of AVPlayer and AVKit\n- ✅ React Native bridging APIs\n- ✅ Memory management and threading\n- ✅ CocoaPods for dependencies\n- ⏱ Time investment: 1-2 weeks for full implementation\n\nAndroid (Kotlin/Java)\n- ✅ Kotlin/Java knowledge required\n- ✅ Understanding of ExoPlayer\n- ✅ React Native bridging APIs\n- ✅ Activity lifecycle management\n- ✅ Gradle for dependencies\n- ⏱ Time investment: 1-2 weeks for full implementation\n\nMaintenance\n- Regular updates to match native SDK releases\n- Testing on both platforms for each change\n- Handling breaking changes in React Native or native SDKs\n- Debugging across JavaScript ↔ Native bridge\n\n---\n\nAlternative: Use Expo Modules\n\nFor Expo users, Expo Modules provides a better developer experience:\n\n\n```typescript\n// MuxPlayerModule.ts (Expo Module)\nimport { requireNativeViewManager } from 'expo-modules-core';\nimport { ViewProps } from 'react-native';\n\nexport interface MuxPlayerViewProps extends ViewProps {\n  playbackId: string;\n  onVideoEnd?: () => void;\n}\n\nexport default requireNativeViewManager<MuxPlayerViewProps>('MuxPlayer');\n```\n\n\nExpo Modules offer:\n- Better TypeScript support\n- Easier native module creation\n- Cleaner bridging APIs\n- Built-in event handling\n\nLearn more: Expo Modules Documentation\n\n---\n\nPros and Cons\n\nPros of Native Bridging\n\n✅ Access to advanced features - DRM, PiP, native controls\n✅ Better performance - Direct native rendering\n✅ Platform features - AirPlay, Chromecast, system integration\n✅ More control - Fine-grained control over player behavior\n✅ Offline support - DRM-protected offline playback\n\nCons of Native Bridging\n\n❌ Increased complexity - Two codebases (iOS + Android)\n❌ Maintenance burden - Keep native modules updated\n❌ Harder debugging - Debug across JavaScript and native layers\n❌ Slower iteration - Native changes require rebuilds\n❌ Team requirements - Need iOS and Android developers\n❌ Risk of bugs - More code = more potential issues\n\n---\n\nDecision Framework\n\nUse this decision tree to determine if you need native bridging:\n\n\n```\nDo you need DRM?\n├─ Yes → Consider native bridging\n└─ No → Do you need advanced features (PiP, AirPlay, Chromecast)?\n    ├─ Yes → Consider native bridging\n    └─ No → Do you have performance issues with react-native-video?\n        ├─ Yes → Try optimization first, then consider native\n        └─ No → **Stick with react-native-video** ✅\n```\n\n\nQuestions to ask:\n1. Can I achieve this with react-native-video?\n2. Have I exhausted optimization options?\n3. Do I have iOS/Android developers on the team?\n4. Is the added complexity worth it?\n5. Can I maintain this long-term?\n\nIf you answered \"no\" to questions 3, 4, or 5, stick with JavaScript solutions.\n\n---\n\nThird-Party Solutions\n\nBefore building your own bridge, check for existing solutions:\n\nReact Native Video DRM\nSome community packages add DRM support to react-native-video:\n- react-native-video (has basic DRM support built-in)\n- Check npm for DRM extensions\n\nExpo Video\nExpo's video package includes some native features:\n- expo-av - Basic native video support\n- Works in Expo Go\n- No custom bridge needed\n\nCommercial Solutions\n- Bitmovin Player - Commercial player with React Native SDK\n- THEOplayer - Another commercial option\n- Often include support and maintenance\n\n---\n\nResources\n\nOfficial Documentation\n- Mux Player iOS\n- Mux Player Android\n- React Native Native Modules (iOS)\n- React Native Native Modules (Android)\n- Expo Modules\n\nTutorials\n- Building Native Modules for React Native\n- React Native Bridging Tutorial\n- Expo Modules Tutorial\n\n---\n\nRecommendation\n\nFor most React Native + Mux apps:\n\n1. Start with react-native-video ✅\n   - Covers 95% of use cases\n   - Simple to implement\n   - Easy to maintain\n\n2. Optimize JavaScript first\n   - Follow Best Practices guide\n   - Profile and fix performance issues\n   - Consider caching and preloading\n\n3. Only consider native bridging if:\n   - You absolutely need DRM\n   - JavaScript performance is insufficient after optimization\n   - You have iOS/Android developers available\n   - You're prepared for ongoing maintenance\n\n4. If you do bridge:\n   - Start with Expo Modules if using Expo\n   - Focus on one platform first (iOS or Android)\n   - Thoroughly document your bridge code\n   - Set up comprehensive tests\n   - Plan for long-term maintenance\n\n---\n\nNext Steps\n\n  <GuideCard\n    title=\"Best Practices\"\n    description=\"Optimize your JavaScript solution before considering native bridging\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/best-practices\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Example App\"\n    description=\"See a complete implementation using JavaScript solutions\"\n    links={[\n      {title: \"View the example\", href: \"/docs/guides/react-native/example-app\"},\n    ]}\n  />\n  <GuideCard\n    title=\"React Native Native Modules\"\n    description=\"Official React Native documentation for building native modules\"\n    links={[\n      {title: \"Read the docs\", href: \"https://reactnative.dev/docs/native-modules-intro\"},\n    ]}\n  />"
  },
  {
    "id": "167-_guides/frameworks/react-native-quickstart",
    "title": "Play video in React Native",
    "path": "_guides/frameworks/react-native-quickstart.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-quickstart",
    "content": "Mux delivers video using HLS (HTTP Live Streaming), which is natively supported on both iOS and Android. To play Mux videos in React Native, you'll use expo-video, a cross-platform, performant video component with native support for React Native and Expo.\n\nInstall the package using your preferred package manager:\n\n\n```bash\n# npm\nnpm install expo-video\n\n# yarn\nyarn add expo-video\n\n# pnpm\npnpm add expo-video\n```\n\n\n  This guide assumes you're using Expo. If you're using bare React Native without Expo, you'll need to install the expo package first and configure your project for Expo modules. See the Expo documentation for details.\n\nFor iOS in a bare workflow, install the native dependencies:\n\n\n```bash\ncd ios && pod install && cd ..\n```\n\n\nCreate a new file called components/video-player.tsx in your project and add the following code. You'll need a Mux playback ID to construct the video URL.\n\nIf you don't have a video in Mux yet, you can use this demo playback ID for testing: OfjbQ3esQifgboENTs4oDXslCP5sSnst\n\n\n```tsx\nimport React from 'react';\nimport { StyleSheet, View } from 'react-native';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nexport default function VideoPlayer() {\n  // Replace with your own playback ID from https://dashboard.mux.com\n  const playbackId = 'OfjbQ3esQifgboENTs4oDXslCP5sSnst';\n  const videoSource = `https://stream.mux.com/${playbackId}.m3u8`;\n\n  const player = useVideoPlayer(videoSource, (player) => {\n    player.loop = false;\n    player.play();\n  });\n\n  return (\n    <View style={styles.container}>\n      <VideoView\n        player={player}\n        style={styles.video}\n        allowsFullscreen\n        allowsPictureInPicture\n        nativeControls\n        contentFit=\"contain\"\n      />\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n    justifyContent: 'center',\n    alignItems: 'center',\n    backgroundColor: '#000',\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n});\n```\n\n\nUnderstanding the video URL\n\nMux videos are streamed using the format:\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8\n```\n\n\n- {PLAYBACK_ID} is the unique identifier for your video\n- .m3u8 is the HLS manifest file format\n\n  New to Mux? Learn about playback IDs and creating video assets in the main Mux docs.\n\nImport and use the VideoPlayer component in your app. If you used create-expo-app, you'll likely find your main screen at app/(tabs)/index.tsx or app/index.tsx. Import and add the component:\n\n\n```tsx\nimport VideoPlayer from '@/components/video-player';\n\nexport default function HomeScreen() {\n  return <VideoPlayer />;\n}\n```\n\n\nThen run your app:\n\n\n```bash\n# Start Expo dev server\nnpx expo start\n\n# Press 'i' for iOS or 'a' for Android\n# Or scan the QR code with Expo Go\n```\n\n\nYou should see your video playing with native controls! The video will stream using HLS with adaptive bitrate, automatically adjusting quality based on the viewer's network conditions.\n\nCommon next steps\n\nNow that you have basic playback working, here are some common things you'll want to do:\n\nAdd a poster image (thumbnail)\n\nMux provides thumbnails for your videos using the same playback ID. Display a poster image that the user taps to start playback:\n\n\n```tsx highlight=1-2 add=6,9,16-19,31-39,55-59 remove=13\nimport React, { useState } from 'react';\nimport { StyleSheet, View, Image, Pressable } from 'react-native';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nexport default function VideoPlayer() {\n  const [showPoster, setShowPoster] = useState(true);\n  const playbackId = 'OfjbQ3esQifgboENTs4oDXslCP5sSnst';\n  const videoSource = `https://stream.mux.com/${playbackId}.m3u8`;\n  const posterSource = `https://image.mux.com/${playbackId}/thumbnail.png?time=0`;\n\n  const player = useVideoPlayer(videoSource, (player) => {\n    player.loop = false;\n    // Don't autoplay - wait for user to tap poster\n  });\n\n  const handlePosterPress = () => {\n    setShowPoster(false);\n    player.play();\n  };\n\n  return (\n    <View style={styles.container}>\n      <VideoView\n        player={player}\n        style={styles.video}\n        allowsFullscreen\n        allowsPictureInPicture\n        nativeControls\n        contentFit=\"contain\"\n      />\n      {showPoster && (\n        <Pressable onPress={handlePosterPress} style={styles.poster}>\n          <Image\n            source={{ uri: posterSource }}\n            style={styles.poster}\n            resizeMode=\"cover\"\n          />\n        </Pressable>\n      )}\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n    justifyContent: 'center',\n    alignItems: 'center',\n    backgroundColor: '#000',\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  poster: {\n    position: 'absolute',\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n});\n```\n\n\nThe thumbnail URL format is:\n\n\n```\nhttps://image.mux.com/{PLAYBACK_ID}/thumbnail.png?time={SECONDS}\n```\n\n\nSet time to capture a frame at a specific timestamp (e.g., time=5 for 5 seconds in).\n\nHandle player events\n\nTrack loading, playback progress, and errors using expo-video's event system:\n\n\n```tsx highlight=2 add=3,13,16-40,44-46,55-63,79-94\nimport React from 'react';\nimport { StyleSheet, View, Text, ActivityIndicator } from 'react-native';\nimport { useEvent } from 'expo';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nexport default function VideoPlayer() {\n  const playbackId = 'OfjbQ3esQifgboENTs4oDXslCP5sSnst';\n  const videoSource = `https://stream.mux.com/${playbackId}.m3u8`;\n\n  const player = useVideoPlayer(videoSource, (player) => {\n    player.loop = false;\n    player.play();\n    player.timeUpdateEventInterval = 0.5; // Update time every 0.5 seconds\n  });\n\n  // Listen to status changes (loading, readyToPlay, error)\n  const { status, error } = useEvent(player, 'statusChange', {\n    status: player.status,\n  });\n\n  // Listen to playback progress\n  const timeUpdate = useEvent(player, 'timeUpdate');\n  const currentTime = timeUpdate?.currentTime ?? 0;\n\n  // Listen to playing state changes\n  const { isPlaying } = useEvent(player, 'playingChange', {\n    isPlaying: player.playing,\n  });\n\n  if (status === 'error' && error) {\n    return (\n      <View style={styles.container}>\n        <Text style={styles.errorText}>Failed to load video: {error.message}</Text>\n      </View>\n    );\n  }\n\n  return (\n    <View style={styles.container}>\n      {status === 'loading' && (\n        <ActivityIndicator size=\"large\" color=\"#fff\" style={styles.loader} />\n      )}\n      <VideoView\n        player={player}\n        style={styles.video}\n        allowsFullscreen\n        allowsPictureInPicture\n        nativeControls\n        contentFit=\"contain\"\n      />\n      <View style={styles.info}>\n        <Text style={styles.infoText}>Status: {status}</Text>\n        <Text style={styles.infoText}>\n          Time: {Math.floor(currentTime)}s / {Math.floor(player.duration)}s\n        </Text>\n        <Text style={styles.infoText}>\n          {isPlaying ? 'Playing' : 'Paused'}\n        </Text>\n      </View>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n    justifyContent: 'center',\n    alignItems: 'center',\n    backgroundColor: '#000',\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  loader: {\n    position: 'absolute',\n  },\n  info: {\n    marginTop: 20,\n    padding: 10,\n  },\n  infoText: {\n    color: '#fff',\n    fontSize: 14,\n    marginBottom: 5,\n  },\n  errorText: {\n    color: '#fff',\n    fontSize: 16,\n  },\n});\n```\n\n\nSupport different aspect ratios\n\nFor portrait videos (like Stories or Reels), adjust the aspect ratio in your styles:\n\n\n```tsx highlight=4\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 9 / 16, // Portrait mode\n  },\n});\n```\n\n\nPlatform considerations\n\niOS vs Android\n\nBoth iOS and Android have native HLS support, so expo-video works seamlessly on both platforms. However, there are a few differences to be aware of:\n\n- iOS: HLS playback is handled by AVPlayer\n- Android: HLS playback uses ExoPlayer (Media3)\n- Web: Uses HTML5 video with HLS.js for HLS support\n\nThese differences are handled automatically by expo-video, but you may notice slight variations in buffering behavior or UI controls across platforms.\n\nExpo Go limitations\n\nexpo-video works with Expo Go for basic playback, but for advanced features like Picture-in-Picture or background playback, you'll need to create a development build.\n\n  Features like Picture-in-Picture (allowsPictureInPicture) and background playback require configuration through the config plugin and a custom development build. These features will not work in Expo Go.\n\nConfiguration\n\nTo enable advanced features, add the expo-video config plugin to your app.json:\n\n\n```json\n{\n  \"expo\": {\n    \"plugins\": [\n      [\n        \"expo-video\",\n        {\n          \"supportsBackgroundPlayback\": true,\n          \"supportsPictureInPicture\": true\n        }\n      ]\n    ]\n  }\n}\n```\n\n\nAfter adding the config plugin, rebuild your app with eas build or npx expo run:ios/npx expo run:android.\n\nWhat you've learned\n\nYou now know how to:\n- Install and set up expo-video\n- Create a video player using the useVideoPlayer hook\n- Play Mux videos using playback IDs\n- Display poster images (thumbnails)\n- Handle player events with the useEvent hook (status, progress, playback state)\n- Adjust for different aspect ratios\n- Configure advanced features like Picture-in-Picture\n\nNext Steps\n\n  <GuideCard\n    title=\"Video playback deep dive\"\n    description=\"Learn about managing video state, custom controls, error handling, and optimizing playback in React Native\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/frameworks/react-native-video-playback\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Upload videos to Mux\"\n    description=\"Learn how to upload videos from React Native or ingest videos from URLs for AI-generated content\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/frameworks/react-native-uploading-videos\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Build a Stories UI\"\n    description=\"Create an Instagram Stories or TikTok-style vertical video feed with swipe navigation\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/frameworks/react-native-stories-reels-ui\"},\n    ]}\n  />"
  },
  {
    "id": "168-_guides/frameworks/react-native-stories-reels-ui",
    "title": "Build a Stories/Reels UI in React Native",
    "path": "_guides/frameworks/react-native-stories-reels-ui.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-stories-reels-ui",
    "content": "This guide shows you how to build a vertical, full-screen video feed similar to Instagram Stories, TikTok, or Snapchat Spotlight. Users swipe up and down to navigate between videos, with automatic playback and gesture controls.\n\n  This is one of the most engaging UX patterns for short-form video. It's perfect for AI-generated content, user stories, or any vertical video feed.\n\nWhat we're building\n\nA Stories-style interface with:\n- Full-screen vertical videos (one video visible at a time)\n- Swipe navigation (swipe up/down to see next/previous video)\n- Auto-play (current video plays automatically)\n- Gesture controls (tap to pause, double-tap to like)\n- UI overlay (username, caption, stats, actions)\n- Smooth transitions between videos\n- Preloading for seamless playback\n\n---\n\nArchitecture overview\n\nThe Stories UI uses these key components:\n\n\n```\nStoriesScreen\n  ├── FlatList (pagingEnabled, vertical)\n  │   └── StoryItem (full-screen video + overlay)\n  │       ├── MuxVideo (with auto-play logic)\n  │       ├── VideoOverlay (username, stats, actions)\n  │       └── GestureDetector (tap, double-tap)\n  └── PreloadManager (loads next videos)\n```\n\n\n---\n\nStep 1: Configure FlatList for full-screen paging\n\nThe foundation is a FlatList configured for vertical paging:\n\n\n```tsx\nimport React, { useRef, useState, useCallback } from 'react';\nimport {\n  FlatList,\n  Dimensions,\n  StyleSheet,\n  ViewToken,\n  View,\n} from 'react-native';\n\nconst { height: SCREEN_HEIGHT } = Dimensions.get('window');\n\ninterface Video {\n  id: string;\n  playbackId: string;\n  title: string;\n  username: string;\n  userId: string;\n  viewCount: number;\n  likeCount: number;\n}\n\ninterface StoriesFeedProps {\n  videos: Video[];\n}\n\nexport default function StoriesFeed({ videos }: StoriesFeedProps) {\n  const [currentIndex, setCurrentIndex] = useState(0);\n  const flatListRef = useRef<FlatList>(null);\n\n  const onViewableItemsChanged = useCallback(\n    ({ viewableItems }: { viewableItems: ViewToken[] }) => {\n      if (viewableItems.length > 0) {\n        const index = viewableItems[0].index;\n        if (index !== null) {\n          setCurrentIndex(index);\n        }\n      }\n    },\n    []\n  );\n\n  const viewabilityConfig = useRef({\n    itemVisiblePercentThreshold: 50, // Item is \"visible\" when 50% is on screen\n  }).current;\n\n  return (\n    <FlatList\n      ref={flatListRef}\n      data={videos}\n      renderItem={({ item, index }) => (\n        <StoryItem\n          video={item}\n          isActive={index === currentIndex}\n        />\n      )}\n      keyExtractor={(item) => item.id}\n      pagingEnabled\n      showsVerticalScrollIndicator={false}\n      snapToInterval={SCREEN_HEIGHT}\n      snapToAlignment=\"start\"\n      decelerationRate=\"fast\"\n      onViewableItemsChanged={onViewableItemsChanged}\n      viewabilityConfig={viewabilityConfig}\n      getItemLayout={(data, index) => ({\n        length: SCREEN_HEIGHT,\n        offset: SCREEN_HEIGHT * index,\n        index,\n      })}\n      windowSize={3} // Render 1 above, 1 current, 1 below\n      maxToRenderPerBatch={2}\n      removeClippedSubviews\n    />\n  );\n}\n```\n\n\nKey FlatList props\n\n| Prop | Purpose |\n|------|---------|\n| pagingEnabled | Snaps to full screens |\n| snapToInterval={SCREEN_HEIGHT} | Ensures exact screen alignment |\n| snapToAlignment=\"start\" | Aligns to top of screen |\n| decelerationRate=\"fast\" | Quick snap to next video |\n| windowSize={3} | Renders 3 items (prev, current, next) |\n| getItemLayout | Optimizes scroll performance |\n| removeClippedSubviews | Unmounts off-screen items (memory optimization) |\n\n---\n\nStep 2: Build the StoryItem component\n\nEach story item is a full-screen video with controls:\n\n\n```tsx\nimport React, { useRef, useState, useEffect } from 'react';\nimport { View, StyleSheet, Dimensions, Pressable } from 'react-native';\nimport Video, { VideoRef } from 'react-native-video';\nimport { Gesture, GestureDetector } from 'react-native-gesture-handler';\n\nconst { width: SCREEN_WIDTH, height: SCREEN_HEIGHT } = Dimensions.get('window');\n\ninterface StoryItemProps {\n  video: Video;\n  isActive: boolean;\n}\n\nexport function StoryItem({ video, isActive }: StoryItemProps) {\n  const videoRef = useRef<VideoRef>(null);\n  const [paused, setPaused] = useState(!isActive);\n  const [liked, setLiked] = useState(false);\n\n  // Auto-play when active, pause when not\n  useEffect(() => {\n    setPaused(!isActive);\n  }, [isActive]);\n\n  // Single tap: pause/play\n  const singleTap = Gesture.Tap()\n    .numberOfTaps(1)\n    .onEnd(() => {\n      setPaused((prev) => !prev);\n    });\n\n  // Double tap: like\n  const doubleTap = Gesture.Tap()\n    .numberOfTaps(2)\n    .onEnd(() => {\n      setLiked(true);\n      // TODO: Call API to like video\n    });\n\n  const taps = Gesture.Exclusive(doubleTap, singleTap);\n\n  return (\n    <View style={styles.container}>\n      <GestureDetector gesture={taps}>\n        <View style={styles.videoContainer}>\n          <Video\n            ref={videoRef}\n            source={{ uri: `https://stream.mux.com/${video.playbackId}.m3u8` }}\n            poster={`https://image.mux.com/${video.playbackId}/thumbnail.png?time=0`}\n            posterResizeMode=\"cover\"\n            style={styles.video}\n            paused={paused}\n            repeat={true} // Loop the video\n            resizeMode=\"cover\"\n            onError={(error) => console.error('Video error:', error)}\n          />\n\n          {/* Overlay UI */}\n          <VideoOverlay\n            username={video.username}\n            title={video.title}\n            viewCount={video.viewCount}\n            likeCount={video.likeCount}\n            liked={liked}\n            onLike={() => setLiked(!liked)}\n          />\n\n          {/* Like animation (shown on double-tap) */}\n          {liked && <LikeAnimation />}\n        </View>\n      </GestureDetector>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    width: SCREEN_WIDTH,\n    height: SCREEN_HEIGHT,\n    backgroundColor: '#000',\n  },\n  videoContainer: {\n    flex: 1,\n    position: 'relative',\n  },\n  video: {\n    position: 'absolute',\n    top: 0,\n    left: 0,\n    right: 0,\n    bottom: 0,\n  },\n});\n```\n\n\n  Install gesture handler if you haven't already:\n\n```bash\n  npx expo install react-native-gesture-handler\n  ```\n\n\n---\n\nStep 3: Create the video overlay\n\nThe overlay displays video metadata and actions:\n\n\n```tsx\nimport React from 'react';\nimport { View, Text, StyleSheet, TouchableOpacity } from 'react-native';\nimport { LinearGradient } from 'expo-linear-gradient';\n\ninterface VideoOverlayProps {\n  username: string;\n  title: string;\n  viewCount: number;\n  likeCount: number;\n  liked: boolean;\n  onLike: () => void;\n}\n\nexport function VideoOverlay({\n  username,\n  title,\n  viewCount,\n  likeCount,\n  liked,\n  onLike,\n}: VideoOverlayProps) {\n  return (\n    <>\n      {/* Top gradient for better text readability */}\n      <LinearGradient\n        colors={['rgba(0,0,0,0.6)', 'transparent']}\n        style={styles.topGradient}\n      />\n\n      {/* Bottom gradient and content */}\n      <LinearGradient\n        colors={['transparent', 'rgba(0,0,0,0.8)']}\n        style={styles.bottomGradient}\n      >\n        <View style={styles.bottomContent}>\n          {/* Left side: User info and caption */}\n          <View style={styles.leftContent}>\n            <Text style={styles.username}>@{username}</Text>\n            <Text style={styles.title} numberOfLines={2}>\n              {title}\n            </Text>\n            <Text style={styles.views}>\n              {formatNumber(viewCount)} views\n            </Text>\n          </View>\n\n          {/* Right side: Actions */}\n          <View style={styles.rightContent}>\n            <ActionButton\n              icon={liked ? '❤️' : '🤍'}\n              label={formatNumber(likeCount)}\n              onPress={onLike}\n            />\n            <ActionButton\n              icon=\"💬\"\n              label=\"Comment\"\n              onPress={() => {/* TODO */}}\n            />\n            <ActionButton\n              icon=\"🔗\"\n              label=\"Share\"\n              onPress={() => {/* TODO */}}\n            />\n          </View>\n        </View>\n      </LinearGradient>\n    </>\n  );\n}\n\nfunction ActionButton({\n  icon,\n  label,\n  onPress,\n}: {\n  icon: string;\n  label: string;\n  onPress: () => void;\n}) {\n  return (\n    <TouchableOpacity style={styles.actionButton} onPress={onPress}>\n      <Text style={styles.actionIcon}>{icon}</Text>\n      <Text style={styles.actionLabel}>{label}</Text>\n    </TouchableOpacity>\n  );\n}\n\nfunction formatNumber(num: number): string {\n  if (num >= 1000000) return `${(num / 1000000).toFixed(1)}M`;\n  if (num >= 1000) return `${(num / 1000).toFixed(1)}K`;\n  return num.toString();\n}\n\nconst styles = StyleSheet.create({\n  topGradient: {\n    position: 'absolute',\n    top: 0,\n    left: 0,\n    right: 0,\n    height: 150,\n    zIndex: 1,\n  },\n  bottomGradient: {\n    position: 'absolute',\n    bottom: 0,\n    left: 0,\n    right: 0,\n    paddingBottom: 40,\n    zIndex: 1,\n  },\n  bottomContent: {\n    flexDirection: 'row',\n    padding: 20,\n    justifyContent: 'space-between',\n    alignItems: 'flex-end',\n  },\n  leftContent: {\n    flex: 1,\n    marginRight: 20,\n  },\n  username: {\n    color: '#fff',\n    fontSize: 16,\n    fontWeight: 'bold',\n    marginBottom: 5,\n  },\n  title: {\n    color: '#fff',\n    fontSize: 14,\n    marginBottom: 8,\n  },\n  views: {\n    color: 'rgba(255,255,255,0.7)',\n    fontSize: 12,\n  },\n  rightContent: {\n    alignItems: 'center',\n    gap: 20,\n  },\n  actionButton: {\n    alignItems: 'center',\n  },\n  actionIcon: {\n    fontSize: 32,\n    marginBottom: 4,\n  },\n  actionLabel: {\n    color: '#fff',\n    fontSize: 12,\n    fontWeight: '500',\n  },\n});\n```\n\n\n---\n\nStep 4: Add like animation\n\nShow a heart animation when users double-tap:\n\n\n```tsx\nimport React, { useEffect } from 'react';\nimport { StyleSheet } from 'react-native';\nimport Animated, {\n  useSharedValue,\n  useAnimatedStyle,\n  withSpring,\n  withSequence,\n  runOnJS,\n} from 'react-native-reanimated';\n\nexport function LikeAnimation({ onComplete }: { onComplete?: () => void }) {\n  const scale = useSharedValue(0);\n  const opacity = useSharedValue(1);\n\n  useEffect(() => {\n    scale.value = withSequence(\n      withSpring(1.2, { damping: 10 }),\n      withSpring(1, { damping: 10 }),\n      withSpring(0, { damping: 10 }, () => {\n        if (onComplete) {\n          runOnJS(onComplete)();\n        }\n      })\n    );\n\n    opacity.value = withSequence(\n      withSpring(1),\n      withSpring(1),\n      withSpring(0)\n    );\n  }, []);\n\n  const animatedStyle = useAnimatedStyle(() => ({\n    transform: [{ scale: scale.value }],\n    opacity: opacity.value,\n  }));\n\n  return (\n    <Animated.View style={[styles.container, animatedStyle]}>\n      <Animated.Text style={styles.heart}>❤️</Animated.Text>\n    </Animated.View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    position: 'absolute',\n    top: '50%',\n    left: '50%',\n    marginLeft: -50,\n    marginTop: -50,\n    zIndex: 10,\n  },\n  heart: {\n    fontSize: 100,\n  },\n});\n```\n\n\n---\n\nStep 5: Add progress indicator\n\nShow progress at the top (like Instagram Stories):\n\n\n```tsx\nimport React, { useEffect } from 'react';\nimport { View, StyleSheet, Dimensions } from 'react-native';\nimport Animated, {\n  useSharedValue,\n  useAnimatedStyle,\n  withTiming,\n  Easing,\n} from 'react-native-reanimated';\n\nconst { width: SCREEN_WIDTH } = Dimensions.get('window');\n\ninterface ProgressIndicatorProps {\n  duration: number; // Video duration in seconds\n  paused: boolean;\n}\n\nexport function ProgressIndicator({ duration, paused }: ProgressIndicatorProps) {\n  const progress = useSharedValue(0);\n\n  useEffect(() => {\n    if (!paused) {\n      progress.value = withTiming(1, {\n        duration: duration * 1000,\n        easing: Easing.linear,\n      });\n    }\n  }, [paused, duration]);\n\n  const animatedStyle = useAnimatedStyle(() => ({\n    width: `${progress.value * 100}%`,\n  }));\n\n  return (\n    <View style={styles.container}>\n      <Animated.View style={[styles.progress, animatedStyle]} />\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    position: 'absolute',\n    top: 50, // Below status bar\n    left: 0,\n    right: 0,\n    height: 2,\n    backgroundColor: 'rgba(255,255,255,0.3)',\n    zIndex: 10,\n  },\n  progress: {\n    height: '100%',\n    backgroundColor: '#fff',\n  },\n});\n```\n\n\n---\n\nStep 6: Preload adjacent videos\n\nPreload the next video for seamless transitions:\n\n\n```tsx\nimport { useEffect } from 'react';\nimport Video from 'react-native-video';\n\ninterface PreloadManagerProps {\n  videos: Video[];\n  currentIndex: number;\n}\n\nexport function PreloadManager({ videos, currentIndex }: PreloadManagerProps) {\n  useEffect(() => {\n    // Preload next video\n    const nextIndex = currentIndex + 1;\n    if (nextIndex < videos.length) {\n      const nextVideo = videos[nextIndex];\n      // Create hidden video component to trigger preload\n      Video.preload(`https://stream.mux.com/${nextVideo.playbackId}.m3u8`);\n    }\n\n    // Optionally preload previous video\n    const prevIndex = currentIndex - 1;\n    if (prevIndex >= 0) {\n      const prevVideo = videos[prevIndex];\n      Video.preload(`https://stream.mux.com/${prevVideo.playbackId}.m3u8`);\n    }\n  }, [currentIndex, videos]);\n\n  return null;\n}\n```\n\n\n  HLS streaming means videos don't need to fully download before playing. Preloading just fetches the manifest and initial segments for instant startup.\n\n---\n\nComplete StoriesFeed implementation\n\nPutting it all together:\n\n\n```tsx\nimport React, { useRef, useState, useCallback, useEffect } from 'react';\nimport {\n  FlatList,\n  Dimensions,\n  StyleSheet,\n  ViewToken,\n  View,\n  StatusBar,\n} from 'react-native';\nimport Video, { VideoRef } from 'react-native-video';\nimport { Gesture, GestureDetector } from 'react-native-gesture-handler';\nimport Animated, { FadeIn, FadeOut } from 'react-native-reanimated';\nimport { SafeAreaView } from 'react-native-safe-area-context';\n\nconst { width: SCREEN_WIDTH, height: SCREEN_HEIGHT } = Dimensions.get('window');\n\ninterface Video {\n  id: string;\n  playbackId: string;\n  title: string;\n  username: string;\n  userId: string;\n  viewCount: number;\n  likeCount: number;\n  duration: number;\n}\n\ninterface StoriesFeedProps {\n  videos: Video[];\n  initialIndex?: number;\n}\n\nexport default function StoriesFeed({ videos, initialIndex = 0 }: StoriesFeedProps) {\n  const [currentIndex, setCurrentIndex] = useState(initialIndex);\n  const flatListRef = useRef<FlatList>(null);\n\n  // Hide status bar for full-screen experience\n  useEffect(() => {\n    StatusBar.setHidden(true);\n    return () => StatusBar.setHidden(false);\n  }, []);\n\n  const onViewableItemsChanged = useCallback(\n    ({ viewableItems }: { viewableItems: ViewToken[] }) => {\n      if (viewableItems.length > 0) {\n        const index = viewableItems[0].index;\n        if (index !== null && index !== currentIndex) {\n          setCurrentIndex(index);\n        }\n      }\n    },\n    [currentIndex]\n  );\n\n  const viewabilityConfig = useRef({\n    itemVisiblePercentThreshold: 50,\n  }).current;\n\n  const renderItem = useCallback(\n    ({ item, index }: { item: Video; index: number }) => {\n      const isActive = index === currentIndex;\n      return <StoryItem video={item} isActive={isActive} />;\n    },\n    [currentIndex]\n  );\n\n  return (\n    <SafeAreaView style={styles.container} edges={['top']}>\n      <FlatList\n        ref={flatListRef}\n        data={videos}\n        renderItem={renderItem}\n        keyExtractor={(item) => item.id}\n        pagingEnabled\n        showsVerticalScrollIndicator={false}\n        snapToInterval={SCREEN_HEIGHT}\n        snapToAlignment=\"start\"\n        decelerationRate=\"fast\"\n        onViewableItemsChanged={onViewableItemsChanged}\n        viewabilityConfig={viewabilityConfig}\n        getItemLayout={(data, index) => ({\n          length: SCREEN_HEIGHT,\n          offset: SCREEN_HEIGHT * index,\n          index,\n        })}\n        windowSize={3}\n        maxToRenderPerBatch={2}\n        removeClippedSubviews\n        initialScrollIndex={initialIndex}\n      />\n\n      {/* Preload adjacent videos */}\n      <PreloadManager videos={videos} currentIndex={currentIndex} />\n    </SafeAreaView>\n  );\n}\n\nfunction StoryItem({ video, isActive }: { video: Video; isActive: boolean }) {\n  const videoRef = useRef<VideoRef>(null);\n  const [paused, setPaused] = useState(!isActive);\n  const [liked, setLiked] = useState(false);\n  const [showLikeAnimation, setShowLikeAnimation] = useState(false);\n\n  useEffect(() => {\n    setPaused(!isActive);\n  }, [isActive]);\n\n  const singleTap = Gesture.Tap()\n    .numberOfTaps(1)\n    .onEnd(() => {\n      setPaused((prev) => !prev);\n    });\n\n  const doubleTap = Gesture.Tap()\n    .numberOfTaps(2)\n    .onEnd(() => {\n      if (!liked) {\n        setLiked(true);\n        setShowLikeAnimation(true);\n        // TODO: Call API to like video\n      }\n    });\n\n  const taps = Gesture.Exclusive(doubleTap, singleTap);\n\n  return (\n    <View style={styles.storyContainer}>\n      <GestureDetector gesture={taps}>\n        <View style={styles.videoWrapper}>\n          <Video\n            ref={videoRef}\n            source={{ uri: `https://stream.mux.com/${video.playbackId}.m3u8` }}\n            poster={`https://image.mux.com/${video.playbackId}/thumbnail.png?time=0`}\n            posterResizeMode=\"cover\"\n            style={styles.video}\n            paused={paused}\n            repeat\n            resizeMode=\"cover\"\n            onError={(error) => console.error('Video error:', error)}\n          />\n\n          {/* Progress indicator */}\n          {isActive && (\n            <ProgressIndicator duration={video.duration} paused={paused} />\n          )}\n\n          {/* Overlay */}\n          <VideoOverlay\n            username={video.username}\n            title={video.title}\n            viewCount={video.viewCount}\n            likeCount={video.likeCount}\n            liked={liked}\n            onLike={() => setLiked(!liked)}\n          />\n\n          {/* Like animation */}\n          {showLikeAnimation && (\n            <Animated.View\n              entering={FadeIn}\n              exiting={FadeOut}\n              style={StyleSheet.absoluteFill}\n            >\n              <LikeAnimation\n                onComplete={() => setShowLikeAnimation(false)}\n              />\n            </Animated.View>\n          )}\n        </View>\n      </GestureDetector>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n    backgroundColor: '#000',\n  },\n  storyContainer: {\n    width: SCREEN_WIDTH,\n    height: SCREEN_HEIGHT,\n  },\n  videoWrapper: {\n    flex: 1,\n    position: 'relative',\n  },\n  video: {\n    position: 'absolute',\n    top: 0,\n    left: 0,\n    right: 0,\n    bottom: 0,\n  },\n});\n```\n\n\n---\n\nPerformance optimization\n\n1. Memory management\n\n\n```tsx\n// Clean up videos when they're far from view\nconst [loadedVideos, setLoadedVideos] = useState<Set<number>>(new Set([0]));\n\nconst onViewableItemsChanged = useCallback(\n  ({ viewableItems }: { viewableItems: ViewToken[] }) => {\n    const visibleIndices = viewableItems.map(item => item.index).filter(Boolean);\n\n    // Load current + adjacent\n    const indicesToLoad = new Set([\n      ...visibleIndices,\n      ...visibleIndices.map(i => i - 1),\n      ...visibleIndices.map(i => i + 1),\n    ].filter(i => i >= 0 && i < videos.length));\n\n    setLoadedVideos(indicesToLoad);\n  },\n  [videos.length]\n);\n\n// In renderItem:\nif (!loadedVideos.has(index)) {\n  return <VideoPlaceholder />;\n}\n```\n\n\n2. Use React.memo\n\n\n```tsx\nconst StoryItem = React.memo(\n  ({ video, isActive }: StoryItemProps) => {\n    // ... component code\n  },\n  (prevProps, nextProps) => {\n    return (\n      prevProps.video.id === nextProps.video.id &&\n      prevProps.isActive === nextProps.isActive\n    );\n  }\n);\n```\n\n\n3. Optimize re-renders\n\n\n```tsx\n// Use useCallback for all event handlers\nconst handleLike = useCallback(() => {\n  // API call\n}, []);\n\nconst handleShare = useCallback(() => {\n  // Share logic\n}, []);\n```\n\n\n---\n\nAdvanced features\n\nHorizontal swipe for user navigation\n\nAdd horizontal swipes to jump between users:\n\n\n```tsx\nconst panGesture = Gesture.Pan()\n  .onEnd((event) => {\n    if (Math.abs(event.translationX) > 100) {\n      if (event.translationX > 0) {\n        // Swipe right - previous user\n        goToPreviousUser();\n      } else {\n        // Swipe left - next user\n        goToNextUser();\n      }\n    }\n  });\n```\n\n\nMultiple videos per user\n\nTrack user stories and show progress bars:\n\n\n```tsx\n<View style={styles.progressBars}>\n  {userVideos.map((video, index) => (\n    <ProgressBar\n      key={video.id}\n      filled={index < currentVideoIndex}\n      active={index === currentVideoIndex}\n    />\n  ))}\n</View>\n```\n\n\nMute toggle\n\n\n```tsx\nconst [muted, setMuted] = useState(false);\n\n<Video\n  source={videoSource}\n  muted={muted}\n/>\n\n<TouchableOpacity onPress={() => setMuted(!muted)}>\n  <Text>{muted ? '🔇' : '🔊'}</Text>\n</TouchableOpacity>\n```\n\n\n---\n\nBest practices\n\n1. Handle video errors gracefully\n\n\n```tsx\nconst [error, setError] = useState(false);\n\n<Video\n  source={videoSource}\n  onError={() => setError(true)}\n/>\n\n{error && (\n  <View style={styles.errorOverlay}>\n    <Text>Video unavailable</Text>\n    <Button title=\"Skip\" onPress={skipToNext} />\n  </View>\n)}\n```\n\n\n2. Respect device orientation\n\n\n```tsx\nimport { useOrientation } from './hooks/useOrientation';\n\nconst orientation = useOrientation();\n\n// Only show Stories UI in portrait mode\nif (orientation === 'landscape') {\n  return <Text>Please rotate your device</Text>;\n}\n```\n\n\n3. Pause on app background\n\n\n```tsx\nimport { AppState } from 'react-native';\n\nuseEffect(() => {\n  const subscription = AppState.addEventListener('change', (nextAppState) => {\n    if (nextAppState !== 'active') {\n      setPaused(true);\n    }\n  });\n\n  return () => subscription.remove();\n}, []);\n```\n\n\n4. Test on real devices\n\nStories UI requires testing on physical devices:\n- Gesture responsiveness varies between simulator and device\n- Video performance is better on real hardware\n- Test on both iOS and Android\n- Test on different screen sizes\n\n  The iOS simulator and Android emulator don't accurately represent real-device video performance. Always test Stories UI on physical devices before shipping.\n\n---\n\nTroubleshooting\n\nVideos don't auto-play\n\n- Check isActive prop is updating correctly\n- Verify paused state changes when isActive changes\n- Ensure onViewableItemsChanged fires (add console.log)\n\nStuttering between videos\n\n- Increase windowSize to preload more videos\n- Verify getItemLayout is set correctly\n- Enable removeClippedSubviews for memory management\n- Check network conditions (poor network = stuttering)\n\nHigh memory usage\n\n- Reduce windowSize (default is 3, ideal for Stories)\n- Use removeClippedSubviews={true}\n- Implement video unloading for far-away items\n- Monitor with Xcode Instruments / Android Profiler\n\nGestures not working\n\n- Wrap root component with `\n- Check react-native-gesture-handler` is installed correctly\n- Verify gesture detector wraps the video container"
  },
  {
    "id": "169-_guides/frameworks/react-native-troubleshooting",
    "title": "Troubleshooting & FAQ",
    "path": "_guides/frameworks/react-native-troubleshooting.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-troubleshooting",
    "content": "Troubleshooting & FAQ\n\nThis guide covers common issues you might encounter when integrating Mux with React Native, along with frequently asked questions.\n\nCommon Issues\n\nVideo Won't Play\n\nSymptom: Video component renders but nothing plays, or you see a black screen.\n\nSolutions:\n\n1. Check if asset is ready\n\n```tsx\n   // Verify asset status before displaying\n   if (video.status !== 'ready') {\n     return <LoadingView />;\n   }\n   ```\n\n\n2. Verify playback ID is correct\n\n```tsx\n   // Check the URL format\n   const playbackUrl = `https://stream.mux.com/${playbackId}.m3u8`;\n   console.log('Playing:', playbackUrl);\n   ```\n\n\n3. Check network connectivity\n\n```tsx\n   import NetInfo from '@react-native-community/netinfo';\n\n   NetInfo.fetch().then(state => {\n     console.log('Connection type:', state.type);\n     console.log('Is connected?', state.isConnected);\n   });\n   ```\n\n\n4. Test on real device\n   - iOS Simulator may have codec limitations\n   - Android Emulator often has video decoding issues\n   - Always test on actual hardware for video playback\n\nThe Android Emulator frequently has issues with HLS video playback. If videos won't play in the emulator but work in your code, test on a real Android device before debugging further.\n\nPlayback Errors\n\nSymptom: Video fails to load with error codes or messages.\n\nSolutions:\n\n1. Invalid playback ID error\n\n```tsx\n   // Error: \"Cannot load m3u8\"\n   // Check if playback ID exists and is correct\n   const handleError = (error: any) => {\n     console.error('Playback error:', error);\n     // Check Mux Dashboard to verify asset exists\n   };\n   ```\n\n\n2. Asset not ready yet\n\n```tsx\n   // Asset is still processing\n   if (video.status === 'preparing') {\n     return (\n       <View>\n         <ActivityIndicator />\n         <Text>Video is processing...</Text>\n       </View>\n     );\n   }\n   ```\n\n\n3. Signed URL expired\n\n```tsx\n   // If using signed playback IDs, tokens expire\n   const isTokenExpired = (url: string) => {\n     const params = new URLSearchParams(url.split('?')[1]);\n     const exp = params.get('exp');\n     if (exp) {\n       return Date.now() / 1000 > parseInt(exp);\n     }\n     return false;\n   };\n\n   // Regenerate token if expired\n   if (isTokenExpired(signedUrl)) {\n     const newUrl = await fetchNewSignedUrl(playbackId);\n     setVideoUrl(newUrl);\n   }\n   ```\n\n\n4. CORS issues with signed playback\n\n```tsx\n   // Signed URLs must include correct audience (aud)\n   // Backend code:\n   const token = Mux.JWT.signPlaybackId(playbackId, {\n     keyId: signingKeyId,\n     keySecret: signingKeySecret,\n     expiration: '7d',\n     params: {\n       // Ensure audience matches your domain/app\n     },\n   });\n   ```\n\n\nUpload Failures\n\nSymptom: Video uploads fail or hang indefinitely.\n\nSolutions:\n\n1. File size too large\n\n```tsx\n   const MAX_FILE_SIZE = 500 * 1024 * 1024; // 500MB recommended for mobile\n\n   const validateFileSize = async (uri: string) => {\n     const fileInfo = await FileSystem.getInfoAsync(uri);\n     if (fileInfo.size > MAX_FILE_SIZE) {\n       throw new Error('File size exceeds 500MB limit');\n     }\n   };\n   ```\n\n\n2. Network interruption\n\n```tsx\n   // Implement retry logic for uploads\n   const uploadWithRetry = async (uploadUrl: string, fileUri: string, maxRetries = 3) => {\n     for (let i = 0; i < maxRetries; i++) {\n       try {\n         const result = await FileSystem.uploadAsync(uploadUrl, fileUri, {\n           httpMethod: 'PUT',\n           uploadType: FileSystem.FileSystemUploadType.BINARY_CONTENT,\n         });\n\n         if (result.status === 200) {\n           return result;\n         }\n       } catch (error) {\n         if (i === maxRetries - 1) throw error;\n         // Wait before retrying (exponential backoff)\n         await new Promise(resolve => setTimeout(resolve, Math.pow(2, i) * 1000));\n       }\n     }\n   };\n   ```\n\n\n3. Upload URL expired\n\n```tsx\n   // Direct upload URLs expire after 48 hours\n   // Always generate fresh URLs right before uploading\n   const { uploadUrl } = await fetch('/api/generate-upload-url').then(r => r.json());\n   // Use immediately\n   await uploadVideo(uploadUrl, videoUri);\n   ```\n\n\n4. Invalid file format\n\n```tsx\n   const SUPPORTED_FORMATS = ['mp4', 'mov', 'avi', 'mkv', 'webm'];\n\n   const validateFileFormat = (uri: string) => {\n     const extension = uri.split('.').pop()?.toLowerCase();\n     if (!extension || !SUPPORTED_FORMATS.includes(extension)) {\n       throw new Error(`Unsupported format: ${extension}`);\n     }\n   };\n   ```\n\n\nPerformance Issues\n\nSymptom: App is slow, videos lag, or device gets hot.\n\nSolutions:\n\n1. Memory leaks in FlatList\n\n```tsx\n   // Problem: Rendering too many videos at once\n   <FlatList\n     data={videos}\n     windowSize={3} // Only render 3 screens worth (1 above, current, 1 below)\n     maxToRenderPerBatch={2}\n     removeClippedSubviews={true}\n   />\n   ```\n\n\n2. Too many videos rendering simultaneously\n\n```tsx\n   // Problem: Multiple videos playing at once\n   const [currentIndex, setCurrentIndex] = useState(0);\n\n   <FlatList\n     data={videos}\n     renderItem={({ item, index }) => (\n       <VideoItem\n         video={item}\n         // Only play the visible video\n         paused={index !== currentIndex}\n       />\n     )}\n   />\n   ```\n\n\n3. Not cleaning up video refs\n\n```tsx\n   // Always cleanup in useEffect\n   useEffect(() => {\n     return () => {\n       if (videoRef.current) {\n         videoRef.current.dismissFullscreenPlayer?.();\n         videoRef.current = null;\n       }\n     };\n   }, []);\n   ```\n\n\n4. Unnecessary re-renders\n\n```tsx\n   // Use React.memo to prevent re-renders\n   const VideoItem = React.memo(({ video, isActive }) => {\n     return <Video source={{ uri: video.url }} paused={!isActive} />;\n   }, (prev, next) => {\n     // Only re-render if these props change\n     return prev.video.id === next.video.id && prev.isActive === next.isActive;\n   });\n   ```\n\n\nPlatform-Specific Issues\n\niOS Simulator vs Device\n\nIssue: Videos play on device but not in simulator (or vice versa).\n\nSolution:\n- iOS Simulator uses macOS codecs, which may differ from device\n- Always test on real iOS devices for accurate results\n- Simulator performance is not representative of device performance\n\n\n```tsx\nimport { Platform } from 'react-native';\n\nif (__DEV__ && Platform.OS === 'ios') {\n  console.warn('Testing on iOS simulator. Video performance may differ on device.');\n}\n```\n\n\nAndroid Codec Support\n\nIssue: Videos work on some Android devices but not others.\n\nSolution:\n- Different Android manufacturers have different codec support\n- HLS (.m3u8) is widely supported, but specific codecs vary\n- Mux automatically encodes videos in multiple formats for compatibility\n\n\n```tsx\n// Check codec support (if needed)\nimport { Platform } from 'react-native';\n\nif (Platform.OS === 'android') {\n  console.log('Android version:', Platform.Version);\n  // Android 4.1+ supports HLS natively\n}\n```\n\n\nMux automatically creates multiple renditions of your videos with different codecs to ensure maximum compatibility across devices. You don't need to worry about codec support - just use the .m3u8 URL.\n\nExpo Go Limitations\n\nIssue: Some features don't work in Expo Go app.\n\nSolution:\n- Expo Go has limitations with custom native modules\n- Basic video playback works fine\n- For advanced features (background video, picture-in-picture), use Expo dev client\n\n\n```bash\n# Create Expo development build\nnpx expo install expo-dev-client\nnpx expo run:ios\nnpx expo run:android\n```\n\n\nLearn more: Expo Development Builds\n\nFrequently Asked Questions\n\nDoes Mux work with Expo?\n\nYes! Mux works great with both Expo and bare React Native apps.\n\nFor video playback, you can use:\n- react-native-video (works in Expo)\n- expo-av (native Expo video package)\n\n\n```tsx\n// With react-native-video (recommended)\nimport Video from 'react-native-video';\n\n<Video source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }} />\n\n// Or with expo-av\nimport { Video } from 'expo-av';\n\n<Video source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }} />\n```\n\n\nMux Data (analytics) officially supports react-native-video. If using expo-av, you may need custom integration for analytics.\n\nCan I use Expo Go?\n\nYes for basic video playback. No for some advanced features.\n\nWorks in Expo Go:\n- Video playback with react-native-video\n- HLS streaming\n- Basic controls\n- Thumbnails\n\nRequires Expo dev client:\n- Background video playback\n- Picture-in-picture\n- Some native features\n- Full Mux Data integration\n\nRecommendation: Start with Expo Go for development, switch to dev client when needed.\n\nDoes react-native-video support HLS?\n\nYes! react-native-video has native HLS support on both iOS and Android.\n\n\n```tsx\nimport Video from 'react-native-video';\n\n// HLS works natively - no special configuration needed\n<Video\n  source={{ uri: 'https://stream.mux.com/PLAYBACK_ID.m3u8' }}\n  controls={true}\n/>\n```\n\n\nHLS features that work automatically:\n- Adaptive bitrate streaming (ABR)\n- Multiple quality levels\n- Automatic quality switching based on network\n- Seeking and scrubbing\n\nHow do I handle offline playback?\n\nMux streams are online-only by default. For offline playback:\n\nOption 1: Download MP4 renditions (static files)\n- Enable MP4 support in Mux (check MP4 renditions guide)\n- Download MP4 to device using react-native-fs or expo-file-system\n- Play local file\n\n\n```tsx\nimport * as FileSystem from 'expo-file-system';\n\n// Download video\nconst downloadVideo = async (mp4Url: string, videoId: string) => {\n  const fileUri = `${FileSystem.documentDirectory}${videoId}.mp4`;\n  const download = await FileSystem.downloadAsync(mp4Url, fileUri);\n  return download.uri;\n};\n\n// Play offline video\n<Video source={{ uri: localFileUri }} />\n```\n\n\nOption 2: Consider DRM requirements\n- If you need DRM-protected offline playback, see the DRM section below\n- React Native DRM support is limited\n\nDownloading videos for offline playback requires careful consideration of:\n- Storage space on user's device\n- Copyright and DRM requirements\n- File size and download time on mobile networks\n\nWhat about DRM (Digital Rights Management)?\n\nReact Native DRM support is limited. Options:\n\n1. Use Mux Player Web in WebView (Recommended for DRM)\n\n```tsx\nimport { WebView } from 'react-native-webview';\n\n<WebView\n  source={{\n    html: `\n      <script src=\"https://cdn.jsdelivr.net/npm/@mux/mux-player\"></script>\n      <mux-player\n        playback-id=\"${playbackId}\"\n        drm-token=\"${drmToken}\"\n      />\n    `\n  }}\n/>\n```\n\n\n2. Native SDKs with bridge (Advanced)\n- Use native Mux Player iOS/Android SDKs\n- Create React Native bridge\n- More complex but full DRM support\n\n3. react-native-video with DRM (Limited)\n- Some DRM support exists but varies by platform\n- Requires significant native configuration\n- Not officially supported by Mux\n\nRecommendation: For most apps, don't use DRM. If you must have DRM, use option 1 (WebView) or hire a mobile DRM specialist.\n\nLearn more: Mux DRM guide\n\nHow much does Mux cost?\n\nMux pricing is based on:\n- Video storage (per GB stored)\n- Encoding (per minute of video encoded)\n- Streaming delivery (per GB delivered)\n- Mux Data (per view tracked)\n\nEstimate for a typical social video app:\n- 1000 videos × 1 minute average = ~10GB storage\n- 1000 video encodes = encoding cost\n- 10,000 views × 10MB average = 100GB delivery\n- 10,000 views tracked = analytics cost\n\nCheck current pricing: Mux Pricing\n\nMux has a free tier that includes encoding and streaming credits. Great for testing and small apps!\n\nHow do I debug playback issues?\n\nStep 1: Enable Mux Data\n\n```tsx\nimport muxReactNativeVideo from '@mux/mux-data-react-native-video';\nconst MuxVideo = muxReactNativeVideo(Video);\n\n<MuxVideo\n  source={{ uri: videoUrl }}\n  muxOptions={{\n    data: {\n      env_key: MUX_DATA_ENV_KEY,\n      video_id: videoId,\n    },\n  }}\n/>\n```\n\n\nStep 2: Check Mux Dashboard\n- Go to Mux Dashboard → Data\n- Look for errors, buffering events, startup time\n- Filter by video_id or user_id\n\nStep 3: Add logging\n\n```tsx\n<Video\n  source={{ uri: videoUrl }}\n  onLoad={(data) => console.log('Video loaded:', data)}\n  onBuffer={(data) => console.log('Buffering:', data.isBuffering)}\n  onError={(error) => console.error('Error:', error)}\n  onProgress={(data) => console.log('Progress:', data.currentTime)}\n/>\n```\n\n\nStep 4: Test on real device with network inspector\n- Use Flipper or React Native Debugger\n- Check network requests to stream.mux.com\n- Verify HLS manifest loads correctly\n\nCommon findings:\n- Asset not in ready state → wait for processing\n- Network timeout → check user's internet connection\n- 403 error → signed URL expired or invalid\n- 404 error → playback ID doesn't exist\n\nCan I use Expo Video instead of react-native-video?\n\nYes, but with limitations.\n\n\n```tsx\n// With expo-av\nimport { Video } from 'expo-av';\n\n<Video\n  source={{ uri: `https://stream.mux.com/${playbackId}.m3u8` }}\n  useNativeControls\n  resizeMode=\"contain\"\n  style={{ width: 300, height: 200 }}\n/>\n```\n\n\nPros:\n- Native to Expo (no extra package)\n- Good for simple use cases\n- Works in Expo Go\n\nCons:\n- Mux Data integration not officially supported\n- Fewer customization options\n- Different API than react-native-video\n\nRecommendation: Use react-native-video for Mux integration. It has better community support and official Mux Data integration.\n\nHow do I handle video rotation and aspect ratios?\n\n\n```tsx\nimport { Dimensions } from 'react-native';\n\nconst { width, height } = Dimensions.get('window');\n\n// Landscape videos (16:9)\n<Video\n  source={{ uri: videoUrl }}\n  style={{ width: '100%', aspectRatio: 16 / 9 }}\n  resizeMode=\"contain\"\n/>\n\n// Portrait videos (9:16) - Stories/Reels\n<Video\n  source={{ uri: videoUrl }}\n  style={{ width: '100%', aspectRatio: 9 / 16 }}\n  resizeMode=\"cover\"\n/>\n\n// Square videos (1:1)\n<Video\n  source={{ uri: videoUrl }}\n  style={{ width: width, aspectRatio: 1 }}\n  resizeMode=\"cover\"\n/>\n\n// Dynamic aspect ratio from API\n<Video\n  source={{ uri: videoUrl }}\n  style={{ width: '100%', aspectRatio: video.aspectRatio || 16/9 }}\n  resizeMode=\"contain\"\n/>\n```\n\n\nGet aspect ratio from Mux:\n\n```tsx\n// Backend: Get asset details\nconst asset = await mux.video.assets.retrieve(assetId);\nconst aspectRatio = asset.aspect_ratio; // e.g., \"16:9\"\n\n// Parse to number\nconst [w, h] = aspectRatio.split(':').map(Number);\nconst ratio = w / h; // 1.777...\n\n// Send to React Native\nreturn { aspectRatio: ratio };\n```\n\n\nHow do I show view counts in real-time?\n\nUse Mux Data API with real-time viewer counts:\n\n\n```tsx\n// Backend endpoint\nimport Mux from '@mux/mux-node';\n\nasync function getRealtimeViewers(playbackId: string) {\n  const token = Mux.JWT.signViewerCounts(playbackId, {\n    keyId: signingKeyId,\n    keySecret: signingKeySecret,\n    type: 'video',\n  });\n\n  const response = await fetch(`https://stats.mux.com/counts?token=${token}`);\n  const data = await response.json();\n\n  return data.current_viewers || 0;\n}\n\n// React Native: Poll for updates\nfunction useRealtimeViewers(videoId: string) {\n  const [viewers, setViewers] = useState(0);\n\n  useEffect(() => {\n    const fetchViewers = async () => {\n      const count = await fetch(`/api/viewers/${videoId}`).then(r => r.json());\n      setViewers(count);\n    };\n\n    fetchViewers();\n    const interval = setInterval(fetchViewers, 10000); // Every 10 seconds\n\n    return () => clearInterval(interval);\n  }, [videoId]);\n\n  return viewers;\n}\n\n// Display\nfunction VideoPlayer({ videoId }: Props) {\n  const viewers = useRealtimeViewers(videoId);\n\n  return (\n    <>\n      <Video source={{ uri: videoUrl }} />\n      <View style={styles.viewersOverlay}>\n        <Text>👁 {viewers} watching</Text>\n      </View>\n    </>\n  );\n}\n```\n\n\nLearn more in the Mux Data Analytics guide.\n\nCan I customize the video player UI?\n\nYes! Build custom controls on top of react-native-video:\n\n\n```tsx\nfunction CustomVideoPlayer({ videoUrl }: Props) {\n  const [paused, setPaused] = useState(true);\n  const [progress, setProgress] = useState(0);\n  const [duration, setDuration] = useState(0);\n\n  return (\n    <View style={styles.container}>\n      <Video\n        source={{ uri: videoUrl }}\n        paused={paused}\n        onLoad={(data) => setDuration(data.duration)}\n        onProgress={(data) => setProgress(data.currentTime)}\n        style={styles.video}\n        controls={false} // Hide default controls\n      />\n\n      {/* Custom controls */}\n      <View style={styles.controls}>\n        <TouchableOpacity onPress={() => setPaused(!paused)}>\n          <Text style={styles.button}>{paused ? '▶️' : '⏸'}</Text>\n        </TouchableOpacity>\n\n        <Slider\n          value={progress}\n          maximumValue={duration}\n          onSlidingComplete={(value) => videoRef.current?.seek(value)}\n          style={styles.slider}\n        />\n\n        <Text style={styles.time}>\n          {formatTime(progress)} / {formatTime(duration)}\n        </Text>\n      </View>\n    </View>\n  );\n}\n```\n\n\nSee complete example in the Video Playback guide.\n\nGetting Help\n\nDocumentation Resources\n\n- Mux Video API Reference\n- Mux Data API Reference\n- react-native-video Documentation\n- Expo Video Documentation\n\nCommunity Support\n\nMux Discord\nJoin the Mux community for quick help and discussions:\ndiscord.gg/mux\n\nStack Overflow\nSearch or ask questions with these tags:\n- [mux] + [react-native]\n- [video-streaming] + [react-native]\n\nGitHub Issues\n- react-native-video issues\n- Mux Node SDK issues\n\nMux Support\n\nFor Mux customers:\nContact support through the Mux Dashboard or email support@mux.com\n\nInclude in your support request:\n- Playback ID or Asset ID\n- Platform (iOS/Android)\n- Device model and OS version\n- Error messages or logs\n- Steps to reproduce\n- Screenshots or screen recordings\n\nDebugging Checklist\n\nBefore reaching out for help, check:\n\n1. Asset Status\n   - [ ] Asset is in ready state (not preparing or errored)\n   - [ ] Playback ID exists and is correct\n\n2. Network\n   - [ ] Device has internet connectivity\n   - [ ] HLS URL is accessible (test in browser)\n   - [ ] No CORS issues (check network inspector)\n\n3. Code\n   - [ ] Video component props are correct\n   - [ ] Error handlers are in place\n   - [ ] Console logs show useful info\n\n4. Testing\n   - [ ] Tested on real device (not just simulator/emulator)\n   - [ ] Tested on both iOS and Android\n   - [ ] Tested with different videos\n\n5. Documentation\n   - [ ] Reviewed relevant guides\n   - [ ] Checked FAQ section\n   - [ ] Searched Discord/Stack Overflow\n\nNext Steps\n\n  <GuideCard\n    title=\"Best Practices\"\n    description=\"Optimize your React Native + Mux integration for production\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/best-practices\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Example App\"\n    description=\"See a complete working implementation with all features\"\n    links={[\n      {title: \"View the example\", href: \"/docs/guides/react-native/example-app\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Mux Support\"\n    description=\"Get help from the Mux team\"\n    links={[\n      {title: \"Contact support\", href: \"https://mux.com/support\"},\n    ]}\n  />"
  },
  {
    "id": "170-_guides/frameworks/react-native-uploading-videos",
    "title": "Upload videos to Mux from React Native",
    "path": "_guides/frameworks/react-native-uploading-videos.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-uploading-videos",
    "content": "There are two primary ways to get videos into Mux from a React Native application:\n\n1. Direct upload from device - User records or selects a video, which is uploaded directly from their mobile device\n2. Upload from URL - Your backend creates a Mux asset from a video URL (ideal for AI-generated content)\n\nThis guide covers both approaches and helps you choose the right one for your use case.\n\nChoosing an upload method\n\n| Method | Use Case | React Native Role | Backend Required | User Experience |\n|--------|----------|-------------------|------------------|-----------------|\n| Direct Upload | User-generated content (camera, library) | High - handles file upload | Yes - generates upload URL | Shows upload progress |\n| Upload from URL | AI-generated videos, pre-hosted content | Low - just displays result | Yes - creates asset | Background process |\n\nWhen to use direct upload\n\nUse direct upload when:\n- Users record videos with their device camera\n- Users select videos from their photo library\n- You need to show upload progress to the user\n- The video file is on the user's device\n\nWhen to use upload from URL\n\nUse upload from URL when:\n- Videos are generated by AI services (Runway, Pika, Fal.ai, etc.)\n- Videos are already hosted elsewhere (S3, GCS, etc.)\n- You want to ingest videos without user intervention\n- The video generation happens on your backend\n\n  For apps that use on-demand generative AI video, upload from URL is the right choice since videos are generated by AI services and returned as URLs.\n\n---\n\nDirect upload from mobile device\n\nDirect uploads allow users to upload videos directly from their React Native app to Mux without the file touching your backend servers.\n\nArchitecture\n\n\n```\nUser Device → Your Backend (generate upload URL) → Mux\n                ↓\n            Upload URL returned\n                ↓\nUser Device → Mux (upload file directly)\n                ↓\n            Mux processes video\n                ↓\n            Webhook → Your Backend (asset ready)\n```\n\n\nStep 1: Generate a signed upload URL (backend)\n\nYour backend must generate a signed upload URL using the Mux API:\n\n\n```javascript\n// Backend: Node.js + Mux SDK\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux({\n  tokenId: process.env.MUX_TOKEN_ID,\n  tokenSecret: process.env.MUX_TOKEN_SECRET,\n});\n\n// API endpoint: POST /api/generate-upload-url\nexport async function generateUploadUrl(req, res) {\n  try {\n    const upload = await mux.video.uploads.create({\n      cors_origin: '*', // Or specify your app's origin\n      new_asset_settings: {\n        playback_policies: ['public'],\n        video_quality: \"basic\"\n      },\n    });\n\n    res.json({\n      uploadUrl: upload.url,\n      uploadId: upload.id,\n    });\n  } catch (error) {\n    console.error('Failed to create upload URL:', error);\n    res.status(500).json({ error: 'Failed to generate upload URL' });\n  }\n}\n```\n\n\n  Never expose your Mux API credentials in your React Native app. Always generate upload URLs from your backend.\n\nStep 2: Record or select video (React Native)\n\nUse Expo Camera or ImagePicker to get a video file:\n\n\n```tsx\nimport * as ImagePicker from 'expo-image-picker';\nimport { useState } from 'react';\n\nexport function useVideoPicker() {\n  const [videoUri, setVideoUri] = useState<string | null>(null);\n\n  const pickVideo = async () => {\n    const result = await ImagePicker.launchImageLibraryAsync({\n      mediaTypes: ImagePicker.MediaTypeOptions.Videos,\n      allowsEditing: true,\n      quality: 1,\n    });\n\n    if (!result.canceled) {\n      setVideoUri(result.assets[0].uri);\n    }\n  };\n\n  const recordVideo = async () => {\n    const result = await ImagePicker.launchCameraAsync({\n      mediaTypes: ImagePicker.MediaTypeOptions.Videos,\n      allowsEditing: true,\n      quality: 1,\n    });\n\n    if (!result.canceled) {\n      setVideoUri(result.assets[0].uri);\n    }\n  };\n\n  return { videoUri, pickVideo, recordVideo };\n}\n```\n\n\nStep 3: Upload to Mux (React Native)\n\nUpload the video file using Expo FileSystem:\n\n\n```tsx\nimport * as FileSystem from 'expo-file-system';\nimport { useState } from 'react';\n\ninterface UploadResult {\n  uploadId: string;\n  assetId?: string;\n}\n\nexport function useVideoUpload() {\n  const [uploading, setUploading] = useState(false);\n  const [uploadProgress, setUploadProgress] = useState(0);\n  const [error, setError] = useState<string | null>(null);\n\n  const uploadVideo = async (videoUri: string): Promise<UploadResult | null> => {\n    setUploading(true);\n    setUploadProgress(0);\n    setError(null);\n\n    try {\n      // Step 1: Get upload URL from your backend\n      const response = await fetch('https://your-api.com/generate-upload-url', {\n        method: 'POST',\n      });\n      const { uploadUrl, uploadId } = await response.json();\n\n      // Step 2: Upload video file to Mux with progress tracking\n      const uploadTask = FileSystem.createUploadTask(\n        uploadUrl,\n        videoUri,\n        {\n          httpMethod: 'PUT',\n          uploadType: FileSystem.FileSystemUploadType.BINARY_CONTENT,\n        },\n        (uploadProgress) => {\n          const progress = uploadProgress.totalBytesSent / uploadProgress.totalBytesExpectedToSend;\n          setUploadProgress(Math.round(progress * 100));\n        }\n      );\n\n      const uploadResponse = await uploadTask.uploadAsync();\n\n      if (!uploadResponse || uploadResponse.status !== 200) {\n        throw new Error('Upload failed');\n      }\n\n      setUploading(false);\n\n      return { uploadId };\n    } catch (err) {\n      console.error('Upload error:', err);\n      setError('Failed to upload video');\n      setUploading(false);\n      setUploadProgress(0);\n      return null;\n    }\n  };\n\n  return { uploadVideo, uploading, uploadProgress, error };\n}\n```\n\n\nStep 4: Handle upload completion\n\nThe video asset won't be ready immediately after upload. You'll need to:\n\n1. Listen for the video.asset.ready webhook on your backend\n2. Update your database with the playback ID\n3. Notify the React Native app (via polling, realtime DB, or push notification)\n\nSee the async processing guide for implementation details.\n\nComplete upload example\n\n\n```tsx\nimport React, { useState } from 'react';\nimport {\n  View,\n  TouchableOpacity,\n  Text,\n  ActivityIndicator,\n  StyleSheet,\n} from 'react-native';\nimport * as ImagePicker from 'expo-image-picker';\nimport * as FileSystem from 'expo-file-system';\n\nexport default function VideoUploader() {\n  const [uploading, setUploading] = useState(false);\n  const [uploadProgress, setUploadProgress] = useState(0);\n  const [uploadId, setUploadId] = useState<string | null>(null);\n\n  const selectAndUploadVideo = async () => {\n    // Step 1: Select video\n    const result = await ImagePicker.launchImageLibraryAsync({\n      mediaTypes: ImagePicker.MediaTypeOptions.Videos,\n      quality: 1,\n    });\n\n    if (result.canceled) return;\n\n    const videoUri = result.assets[0].uri;\n    setUploading(true);\n    setUploadProgress(0);\n\n    try {\n      // Step 2: Get upload URL\n      const response = await fetch('https://your-api.com/generate-upload-url', {\n        method: 'POST',\n      });\n      const { uploadUrl, uploadId } = await response.json();\n\n      // Step 3: Upload to Mux with progress tracking\n      const uploadTask = FileSystem.createUploadTask(\n        uploadUrl,\n        videoUri,\n        {\n          httpMethod: 'PUT',\n          uploadType: FileSystem.FileSystemUploadType.BINARY_CONTENT,\n        },\n        (progress) => {\n          const percentage = progress.totalBytesSent / progress.totalBytesExpectedToSend;\n          setUploadProgress(Math.round(percentage * 100));\n        }\n      );\n\n      await uploadTask.uploadAsync();\n\n      setUploadId(uploadId);\n      setUploading(false);\n\n      // Video is now processing - see async processing guide\n      // for how to get notified when it's ready\n    } catch (error) {\n      console.error('Upload failed:', error);\n      setUploading(false);\n      setUploadProgress(0);\n    }\n  };\n\n  return (\n    <View style={styles.container}>\n      {uploading ? (\n        <View style={styles.uploadingContainer}>\n          <ActivityIndicator size=\"large\" />\n          <Text style={styles.progressText}>Uploading: {uploadProgress}%</Text>\n        </View>\n      ) : uploadId ? (\n        <Text style={styles.text}>\n          Video uploaded! Processing...\n        </Text>\n      ) : (\n        <TouchableOpacity style={styles.button} onPress={selectAndUploadVideo}>\n          <Text style={styles.buttonText}>Select Video</Text>\n        </TouchableOpacity>\n      )}\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    padding: 20,\n    alignItems: 'center',\n  },\n  uploadingContainer: {\n    alignItems: 'center',\n  },\n  button: {\n    backgroundColor: '#007AFF',\n    padding: 15,\n    borderRadius: 8,\n  },\n  buttonText: {\n    color: '#fff',\n    fontSize: 16,\n    fontWeight: 'bold',\n  },\n  text: {\n    fontSize: 16,\n  },\n  progressText: {\n    marginTop: 10,\n    fontSize: 16,\n    color: '#666',\n  },\n});\n```\n\n\n---\n\nUpload from URL (for AI-generated videos)\n\nThis approach is ideal when videos are generated by AI services or already hosted elsewhere. The video never touches the React Native app - your backend handles everything.\n\nArchitecture\n\n\n```\nUser submits prompt → Your Backend → AI Service (Fal.ai, Runway, etc.)\n                                            ↓\n                                      AI returns video URL\n                                            ↓\n                      Your Backend → Mux (create asset from URL)\n                                            ↓\n                                     Mux ingests & processes\n                                            ↓\n                      Webhook → Your Backend (asset ready)\n                                            ↓\n                      Realtime DB → React Native App\n```\n\n\nStep 1: Create asset from URL (backend)\n\nYour backend receives the AI-generated video URL and creates a Mux asset:\n\n\n```javascript\n// Backend: Node.js + Mux SDK\nimport Mux from '@mux/mux-node';\n\nconst mux = new Mux({\n  tokenId: process.env.MUX_TOKEN_ID,\n  tokenSecret: process.env.MUX_TOKEN_SECRET,\n});\n\n// API endpoint: POST /api/create-video-from-url\nexport async function createVideoFromUrl(req, res) {\n  const { videoUrl, userId, prompt } = req.body;\n\n  try {\n    // Create Mux asset from URL\n    const asset = await mux.video.assets.create({\n      input: [{ url: videoUrl }],\n      playback_policies: ['public'],\n      video_quality: \"basic\"\n    });\n\n    // Store in your database\n    await db.videos.create({\n      id: generateId(),\n      userId,\n      prompt,\n      muxAssetId: asset.id,\n      status: 'processing', // Will be updated via webhook\n      createdAt: new Date(),\n    });\n\n    res.json({\n      videoId: video.id,\n      assetId: asset.id,\n      status: 'processing',\n    });\n  } catch (error) {\n    console.error('Failed to create asset:', error);\n    res.status(500).json({ error: 'Failed to create video asset' });\n  }\n}\n```\n\n\n  The video URL must be publicly accessible. Mux will fetch the video file from that URL to ingest it.\n\nStep 2: Handle asset ready webhook (backend)\n\nWhen Mux finishes processing, it sends a webhook to your backend:\n\n\n```javascript\n// Backend: Webhook handler\n\n// check the mux-node-sdk docs for details\n// https://github.com/muxinc/mux-node-sdk/blob/master/api.md#webhooks\nconst mux = new Mux();\n\n// API endpoint: POST /api/webhooks/mux\nexport async function handleMuxWebhook(req, res) {\n  const webhookSecret = process.env.MUX_WEBHOOK_SECRET;\n  const signature = req.headers['mux-signature'];\n\n  // Verify webhook signature\n  try {\n    mux.webhooks.verifySignature(req.body, req.headers, webhookSecret);\n  } catch (error) {\n    console.error('Invalid webhook signature');\n    return res.status(401).json({ error: 'Invalid signature' });\n  }\n\n  const event = req.body;\n\n  // Handle video.asset.ready\n  if (event.type === 'video.asset.ready') {\n    const { id, playback_ids, duration } = event.data;\n\n    // Update database\n    await db.videos.update({\n      where: { muxAssetId: id },\n      data: {\n        status: 'ready',\n        playbackId: playback_ids[0].id,\n        duration,\n      },\n    });\n\n    // Video is now ready to play!\n    // Your realtime database will notify the React Native app\n  }\n\n  // Handle video.asset.errored\n  if (event.type === 'video.asset.errored') {\n    const { id } = event.data;\n\n    await db.videos.update({\n      where: { muxAssetId: id },\n      data: {\n        status: 'failed',\n        error: 'Video processing failed',\n      },\n    });\n  }\n\n  res.json({ received: true });\n}\n```\n\n\n  Always verify webhook signatures to ensure requests are actually from Mux. See the webhooks guide for details.\n\nStep 3: React Native subscribes to status updates\n\nYour React Native app doesn't handle the upload - it just waits for the video to be ready:\n\n\n```tsx\nimport React, { useEffect, useState } from 'react';\nimport { View, Text, ActivityIndicator, StyleSheet } from 'react-native';\nimport { supabase } from './supabase'; // or Firebase, etc.\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\ninterface VideoGenerationProps {\n  videoId: string;\n}\n\nexport default function VideoGeneration({ videoId }: VideoGenerationProps) {\n  const [status, setStatus] = useState<'processing' | 'ready' | 'failed'>('processing');\n  const [playbackId, setPlaybackId] = useState<string | null>(null);\n\n  const player = useVideoPlayer(\n    playbackId ? `https://stream.mux.com/${playbackId}.m3u8` : null,\n    (player) => {\n      player.loop = false;\n    }\n  );\n\n  useEffect(() => {\n    // Subscribe to video status changes using Supabase Realtime\n    const subscription = supabase\n      .channel('video-updates')\n      .on(\n        'postgres_changes',\n        {\n          event: 'UPDATE',\n          schema: 'public',\n          table: 'videos',\n          filter: `id=eq.${videoId}`,\n        },\n        (payload) => {\n          const video = payload.new;\n          setStatus(video.status);\n          if (video.status === 'ready') {\n            setPlaybackId(video.playback_id);\n          }\n        }\n      )\n      .subscribe();\n\n    return () => {\n      subscription.unsubscribe();\n    };\n  }, [videoId]);\n\n  if (status === 'failed') {\n    return (\n      <View style={styles.container}>\n        <Text style={styles.errorText}>\n          Video generation failed. Please try again.\n        </Text>\n      </View>\n    );\n  }\n\n  if (status === 'processing' || !playbackId) {\n    return (\n      <View style={styles.container}>\n        <ActivityIndicator size=\"large\" color=\"#007AFF\" />\n        <Text style={styles.text}>Generating your video...</Text>\n      </View>\n    );\n  }\n\n  return (\n    <VideoView\n      player={player}\n      style={styles.video}\n      nativeControls\n    />\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n    justifyContent: 'center',\n    alignItems: 'center',\n    padding: 20,\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  text: {\n    marginTop: 10,\n    fontSize: 16,\n    color: '#666',\n  },\n  errorText: {\n    fontSize: 16,\n    color: '#ff0000',\n    textAlign: 'center',\n  },\n});\n```\n\n\nComplete AI video workflow example\n\nHere's the full flow for an async video generation example app:\n\n\n```tsx\nimport React, { useState } from 'react';\nimport {\n  View,\n  TextInput,\n  TouchableOpacity,\n  Text,\n  ActivityIndicator,\n  StyleSheet,\n} from 'react-native';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nexport default function AIVideoGenerator() {\n  const [prompt, setPrompt] = useState('');\n  const [generating, setGenerating] = useState(false);\n  const [videoId, setVideoId] = useState<string | null>(null);\n  const [playbackId, setPlaybackId] = useState<string | null>(null);\n\n  const player = useVideoPlayer(\n    playbackId ? `https://stream.mux.com/${playbackId}.m3u8` : null,\n    (player) => {\n      player.loop = false;\n    }\n  );\n\n  const generateVideo = async () => {\n    if (!prompt.trim()) return;\n\n    setGenerating(true);\n\n    try {\n      // Step 1: Submit prompt to your backend\n      const response = await fetch('https://your-api.com/generate-video', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ prompt }),\n      });\n\n      const { videoId } = await response.json();\n      setVideoId(videoId);\n\n      // Step 2: Your backend handles:\n      // - Calling AI service (Fal.ai, Runway, etc.)\n      // - Getting video URL from AI service\n      // - Creating Mux asset from URL\n      // - Waiting for Mux webhook\n\n      // Step 3: Poll or subscribe for updates\n      const checkStatus = async () => {\n        const statusResponse = await fetch(\n          `https://your-api.com/videos/${videoId}`\n        );\n        const video = await statusResponse.json();\n\n        if (video.status === 'ready') {\n          setPlaybackId(video.playbackId);\n          setGenerating(false);\n        } else if (video.status === 'failed') {\n          setGenerating(false);\n          alert('Video generation failed');\n        } else {\n          // Still processing, check again in 3 seconds\n          setTimeout(checkStatus, 3000);\n        }\n      };\n\n      checkStatus();\n    } catch (error) {\n      console.error('Generation failed:', error);\n      setGenerating(false);\n    }\n  };\n\n  if (playbackId) {\n    return (\n      <View style={styles.container}>\n        <VideoView\n          player={player}\n          style={styles.video}\n          nativeControls\n        />\n        <TouchableOpacity\n          style={styles.button}\n          onPress={() => {\n            setPrompt('');\n            setPlaybackId(null);\n            setVideoId(null);\n          }}\n        >\n          <Text style={styles.buttonText}>Generate Another</Text>\n        </TouchableOpacity>\n      </View>\n    );\n  }\n\n  return (\n    <View style={styles.container}>\n      <TextInput\n        style={styles.input}\n        placeholder=\"Enter video prompt...\"\n        value={prompt}\n        onChangeText={setPrompt}\n        multiline\n        editable={!generating}\n      />\n\n      {generating ? (\n        <>\n          <ActivityIndicator size=\"large\" color=\"#007AFF\" />\n          <Text style={styles.statusText}>\n            Generating your video...\n          </Text>\n          <Text style={styles.subText}>\n            This usually takes 30-60 seconds\n          </Text>\n        </>\n      ) : (\n        <TouchableOpacity style={styles.button} onPress={generateVideo}>\n          <Text style={styles.buttonText}>Generate Video</Text>\n        </TouchableOpacity>\n      )}\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    flex: 1,\n    padding: 20,\n    justifyContent: 'center',\n  },\n  input: {\n    borderWidth: 1,\n    borderColor: '#ccc',\n    borderRadius: 8,\n    padding: 15,\n    fontSize: 16,\n    marginBottom: 20,\n    minHeight: 100,\n  },\n  button: {\n    backgroundColor: '#007AFF',\n    padding: 15,\n    borderRadius: 8,\n    alignItems: 'center',\n  },\n  buttonText: {\n    color: '#fff',\n    fontSize: 16,\n    fontWeight: 'bold',\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n    marginBottom: 20,\n  },\n  statusText: {\n    fontSize: 16,\n    marginTop: 10,\n    textAlign: 'center',\n  },\n  subText: {\n    fontSize: 14,\n    color: '#666',\n    marginTop: 5,\n    textAlign: 'center',\n  },\n});\n```\n\n\nError handling\n\nDirect upload errors\n\nMobile networks are unreliable, so robust error handling is essential. Here are common upload errors and how to handle them:\n\nCommon error scenarios:\n\n| Error | Cause | Solution |\n|-------|-------|----------|\n| Network timeout | Slow/unstable connection | Implement retry logic, allow resumable uploads |\n| 403 Forbidden | Upload URL expired (valid for 48 hours) | Request a new upload URL from your backend |\n| Connection lost | User switched from WiFi to cellular | Cancel upload, show option to retry |\n| File too large | Video exceeds Mux limits | Validate file size before upload, compress if needed |\n| Out of storage | Device storage full | Check available storage before upload |\n\nEnhanced error handling:\n\n\n```tsx\nimport { useState } from 'react';\nimport * as FileSystem from 'expo-file-system';\nimport * as Network from 'expo-network';\n\ninterface UploadError {\n  message: string;\n  canRetry: boolean;\n  shouldRequestNewUrl: boolean;\n}\n\nexport function useVideoUploadWithRetry() {\n  const [uploading, setUploading] = useState(false);\n  const [uploadProgress, setUploadProgress] = useState(0);\n  const [error, setError] = useState<string | null>(null);\n  const [retryCount, setRetryCount] = useState(0);\n\n  const MAX_RETRIES = 3;\n\n  const handleUploadError = (error: any): UploadError => {\n    const message = error.message?.toLowerCase() || '';\n\n    // Network errors - can retry\n    if (message.includes('network') || message.includes('connection')) {\n      return {\n        message: 'Network error. Check your connection and try again.',\n        canRetry: true,\n        shouldRequestNewUrl: false,\n      };\n    }\n\n    // Timeout errors - can retry\n    if (message.includes('timeout')) {\n      return {\n        message: 'Upload timed out. Try again or use a shorter video.',\n        canRetry: true,\n        shouldRequestNewUrl: false,\n      };\n    }\n\n    // Upload URL expired - need new URL\n    if (message.includes('403') || message.includes('forbidden')) {\n      return {\n        message: 'Upload URL expired. Requesting a new one...',\n        canRetry: true,\n        shouldRequestNewUrl: true,\n      };\n    }\n\n    // Server errors - can retry\n    if (message.includes('500') || message.includes('502') || message.includes('503')) {\n      return {\n        message: 'Server error. Retrying...',\n        canRetry: true,\n        shouldRequestNewUrl: false,\n      };\n    }\n\n    // Client errors - cannot retry\n    if (message.includes('400') || message.includes('413')) {\n      return {\n        message: 'Invalid video file or file too large.',\n        canRetry: false,\n        shouldRequestNewUrl: false,\n      };\n    }\n\n    // Generic error\n    return {\n      message: 'Upload failed. Please try again.',\n      canRetry: true,\n      shouldRequestNewUrl: false,\n    };\n  };\n\n  const uploadVideoWithRetry = async (\n    videoUri: string,\n    getUploadUrl: () => Promise<{ uploadUrl: string; uploadId: string }>\n  ): Promise<{ uploadId: string } | null> => {\n    setUploading(true);\n    setUploadProgress(0);\n    setError(null);\n    setRetryCount(0);\n\n    let uploadUrl: string;\n    let uploadId: string;\n\n    // Get initial upload URL\n    try {\n      const result = await getUploadUrl();\n      uploadUrl = result.uploadUrl;\n      uploadId = result.uploadId;\n    } catch (err) {\n      setError('Failed to get upload URL');\n      setUploading(false);\n      return null;\n    }\n\n    // Retry loop\n    for (let attempt = 0; attempt < MAX_RETRIES; attempt++) {\n      try {\n        setRetryCount(attempt);\n\n        // Check network connectivity before upload\n        const networkState = await Network.getNetworkStateAsync();\n        if (!networkState.isConnected) {\n          throw new Error('No network connection');\n        }\n\n        // Create upload task\n        const uploadTask = FileSystem.createUploadTask(\n          uploadUrl,\n          videoUri,\n          {\n            httpMethod: 'PUT',\n            uploadType: FileSystem.FileSystemUploadType.BINARY_CONTENT,\n          },\n          (progress) => {\n            const percentage =\n              progress.totalBytesSent / progress.totalBytesExpectedToSend;\n            setUploadProgress(Math.round(percentage * 100));\n          }\n        );\n\n        const uploadResponse = await uploadTask.uploadAsync();\n\n        if (!uploadResponse || uploadResponse.status !== 200) {\n          throw new Error(`Upload failed with status ${uploadResponse?.status}`);\n        }\n\n        // Success!\n        setUploading(false);\n        return { uploadId };\n      } catch (err: any) {\n        console.error(`Upload attempt ${attempt + 1} failed:`, err);\n\n        const errorInfo = handleUploadError(err);\n        setError(errorInfo.message);\n\n        // If we can't retry or we've exhausted retries, give up\n        if (!errorInfo.canRetry || attempt === MAX_RETRIES - 1) {\n          setUploading(false);\n          setUploadProgress(0);\n          return null;\n        }\n\n        // If URL expired, get a new one\n        if (errorInfo.shouldRequestNewUrl) {\n          try {\n            const result = await getUploadUrl();\n            uploadUrl = result.uploadUrl;\n            uploadId = result.uploadId;\n          } catch {\n            setError('Failed to get new upload URL');\n            setUploading(false);\n            setUploadProgress(0);\n            return null;\n          }\n        }\n\n        // Wait before retrying (exponential backoff)\n        const delay = Math.min(1000 * Math.pow(2, attempt), 10000);\n        await new Promise((resolve) => setTimeout(resolve, delay));\n      }\n    }\n\n    setUploading(false);\n    setUploadProgress(0);\n    return null;\n  };\n\n  return { uploadVideoWithRetry, uploading, uploadProgress, error, retryCount };\n}\n```\n\n\nUsing the retry hook:\n\n\n```tsx\nimport * as ImagePicker from 'expo-image-picker';\n\nfunction VideoUploader() {\n  const { uploadVideoWithRetry, uploading, uploadProgress, error, retryCount } =\n    useVideoUploadWithRetry();\n\n  const selectAndUpload = async () => {\n    const result = await ImagePicker.launchImageLibraryAsync({\n      mediaTypes: ImagePicker.MediaTypeOptions.Videos,\n    });\n\n    if (result.canceled) return;\n\n    const getUploadUrl = async () => {\n      const response = await fetch('https://your-api.com/generate-upload-url', {\n        method: 'POST',\n      });\n      return response.json();\n    };\n\n    await uploadVideoWithRetry(result.assets[0].uri, getUploadUrl);\n  };\n\n  return (\n    <View>\n      <TouchableOpacity onPress={selectAndUpload} disabled={uploading}>\n        <Text>Select and Upload Video</Text>\n      </TouchableOpacity>\n      {uploading && (\n        <View>\n          <Text>Uploading: {uploadProgress}%</Text>\n          {retryCount > 0 && <Text>Retry attempt {retryCount + 1}</Text>}\n        </View>\n      )}\n      {error && <Text style={{ color: 'red' }}>{error}</Text>}\n    </View>\n  );\n}\n```\n\n\n  Install expo-network to check connectivity: npx expo install expo-network\n\nURL upload errors\n\nCommon issues when creating assets from URLs:\n\n- Invalid URL: Ensure the URL is publicly accessible\n- Unsupported format: Mux supports MP4, MOV, AVI, and more\n- File too large: Check Mux's file size limits\n- URL expired: Some AI services return temporary URLs\n\nBest practices\n\nFor direct upload\n\n1. Show upload progress - Use FileSystem.createUploadTask for progress updates\n2. Validate file size - Check before uploading (e.g., max 5GB)\n3. Handle retries - Network issues are common on mobile\n4. Compress videos - Consider client-side compression for large files\n\nFor URL upload\n\n1. Validate URLs - Ensure they're publicly accessible before sending to Mux\n2. Handle temporary URLs - Some AI services return URLs that expire quickly\n3. Store original URL - Keep a reference in case you need to re-ingest\n4. Set timeouts - AI video generation can take 30-120 seconds\n\nGeneral\n\n1. Use webhooks - More reliable than polling for asset status\n2. Store metadata - Save prompt, user ID, timestamps in your database\n3. Handle failures gracefully - Show clear error messages and retry options\n4. Monitor costs - Track encoding and storage usage\n\n  Learn more about Mux encoding tiers and pricing to optimize costs for your use case."
  },
  {
    "id": "171-_guides/frameworks/react-native-video-feeds",
    "title": "Building Video Feeds",
    "path": "_guides/frameworks/react-native-video-feeds.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-video-feeds",
    "content": "Building Video Feeds\n\nThis guide shows you how to build performant scrollable video feeds in React Native with Mux. You'll learn patterns for auto-play, preloading, memory management, and infinite scrolling - the foundation for apps like YouTube, Instagram, and TikTok's main feeds.\n\nThis guide covers horizontal scrolling feeds (like YouTube) and vertical scrolling feeds (like Instagram). For full-screen vertical swiping (Stories/Reels), see the Stories/Reels UI guide.\n\nFlatList Fundamentals\n\nReact Native's FlatList is the foundation for performant video feeds:\n\n\n```tsx\nimport { FlatList } from 'react-native';\nimport { VideoCard } from './VideoCard';\n\ninterface Video {\n  id: string;\n  playbackId: string;\n  title: string;\n  thumbnailUrl: string;\n  duration: number;\n  views: number;\n}\n\nexport function VideoFeed() {\n  const [videos, setVideos] = useState<Video[]>([]);\n  const [currentlyPlayingId, setCurrentlyPlayingId] = useState<string | null>(null);\n\n  return (\n    <FlatList\n      data={videos}\n      renderItem={({ item }) => (\n        <VideoCard\n          video={item}\n          isPlaying={item.id === currentlyPlayingId}\n        />\n      )}\n      keyExtractor={(item) => item.id}\n      // Performance optimizations\n      initialNumToRender={3}\n      maxToRenderPerBatch={5}\n      windowSize={5}\n      removeClippedSubviews={true}\n    />\n  );\n}\n```\n\n\n---\n\nVisibility Tracking (Auto-Play)\n\nAuto-play videos when they become visible in the viewport:\n\n\n```tsx\nimport { useRef, useState } from 'react';\nimport { FlatList, ViewabilityConfig } from 'react-native';\n\nexport function VideoFeed() {\n  const [videos, setVideos] = useState<Video[]>([]);\n  const [visibleVideoId, setVisibleVideoId] = useState<string | null>(null);\n\n  // Configure what counts as \"visible\"\n  const viewabilityConfig: ViewabilityConfig = {\n    itemVisiblePercentThreshold: 50, // Video is visible when 50% is on screen\n    minimumViewTime: 500, // Must be visible for 500ms\n  };\n\n  // Track which video is currently visible\n  const onViewableItemsChanged = useRef(({ viewableItems }) => {\n    if (viewableItems.length > 0) {\n      // Get the first fully visible video\n      const visibleVideo = viewableItems.find(\n        (item) => item.isViewable && item.item.playbackId\n      );\n\n      if (visibleVideo) {\n        setVisibleVideoId(visibleVideo.item.id);\n      }\n    } else {\n      // No videos visible, pause all\n      setVisibleVideoId(null);\n    }\n  }).current;\n\n  return (\n    <FlatList\n      data={videos}\n      renderItem={({ item }) => (\n        <VideoCard\n          video={item}\n          shouldPlay={item.id === visibleVideoId}\n        />\n      )}\n      keyExtractor={(item) => item.id}\n      onViewableItemsChanged={onViewableItemsChanged}\n      viewabilityConfig={viewabilityConfig}\n    />\n  );\n}\n```\n\n\n---\n\nVideo Card Component\n\nIndividual video item with auto-play support:\n\n\n```tsx\nimport Video from 'react-native-video';\nimport { useState, useEffect } from 'react';\nimport { View, Text, Image, StyleSheet, TouchableOpacity } from 'react-native';\n\ninterface VideoCardProps {\n  video: Video;\n  shouldPlay: boolean;\n}\n\nexport function VideoCard({ video, shouldPlay }: VideoCardProps) {\n  const [paused, setPaused] = useState(!shouldPlay);\n  const [showControls, setShowControls] = useState(false);\n  const [muted, setMuted] = useState(true); // Start muted for auto-play\n\n  const playbackUrl = `https://stream.mux.com/${video.playbackId}.m3u8`;\n  const thumbnailUrl = `https://image.mux.com/${video.playbackId}/thumbnail.jpg`;\n\n  // Sync paused state with shouldPlay prop\n  useEffect(() => {\n    setPaused(!shouldPlay);\n  }, [shouldPlay]);\n\n  return (\n    <View style={styles.container}>\n      <TouchableOpacity\n        activeOpacity={1}\n        onPress={() => setPaused(!paused)}\n        style={styles.videoContainer}\n      >\n        <Video\n          source={{ uri: playbackUrl }}\n          style={styles.video}\n          resizeMode=\"cover\"\n          paused={paused}\n          muted={muted}\n          repeat={false}\n          poster={thumbnailUrl}\n          posterResizeMode=\"cover\"\n        />\n\n        {/* Mute toggle */}\n        <TouchableOpacity\n          style={styles.muteButton}\n          onPress={() => setMuted(!muted)}\n        >\n          <Text style={styles.muteIcon}>{muted ? '🔇' : '🔊'}</Text>\n        </TouchableOpacity>\n\n        {/* Play/Pause overlay */}\n        {paused && (\n          <View style={styles.pausedOverlay}>\n            <View style={styles.playButton}>\n              <Text style={styles.playIcon}>▶️</Text>\n            </View>\n          </View>\n        )}\n      </TouchableOpacity>\n\n      {/* Video metadata */}\n      <View style={styles.metadata}>\n        <Text style={styles.title} numberOfLines={2}>\n          {video.title}\n        </Text>\n        <Text style={styles.views}>\n          {video.views.toLocaleString()} views\n        </Text>\n      </View>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    marginBottom: 24,\n  },\n  videoContainer: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n    backgroundColor: '#000',\n    borderRadius: 12,\n    overflow: 'hidden',\n  },\n  video: {\n    width: '100%',\n    height: '100%',\n  },\n  pausedOverlay: {\n    ...StyleSheet.absoluteFillObject,\n    justifyContent: 'center',\n    alignItems: 'center',\n    backgroundColor: 'rgba(0, 0, 0, 0.3)',\n  },\n  playButton: {\n    width: 64,\n    height: 64,\n    borderRadius: 32,\n    backgroundColor: 'rgba(255, 255, 255, 0.9)',\n    justifyContent: 'center',\n    alignItems: 'center',\n  },\n  playIcon: {\n    fontSize: 24,\n  },\n  muteButton: {\n    position: 'absolute',\n    bottom: 12,\n    right: 12,\n    width: 36,\n    height: 36,\n    borderRadius: 18,\n    backgroundColor: 'rgba(0, 0, 0, 0.6)',\n    justifyContent: 'center',\n    alignItems: 'center',\n  },\n  muteIcon: {\n    fontSize: 18,\n  },\n  metadata: {\n    marginTop: 12,\n    paddingHorizontal: 4,\n  },\n  title: {\n    fontSize: 16,\n    fontWeight: '600',\n    color: '#000',\n    marginBottom: 4,\n  },\n  views: {\n    fontSize: 14,\n    color: '#666',\n  },\n});\n```\n\n\n---\n\nPreloading Strategy\n\nPreload video metadata for smooth playback starts:\n\n\n```tsx\nimport { useEffect, useRef } from 'react';\n\nexport function VideoCard({ video, shouldPlay }: VideoCardProps) {\n  const videoRef = useRef<Video>(null);\n  const [isReady, setIsReady] = useState(false);\n\n  // Preload video when component mounts\n  useEffect(() => {\n    // Video component loads metadata automatically\n    // We just need to track when it's ready\n  }, []);\n\n  return (\n    <Video\n      ref={videoRef}\n      source={{ uri: playbackUrl }}\n      paused={!shouldPlay || !isReady}\n      onLoad={() => setIsReady(true)} // Video is ready to play\n      onBuffer={({ isBuffering }) => {\n        // Handle buffering states\n        if (isBuffering) {\n          setIsLoading(true);\n        }\n      }}\n      onReadyForDisplay={() => {\n        // Video is ready to display\n        setIsReady(true);\n      }}\n    />\n  );\n}\n```\n\n\nHLS (the format Mux uses) handles adaptive streaming automatically. You don't need to preload entire videos - just let the HLS manifest load and the player will handle the rest.\n\n---\n\nMemory Management\n\nProperly manage memory in video feeds to prevent crashes:\n\n\n```tsx\nimport { FlatList } from 'react-native';\nimport React, { memo } from 'react';\n\n// Memoize VideoCard to prevent unnecessary re-renders\nconst VideoCard = memo(({ video, shouldPlay }: VideoCardProps) => {\n  return (\n    <Video\n      source={{ uri: `https://stream.mux.com/${video.playbackId}.m3u8` }}\n      paused={!shouldPlay}\n    />\n  );\n}, (prevProps, nextProps) => {\n  // Only re-render if video ID or shouldPlay changes\n  return (\n    prevProps.video.id === nextProps.video.id &&\n    prevProps.shouldPlay === nextProps.shouldPlay\n  );\n});\n\nexport function VideoFeed() {\n  return (\n    <FlatList\n      data={videos}\n      renderItem={({ item }) => <VideoCard video={item} />}\n\n      // Memory management\n      windowSize={3} // Render 3 screens worth of content\n      maxToRenderPerBatch={3} // Render 3 items per batch\n      initialNumToRender={2} // Only render 2 items initially\n      removeClippedSubviews={true} // Remove off-screen views (Android)\n\n      // Performance optimizations\n      getItemLayout={(data, index) => ({\n        length: ITEM_HEIGHT,\n        offset: ITEM_HEIGHT * index,\n        index,\n      })}\n    />\n  );\n}\n```\n\n\nCleanup Video References\n\n\n```tsx\nexport function VideoCard({ video, shouldPlay }: VideoCardProps) {\n  const videoRef = useRef<Video>(null);\n\n  useEffect(() => {\n    return () => {\n      // Cleanup when component unmounts\n      if (videoRef.current) {\n        videoRef.current = null;\n      }\n    };\n  }, []);\n\n  return <Video ref={videoRef} />;\n}\n```\n\n\n---\n\nPagination and Infinite Scroll\n\nLoad more videos as the user scrolls:\n\n\n```tsx\nexport function VideoFeed() {\n  const [videos, setVideos] = useState<Video[]>([]);\n  const [loading, setLoading] = useState(false);\n  const [hasMore, setHasMore] = useState(true);\n  const [page, setPage] = useState(1);\n\n  // Load initial videos\n  useEffect(() => {\n    loadVideos();\n  }, []);\n\n  const loadVideos = async () => {\n    if (loading || !hasMore) return;\n\n    setLoading(true);\n\n    try {\n      const response = await fetch(`${API_URL}/videos?page=${page}&limit=10`);\n      const newVideos = await response.json();\n\n      if (newVideos.length === 0) {\n        setHasMore(false);\n      } else {\n        setVideos((prev) => [...prev, ...newVideos]);\n        setPage((prev) => prev + 1);\n      }\n    } catch (error) {\n      console.error('Failed to load videos:', error);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const handleEndReached = () => {\n    loadVideos();\n  };\n\n  return (\n    <FlatList\n      data={videos}\n      renderItem={({ item }) => <VideoCard video={item} />}\n      keyExtractor={(item) => item.id}\n      onEndReached={handleEndReached}\n      onEndReachedThreshold={0.5} // Load more when 50% from bottom\n      ListFooterComponent={\n        loading ? (\n          <View style={styles.loader}>\n            <ActivityIndicator size=\"large\" />\n          </View>\n        ) : null\n      }\n    />\n  );\n}\n```\n\n\n---\n\nPull to Refresh\n\nAllow users to refresh the feed:\n\n\n```tsx\nimport { RefreshControl } from 'react-native';\n\nexport function VideoFeed() {\n  const [refreshing, setRefreshing] = useState(false);\n\n  const handleRefresh = async () => {\n    setRefreshing(true);\n\n    try {\n      const response = await fetch(`${API_URL}/videos?page=1&limit=10`);\n      const newVideos = await response.json();\n\n      setVideos(newVideos);\n      setPage(2);\n      setHasMore(true);\n    } catch (error) {\n      console.error('Failed to refresh:', error);\n    } finally {\n      setRefreshing(false);\n    }\n  };\n\n  return (\n    <FlatList\n      data={videos}\n      renderItem={({ item }) => <VideoCard video={item} />}\n      refreshControl={\n        <RefreshControl\n          refreshing={refreshing}\n          onRefresh={handleRefresh}\n          tintColor=\"#007AFF\"\n        />\n      }\n    />\n  );\n}\n```\n\n\n---\n\nEmpty and Error States\n\nHandle empty feeds and errors gracefully:\n\n\n```tsx\nexport function VideoFeed() {\n  const [videos, setVideos] = useState<Video[]>([]);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState<string | null>(null);\n\n  // Empty state\n  if (!loading && videos.length === 0 && !error) {\n    return (\n      <View style={styles.emptyContainer}>\n        <Text style={styles.emptyIcon}>📹</Text>\n        <Text style={styles.emptyTitle}>No videos yet</Text>\n        <Text style={styles.emptyText}>\n          Check back later for new content!\n        </Text>\n      </View>\n    );\n  }\n\n  // Error state\n  if (error) {\n    return (\n      <View style={styles.errorContainer}>\n        <Text style={styles.errorIcon}>⚠️</Text>\n        <Text style={styles.errorTitle}>Unable to load videos</Text>\n        <Text style={styles.errorText}>{error}</Text>\n        <TouchableOpacity\n          style={styles.retryButton}\n          onPress={() => loadVideos()}\n        >\n          <Text style={styles.retryButtonText}>Retry</Text>\n        </TouchableOpacity>\n      </View>\n    );\n  }\n\n  // Loading state\n  if (loading && videos.length === 0) {\n    return (\n      <View style={styles.loadingContainer}>\n        <ActivityIndicator size=\"large\" color=\"#007AFF\" />\n        <Text style={styles.loadingText}>Loading videos...</Text>\n      </View>\n    );\n  }\n\n  return (\n    <FlatList\n      data={videos}\n      renderItem={({ item }) => <VideoCard video={item} />}\n    />\n  );\n}\n```\n\n\n---\n\nComplete Video Feed Implementation\n\nHere's a complete, production-ready video feed:\n\n\n```tsx\nimport React, { useState, useEffect, useRef } from 'react';\nimport {\n  FlatList,\n  View,\n  Text,\n  ActivityIndicator,\n  RefreshControl,\n  StyleSheet,\n  ViewToken,\n} from 'react-native';\nimport { VideoCard } from './VideoCard';\n\ninterface Video {\n  id: string;\n  playbackId: string;\n  title: string;\n  views: number;\n  duration: number;\n}\n\nconst ITEM_HEIGHT = 280; // Approximate height for getItemLayout\n\nexport function VideoFeed() {\n  const [videos, setVideos] = useState<Video[]>([]);\n  const [loading, setLoading] = useState(true);\n  const [refreshing, setRefreshing] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n  const [page, setPage] = useState(1);\n  const [hasMore, setHasMore] = useState(true);\n  const [visibleVideoId, setVisibleVideoId] = useState<string | null>(null);\n\n  // Load initial videos\n  useEffect(() => {\n    loadVideos();\n  }, []);\n\n  const loadVideos = async (isRefresh = false) => {\n    if ((loading && !isRefresh) || !hasMore) return;\n\n    if (isRefresh) {\n      setRefreshing(true);\n      setPage(1);\n      setHasMore(true);\n    } else {\n      setLoading(true);\n    }\n\n    try {\n      const currentPage = isRefresh ? 1 : page;\n      const response = await fetch(\n        `${API_URL}/videos?page=${currentPage}&limit=10`\n      );\n\n      if (!response.ok) {\n        throw new Error('Failed to load videos');\n      }\n\n      const newVideos: Video[] = await response.json();\n\n      if (newVideos.length === 0) {\n        setHasMore(false);\n      } else {\n        if (isRefresh) {\n          setVideos(newVideos);\n        } else {\n          setVideos((prev) => [...prev, ...newVideos]);\n        }\n        setPage((prev) => prev + 1);\n      }\n\n      setError(null);\n    } catch (err) {\n      setError(err instanceof Error ? err.message : 'An error occurred');\n    } finally {\n      setLoading(false);\n      setRefreshing(false);\n    }\n  };\n\n  // Visibility tracking\n  const viewabilityConfig = useRef({\n    itemVisiblePercentThreshold: 50,\n    minimumViewTime: 300,\n  }).current;\n\n  const onViewableItemsChanged = useRef(\n    ({ viewableItems }: { viewableItems: ViewToken[] }) => {\n      if (viewableItems.length > 0) {\n        const visibleItem = viewableItems[0];\n        if (visibleItem.item && visibleItem.isViewable) {\n          setVisibleVideoId(visibleItem.item.id);\n        }\n      } else {\n        setVisibleVideoId(null);\n      }\n    }\n  ).current;\n\n  // Render item\n  const renderItem = ({ item }: { item: Video }) => (\n    <VideoCard\n      video={item}\n      shouldPlay={item.id === visibleVideoId}\n    />\n  );\n\n  // Empty state\n  const renderEmpty = () => {\n    if (loading) return null;\n\n    return (\n      <View style={styles.emptyContainer}>\n        <Text style={styles.emptyIcon}>📹</Text>\n        <Text style={styles.emptyTitle}>No videos yet</Text>\n        <Text style={styles.emptyText}>Check back later for new content!</Text>\n      </View>\n    );\n  };\n\n  // Footer (loading indicator)\n  const renderFooter = () => {\n    if (!loading || videos.length === 0) return null;\n\n    return (\n      <View style={styles.footer}>\n        <ActivityIndicator size=\"small\" color=\"#007AFF\" />\n      </View>\n    );\n  };\n\n  // Error state\n  if (error && videos.length === 0) {\n    return (\n      <View style={styles.errorContainer}>\n        <Text style={styles.errorIcon}>⚠️</Text>\n        <Text style={styles.errorTitle}>Unable to load videos</Text>\n        <Text style={styles.errorText}>{error}</Text>\n        <TouchableOpacity\n          style={styles.retryButton}\n          onPress={() => loadVideos()}\n        >\n          <Text style={styles.retryText}>Retry</Text>\n        </TouchableOpacity>\n      </View>\n    );\n  }\n\n  return (\n    <FlatList\n      data={videos}\n      renderItem={renderItem}\n      keyExtractor={(item) => item.id}\n      // Visibility tracking\n      onViewableItemsChanged={onViewableItemsChanged}\n      viewabilityConfig={viewabilityConfig}\n      // Pagination\n      onEndReached={() => loadVideos()}\n      onEndReachedThreshold={0.5}\n      // Pull to refresh\n      refreshControl={\n        <RefreshControl\n          refreshing={refreshing}\n          onRefresh={() => loadVideos(true)}\n        />\n      }\n      // Empty state\n      ListEmptyComponent={renderEmpty}\n      // Footer\n      ListFooterComponent={renderFooter}\n      // Performance\n      initialNumToRender={3}\n      maxToRenderPerBatch={5}\n      windowSize={5}\n      removeClippedSubviews={true}\n      getItemLayout={(data, index) => ({\n        length: ITEM_HEIGHT,\n        offset: ITEM_HEIGHT * index,\n        index,\n      })}\n      // Styling\n      contentContainerStyle={styles.contentContainer}\n      showsVerticalScrollIndicator={true}\n    />\n  );\n}\n\nconst styles = StyleSheet.create({\n  contentContainer: {\n    paddingHorizontal: 16,\n    paddingTop: 16,\n    flexGrow: 1,\n  },\n  emptyContainer: {\n    flex: 1,\n    justifyContent: 'center',\n    alignItems: 'center',\n    paddingVertical: 64,\n  },\n  emptyIcon: {\n    fontSize: 64,\n    marginBottom: 16,\n  },\n  emptyTitle: {\n    fontSize: 20,\n    fontWeight: '600',\n    color: '#000',\n    marginBottom: 8,\n  },\n  emptyText: {\n    fontSize: 16,\n    color: '#666',\n    textAlign: 'center',\n  },\n  errorContainer: {\n    flex: 1,\n    justifyContent: 'center',\n    alignItems: 'center',\n    padding: 32,\n  },\n  errorIcon: {\n    fontSize: 64,\n    marginBottom: 16,\n  },\n  errorTitle: {\n    fontSize: 20,\n    fontWeight: '600',\n    color: '#000',\n    marginBottom: 8,\n  },\n  errorText: {\n    fontSize: 16,\n    color: '#666',\n    textAlign: 'center',\n    marginBottom: 24,\n  },\n  retryButton: {\n    backgroundColor: '#007AFF',\n    paddingHorizontal: 24,\n    paddingVertical: 12,\n    borderRadius: 8,\n  },\n  retryText: {\n    color: '#fff',\n    fontSize: 16,\n    fontWeight: '600',\n  },\n  footer: {\n    paddingVertical: 24,\n    alignItems: 'center',\n  },\n});\n```\n\n\n---\n\nPerformance Tips\n\nDo's ✅\n- Use React.memo for VideoCard components\n- Implement proper getItemLayout for FlatList\n- Set reasonable windowSize (3-5 screens)\n- Use removeClippedSubviews on Android\n- Mute videos by default for auto-play\n- Only play one video at a time\n- Cleanup video refs on unmount\n\nDon'ts ❌\n- Don't render all videos at once\n- Don't play multiple videos simultaneously\n- Don't forget to pause videos when scrolled away\n- Don't load entire videos in advance (HLS handles streaming)\n- Don't skip keyExtractor (causes render issues)\n\n---\n\nHorizontal Video Feed\n\nFor YouTube-style horizontal scrolling:\n\n\n```tsx\nexport function HorizontalVideoFeed() {\n  return (\n    <FlatList\n      data={videos}\n      renderItem={({ item }) => <VideoCard video={item} />}\n      horizontal\n      pagingEnabled\n      showsHorizontalScrollIndicator={false}\n      snapToAlignment=\"center\"\n      decelerationRate=\"fast\"\n      snapToInterval={CARD_WIDTH + CARD_MARGIN}\n    />\n  );\n}\n```\n\n\n---\n\nNext Steps\n\n  <GuideCard\n    title=\"Stories/Reels UI\"\n    description=\"Build full-screen vertical video swiper like TikTok and Instagram Stories\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/stories-reels-ui\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Mux Data Analytics\"\n    description=\"Track video performance and display engagement metrics\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/mux-data-analytics\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Best Practices\"\n    description=\"Optimize video feed performance for production\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/guides/react-native/best-practices\"},\n    ]}\n  />"
  },
  {
    "id": "172-_guides/frameworks/react-native-video-playback",
    "title": "Video playback in React Native",
    "path": "_guides/frameworks/react-native-video-playback.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/react-native-video-playback",
    "content": "This guide covers everything you need to know to build a robust, production-ready video player in React Native using Mux and expo-video. If you haven't already, start with the quickstart guide to get basic playback working.\n\nUnderstanding HLS playback\n\nMux delivers video using HLS (HTTP Live Streaming), which is natively supported on both iOS and Android. This means:\n\n- Videos stream in segments, not as a single large file\n- Quality automatically adapts to network conditions (ABR - Adaptive Bitrate)\n- Playback can start before the entire video downloads\n- Works seamlessly on cellular networks\n\n  Learn more about how Mux handles video streaming in the main documentation.\n\nPlayback IDs and URLs\n\nEvery Mux video has a playback ID that you use to construct the streaming URL:\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8\n```\n\n\nPublic vs Signed playback\n\nMux supports two types of playback policies:\n\n- Public playback IDs: Anyone with the URL can play the video\n- Signed playback IDs: Requires a JWT token for access control\n\nFor signed playback, you'll need to generate a JWT on your backend and include it as a query parameter:\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?token={JWT}\n```\n\n\n  Learn how to secure video playback with signed URLs including JWT generation and domain restrictions.\n\nFor React Native apps, handle signed URLs by fetching the token from your backend before playing:\n\n\n```tsx\nimport React, { useState, useEffect } from 'react';\nimport { View, ActivityIndicator, StyleSheet } from 'react-native';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nfunction SecureVideoPlayer({ playbackId }: { playbackId: string }) {\n  const [videoUrl, setVideoUrl] = useState<string | null>(null);\n\n  useEffect(() => {\n    // Fetch signed URL from your backend\n    fetch('https://your-api.com/video/signed-url', {\n      method: 'POST',\n      body: JSON.stringify({ playbackId }),\n    })\n      .then(res => res.json())\n      .then(data => setVideoUrl(data.url));\n  }, [playbackId]);\n\n  const player = useVideoPlayer(videoUrl, player => {\n    player.play();\n  });\n\n  if (!videoUrl) {\n    return <ActivityIndicator />;\n  }\n\n  return (\n    <VideoView\n      player={player}\n      style={styles.video}\n      nativeControls\n    />\n  );\n}\n\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n});\n```\n\n\nManaging player state\n\nBuilding a robust video player requires handling multiple states: loading, playing, paused, buffering, and errors. The expo-video library uses an event-based system with hooks from the expo package.\n\n\n```tsx\nimport React from 'react';\nimport { View, ActivityIndicator, Text, StyleSheet } from 'react-native';\nimport { useEvent } from 'expo';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\ninterface VideoPlayerProps {\n  playbackId: string;\n}\n\nexport default function VideoPlayer({ playbackId }: VideoPlayerProps) {\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.loop = false;\n      player.play();\n    }\n  );\n\n  const { status, error } = useEvent(player, 'statusChange', {\n    status: player.status,\n  });\n\n  const { isPlaying } = useEvent(player, 'playingChange', {\n    isPlaying: player.playing,\n  });\n\n  if (status === 'error') {\n    return (\n      <View style={styles.container}>\n        <Text style={styles.errorText}>\n          {error?.message || 'Failed to load video. Please try again.'}\n        </Text>\n      </View>\n    );\n  }\n\n  return (\n    <View style={styles.container}>\n      {status === 'loading' && (\n        <ActivityIndicator\n          size=\"large\"\n          color=\"#fff\"\n          style={styles.loader}\n        />\n      )}\n      <VideoView\n        player={player}\n        style={styles.video}\n        nativeControls\n        contentFit=\"contain\"\n      />\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    position: 'relative',\n    backgroundColor: '#000',\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  loader: {\n    position: 'absolute',\n    top: '50%',\n    left: '50%',\n    marginLeft: -20,\n    marginTop: -20,\n    zIndex: 10,\n  },\n  errorText: {\n    color: '#fff',\n    textAlign: 'center',\n    padding: 20,\n  },\n});\n```\n\n\nListening to player events\n\nThe expo-video player emits events that you can listen to using hooks from the expo package:\n\nUsing the useEvent hook\n\nCreates a listener that returns a stateful value for use in components:\n\n\n```tsx\nimport { useEvent } from 'expo';\n\nconst { status, error } = useEvent(player, 'statusChange', {\n  status: player.status,\n});\n\nconst { isPlaying } = useEvent(player, 'playingChange', {\n  isPlaying: player.playing,\n});\n```\n\n\nUsing the useEventListener hook\n\nFor side effects when events occur:\n\n\n```tsx\nimport { useEventListener } from 'expo';\n\nuseEventListener(player, 'statusChange', ({ status, error }) => {\n  console.log('Player status changed:', status);\n  if (error) {\n    console.error('Player error:', error);\n  }\n});\n\nuseEventListener(player, 'playToEnd', () => {\n  console.log('Video finished playing');\n  player.replay();\n});\n```\n\n\nKey player events\n\n| Event | When it fires | Use case |\n|-------|---------------|----------|\n| statusChange | Player status changes (idle, loading, readyToPlay, error) | Show loading states, handle errors |\n| playingChange | Play/pause state changes | Update play/pause button |\n| timeUpdate | Periodically during playback | Update progress bar |\n| sourceLoad | Video source finishes loading | Get duration, available tracks |\n| playToEnd | Video finishes playing | Auto-play next video, show replay |\n\nPoster images and thumbnails\n\nMux automatically generates thumbnails for your videos. Display a poster image that users tap to start playback:\n\n\n```tsx\nimport React, { useState } from 'react';\nimport { View, Image, Pressable, StyleSheet } from 'react-native';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nexport default function VideoWithPoster({ playbackId }: { playbackId: string }) {\n  const [showPoster, setShowPoster] = useState(true);\n  const posterUrl = `https://image.mux.com/${playbackId}/thumbnail.png?time=0`;\n\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.loop = false;\n      // Don't autoplay - wait for user to tap poster\n    }\n  );\n\n  const handlePosterPress = () => {\n    setShowPoster(false);\n    player.play();\n  };\n\n  return (\n    <View style={styles.container}>\n      <VideoView\n        player={player}\n        style={styles.video}\n        nativeControls\n        contentFit=\"contain\"\n      />\n      {showPoster && (\n        <Pressable onPress={handlePosterPress} style={styles.poster}>\n          <Image\n            source={{ uri: posterUrl }}\n            style={styles.poster}\n            resizeMode=\"cover\"\n          />\n        </Pressable>\n      )}\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    position: 'relative',\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  poster: {\n    position: 'absolute',\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n});\n```\n\n\nThumbnail URL options\n\n\n```\nhttps://image.mux.com/{PLAYBACK_ID}/thumbnail.{format}?{params}\n```\n\n\nCommon parameters:\n\n- time - Timestamp in seconds (e.g., time=5 for 5 seconds in)\n- width - Thumbnail width in pixels (e.g., width=640)\n- height - Thumbnail height in pixels (e.g., height=360)\n- fit_mode - How to resize: preserve, stretch, crop, smartcrop\n\nExample:\n\n\n```tsx\nconst thumbnail = `https://image.mux.com/${playbackId}/thumbnail.jpg?time=5&width=1280&fit_mode=smartcrop`;\n```\n\n\n  Learn more about thumbnail options and image transformations in the main docs.\n\nAspect ratios for different use cases\n\nChoose the right aspect ratio based on your app's design:\n\nLandscape video (16:9)\n\nStandard for most video content:\n\n\n```tsx\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9, // 1.777\n  },\n});\n```\n\n\nPortrait video (9:16)\n\nFor Stories, Reels, or TikTok-style feeds:\n\n\n```tsx\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 9 / 16, // 0.5625\n  },\n});\n```\n\n\nSquare video (1:1)\n\nFor social feeds:\n\n\n```tsx\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 1, // 1.0\n  },\n});\n```\n\n\nDynamic aspect ratio\n\nMatch the video's actual dimensions using the sourceLoad event:\n\n\n```tsx\nimport { View, StyleSheet } from 'react-native';\nimport { useEvent } from 'expo';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nexport default function DynamicVideoPlayer({ playbackId = \"TPsqaPkOFCKQHVGQ00Khp0256fLo4FAsEHjCTeWi02JyrM\" }: { playbackId: string }) {\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.play();\n    }\n  );\n\n  const loadedMetadata = useEvent(player, 'sourceLoad');\n\n  // Calculate aspect ratio from available video tracks\n  const aspectRatio = (() => {\n    const tracks = loadedMetadata?.availableVideoTracks;\n    if (tracks && tracks.length > 0) {\n      const { width, height } = tracks[0].size;\n      return width / height;\n    }\n    return 16 / 9; // Default fallback\n  })();\n\n  return (\n    <VideoView\n      player={player}\n      style={[styles.video, { aspectRatio }]}\n      nativeControls\n    />\n  );\n}\n\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n  },\n});\n```\n\n\n  The sourceLoad event and video track metadata work reliably on iOS and Android. On web, this event may not fire consistently. If you need dynamic aspect ratios across all platforms, consider fetching video dimensions from the Mux API or storing them alongside your playback ID.\n\nFullscreen support\n\nEnable fullscreen mode using the VideoView ref methods:\n\n\n```tsx\nimport React, { useRef } from 'react';\nimport { View, TouchableOpacity, Text, StyleSheet } from 'react-native';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nexport default function VideoPlayerWithFullscreen({ playbackId }: { playbackId: string }) {\n  const videoRef = useRef<VideoView>(null);\n\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.play();\n    }\n  );\n\n  const enterFullscreen = async () => {\n    await videoRef.current?.enterFullscreen();\n  };\n\n  const exitFullscreen = async () => {\n    await videoRef.current?.exitFullscreen();\n  };\n\n  return (\n    <View>\n      <VideoView\n        ref={videoRef}\n        player={player}\n        style={styles.video}\n        nativeControls={false}\n        allowsFullscreen\n        onFullscreenEnter={() => console.log('Entered fullscreen')}\n        onFullscreenExit={() => console.log('Exited fullscreen')}\n      />\n      <TouchableOpacity onPress={enterFullscreen} style={styles.button}>\n        <Text style={styles.buttonText}>Go big or go home</Text>\n      </TouchableOpacity>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  button: {\n    backgroundColor: '#ec9430ff',\n    padding: 12,\n    borderRadius: 8,\n    marginTop: 10,\n    alignItems: 'center',\n  },\n  buttonText: {\n    color: '#fff',\n    fontWeight: 'bold',\n  },\n});\n```\n\n\n  Fullscreen behavior is handled natively by the platform. On iOS, this uses AVPlayerViewController. On Android, this uses ExoPlayer's fullscreen controller.\n\nError handling\n\nNetwork issues are common on mobile. Implement robust error handling:\n\n\n```tsx\nimport React, { useState, useCallback } from 'react';\nimport { View, Text, TouchableOpacity, StyleSheet } from 'react-native';\nimport { useEvent } from 'expo';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nfunction VideoPlayerWithRetry({ playbackId }: { playbackId: string }) {\n  const [retryKey, setRetryKey] = useState(0);\n\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.play();\n    }\n  );\n\n  const { status, error } = useEvent(player, 'statusChange', {\n    status: player.status,\n  });\n\n  const retry = useCallback(() => {\n    player.replay();\n    setRetryKey(prev => prev + 1);\n  }, [player]);\n\n  const getErrorMessage = (error: any) => {\n    // Categorize errors based on the error message\n    const message = error?.message || '';\n    if (message.includes('network') || message.includes('ENOTFOUND')) {\n      return 'Network error. Check your connection.';\n    } else if (message.includes('403') || message.includes('forbidden')) {\n      return 'This video is not available.';\n    }\n    return 'Failed to load video.';\n  };\n\n  if (status === 'error') {\n    return (\n      <View style={styles.errorContainer}>\n        <Text style={styles.errorText}>{getErrorMessage(error)}</Text>\n        <TouchableOpacity style={styles.retryButton} onPress={retry}>\n          <Text style={styles.retryText}>Retry</Text>\n        </TouchableOpacity>\n      </View>\n    );\n  }\n\n  return (\n    <VideoView\n      key={retryKey}\n      player={player}\n      style={styles.video}\n      nativeControls\n    />\n  );\n}\n\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  errorContainer: {\n    backgroundColor: '#000',\n    padding: 40,\n    alignItems: 'center',\n    justifyContent: 'center',\n    aspectRatio: 16 / 9,\n  },\n  errorText: {\n    color: '#fff',\n    fontSize: 16,\n    textAlign: 'center',\n    marginBottom: 20,\n  },\n  retryButton: {\n    backgroundColor: '#fff',\n    paddingHorizontal: 20,\n    paddingVertical: 10,\n    borderRadius: 5,\n  },\n  retryText: {\n    color: '#000',\n    fontWeight: 'bold',\n  },\n});\n```\n\n\nCommon error scenarios\n\n| Error | Cause | Solution |\n|-------|-------|----------|\n| Network timeout | Slow/no connection | Show retry button, check network status |\n| 403 Forbidden | Invalid playback ID or signed URL expired | Refresh token, verify playback ID |\n| Video not loading | Asset still processing | Check asset status, show \"processing\" message |\n| Playback stalled | Poor network | HLS handles this automatically via ABR |\n\nCustom controls\n\nBuild custom video controls by setting nativeControls={false} and tracking playback state with events. This example creates a control bar with a play/pause button, scrubbing slider, and current/total time displays using @react-native-community/slider:\n\n\n```tsx\nimport React from 'react';\nimport { View, TouchableOpacity, Text, StyleSheet } from 'react-native';\nimport { useEvent } from 'expo';\nimport { useVideoPlayer, VideoView } from 'expo-video';\nimport Slider from '@react-native-community/slider';\n\nexport default function CustomControlsPlayer({ playbackId }: { playbackId: string }) {\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.timeUpdateEventInterval = 0.25; // Update every 250ms\n    }\n  );\n\n  const { isPlaying } = useEvent(player, 'playingChange', {\n    isPlaying: player.playing,\n  });\n\n  const timeUpdate = useEvent(player, 'timeUpdate');\n  const currentTime = timeUpdate?.currentTime ?? 0;\n  const duration = player.duration;\n\n  const handleSeek = (time: number) => {\n    player.currentTime = time;\n  };\n\n  const togglePlayback = () => {\n    if (isPlaying) {\n      player.pause();\n    } else {\n      player.play();\n    }\n  };\n\n  const formatTime = (seconds: number) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  return (\n    <View style={styles.container}>\n      <VideoView\n        player={player}\n        style={styles.video}\n        nativeControls={false}\n        contentFit=\"contain\"\n      />\n\n      <View style={styles.controls}>\n        <TouchableOpacity onPress={togglePlayback}>\n          <Text style={styles.controlText}>\n            {isPlaying ? '⏸' : '▶'}\n          </Text>\n        </TouchableOpacity>\n\n        <Text style={styles.time}>{formatTime(currentTime)}</Text>\n\n        <Slider\n          style={styles.slider}\n          value={currentTime}\n          minimumValue={0}\n          maximumValue={duration || 1}\n          onSlidingComplete={handleSeek}\n          minimumTrackTintColor=\"#fff\"\n          maximumTrackTintColor=\"#666\"\n          thumbTintColor=\"#fff\"\n        />\n\n        <Text style={styles.time}>{formatTime(duration || 0)}</Text>\n      </View>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    backgroundColor: '#000',\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  controls: {\n    flexDirection: 'row',\n    alignItems: 'center',\n    padding: 10,\n    backgroundColor: 'rgba(0,0,0,0.7)',\n  },\n  controlText: {\n    color: '#fff',\n    fontSize: 24,\n    marginRight: 10,\n  },\n  time: {\n    color: '#fff',\n    fontSize: 12,\n    marginHorizontal: 5,\n  },\n  slider: {\n    flex: 1,\n    marginHorizontal: 10,\n  },\n});\n```\n\n\nPlayback speed control\n\nAllow users to adjust playback speed for faster or slower viewing:\n\n\n```tsx\nimport React, { useState, useCallback } from 'react';\nimport { View, TouchableOpacity, Text, StyleSheet } from 'react-native';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nconst PLAYBACK_SPEEDS = [0.5, 0.75, 1, 1.25, 1.5, 2];\n\nexport default function VideoPlayerWithSpeed({ playbackId }: { playbackId: string }) {\n  const [speedIndex, setSpeedIndex] = useState(2); // Default to 1x\n\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.play();\n    }\n  );\n\n  const cycleSpeed = useCallback(() => {\n    const nextIndex = (speedIndex + 1) % PLAYBACK_SPEEDS.length;\n    setSpeedIndex(nextIndex);\n    player.playbackRate = PLAYBACK_SPEEDS[nextIndex];\n  }, [player, speedIndex]);\n\n  return (\n    <View style={styles.container}>\n      <VideoView\n        player={player}\n        style={styles.video}\n        nativeControls\n        contentFit=\"contain\"\n      />\n      <TouchableOpacity onPress={cycleSpeed} style={styles.speedButton}>\n        <Text style={styles.speedText}>\n          Speed: {PLAYBACK_SPEEDS[speedIndex]}x\n        </Text>\n      </TouchableOpacity>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    backgroundColor: '#000',\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  speedButton: {\n    backgroundColor: '#ec9430ff',\n    padding: 12,\n    margin: 10,\n    borderRadius: 8,\n    alignItems: 'center',\n  },\n  speedText: {\n    color: '#fff',\n    fontSize: 14,\n    fontWeight: 'bold',\n  },\n});\n```\n\n\nTip: Use player.preservesPitch = true (default) to maintain audio pitch at higher speeds, or set to false for a \"chipmunk\" effect.\n\nPicture-in-Picture support\n\nEnable Picture-in-Picture mode for background video playback:\n\n\n```tsx\nimport React, { useRef, useState, useCallback } from 'react';\nimport { View, TouchableOpacity, Text, StyleSheet, Platform } from 'react-native';\nimport { useVideoPlayer, VideoView, isPictureInPictureSupported } from 'expo-video';\n\nexport default function VideoPlayerWithPiP({ playbackId }: { playbackId: string }) {\n  const videoRef = useRef<VideoView>(null);\n  const [isInPiP, setIsInPiP] = useState(false);\n\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.play();\n    }\n  );\n\n  const togglePiP = useCallback(() => {\n    if (!isInPiP) {\n      videoRef.current?.startPictureInPicture();\n    } else {\n      videoRef.current?.stopPictureInPicture();\n    }\n  }, [isInPiP]);\n\n  // Check PiP support (function only exists on iOS and Android)\n  const pipSupported = Platform.OS !== 'web' && isPictureInPictureSupported();\n\n  if (!pipSupported) {\n    return (\n      <View style={styles.container}>\n        <Text style={styles.errorText}>\n          Picture-in-Picture is not supported on this platform.\n        </Text>\n      </View>\n    );\n  }\n\n  return (\n    <View style={styles.container}>\n      <VideoView\n        ref={videoRef}\n        player={player}\n        style={styles.video}\n        nativeControls\n        allowsPictureInPicture\n        startsPictureInPictureAutomatically\n        onPictureInPictureStart={() => setIsInPiP(true)}\n        onPictureInPictureStop={() => setIsInPiP(false)}\n      />\n      <TouchableOpacity onPress={togglePiP} style={styles.button}>\n        <Text style={styles.buttonText}>\n          {isInPiP ? 'Exit' : 'Enter'} Picture-in-Picture\n        </Text>\n      </TouchableOpacity>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  container: {\n    backgroundColor: '#000',\n  },\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  button: {\n    backgroundColor: '#ec9430ff',\n    padding: 12,\n    margin: 10,\n    borderRadius: 8,\n    alignItems: 'center',\n  },\n  buttonText: {\n    color: '#fff',\n    fontWeight: 'bold',\n  },\n  errorText: {\n    color: '#fff',\n    textAlign: 'center',\n    padding: 20,\n  },\n});\n```\n\n\n  Picture-in-Picture requires configuration in your app.json:\n\n```json\n  {\n    \"expo\": {\n      \"plugins\": [\n        [\"expo-video\", { \"supportsPictureInPicture\": true }]\n      ]\n    }\n  }\n  ```\n\n\niOS vs Android considerations\n\nWhile expo-video abstracts most platform differences, be aware of:\n\niOS (AVPlayer)\n- Native HLS support\n- Picture-in-Picture available on iOS 14+\n- Smooth fullscreen transitions\n- AirPlay support via allowsExternalPlayback\n- Respects system audio settings\n\nAndroid (ExoPlayer)\n- Native HLS support via ExoPlayer\n- Picture-in-Picture on Android 12+\n- Configurable surface type (SurfaceView vs TextureView)\n- May require additional permissions for background playback\n\n  Test your video player on both iOS and Android physical devices, not just simulators. Network behavior and video codecs can differ between simulators and real devices.\n\nPlatform-specific configuration\n\nOptimize playback for each platform by detecting the OS and adjusting player settings. This example shows iOS-specific AirPlay support, platform-specific buffer configurations, and Android's TextureView for overlapping videos:\n\n\n```tsx\nimport { Platform } from 'react-native';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nexport default function PlatformAwarePlayer({ playbackId }: { playbackId: string }) {\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.play();\n\n      // iOS-specific settings\n      if (Platform.OS === 'ios') {\n        player.allowsExternalPlayback = true; // Enable AirPlay\n      }\n\n      // Configure buffer options\n      player.bufferOptions = {\n        preferredForwardBufferDuration: Platform.OS === 'ios' ? 0 : 20,\n        minBufferForPlayback: 2,\n      };\n    }\n  );\n\n  return (\n    <VideoView\n      player={player}\n      style={{ width: '100%', aspectRatio: 16 / 9 }}\n      nativeControls\n      // Android-specific: use TextureView for overlapping videos\n      surfaceType={Platform.OS === 'android' ? 'textureView' : undefined}\n    />\n  );\n}\n```\n\n\nPerformance tips\n\n1. Pause videos when not visible\n\n\n```tsx\nimport { useEffect } from 'react';\nimport { AppState } from 'react-native';\nimport { useVideoPlayer, VideoView } from 'expo-video';\n\nexport default function VideoPlayer({ playbackId }: { playbackId: string }) {\n  const player = useVideoPlayer(\n    `https://stream.mux.com/${playbackId}.m3u8`,\n    player => {\n      player.staysActiveInBackground = false;\n    }\n  );\n\n  useEffect(() => {\n    const subscription = AppState.addEventListener('change', (nextAppState) => {\n      if (nextAppState === 'active') {\n        player.play();\n      } else {\n        player.pause();\n      }\n    });\n\n    return () => subscription.remove();\n  }, [player]);\n\n  return (\n    <VideoView\n      player={player}\n      style={{ width: '100%', aspectRatio: 16 / 9 }}\n      nativeControls\n    />\n  );\n}\n```\n\n\n2. Preload videos for smoother transitions\n\n\n```tsx\nimport { useVideoPlayer, VideoView, VideoSource } from 'expo-video';\nimport { useState, useCallback } from 'react';\nimport { TouchableOpacity, Text, View, StyleSheet } from 'react-native';\n\nconst video1: VideoSource = 'https://stream.mux.com/PLAYBACK_ID_1.m3u8';\nconst video2: VideoSource = 'https://stream.mux.com/PLAYBACK_ID_2.m3u8';\n\nexport default function PreloadingPlayer() {\n  // Create both players - the second one preloads in the background\n  const player1 = useVideoPlayer(video1, player => {\n    player.play();\n  });\n\n  const player2 = useVideoPlayer(video2, player => {\n    player.currentTime = 0; // Preload from the start\n  });\n\n  const [currentPlayer, setCurrentPlayer] = useState(player1);\n\n  const switchVideo = useCallback(() => {\n    currentPlayer.pause();\n    if (currentPlayer === player1) {\n      setCurrentPlayer(player2);\n      player2.play();\n    } else {\n      setCurrentPlayer(player1);\n      player1.play();\n    }\n  }, [currentPlayer, player1, player2]);\n\n  return (\n    <View>\n      <VideoView player={currentPlayer} style={styles.video} nativeControls />\n      <TouchableOpacity onPress={switchVideo} style={styles.button}>\n        <Text style={styles.buttonText}>Switch Video</Text>\n      </TouchableOpacity>\n    </View>\n  );\n}\n\nconst styles = StyleSheet.create({\n  video: {\n    width: '100%',\n    aspectRatio: 16 / 9,\n  },\n  button: {\n    backgroundColor: '#4630ec',\n    padding: 12,\n    borderRadius: 8,\n    marginTop: 10,\n    alignItems: 'center',\n  },\n  buttonText: {\n    color: '#fff',\n    fontWeight: 'bold',\n  },\n});\n```\n\n\n3. Enable video caching\n\nIf your app frequently replays the same videos, enable caching to minimize network usage and improve playback performance. The cache is persistent and managed on a least-recently-used (LRU) basis:\n\n\n```tsx\nimport { useVideoPlayer, VideoView, VideoSource } from 'expo-video';\n\nfunction CachedVideoPlayer({ playbackId }: { playbackId: string }) {\n  const videoSource: VideoSource = {\n    uri: `https://stream.mux.com/${playbackId}.m3u8`,\n    useCaching: true,\n    metadata: {\n      title: 'My Video',\n    },\n  };\n\n  const player = useVideoPlayer(videoSource, player => {\n    player.play();\n  });\n\n  return (\n    <VideoView\n      player={player}\n      style={{ width: '100%', aspectRatio: 16 / 9 }}\n      nativeControls\n    />\n  );\n}\n```\n\n\nHow caching works:\n- The cache is persistent across app launches\n- Videos are evicted on a least-recently-used basis when the cache size limit is reached (default: 1GB)\n- The system may clear the cache when device storage is low\n- Cached videos can be played offline until the cached data is exhausted\n\nManaging the cache:\n\n```tsx\nimport {\n  setVideoCacheSizeAsync,\n  getCurrentVideoCacheSize,\n  clearVideoCacheAsync\n} from 'expo-video';\n\n// Set cache size to 500MB (must be called when no players exist)\nawait setVideoCacheSizeAsync(500 * 1024 * 1024);\n\n// Get current cache size\nconst cacheSize = getCurrentVideoCacheSize();\nconsole.log(`Cache is using ${cacheSize} bytes`);\n\n// Clear all cached videos (must be called when no players exist)\nawait clearVideoCacheAsync();\n```\n\n\n  Caching limitations:\n  - HLS video sources cannot be cached on iOS due to platform limitations\n  - DRM-protected videos cannot be cached on Android and iOS\n  - Cache management functions can only be called when no VideoPlayer instances exist\n\n4. Optimize poster image loading\n\nUse lower resolution thumbnails for poster images to reduce initial load time:\n\n\n```tsx\nconst posterUrl = `https://image.mux.com/${playbackId}/thumbnail.jpg?width=640&time=0`;\n```\n\n\nAdditional expo-video features\n\nThis guide covers the most common video playback patterns with Mux. The expo-video library offers many additional capabilities beyond what's covered here.\n\nFor advanced features and patterns, see the official expo-video examples repository:\n\n- Playback controls - Volume sliders, AirPlay button, and seekBy() / replay() methods\n- DRM and content protection - Widevine and FairPlay integration\n- Subtitles and closed captions - Adding text tracks to videos\n\n  Mux supports most of these features natively. For example, Mux can automatically generate subtitles, provide DRM protection, and deliver multiple audio tracks. Learn more in the Video features documentation.\n\nNext Steps\n\n  <GuideCard\n    title=\"Upload videos to Mux\"\n    description=\"Learn how to upload videos from React Native or ingest videos from URLs for AI-generated content\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/frameworks/react-native-uploading-videos\"},\n    ]}\n  />\n  <GuideCard\n    title=\"Build a Stories UI\"\n    description=\"Create an Instagram Stories or TikTok-style vertical video feed with swipe navigation\"\n    links={[\n      {title: \"Read the guide\", href: \"/docs/frameworks/react-native-stories-reels-ui\"},\n    ]}\n  />"
  },
  {
    "id": "173-_guides/frameworks/remix-js",
    "title": "Add high-performance video to your Remix.js application",
    "path": "_guides/frameworks/remix-js.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/remix-js",
    "content": "When should you use Mux with Remix.js?\nWhen adding video to your Remix.js app, you'll encounter some common hurdles. First, videos are large. Storing them in your public directory can lead to excessive bandwidth consumption and poor Git repository performance. Next, it's important to compress and optimize your videos for the web. Then, as network conditions change, you might want to adapt the quality of your video to ensure a smooth playback experience for your users. Finally, you may want to integrate additional features like captions, thumbnails, and analytics.\n\nYou might consider using Mux's APIs and components to handle these challenges, and more.\n\nQuickly drop in a video with Mux Player\n\nThe quickest way to add a video to your site is with Mux Player. Here's what Mux Player looks like in action:\n\n\n```jsx\nimport MuxPlayer from \"@mux/mux-player-react\";\n\nexport default function Page() {\n  return (\n    <MuxPlayer\n      playbackId=\"jwmIE4m9De02B8TLpBHxOHX7ywGnjWxYQxork1Jn5ffE\"\n      metadata={{\n        video_title: \"Test video title\",\n        viewer_user_id: \"user-id-007\",\n      }}\n    />\n  );\n}\n```\n\n\nIf your site has just a few videos, you might upload them to Mux directly through the dashboard. In the Mux Dashboard, on your video assets page, select \"Create New Asset\". On the next screen, you can upload a video directly to Mux.\n\nYou'll then be able to see your new asset on your video assets page. When you click on the asset, you can find the asset's playback ID in the \"Playback and Thumbnails\" tab. This playback ID can be used in the playbackId prop of the Mux Player component.\n\nYou can read more about Mux Player, including how to customize its look and feel, over in the Mux Player guides.\n\nIf you're managing more videos, you might take a look at our CMS integrations.\n\nFinally, if you need more control over your video workflow, read on.\n\nUse the API to build your video workflow\n\nIf you're looking to build your own video workflow that enables uploading, playback, and more in your application, you can use the Mux API and components like Mux Player and Mux Uploader.\n\nExample: allowing users to upload video to your app\nOne reason you might want to build your own video workflow is when you want to allow users to upload video to your app.\n\nLet's start by adding a new page where users can upload videos. This will involve using the Mux Uploader component, which will upload videos to a Mux Direct Uploads URL.\n\nIn the code sample below, we'll create an upload URL using the Mux Node SDK and the Direct Uploads URL API. We'll pass that URL to the Mux Uploader component, which will handle uploading for us.\n\nIn production, you'll want to apply additional security measures to your upload URL. Consider protecting the route with authentication to prevent unauthorized users from uploading videos. Also, use cors_origin and consider playback_policy to further restrict where uploads can be performed and who can view uploaded videos.\n\nNext, we'll create an API endpoint that will listen for Mux webhooks. When we receive the notification that the video has finished uploading and is ready for playback, we'll add the video's metadata to our database.\n\nFinally, let's make a playback page. We retrieve the video metadata from our database, and play it by passing its playbackId to Mux Player:\n\nAnd we've got upload and playback. Nice!\n\nWhat's next? You can integrate with your CMS. You can optimize your loading experience. Or get started with the example project below:\n\nExample projects\n\n  <GuideCard\n    title=\"remix-examples/mux-video\"\n    description={<>\n      This is a bare-bones starter application with Remix.js that uses:\n\n        Mux Direct Uploads and Mux Uploader\n        Mux Video + Mux Data\n        Mux Player\n\n    }\n    links={[\n      {\n        title: \"View project →\",\n        href: \"https://github.com/remix-run/examples/tree/main/mux-video\",\n      },\n    ]}\n  />"
  },
  {
    "id": "174-_guides/frameworks/sveltekit",
    "title": "Add high-performance video to your SvelteKit application",
    "path": "_guides/frameworks/sveltekit.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/frameworks/sveltekit",
    "content": "When should you use Mux with Svelte?\nWhen adding video to your SvelteKit app, you'll encounter some common hurdles. First, videos are large. Storing them in your public directory can lead to excessive bandwidth consumption and poor Git repository performance. Next, it's important to compress and optimize your videos for the web. Then, as network conditions change, you might want to adapt the quality of your video to ensure a smooth playback experience for your users. Finally, you may want to integrate additional features like captions, thumbnails, and analytics.\n\nYou might consider using Mux's APIs and components to handle these challenges, and more.\n\nQuickly drop in a video with Mux Player\n\nThe quickest way to add a video to your site is with Mux Player. Here's what Mux Player looks like in action:\n\n\n```svelte\n<script lang=\"ts\">\n  import \"@mux/mux-player\";\n</script>\n\n<mux-player\n  playback-id=\"jwmIE4m9De02B8TLpBHxOHX7ywGnjWxYQxork1Jn5ffE\"\n  metadata-video-title=\"Test VOD\"\n  metadata-viewer-user-id=\"user-id-007\"\n></mux-player>\n```\n\n\nIf your site has just a few videos, you might upload them to Mux directly through the dashboard. In the Mux Dashboard, on your video assets page, select \"Create New Asset\". On the next screen, you can upload a video directly to Mux.\n\nYou'll then be able to see your new asset on your video assets page. When you click on the asset, you can find the asset's playback ID in the \"Playback and Thumbnails\" tab. This playback ID can be used in the playbackId prop of the Mux Player component.\n\nYou can read more about Mux Player, including how to customize its look and feel, over in the Mux Player guides.\n\nIf you're managing more videos, you might take a look at our CMS integrations.\n\nFinally, if you need more control over your video workflow, read on.\n\nUse the API to build your video workflow\n\nIf you're looking to build your own video workflow that enables uploading, playback, and more in your application, you can use the Mux API and components like Mux Player and Mux Uploader.\n\nExample: allowing users to upload video to your app\nOne reason you might want to build your own video workflow is when you want to allow users to upload video to your app.\n\nLet's start by adding the Mux Node SDK to your project. We'll be using this a lot.\n\n```typescript filename=lib/mux.ts\nimport Mux from '@mux/mux-node';\nimport { MUX_TOKEN_ID, MUX_TOKEN_SECRET } from '$env/static/private';\n\nconst mux = new Mux({\n\ttokenId: MUX_TOKEN_ID,\n\ttokenSecret: MUX_TOKEN_SECRET\n});\n\nexport default mux;\n```\n\n\nNow, we can add a new page where users can upload videos. This will involve using the Mux Uploader component, which will upload videos to a Mux Direct Uploads URL.\n\nWe'll start by creating an upload URL using the Direct Uploads URL API.\n\nIn production, you'll want to apply additional security measures to your upload URL. Consider protecting the route with authentication to prevent unauthorized users from uploading videos. Also, use cors_origin and consider playback_policy to further restrict where uploads can be performed and who can view uploaded videos.\n\nThen, we'll pass that URL to the Mux Uploader component, which will handle uploading for us.\n\nNext, we'll create an API endpoint that will listen for Mux webhooks. When we receive the notification that the video has finished uploading and is ready for playback, we'll add the video's metadata to our database.\n\nFinally, let's make a playback page. We retrieve the video metadata from our database, and play it by passing its playbackId to Mux Player:\n\nAnd we've got upload and playback. Nice!\n\nWhat's next? You can integrate with your CMS. You can optimize your loading experience. Or get started with the example project below:\n\nExample projects\n\n  <GuideCard\n    title=\"muxinc/examples/sveltekit-uploader-and-player\"\n    description={<>\n      This is a bare-bones starter application with SvelteKit that uses:\n\n        Mux Direct Uploads and Mux Uploader\n        Mux Video + Mux Data\n        Mux Player\n\n    }\n    links={[\n      {\n        title: \"View project →\",\n        href: \"https://github.com/muxinc/examples/tree/main/sveltekit-uploader-and-player\",\n      },\n    ]}\n  />"
  },
  {
    "id": "175-_guides/integrations/cms",
    "title": "Integrate with your CMS",
    "path": "_guides/integrations/cms.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/cms",
    "content": "While Mux stores basic video metadata like titles and creator IDs, a content management system (CMS) can help you manage additional content around your videos - like descriptions, categories, related content, and other rich metadata that helps organize your video content within your application's broader content strategy.\n\nMux integrates with the following CMS applications to help you easily manage and deliver video content in your applications. These integrations allow you to easily incorporate Mux videos into your existing CMS workflow.\n\nHeadless CMS integrations\n\n- Sanity\n- Contentful\n- WordPress\n- Strapi\n- Cosmic\n- DatoCMS\n- Prepr\n\nThird-party integrations\n\nThese are integrations that are not officially supported by Mux, but are community-driven and maintained.\n\n- PayloadCMS\n- Statamic\n\nIf there’s an integration you’d like to see or if you’d like to partner with us, let us know!"
  },
  {
    "id": "176-_guides/integrations/contentful",
    "title": "Integrate with Contentful",
    "path": "_guides/integrations/contentful.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/contentful",
    "content": "This is a detailed guide for integrating the Contentful Mux app. To read more about the Mux app and why you may want to use it to power videos in your CMS, read the announcement blog post on Contentful's blog.\n\n1. Enter Mux credentials\n\nCreate an access token in your Mux account - you will need both the access token ID and the access token secret in the Contentful application. The access token should have Read and Write permissions for Mux Video, and also Read for Mux Data.\n\n2. Install App\n\nIn the Contentful dashboard click “Apps > Manage Apps” in the top navigation bar. Scroll down and find the Mux app, click it to start the installation flow.\n\nNext you will see the configuration screen. You can come back to this screen after the app is installed to update the app configuration. Enter your Mux access token and Mux token secret. These are the same credentials you would use to make API requests yourself.\n\nAssign Mux to JSON fields from your content model. In this example I am assigning Mux to take over the “Video Upload” field in my Blog post model. If you add new JSON fields later you can always come back to this configuration screen and assign Mux to the new fields.\n\nYou can also assign Mux fields from the configuration of a particular Content model if you create a JSON Object type field and then edit its appearance as follows:\n\n2.1. Assign Mux Sidebar to a Content model\n\nOnce the plugin is installed and your Content Models are configured, you can add the Mux sidebar by clicking the plus sign and placing it wherever you want. Then click save. This sidebar is used to visualize pending changes with the publication of the Entry in Contentful. This is explained in more detail in the Features and Important Notes section.\n\n3. Upload video\n\nCreate a new entry for your content model. You should see a drag and drop zone and file picker to select an audio or video file:\n\nSelect a video file and a modal will appear with expandable configuration options that you can click to expand and configure the video before it's uploaded. The configuration options available are:\n\n- Video Quality Settings: Allows you to define the video quality. More information: Use different video quality levels\n\n- Privacy Settings: Allows you to define the video visibility between public or protected. More information: Secure video playback\n\n- Metadata: Allows you to add the title in the video metadata. This is also useful for having the title defined in the Mux Dashboard. More information: Add metadata to your videos\n\n- Captions: Allows you to add captions to your videos, both custom and auto-generated captions.\n  - To generate auto-generated captions, you need to specify the video language and it will automatically generate captions.\n  - For custom captions, you need to specify the URL where the captions are located and the caption language.\n\nMore information in Captions and Subtitles section.\n\n- MP4 Generation: Allows you to generate static renditions for your videos, both audio-only and audio with video. More information: Enable static MP4 renditions\n\nAfter configuring these options, click on the upload button and wait for the file to upload to Mux. The amount of time this takes will depend on your network upload speed and the size of the file. Don't close the tab until the upload is complete.\n\nAdditionally, entering a Mux Asset ID from an existing video in Mux, or a URL to an audio or video file will also work in the input field.\n\nAfter the upload is complete you will see a message that says \"Waiting for asset to be playable\" while Mux is processing your video. For normal video files it should only take a minute or so, however longer files, or files that need more processing, may take longer.\n\nYour video is now playable via Mux. You will see a player with your video in the Contentful UI.\n\n4. Playback\n\nWhen you query your Mux video through the Contentful API you will get back a JSON object that looks something like this that is viewable in the Data tab:\n\n\n```json\n{\n  \"version\": 3,\n  \"uploadId\": \"some-upload-id\",\n  \"assetId\": \"some-asset-id\",\n  \"playbackId\": \"YOUR_PLAYBACK_ID\",\n  \"ready\": true,\n  \"ratio\": \"16:9\",\n  \"max_stored_resolution\": \"HD\",\n  \"max_stored_frame_rate\": 29.928,\n  \"duration\": 23.857167,\n  \"audioOnly\": false,\n  \"created_at\": 1664219467,\n  \"audioTracks\": [\n    {\n      \"type\": \"audio\",\n      \"primary\": true,\n      \"max_channels\": 2,\n      \"max_channel_layout\": \"stereo\",\n      \"id\": \"some-audio-track-id\",\n      \"duration\": 10.026667\n    }\n  ],\n  \"meta\": {\n    \"title\": \"some-video-title\",\n    \"external_id\": \"some-external-id\"\n  }\n}\n```\n\n\nYou will need to pull out the playbackId property and construct a URL like this. You will use this URL with a player that supports HLS:\n\n\n```text\nhttps://stream.mux.com/{YOUR_PLAYBACK_ID}.m3u8\n```\n\n\nView Mux's Playback docs for more information about players.\n\nUsing Mux Player\n\nWe made it easy to playback video using Mux Player by including the same code used to play the video in the Contentful dashboard. Simply head to the Player Code tab, click the copy button, and paste this into a website for quicker testing and development.\nYou can also add optional parameters to the example code such as autoplay, mute, and loop by clicking the corresponding checkboxes. This will update the example code for you to use.\n\nAdditionally, there's an option to get iframe example code for embedding the video, providing an alternative integration method.\n\n5. Captions and Subtitles\n\nCaptions can be added before uploading an asset (see the Upload video section) and after uploading in the Captions tab. There are two ways to add captions: auto-generated and custom captions, and they can be used together if desired.\n\nYou must select the type of captions to upload from the dropdown menu.\n\nAuto-Generated Captions\n\nFor auto-generated captions, you need to select the Language Code. This is automatically populated based on the Audio Name you select. It's important to select the same language as the spoken audio in the video so that captions are generated correctly.\n\nThe Audio Name is what will appear in the player when selecting the caption. You can use any name you want.\n\nCustom Captions\n\nCustom captions and subtitles can come from any publicly available URL. Add the URL to the vtt or srt caption file, selecting the caption name and to mark as closed captions.\n\nOne way to upload captions is to use the Contentful Media Manager. After uploading the file to the Manager, right click on the download button and select copy link then paste this link into the URL field.\n\nManaging Captions\n\nCaption files can be added or deleted, and files can be downloaded for further editing. The stored JSON object will also reflect additional caption files. Existing captions will be displayed after clicking the Resync button under the Data tab or when entering to the entry. Deleting a caption will appear in the Mux sidebar and require publishing to take effect in Mux.\n\n6. Audio Tracks\n\nYou can add new audio tracks to an existing asset in the Audio Tracks section. This is useful for providing multiple language audio tracks or alternative audio content for your videos.\n\nAdding Audio Tracks\n\nTo upload a new audio track, you need to provide a public URL of an audio file. One way to obtain this is by using the Contentful Media Manager, in the same way as described in the Captions section.\n\nYou need to specify the Language Code, which is automatically populated when you indicate the Audio Name. The Audio Name can contain any text and is what will be displayed in the player when users want to select from the available audio tracks.\n\nManaging Audio Tracks\n\nAudio tracks can be added or deleted, and the stored JSON object will reflect the additional audio tracks. Deleting an audio track will appear in the Mux sidebar and require publishing to take effect in Mux.\n\n7. Mux Sidebar\n\nThe Mux sidebar provides a visual interface to track the synchronization status between your Contentful entries and Mux assets. This sidebar displays:\n\n- Pending actions that need to be synchronized with Mux\n- Any changes that require publishing to take effect in Mux\n\n8. Publishing Requirements and Breaking Changes\n\nAs part of the version 2.0 plugin release, changes were made to maintain data integrity and consistency between what is published in Contentful and what is stored in Mux. For example, to change a video from public to protected, its playback ID must be regenerated, and if that video is published in Contentful, the new playback ID couldn't be obtained previously.\n\nTo solve this, some actions that we consider \"breaking changes\" will not be executed in Mux until the user clicks \"Publish\" on the pending changes.\n\nBreaking Changes That Require Publishing\n\nThe following changes will appear as pending in the Mux sidebar and will only be applied to Mux when you click \"Publish changes\" in Contentful:\n\n- Delete Video - Removing a video asset\n- Delete Captions - Removing caption/subtitle files\n- Delete Audio - Removing audio tracks\n- Change Metadata Title - Modifying the title in the metadata section\n- Delete MP4 Renditions - Removing static MP4 files\n- Change Video Visibility - Switching between public/protected settings\n\nPublishing Workflow\n\nFor example, if you want to change the visibility of an existing video, this will be a pending change that appears in the sidebar and the change will be made in Mux when you click \"Publish changes\" in Contentful.\n\nThe same happens with actions like deletions - if you want to delete a caption, it will appear marked for deletion but will only be removed when you publish. You can also undo deletions to prevent them from being deleted when you publish.\n\nExplore advanced options\n\nAdvanced: Signed URLs\n\nEnabling signed URLs in Contentful will require you to generate your own signing tokens on your application server. This involves creating a signing key and using that to generate JSON web tokens when you want to access your videos and thumbnails outside of Contentful.\n\nBy default, all assets uploaded to Mux through Contentful will be created with a single playback policy of \"public\". This means that your videos and thumbnails are accessible with https://stream.mux.com/{PLAYBACK_ID}.m3u8 and https://image.mux.com/{PLAYBACK_ID}/thumbnail.jpg.\n\nIf you want more control over controlling the playback and thumbnail access, you can enable this feature on the Contentful configuration page:\n\nWhen you enable this feature, the following things will happen:\n\n1. The Mux App in Contentful will use the Mux API to create a URL signing key and save this with your Contentful configuration.\n2. When uploading an asset, you can select \"Protected\" in the Privacy Settings section of the configuration modal. If you select this option, the asset will be created with playback_policy: \"signed\" (instead of \"public\").\n3. The signing key from Step 1 will be used by the Mux App to preview content inside the Contentful UI.\n4. When you access your content in your own application, outside of Contentful, the Mux asset will no longer have the key playbackId, it will now be called signedPlaybackId.\n\n\n```json\n{\n  \"uploadId\": \"some-upload-id\",\n  \"assetId\": \"some-asset-id\",\n  \"signedPlaybackId\": \"YOUR_SIGNED_PLAYBACK_ID\",\n  \"ready\": true,\n  \"ratio\": \"16:9\"\n}\n```\n\n\n5. You should use the value from signedPlaybackId to create URLs for playback and for thumbnail generation.\n\n- Playback https://stream.mux.com/{SIGNED_PLAYBACK_ID}.m3u8?token={TOKEN}\n- Thumbnails https://image.mux.com/{SIGNED_PLAYBACK_ID}/thumbnail.jpg?token={TOKEN}\n\n6. The TOKEN parameter for the above URLs is something you create on your server according to Step 2 in Security: Signed URLs.\n\nNote that in the Contentful UI when an asset is using a signed URL you will see this notice.\n\nPublic and signed playback IDs can be toggled per-entry under the Data tab. Each time the IDs are toggled, the old playback ID is deleted, and a new ID is created in its place.\n\nNote about version 2.0 release\n\nDuring the month of August 2025, version 2.0 of the plugin was released. No action is required as the plugin updates automatically.\n\nThere are no changes to the previous data structure, but new fields have been added that are necessary to support new features such as audio tracks, MP4 renditions, and others.\n\nIf you were already using the plugin previously, you may notice that when entering an entry that has a video, it changes to 'Changed' status. This occurs because the new video data is retrieved and stored in Contentful's data. It's like an automatic resync that runs.\n\nThis is expected behavior and only occurs with videos uploaded before the new version or if changes are made to videos outside of Contentful, as it synchronizes automatically.\n\nNote about migrating from the old Contentful extension\n\nBefore releasing the Contentful App, Mux had an officially supported Contentful extension.\n\nThe underlying data structure has not changed, so you can safely migrate to the app without losing data by following these steps:\n\n1. Uninstall the extension (now your video fields should look like raw JSON)\n2. Install the app\n3. On the configuration screen, apply the Mux App to the video fields that you had before"
  },
  {
    "id": "177-_guides/integrations/cosmic",
    "title": "Integrate with Cosmic",
    "path": "_guides/integrations/cosmic.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/cosmic",
    "content": "1. Install the Mux Extension\n\nLog in to your Cosmic JS account and navigate to Your Bucket > Settings > Extensions. Click the Extensions tab and find the Mux Videos Extension. Hit Install.\n\n2. Enter Mux credentials\n\nAfter installing, you will be redirected to the Extension settings page. Under Query Parameters, you will need to provide the Mux API credentials on your Mux account (mux_access_token, mux_secret).\n\nIf you need to generate a new Access Token, go to the Access Token settings of your Mux account dashboard.\n\nThe access token should have Read and Write permissions for Mux Video.\n\nGo back to the Cosmic Extensions setting page, enter your Mux credentials, and save your Extension.\n\n3. Upload video\n\nAfter installing the Extension and setting your Mux account keys, click the Mux Videos Extension link in the left-hand nav. Next, upload your videos.\n\nThe Extension saves the uploaded video data to the Mux Videos Object Type. Now you can add your Mux Videos to any Object using an Object metafield. Then you can fetch Mux data into your application by using the mux_playback_url property located in the Object metadata.\n\n4. Playback\n\nTo retrieve your video for playback, check out the Cosmic docs to see how to add the Mux playback URL to your HTML Video player."
  },
  {
    "id": "178-_guides/integrations/datocms",
    "title": "Integrate with DatoCMS",
    "path": "_guides/integrations/datocms.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/datocms",
    "content": "Mux is by default enabled in every new DatoCMS project. The integration allows you to upload videos directly from DatoCMS dashboard or using the REST API. The CMS interface will then allow you to use the videos in the content, while on the API side you’ll be able to retrieve the Mux Video URLs and the thumbnail.\n\n1. Upload video\n\nJust drag and drop a video in DatoCMS media area, like this:\n\n2. Fetch video information via GraphQL\n\nFor every video that you upload, you can get on the API a custom video object with the following properties:\n\n- HLS video streaming URL.\n- High, medium and low quality MP4 versions of the video to support legacy browsers that do not support HLS.\n- Duration and frame rate of the video.\n- Thumbnail URL: resizable, cropable and available in JPEG, PNG and GIF format.\n\nSee the full page of this embedded example here in the GraphQL explorer.\n\n<iframe\n  src=\"https://cda-explorer.datocms.com/?embed=&apitoken=faeb9172e232a75339242faafb9e56de8c8f13b735f7090964&query=%7B%0A%20%20allUploads%28filter%3A%20%7Btype%3A%20%7Beq%3A%20video%7D%2C%20resolution%3A%20%7B%7D%2C%20smartTags%3A%20%7B%7D%7D%29%20%7B%0A%20%20%20%20video%20%7B%0A%20%20%20%20%20%20streamingUrl%0A%20%20%20%20%20%20mp4High%3A%20mp4Url%28res%3A%20high%29%0A%20%20%20%20%20%20mp4Med%3A%20mp4Url%28res%3A%20medium%29%0A%20%20%20%20%20%20mp4Low%3A%20mp4Url%28res%3A%20low%29%0A%20%20%20%20%20%20duration%0A%20%20%20%20%20%20framerate%0A%20%20%20%20%20%20thumbJpg%3A%20thumbnailUrl%28format%3A%20jpg%29%0A%20%20%20%20%20%20thumbPng%3A%20thumbnailUrl%28format%3A%20png%29%0A%20%20%20%20%20%20thumbGif%3A%20thumbnailUrl%28format%3A%20gif%29%0A%20%20%20%20%7D%0A%20%20%7D%0A%7D%0A\"\n  title=\"CDA GraphQL Explorer | DatoCMS\"\n  width=\"100%\"\n  height=\"500px\"\n  style={{ border: \"none\" }}\n>"
  },
  {
    "id": "179-_guides/integrations/installing-mcp-locally",
    "title": "Install the local Mux MCP Server",
    "path": "_guides/integrations/installing-mcp-locally.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/installing-mcp-locally",
    "content": "If you're interested in getting started quickly, and to read more about the MCP server, check out this guide. This guide walks you through building and installing the Mux MCP Server locally on your machine and connecting it to various AI clients.\n\nThe Mux MCP (Model Context Protocol) Server brings Mux's Video and Data platform capabilities directly to your AI tools. Once installed, you can upload videos, manage live streams, analyze video performance, and access practically all of Mux's video infrastructure through natural language prompts in supported AI clients.\n\nPrerequisites\n\nBefore installing the Mux MCP Server, make sure you meet the following prerequisites:\n\n- Node.js installed on locally on your machine (instructions available here)\n- A Mux account (sign up at mux.com if you don't have one)\n- Your Mux API access token and secret key from the Mux Dashboard (detailed instructions are available below)\n- Claude Desktop, Cursor, or any other client that supports local MCP servers, installed and updated to the latest version\n\nInstallation\n\nGet your Mux API credentials and configure access\n\n1. Log into your Mux Dashboard\n2. Navigate to Settings → Access Tokens\n3. Generate a new access token or use an existing one\n4. Copy your Access Token ID and Secret Key - you'll need both for the configuration\n\nRequired Scopes\n\n- Your Mux access token should be configured for your desired Environment and read/write access\n- We recommend clearly labeling this access token in Mux, for example: MCP Access Token\n\nImportant: Replace the placeholder values when adding to your AI client's config using the templates provided below:\n\n- Replace your_access_token_id with your actual Mux Access Token ID\n- Replace your_secret_key with your actual Mux Secret Key\n\n  Note: If you're using a tool that manages Node versions like Mise, you'll probably need to make sure you execute the npx commands found in the following examples from within that context. An example Mise command could look something like this:\n\nmise x node@20 -- npx -y @mux/mcp@latest\n\nAccordingly, the following examples would need to be changed similarly to below:\n\n\n```json\n      \"command\": \"mise\",\n      \"args\": [\"x\", \"node@20\", \"--\", \"npx\", \"-y\", \"@mux/mcp@latest\",\"--tools=dynamic\",\"--client=claude\"],\n```\n\n\nFor Claude\n\n* You must use Claude's Desktop app to install local MCP servers.\n\nWe support the recently released Claude Desktop Extensions format, so you can download this DXT file and open it with Claude Desktop to install it. Once it's installed, configure the environment variables you need and you're good to go.\n\nIf you'd like to configure it manually, follow the next steps.\n\nStep A: Configure Claude Desktop\n\nFollow Claude's instructions to locate your Claude Desktop configuration file on your machine.\n\nmacOS/Linux:\n\n\n```\n~/Library/Application\\ Support/Claude/claude_desktop_config.json\n```\n\n\nWindows:\n\n\n```\n%APPDATA%\\Claude\\claude_desktop_config.json\n```\n\n\nStep B: Add the MCP Server configuration\n\nAdd this configuration block to your claude_desktop_config.json file:\n\n\n```json\n{\n  \"globalShortcut\": \"\",\n  \"mcpServers\": {\n    \"mux\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@mux/mcp@latest\",\"--tools=dynamic\",\"--client=claude\"],\n      \"env\": {\n        \"MUX_TOKEN_ID\": \"your_access_token_id\",\n        \"MUX_TOKEN_SECRET\": \"your_secret_key\"\n      }\n    }\n  }\n}\n```\n\n\nStep C: Restart Claude Desktop\n\nClose and reopen Claude Desktop to load the new MCP server configuration.\n\nFor Cursor\n\nStep A: Locate the Settings File\n\nFollow the paths below to locate your Cursor MCP configuration file. If the file does not exist, you can create it.\n\nmacOS/Linux:\n\n\n```\n~/.cursor/mcp.json\n```\n\n\nWindows:\n\n\n```\nC:/Users/<username>/.cursor/mcp.json\n```\n\n\nStep B: Add the MCP Server Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"mux\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@mux/mcp@latest\",\"--tools=dynamic\",\"--client=cursor\"],\n      \"env\": {\n        \"MUX_TOKEN_ID\": \"your_access_token_id\",\n        \"MUX_TOKEN_SECRET\": \"your_secret_key\"\n      }\n    }\n  }\n}\n```\n\n\nFor VSCode\n\nTo add the server to all of your workspaces globally, add the server configuration to your settings.json file.\n\nStep A: Locate the Settings File\n\nmacOS:\n\n\n```\n~/Library/Application\\ Support/Code/User/settings.json\n```\n\n\nLinux:\n\n\n```\n~/.config/Code/User/settings.json\n```\n\n\nWindows:\n\n\n```\n%APPDATA%\\Code\\User\\settings.json\n```\n\n\nStep B: Add the MCP Server Configuration\n\n\n```json\n{\n  \"mcp\": {\n    \"servers\": {\n      \"mux\": {\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@mux/mcp@latest\",\"--tools=dynamic\"],\n        \"env\": {\n          \"MUX_TOKEN_ID\": \"your_access_token_id\",\n          \"MUX_TOKEN_SECRET\": \"your_secret_key\"\n        }\n      }\n    }\n  }\n}\n```\n\nStep C: Starting the MCP Server\n\nIn VSCode, make sure to click on the Start button in the MCP Server to start the server. You can do this directly from the settings file, or from the Command Palette with MCP: List Servers .\n\nVerify installation\n\nTest that the Mux MCP Server is working by asking your AI client:\n\n> Give me the details for the most recently created Mux Video asset (using the Mux tool)\n\nor\n\n> Using the Mux MCP, list the best performing countries for video streaming over the last month using Mux Data\n\nIf the installation was successful, Claude will connect to the Mux API through the MCP server and return information about your video performance or assets.\n\nTroubleshooting\n\nBuild Issues\n\nIf you encounter errors during the build process:\n\n- Make sure you have the correct Node.js version installed, and that npx is accessible in your PATH (npx -v)\n\nConnection Issues\n\nIf Claude can't connect to the MCP server:\n\n- Double-check that your file path in the args field is correct and points to the built MCP server file\n- Verify your Mux credentials are correct and properly formatted\n- Make sure there are no extra spaces or characters in your token values\n- Confirm your API tokens have the necessary permissions in your Mux account\n\nClaude Desktop Issues\n\nIf MCP features don't appear in Claude:\n\n- Ensure you're using the latest version of Claude Desktop - older versions may not support MCP\n- Verify your JSON configuration is valid (no missing commas or brackets)\n- Check that Claude Desktop has restarted completely after configuration changes\n\nGetting help\n\nIf you run into issues or have questions:\n\n- Check the Model Context Protocol documentation for general MCP setup guidance\n- Review Claude's MCP documentation for Claude-specific configuration\n- Visit our API Reference for detailed endpoint documentation\n- Contact support: mux.com/support"
  },
  {
    "id": "180-_guides/integrations/mcp-server",
    "title": "Using the Mux MCP Server",
    "path": "_guides/integrations/mcp-server.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/mcp-server",
    "content": "The Mux MCP (Model Context Protocol) Server brings Mux's Video and Data platform capabilities directly to your AI tools. Once set up, you can upload videos, manage live streams, analyze video performance, and access practically all of Mux's video infrastructure through natural language prompts in supported AI clients.\n\nThis guide walks you through the functionality in Mux's MCP server, and connecting it to various AI clients.\n\nTools & Routes\n\nHere are the following tools and API routes supported in the local Mux MCP Server:\n\n- Video API: Create assets, uploads, live streams, playback URLs\n- Data API: Query metrics, dimensions, real-time data\n- Webhook management: List and verify webhook signatures\n- Asset management: Retrieve, update video metadata\n- Live streaming: Create streams, manage recordings\n- Analytics: Performance metrics, viewer data, error tracking\n\nHere are the tools and routes we don't currently support in the local Mux MCP Server. Generally speaking, these are composed of endpoints which can execute deletions, and are disabled for safety:\n\n- Asset deletion endpoints\n- Live stream deletion endpoints\n- Webhook deletion endpoints\n\nPrompt examples\n\nVideo Management\n\n Using the Mux tool, create a webpage where I can upload a video to Mux\n Give me the playback URL for the most recently uploaded video to my Mux account, use Mux MCP\n List all my video assets and their current status (using the Mux MCP tool)\n With the Mux tool: Show me recent video uploads\n Using Mux MCP, generate a subtitles track for asset ID: ASSET_ID\n\nMux Data Analytics and Performance\n\n Using the Mux MCP, tell me the best performing country for video streaming over the last month\n Show me video performance metrics for the last week using the Mux tool\n With the Mux tool: what are the top performing videos by view count?\n Using Mux, which countries have the highest video engagement?\n What are the most common video errors in my account (use the Mux MCP)?\n Show me breakdown values for video quality metrics using the Mux MCP tool\n List all available data dimensions I can filter by, use the Mux MCP to answer this prompt\n\nPrerequisites\n\nBefore utilizing the Mux MCP Server, make sure you meet the following prerequisites:\n\n- A Mux account (sign up at mux.com if you don't have one)\n- Claude Desktop, Cursor, or any other client that supports remote MCP servers, installed and updated to the latest version\n\nConfiguring the Mux MCP Server\n\nMux's MCP server is hosted at https://mcp.mux.com, and when using this remote MCP server, authentication should be handled automatically, with no need for grabbing Access Token information from the Dashboard. In order to configure the Mux MCP server in your client, you need to add an MCP server, which is sometimes called a \"connector\" (Claude/Claude Code/ChatGPT), an \"extension\" (Goose), or simply an MCP Server (VSCode), and enter the URL https://mcp.mux.com as the location.\n\nOnce configured, the LLM client and our MCP server should negotiate authentication and authorization, prompting you automatically to:\n\n- Log in to https://dashboard.mux.com via whatever means you normally log in (this is skipped if you're already logged in)\n- Choose which environment you want to authorize this connection for\n\nWhen you're already logged in, your experience will look something like this:\n\nAnd that's it, you're good to go!\n\nConfiguration options\n\nBy default, https://mcp.mux.com will be configured in the simplest manner (though this may change in the future), exposing access to the full set of tools available to Mux. That said, depending on your workflow, you may want to limit this set of tools in some way. For that reason, Mux supports query parameters to configure the MCP server. A more complete set of configuration options can be seen here, and most of those work simply as query params. However, a few bear mentioning directly:\n\n- tools: options are all (default), and dynamic.\n  - Use dynamic if you want to expose tools mean to allow the LLMs to dynamically discover endpoints and tools, which can aid in controlling context windows and speeding up processing if a lot of tools are available.\n- resource: array of resources (sets of APIs) to expose, such as video.. These act as an inclusion set, rather than excluding, so you can chain multiple to expand the list of tools. Some options include:\n  - video.: all Mux Video APIs\n  - data.: all Mux Data APIs\n  - system.: all System APIs, such as managing Signing Keys\n  - video.asset.: the APIs used to manage Mux Video assets\n  - ...and so on\n- client: options are claude (default), claude-code, cursor, openai-agents.\n  - Each LLM has varying support for capabilities related to complex JSON schemas, and these are tested defaults for each of the known clients. You can read more about this in this doc by Stainless.\n\nYou can also chain these together. For instance, if you want to configure an MCP server that exposes _only_ the Video APIs, but does it in a dynamic way, for Cursor, you'd just use https://mcp.mux.com?client=cursor&resource=video.&tools=dynamic as your remote URL.\n\nA note on remote MCP support\n\nThese days, most LLM clients directly support remote MCP servers (rather than locally installed ones), so you shouldn't have much trouble getting set up. That said, there are still some clients (particularly older versions) that don't have built-in remote MCP support (such as Goose as of the time I wrote this guide). For those situations, you have two options:\n1. You can still install our MCP server locally\n1. You can utilize mcp-remote, which brings support for remote MCP servers to practically any LLM client (and may perform better than the built-in remote MCP support depending on the client).\n\nHaving trouble?\n\nIf you run into issues or have questions:\n\n- Check the Model Context Protocol documentation for general MCP setup guidance\n- Review Claude's MCP documentation for Claude-specific configuration\n- Visit our API Reference for detailed endpoint documentation\n- Contact support: mux.com/support"
  },
  {
    "id": "181-_guides/integrations/mux-csharp-sdk",
    "title": "Add high-performance video to your C# application",
    "path": "_guides/integrations/mux-csharp-sdk.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/mux-csharp-sdk",
    "content": "Frameworks supported\n- .NET Core >=1.0\n- .NET Framework >=4.6\n- Mono/Xamarin >=vNext\n\nDependencies\n\n- RestSharp - 106.11.4 or later\n- Json.NET - 12.0.3 or later\n- JsonSubTypes - 1.7.0 or later\n- System.ComponentModel.Annotations - 4.7.0 or later\n\nThe DLLs included in the package may not be the latest version. We recommend using NuGet to obtain the latest version of the packages:\n\n```\nInstall-Package RestSharp\nInstall-Package Newtonsoft.Json\nInstall-Package JsonSubTypes\nInstall-Package System.ComponentModel.Annotations\n```\n\n\nNOTE: RestSharp versions greater than 105.1.0 have a bug which causes file uploads to fail. See RestSharp742\n\nInstallation\nGenerate the DLL using your preferred tool (e.g. dotnet build)\n\nThen include the DLL (under the bin folder) in the Cproject, and use the namespaces:\n\n```csharp\nusing Mux.Csharp.Sdk.Api;\nusing Mux.Csharp.Sdk.Client;\nusing Mux.Csharp.Sdk.Model;\n```\n\n\nUsage\n\nAt this moment, this SDK is not suitable for parsing or modeling webhook payloads, due to some incompatibilities in our API spec and our SDK generation tooling. We are working on resolving these issues, but for now you should only use this SDK for Mux's REST APIs.\n\nTo use the API client with a HTTP proxy, setup a System.Net.WebProxy\n\n```csharp\nConfiguration c = new Configuration();\nSystem.Net.WebProxy webProxy = new System.Net.WebProxy(\"http://myProxyUrl:80/\");\nwebProxy.Credentials = System.Net.CredentialCache.DefaultCredentials;\nc.Proxy = webProxy;\n```\n\n\nGetting Started\n\n\n```csharp\nusing System.Collections.Generic;\nusing System.Diagnostics;\nusing Mux.Csharp.Sdk.Api;\nusing Mux.Csharp.Sdk.Client;\nusing Mux.Csharp.Sdk.Model;\n\nnamespace Example\n{\n    public class Example\n    {\n        public static void Main()\n        {\n\n            Configuration config = new Configuration();\n            config.BasePath = \"https://api.mux.com\";\n            // Configure HTTP basic authorization: accessToken\n            config.Username = \"YOUR_USERNAME\";\n            config.Password = \"YOUR_PASSWORD\";\n\n            var apiInstance = new AssetsApi(config);\n            var createAssetRequest = new CreateAssetRequest(); // CreateAssetRequest |\n\n            try\n            {\n                // Create an asset\n                AssetResponse result = apiInstance.CreateAsset(createAssetRequest);\n                Debug.WriteLine(result);\n            }\n            catch (ApiException e)\n            {\n                Debug.Print(\"Exception when calling AssetsApi.CreateAsset: \" + e.Message );\n                Debug.Print(\"Status Code: \"+ e.ErrorCode);\n                Debug.Print(e.StackTrace);\n            }\n\n        }\n    }\n}\n```\n\n\nFull documentation\nCheck out the Mux CSDK docs for more information."
  },
  {
    "id": "182-_guides/integrations/mux-elixir-sdk",
    "title": "Add high-performance video to your Elixir application",
    "path": "_guides/integrations/mux-elixir-sdk.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/mux-elixir-sdk",
    "content": "Installation\n\nAdd mux to your list of dependencies in mix.exs.\n\n\n```elixir\ndef deps do\n  [\n    {:mux, \"~> 3.2.1\"}\n  ]\nend\n```\n\n\nQuickstart\n\nTo start, we'll need a Mux access token. We'll put our access token in our application configuration.\n\n\n```elixir\n# config/dev.exs\nconfig :mux,\n  access_token_id: \"abcd1234\",\n  access_token_secret: \"efghijkl\"\n```\n\n\nThen use this config to initialize a new client in your application.\n\n\n```elixir\nclient = Mux.client()\n```\n\n\nYou can also pass the access token ID and secret directly to client/2 function if you'd prefer:\n\n\n```elixir\nclient = Mux.client(\"access_token_id\", \"access_token_secret\")\n```\n\n\nNow we can use the client to upload new videos, manage playback IDs, etc.\n\n\n```elixir\nparams = %{\n  input: \"https://example.com/video.mp4\"\n}\n{:ok, asset, _} = Mux.Video.Assets.create(client, params);\n```\n\n\nFull documentation\nCheck out the Mux Elixir SDK docs for more information."
  },
  {
    "id": "183-_guides/integrations/mux-go-sdk",
    "title": "Add high-performance video to your Go application",
    "path": "_guides/integrations/mux-go-sdk.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/mux-go-sdk",
    "content": "Installation\n\nPull the Mux Go SDK from GitHub.\n\n\n```curl\ngo get github.com/muxinc/mux-go\n```\n\n\nQuickstart\n\nTo start, we'll need a Mux access token. We'll put our access token in our application configuration.\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"os\"\n    \"github.com/muxinc/mux-go\"\n)\n\nfunc main() {\n    // API Client Initialization\n    client := muxgo.NewAPIClient(\n        muxgo.NewConfiguration(\n            muxgo.WithBasicAuth(os.Getenv(\"MUX_TOKEN_ID\"), os.Getenv(\"MUX_TOKEN_SECRET\")),\n        ))\n    // Create the Asset\n    asset, err := client.AssetsApi.CreateAsset(muxgo.CreateAssetRequest{\n        Input: []muxgo.InputSettings{\n            muxgo.InputSettings{\n                Url: \"https://storage.googleapis.com/muxdemofiles/mux-video-intro.mp4\",\n            },\n        },\n        PlaybackPolicy: []muxgo.PlaybackPolicy{muxgo.PUBLIC},\n    })\n\n    // Check everything was good, and output the playback URL\n    if err == nil {\n        fmt.Printf(\"Playback URL: https://stream.mux.com/%s.m3u8 \\n\", asset.Data.PlaybackIds[0].Id)\n    } else {\n        fmt.Printf(\"Oh no, there was an error: %s \\n\", err)\n    }\n}\n```\n\n\nFull documentation\nCheck out the Mux Go SDK docs for more information."
  },
  {
    "id": "184-_guides/integrations/mux-java-sdk",
    "title": "Add high-performance video to your Java application",
    "path": "_guides/integrations/mux-java-sdk.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/mux-java-sdk",
    "content": "Installation\n\nThere are several ways to add the Mux Java SDK to your project:\n\nMaven\n\nAdd this dependency to your project's POM:\n\n\n```xml\n<dependency>\n  <groupId>com.mux</groupId>\n  <artifactId>mux-sdk-java</artifactId>\n  <version>1.0.0</version>\n  <scope>compile</scope>\n</dependency>\n```\n\n\nGradle\n\nAdd this dependency to your project's build file:\n\n\n```gradle\ncompile \"com.mux:mux-sdk-java:1.0.0\"\n```\n\n\nQuickstart\n\nTo start, you'll need a Mux access token. Once you've got that, you're off to the races!\n\n\n```java\n// Import classes:\nimport com.mux.ApiClient;\nimport com.mux.ApiException;\nimport com.mux.Configuration;\nimport com.mux.auth.*;\nimport com.mux.models.*;\nimport com.mux.sdk.AssetsApi;\n\npublic class Example {\n  public static void main(String[] args) {\n    ApiClient defaultClient = Configuration.getDefaultApiClient();\n    defaultClient.setBasePath(\"https://api.mux.com\");\n\n    // Configure HTTP basic authorization: accessToken\n    HttpBasicAuth accessToken = (HttpBasicAuth) defaultClient.getAuthentication(\"accessToken\");\n    accessToken.setUsername(\"YOUR USERNAME\");\n    accessToken.setPassword(\"YOUR PASSWORD\");\n\n    AssetsApi apiInstance = new AssetsApi(defaultClient);\n    CreateAssetRequest createAssetRequest = {\"input\":[{\"url\":\"https://muxed.s3.amazonaws.com/leds.mp4\"}],\"playback_policy\":[\"public\"],\"video_quality\":\"basic\"}; // CreateAssetRequest |\n    try {\n      AssetResponse result = apiInstance.createAsset(createAssetRequest)\n            .execute();\n      System.out.println(result);\n    } catch (ApiException e) {\n      System.err.println(\"Exception when calling AssetsApi#createAsset\");\n      System.err.println(\"Status code: \" + e.getCode());\n      System.err.println(\"Reason: \" + e.getResponseBody());\n      System.err.println(\"Response headers: \" + e.getResponseHeaders());\n      e.printStackTrace();\n    }\n  }\n}\n\n```\n\n\nFull documentation\nCheck out the Mux Java SDK docs for more information."
  },
  {
    "id": "185-_guides/integrations/mux-node-sdk",
    "title": "Add high-performance video to your Node application",
    "path": "_guides/integrations/mux-node-sdk.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/mux-node-sdk",
    "content": "Installation\n\nAdd a dependency on the @mux/mux-node package via npm or yarn.\n\n\n```bash\nnpm install @mux/mux-node\n```\n\n\nQuickstart\n\nTo start, you'll need a Mux access token. Once you've got that, you're off to the races!\n\n\n```javascript\nimport Mux from '@mux/mux-node';\nconst mux = new Mux({\n  tokenId: process.env.MUX_TOKEN_ID,\n  tokenSecret: process.env.MUX_TOKEN_SECRET\n});\n\nconst asset = await mux.video.assets.create({\n  input: [{ url: 'https://storage.googleapis.com/muxdemofiles/mux-video-intro.mp4' }],\n  playback_policy: ['public'],\n});\n```\n\n\nFull documentation\nCheck out the Mux Node SDK docs for more information."
  },
  {
    "id": "186-_guides/integrations/mux-php-sdk",
    "title": "Add high-performance video to your PHP application",
    "path": "_guides/integrations/mux-php-sdk.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/mux-php-sdk",
    "content": "Installation\n\nWe publish Mux PHP to Packagist. You should depend on Mux PHP by adding us to your composer.json file.\n\n\n```php\ncomposer require mux/mux-php\n```\n\n\nQuickstart\n\nTo start, you'll need a Mux access token. Once you've got that, you're off to the races!\n\n\n```php\n// Authentication Setup\n$config = MuxPhp\\Configuration::getDefaultConfiguration()\n    ->setUsername(getenv('MUX_TOKEN_ID'))\n    ->setPassword(getenv('MUX_TOKEN_SECRET'));\n\n// API Client Initialization\n$assetsApi = new MuxPhp\\Api\\AssetsApi(\n    new GuzzleHttp\\Client(),\n    $config\n);\n\n// Create Asset Request\n$input = new MuxPhp\\Models\\InputSettings([\"url\" => \"https://storage.googleapis.com/muxdemofiles/mux-video-intro.mp4\"]);\n$createAssetRequest = new MuxPhp\\Models\\CreateAssetRequest([\"input\" => $input, \"playback_policy\" => [MuxPhp\\Models\\PlaybackPolicy::PUBLIC_PLAYBACK_POLICY] ]);\n\n// Ingest\n$result = $assetsApi->createAsset($createAssetRequest);\n\n// Print URL\nprint \"Playback URL: https://stream.mux.com/\" . $result->getData()->getPlaybackIds()[0]->getId() . \".m3u8\\n\"\n```\n\n\nFull documentation\nCheck out the Mux PHP SDK docs for more information."
  },
  {
    "id": "187-_guides/integrations/mux-python-sdk",
    "title": "Add high-performance video to your Python application",
    "path": "_guides/integrations/mux-python-sdk.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/mux-python-sdk",
    "content": "Installation\n\nInstall this module using either pip or by installing from source.\n\n\n```curl\n# Via pip\npip install git+https://github.com/muxinc/mux-python.git\n\n# Via source\ngit checkout https://github.com/muxinc/mux-python.git\ncd mux-python\npython setup.py install --user\n```\n\n\nQuickstart\n\nTo start, you'll need a Mux access token. Once you've got that, you're off to the races!\n\n\n```python\nimport os\nimport mux_python\nfrom mux_python.rest import ApiException\n\n# Authentication Setup\nconfiguration = mux_python.Configuration()\nconfiguration.username = os.environ['MUX_TOKEN_ID']\nconfiguration.password = os.environ['MUX_TOKEN_SECRET']\n\n# API Client Initialization\nassets_api = mux_python.AssetsApi(mux_python.ApiClient(configuration))\n\n# List Assets\nprint(\"Listing Assets: \\n\")\ntry:\n    list_assets_response = assets_api.list_assets()\n    for asset in list_assets_response.data:\n        print('Asset ID: ' + asset.id)\n        print('Status: ' + asset.status)\n        print('Duration: ' + str(asset.duration) + \"\\n\")\nexcept ApiException as e:\n    print(\"Exception when calling AssetsApi->list_assets: %s\\n\" % e)\n```\n\n\nFull documentation\nCheck out the Mux Python SDK docs for more information."
  },
  {
    "id": "188-_guides/integrations/mux-ruby-sdk",
    "title": "Add high-performance video to your Ruby application",
    "path": "_guides/integrations/mux-ruby-sdk.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/mux-ruby-sdk",
    "content": "Installation\n\nAdd mux_ruby to your project's Gemfile.\n\n\n```ruby\ngem 'mux_ruby'\n```\n\n\nQuickstart\n\nTo start, you'll need a Mux access token. Once you've got that, you're off to the races!\n\n\n```ruby\nrequire 'mux_ruby'\n\n# Auth Setup\nopenapi = MuxRuby.configure do |config|\n  config.username = ENV['MUX_TOKEN_ID']\n  config.password = ENV['MUX_TOKEN_SECRET']\nend\n\n# API Client Init\nassets_api = MuxRuby::AssetsApi.new\n\n# List Assets\nputs \"Listing Assets in account:\\n\\n\"\n\nassets = assets_api.list_assets()\nassets.data.each do | asset |\n  puts \"Asset ID: #{asset.id}\"\n  puts \"Status: #{asset.status}\"\n  puts \"Duration: #{asset.duration.to_s}\\n\\n\"\nend\n```\n\n\nFull documentation\nCheck out the Mux Ruby SDK docs for more information."
  },
  {
    "id": "189-_guides/integrations/prepr",
    "title": "Integrate with Prepr",
    "path": "_guides/integrations/prepr.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/prepr",
    "content": "Mux is enabled for every new Prepr account by default. You can upload your videos to Prepr, add them to a content model and query their URLs to display them on your website. Follow the steps below to get started.\n\nUsing Mux with Prepr\n\nUpload video content to Prepr\n\n1. Create a free Prepr account before you get started.\n2. Log in to the Prepr and navigate to the Media page.\n3. Simply drag and drop audio/video files from your local folders into the Media page directly.\n\nOnce uploaded, the videos are ready to be used in content items.\n\nAdd live streams to Prepr\n\n1. Navigate to the Media page.\n2. Click the Upload asset dropdown and choose the Add live stream option.\n\n3. Enter the broadcasting details as described in the Start broadcasting a live stream guide.\n\nThe livestream asset is now ready to be used in content items with an asset field.\n\nAdd videos to content items\n\nOnce your video(s) have been uploaded, you can add them to a content item. Follow the steps below to do this.\n\n1. Navigate to the Content page.\n2. Create a new content item or open one of your existing content items with an assets field.\n3. Simply drag and drop audio/video files from your local folders into the field directly or click the assets field to add the video you previously uploaded to the Media page.\n4. Save or publish the content item to make the video available to the front-end application.\n\nQuerying the GraphQL API\n\nNow you can query the URLs or playback IDs of your videos to embed them on your website.\n\nTo learn how to play video content on your website, please follow these instructions provided by Mux.\n\nYour query could look something like the example below. In this example, Posts is the name of your content model and videos is the name of the assets field. It has various options:\n\n- The HLS streaming URL is returned by default as the url field.\n- The playback ID can be returned by using the playback_id field.\n- You can use the res option to request MP4 versions in high, medium and/or low quality to support legacy browsers that do not support HLS.\n- You can query the duration of video content using the duration option.\n- The cover image can be requested using the cover field. It is adjustable using width, height, animated, and time arguments.\n\n\n```gql\n{\n  Posts {\n    items {\n      videos {\n        hls: url\n        playback_id\n        mp4High: url(res: \"high\")\n        mp4Medium: url(res: \"medium\")\n        mp4Low: url(res: \"low\")\n        duration\n        cover\n      }\n    }\n  }\n}\n```\n\n\nUsing additional Mux features in Prepr\n\nStatic Renditions\n\nBy default Prepr uses the plus quality level, MP4 support is enabled on all accounts. This option will create Static Renditions for the Asset and will make MP4 files available for download to client devices using the url field.\n\nCaptions/Subtitles\n\nWhile editing an asset from the Media page, content editors can easily upload their own captions file (supported formats are .vtt and .srt) by clicking the \\+ Add subtitles link. Take a look at Add subtitles/captions to videos for more details."
  },
  {
    "id": "190-_guides/integrations/sanity",
    "title": "Integrate with Sanity",
    "path": "_guides/integrations/sanity.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/sanity",
    "content": "This guide assumes you already have a Sanity Studio set up. If you haven't created your Sanity Studio yet, follow the Sanity Studio quickstart guide to get started.\n\n1. Install Mux plugin\n\nRun this command in your Sanity project folder:\n\n\n```sh\nnpm i sanity-plugin-mux-input\n```\n\n\n2. Use in a schema\n\nTo use Mux video in your Sanity schemas, you'll need to create a schema type, import it to your schema types index, and configure the Mux plugin in your Sanity configuration file.\n\n2.1. Create a schema type\n\nCreate a new file in your schemaTypes directory (or schemas directory, depending on your setup). For example, create a file called videoBlogPost.ts:\n\n\n```typescript\n// schemaTypes/videoBlogPost.ts\nimport { defineType, defineField } from 'sanity'\n\nexport default defineType({\n  title: 'Video blog post',\n  name: 'videoBlogPost',\n  type: 'document',\n  fields: [\n    defineField({\n      name: 'title',\n      type: 'string',\n      title: 'Title'\n    }),\n    defineField({\n      name: 'video',\n      type: 'mux.video',\n      title: 'Video file'\n    })\n  ]\n})\n```\n\n\n2.2. Import the schema type\n\nImport your new schema type in your schema types index file (usually schemaTypes/index.ts or schemas/index.ts):\n\n\n```typescript\n// schemaTypes/index.ts\nimport videoBlogPost from './videoBlogPost'\n\nexport const schemaTypes = [videoBlogPost]\n```\n\n\n2.3. Configure the Mux plugin\n\nAdd the Mux plugin to your Sanity configuration file (sanity.config.ts or sanity.config.js):\n\n\n```typescript\n// sanity.config.ts\nimport { defineConfig } from 'sanity'\nimport { structureTool } from 'sanity/structure'\nimport { muxInput } from 'sanity-plugin-mux-input'\nimport { schemaTypes } from './schemaTypes'\n\nexport default defineConfig({\n  name: 'default',\n  title: 'My Sanity Project',\n\n  projectId: 'your-project-id',\n  dataset: 'production',\n\n  plugins: [\n    structureTool(),\n    muxInput()\n  ],\n\n  schema: {\n    types: schemaTypes,\n  },\n})\n```\n\n\n3. Enter Mux credentials\n\nGenerate a new Access Token by going to the Access Token settings of your Mux account dashboard.\n\nThe access token should have Mux Video Read and Write permissions as well as Mux Data (read-only).\nIf you want to use signed playback, you need to enable both Read and Write permissions for the System section. For more information, check out the Signed Tokens section.\n\nBack in Sanity Studio, navigate to the Videos section in your studio menu, then click on Configure plugin. Enter your Access Token ID and Secret Key in the configuration settings.\n\nYou'll also see an option to Enable signed URLs. This feature allows you to create videos with signed playback policies for additional security. If you're unsure, you can leave this disabled for now—you can learn more about this feature in the Signed Tokens section below.\n\n4. Upload video\n\nUse the select button to open the file explorer on your system, drag the file right into the input area, or paste the URL to the video in the field. Once it's done uploading, you can select the thumbnail you want for the preview.\n\nYou now have the ability to upload content to Mux through Sanity CMS!\n\nTo retrieve your video for playback, check out the Sanity docs for instructions.\n\n5. Explore advanced options\n\nSigned Tokens\n\nEnabling signed URLs in Sanity will require you to generate your own signing tokens on your application server. This involves creating a signing key and using that to generate JSON web tokens when you want to access your videos and thumbnails outside of Sanity.\n\nBy default, all assets uploaded to Mux through Sanity will be created with a playback policy of \"public\". This means that your videos and thumbnails are accessible with https://stream.mux.com/{PLAYBACK_ID}.m3u8 and https://image.mux.com/{PLAYBACK_ID}/thumbnail.jpg.\n\nIf you want more control over delivery of the playback and thumbnail access, you can enable this feature on the Sanity configuration popover:\n\nWhen you enable this feature, the following things will happen:\n\n1. The Mux Plugin in Sanity will use the Mux API to create a URL signing key and save this with your secrets document.\n2. Any assets that get created while this feature is enabled will be created with playback_policy: \"signed\" (instead of \"public\").\n3. The signing key from Step 1 will be used by the Mux Plugin to preview content inside the Sanity UI.\n4. When you access your content in your own application, use the MuxAsset.data.playback_ids property to determine if the asset has a signed or public policy.\n\n\n```json\n{\n  \"_id\": \"0779365f-bbd1-46ab-9d78-c55feeb28faa\",\n  \"_type\": \"mux.videoAsset\",\n  \"assetId\": \"fNMFNYMq48EwgJM7AIn1rNldiFBcVIdK\",\n  \"data\": {\n    \"playback_ids\": [\n      {\n        \"id\": \"01cBJKm5KoeQii00YYGU7Rvpzvh6V01l4ZK\",\n        \"policy\": \"public\"\n      }\n    ]\n  },\n  \"status\": \"ready\"\n}\n```\n\n\n5. You should use the signed playbackId to create URLs for playback and for thumbnail generation.\n\n- Playback https://stream.mux.com/{SIGNED_PLAYBACK_ID}.m3u8?token={TOKEN}\n- Thumbnails https://image.mux.com/{SIGNED_PLAYBACK_ID}/thumbnail.jpg?token={TOKEN}\n\n6. The TOKEN parameter for the above URLs is something you create on your server according to Step 2 in Secure video playback\n\nNote that in the Sanity UI when an asset is using a signed URL you will see this green notice.\n\nEncoding Tiers\n\nWhen uploading a new video, you can select which Encoding Tier is used when preparing the Asset. Possible selections are Smart and Baseline. When choosing Smart, additional options are made available for maximum resolutions (1080p, 2K or 4K).\n\nMore details can be found in our Use Encoding Tiers guide.\n\nStatic Renditions\n\nWhen using the Smart Encoding Tier, an option to enable downloadable MP4s will be available. This option will create Static Renditions for the Asset and will make MP4 files available for download to client devices using a formatted URL.\n\nMax Video Resolution\n\nYou can specify the maximum resolution to encode the uploaded video. This option is particularly important in managing costs when uploaded videos are higher than 1080p resolution and also allows you to encode and play videos in 2k or 4k resolutions.\nMore information on the feature is available in our docs. Also, read more on this feature announcement in our blog post.\n\nCaptions/Subtitles\n\nWith Mux's auto-generated captions, you can easily add captions to videos uploaded by selecting the language of the spoken words. When using this auto-generated option, Mux will generate captions automatically while it prepares the Asset. More details can be found in the Add auto-generated captions to your videos and use transcripts section of our documentation.\n\nThe \"Auto-generated\" captions configuration should only be used to generate a single language captions track. The language selected must match the spoken language.\n\nRelease notes\n\nCurrent release\n\nv2.10.0\n\n- Importing Mux videos will include the video title\n- Added the ability to backfill titles for existing Mux videos.\n\nPrevious releases\n\nSee GitHub"
  },
  {
    "id": "191-_guides/integrations/strapi",
    "title": "Integrate with Strapi",
    "path": "_guides/integrations/strapi.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/strapi",
    "content": "The Mux Video Uploader plugin allows editors to upload content directly to Mux from within the Strapi interface, then associate those videos with their custom collection types.\n\nRequirements\n\n- A working installation of Strapi that is publicly accessible through a hostname\n- An Access Token and Secret Key which is provisioned within Mux Dashboard\n- Configure a Webhooks listener within Mux Dashboard so that Strapi can be informed of upload progress.\n\n1. Install the Mux Video Uploader plugin\n\nWith your existing Strapi installation, run the following command in the root of your Strapi project to install the plugin. Be sure to restart Strapi for the plugin to take effect.\n\nAs of the 2.1.0 version of this player, only Strapi v4 will be supported. To use with Strapi v3, please use version 2.0.0 of this plugin.\n\nInstall instructions for Strapi v5\n\nRun this command in your project folder if you are using NPM:\n\n\n```sh\nnpm i strapi-plugin-mux-video-uploader@latest\n```\n\n\nOr this command if you are using yarn with your project:\n\n\n```sh\nyarn add strapi-plugin-mux-video-uploader@latest\n```\n\n\nInstall instructions for Strapi v4\n\nRun this command in your project folder if you are using NPM:\n\n\n```sh\nnpm i strapi-plugin-mux-video-uploader@2.8.4\n```\n\n\nOr this command if you are using yarn with your project:\n\n\n```sh\nyarn add strapi-plugin-mux-video-uploader@2.8.4\n```\n\n\nInstall instructions for Strapi v3\n\nRun this command in your project folder if you are using NPM:\n\n\n```sh\nnpm i strapi-plugin-mux-video-uploader@2.0.0\n```\n\n\nOr this command if you are using yarn with your project:\n\n\n```sh\nyarn add strapi-plugin-mux-video-uploader@2.0.0\n```\n\n\n2. Create access token in Mux\n\nGenerate a new Access Token by going to the Access Token settings of your Mux account dashboard.\n\n<Image\n  src=\"/docs/images/settings-api-access-tokens.png\"\n  width={500} height={500}\n  alt=\"Mux access token settings\"\n/>\n\nThe access token should have Mux Video Read and Write permissions.\n\n<Image\n  src=\"/docs/images/new-access-token.png\"\n  width={760}\n  height={376}\n  alt=\"Mux Video access token permissions\"\n  sm\n/>\n\nAfter clicking the \"Generate Token\" button, save the \"Access Token ID\" and \"Secret Key\" to be used later.\n\n3. Configure Webhook listener\n\nPart of the upload process includes Mux updating Strapi with the completion of the upload and processing. In order for Mux to make this communication, a Webhook needs to be established so that events are sent to your Strapi installation.\n\nCreate a new Webhook configuration in Mux Dashboard. There will be a space to add a \"URL to notify\". This value should be formatted based on your Strapi's hostname\n\n\n```txt\n{YOUR_STRAPI_DOMAIN_HERE}/mux-video-uploader/webhook-handler\n```\n\n\nAfter saving, copy the \"Signing Secret\" which will be used later.\n\n4. Setup configuration in Strapi\n\nIn Strapi, visit the Settings page and navigate to the MUX VIDEO UPLOADER section.\n\nUsing the details saved in the previous step, fill in the fields with the appropriate values.\n\nClick the \"Save\" button to persist the changes.\n\n5. Upload video\n\nUse the Mux Video Uploader page that is now available in Strapi's menu to upload either with a remote URL or directly using a local video file.\n\nFrom here, relationships of Mux assets can be modeled to custom collection types within Strapi to tie metadata with playable content.\n\nYou now have the ability to upload content to Mux through Strapi CMS!\n\nAt this point, querying Strapi using REST or GraphQL will give you access to the playback_id information. This playback_id can be used by your client applications to stream content or retrieve thumbnails.\n\n6. Explore advanced options\n\nSigned tokens\n\nEnabling signed URLs in Strapi will require you to generate your own signing tokens on your application server. This involves creating a signing key and using that to generate JSON web tokens when you want to access your videos and thumbnails outside of Strapi.\n\nBy default, all assets uploaded to Mux through Strapi will be created with a playback policy of \"public\". This means that your videos and thumbnails are accessible with https://stream.mux.com/{PLAYBACK_ID}.m3u8 and https://image.mux.com/{PLAYBACK_ID}/thumbnail.jpg.\n\nIf you want more control over delivery of the playback and thumbnail access, you can enable this feature in the Strapi settings for the Mux Video Uploader.\n\nWhen you enable this feature, the following things will happen:\n\n1. The Mux Plugin in Strapi will save the signing keys that you've generated and be available immediately.\n2. Any Assets that get created with the Signed Playback URL setting enabled will be created with playback_policy: \"signed\" (instead of \"public\").\n3. The signing key from Step 1 will be used by the Mux Plugin to preview content inside the Strapi UI.\n4. When you access your content in your own application, use the MuxAsset.signed property to determine if the asset is signed by either a true or false value.\n\n\n```json\n{\n  \"id\": 9,\n  \"upload_id\": null,\n  \"asset_id\": \"H9H01yni83yRLuu6cKaf8jQI8XW01SPp5XI7WrGsD37n00\",\n  \"playback_id\": \"aAqXNee00zlfzR2Rsw01NmGBvxSg1Ocs3g008YChvtG6aM\",\n  \"signed\": true,\n  \"isReady\": true,\n  \"duration\": 25.492133,\n  \"aspect_ratio\": \"16:9\",\n  \"createdAt\": \"2024-04-01T23:48:19.760Z\",\n  \"updatedAt\": \"2024-04-01T23:48:21.605Z\"\n}\n```\n\n\n5. You should use the signed playback_id to create URLs for playback and for thumbnail generation.\n\n- Playback https://stream.mux.com/{SIGNED_PLAYBACK_ID}.m3u8?token={TOKEN}\n- Thumbnails https://image.mux.com/{SIGNED_PLAYBACK_ID}/thumbnail.jpg?token={TOKEN}\n\n6. The TOKEN parameter for the above URLs is something you create on your server according to Step 2 in Secure video playback\n\nNote that in the Strapi UI when an asset is using a signed URL you will see a lock icon on the Asset list.\n\nEncoding Tiers\n\nWhen uploading a new video, you can select what Encoding Tier used when preparing the Asset.  Possible selections are Smart and Baseline.  When choosing Smart additional options are made available for maximum stream resolutions (1080p, 2K or 4K).\n\nMore details can be found in our Use Encoding Tiers section.\n\nStatic Renditions\n\nWhen using the Smart Encoding Tier, an option to enable downloadable MP4s will be available.  This option will create Static Renditions for the Asset and will make MP4 files available for download to client devices using a formatted URL.\n\nCaptions/Subtitles\n\nWith Mux&apos;s auto-generated captions, editors can easily add captions to videos being uploaded from Strapi.  When using the \"Auto-generated\" option, Mux will generate captions automatically while it prepares the Asset.  More details can be found in the Add auto-generated captions to your videos and use transcripts section of our documentation.\n\nIf you choose to upload a \"Custom\" captions file (supported formats are .vtt and .srt), your file will be uploaded to your instance of Strapi and Mux will pull it via a public URL from your Strapi instance.  Take a look at our Add subtitles/captions to videos for more details.\n\nRelease notes\n\nCurrent release\n\nv3.0.1\n\n- Upgrade to Strapi v5\n- Breaking change— Plugin configuration is now done using Strapi's file based config.  Details on how to do this can be found in the README.md.\n- Refreshed library versions to latest\n- Both auto-generated and custom captions can be added on upload\n- Previous issue with preview player is resolved, plugin now uses Mux Player again"
  },
  {
    "id": "192-_guides/integrations/wordpress",
    "title": "Integrate with WordPress",
    "path": "_guides/integrations/wordpress.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/integrations/wordpress",
    "content": "This guide explains how to integrate Mux with WordPress using the Mux Video Uploader plugin by 2Coders. This integration enables you to leverage Mux's powerful video infrastructure while maintaining the familiar WordPress content management experience.\n\nFollow the steps below to integrate Mux with your WordPress site\n\n1. Install the Plugin\n\nWordPress plugin can be installed either from WordPress Plugin Directory or Manually by uploading a zipped plugin file.\n\nYou should be on WordPress.com Business pricing plan or higher to install the Mux Video Uploader plugin. However, there is no such requirement for Self-Hosted WordPress instance.\n\nA. From the WordPress Plugin Directory\n\n1. In your WordPress admin panel, navigate to Plugins > Add Plugin on the sidebar\n2. Search and select \"Mux Video Uploader by 2Coders\"\n\n\n\n3. Click Install and activate button on the plugin page.\n\n\n\nB: Manual Installation\n\n1. Download the plugin ZIP file from the WordPress.org site.\n2. In your WordPress admin panel, go to Plugins > Add Plugin\n3. Click Upload Plugin and select the downloaded ZIP file\n\n\n\n4. Click Install Now and then Activate Plugin\n\nAfter the plugin is properly installed, you should see the Mux Video Uploader plugin on the Installed Plugins page.\n\n2. Create a Mux Account\nIf you don't already have a Mux account:\n\n1. Sign up at mux.com\n2. After creating your account, navigate to your dashboard\n3. Generate API Access Token. You'll need both an Access Token ID and Secret Key for the plugin to make API requests.\n\n\n\n   The access token should have Mux Video Read and Write permissions as well as Mux Data (read-only).\n\n\n\n3. Connect WordPress to Mux\n\nIn your WordPress admin panel, locate the new Mux Video menu item\n1. Go to Mux Video > Settings\n2. Enter your Mux API credentials (API ID and Secret Key)\n3. Click Save Settings\n\n\n\n4. Upload Video\n\nThe video below shows how to upload a video on WordPress using the Mux Video Uploader plugin. You can also enable advanced features, like Signed URLs, Subtitles & Captions, and MP4 generation during asset creation or later on from the Assets List page.\n\n5. Play Video\n\nUsing the Gutenberg Block\n\nThe uploaded video can be added to your WordPress site using the Gutenberg block Editor:\n\n1. Add or Edit a post or page\n2. Click the + icon to add a new block\n3. Search for \"Mux Video\" and select the block\n4. Choose the asset from the list and click Insert\n5. Preview and publish your content\n\nWhen using the Gutenberg block, the video is embedded onto the page with the default Mux Player configuration.\n\nUsing the Shortcode Block\n\nThe same uploaded videos can also be added using the Shortcode block. With the Shortcode, you can customize the Mux Player configuration instead of using the default configuration.\n\nAdvanced video options\n\nVideo Quality Levels\n\nWhen uploading a new video, you can select which Video Quality Levels is used when preparing the Asset. Possible selections are Basic, Plus and Premium. More details can be found in our Use Video Quality Options guide.\n\nMP4 Generation\n\nEach Asset can be enabled to generate downloadable MP4s. You can select Highest or Audio-Only or both. This will create Static Renditions for the Asset and will make MP4 files available for download to client devices using a formatted URL.\n\nSigned Tokens\n\nWhen uploading a new video, you can select Protected option when you want to secure the video playback and Public to make the video publicly available. Learn more about Secure video playback.\n\nMux Video Uploader plugin creates a signing key when configuring the Access Tokens on the plugin's Settings page. The plugin generates Signed URLs when Protected option is selected when uploading the video and available on the Asset page as shown in the image below.\n\nAuto-Generate and Upload Custom Captions/Subtitles\n\nWith Mux's auto-generated captions, you can easily add captions to videos uploaded by selecting the language of the spoken words. Mux can generate captions automatically while preparing the asset or later. For generating captions later, go to that Asset entry on the Asset List section of the plugin and click on Add Captions. More details can be found in the Add auto-generated captions to your videos and use transcripts section of our documentation.\n\nThe \"Auto-generated\" captions configuration should only be used to generate a single language captions track. The language selected must match the spoken language.\n\nAdditionally, you can upload one or more custom caption files (during asset creation step or later) for a single asset."
  },
  {
    "id": "193-_guides/pricing/estimating-video-costs",
    "title": "Estimating your Mux Video costs",
    "path": "_guides/pricing/estimating-video-costs.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/pricing/estimating-video-costs",
    "content": "If there’s one thing to take away from Mux’s video pricing model, it’s that minutes are everything. Minutes encoded, minutes stored, and minutes delivered are the only things that matter when it comes to billing. We’ve written previously about why we think this is a better way of charging for video.\n\nYou can find all of our costs on our pricing page, but you may be wondering how you can calculate estimates using these numbers. We’re going to outline a couple ways you can do this so you can be confident that you can predict your costs at any time.\n\nUser-generated content platform\n\nIf you’re building a user-generated content platform (UGC), then encoding & storage is going to be a big consideration for you. Most UGC platforms follow some kind of power-law distribution, where a small percentage of the content makes up a large amount of views (in YouTube’s case, for example, much less than 1% of the content uploaded makes up much more than 99% of the views.\n\nYour split might not be as extreme, maybe it’s close to 95/5, 90/10 or even 80/20, but this is the general tendency that we see for UGC platforms. You will want to consider using the basic video quality level, which is $0 encoding and pairing that with Automatic Cold Storage so that you get a cheaper storage rate for assets that are rarely viewed.\n\nUse high, medium and low ranges to make your estimates\n\nIf you have an existing application, you can use your existing usage patterns to estimate how much video your users might watch. If you don’t have any existing users to benchmark off of, estimating will be a little trickier. For example:\n\n- Out of 1,000 monthly active users, we think 25% of them will engage with our new video product. Out of that 250 users we think 100 of them will stream 10 minutes of video and 150 of them might stream 25 minutes of video.\n\nIf you’re launching something entirely new, then we recommend making 3 separate estimates where you model scenarios that account for how popular your video might be. Here’s some examples:\n\n- Low end: we think in the first few months we’ll get 150 active users on our product. Out of those 150 we think they’ll each stream 45 minutes of video per month.\n- Middle of the road: we think in the first few months we’ll get 400 active users and they’ll be streaming an hour and a half of video per month.\n- Moonshot: in the best case scenario we think we’ll get 1,000 active users and they’ll stream 2 and a half hours of video per month\n\nNow, for each of those 3 scenarios you can plug the results into the calculator and get a range of costs. That range might be large, but you will have a good idea of how your costs will look depending on the uptake of your users.\n\nWorking with Gigabytes instead of minutes\n\nSome services charge for video based on file sizes, either stored or as bandwidth for delivery. There’s a couple ways you can compare these costs with Mux’s minute based pricing. These will only be a guide because 1GB of video can vary in duration depending on the bitrate, but we can use some estimates that will work for common video encoding settings and work from there.\n\n1 minute of 1080p video averages around 38MB (at 5Mbps), this works out at 25 minutes of video per Gigabyte.\n\nHere’s some example conversions based on how many gigabytes you might have using this as a base:\n\n| Video (1080p, 5Mbps) | Estimated minutes |\n| --- | --- |\n| 1GB | 25 minutes |\n| 10GB | 250 minutes |\n| 100GB | 2,500 minutes |\n\nTaking how many gigabytes you have and multiplying it by 25 for 1080p content should give you an estimate in minutes that you can plug into the calculator.\n\nHere’s some estimates you can use for different resolutions:\n\n| Resolution | Estimated minutes per GB |\n| --- | --- |\n| 720p (3.5Mbps) | 40 minutes |\n| 1080p (5Mbps) | 25 minutes |\n| 1440p (2K, 8Mbps) | 15 minutes |\n| 2160p (4K, 12Mbps) | 10 minutes |\n\nWhat to consider when estimating your delivery\n\nViews (mostly) don’t matter\n\nYou might be used to thinking of delivery in terms of how many views a video had, as that’s a good metric for how popular a video is. From Mux’s perspective, 1 person viewing a video for 10 minutes is identical to 10 users watching a 1 minute video each. When you add it all up, 10 minutes of video has been delivered, and that’s how it will appear on your bill.\n\nMinutes delivered, not minutes watched\n\nMux bills on minutes delivered even if they weren’t watched. If a viewer starts playing a 20 minute video, they might only watch 5 minutes. Additionally, the player might have preloaded an extra minute of video that the viewer never saw. From a billing perspective, this is 6 minutes of delivery even though that extra minute was never seen, because we still had to deliver it to the client as requested by the player.\n\nAre looping videos charged for each time they repeat?\n\nWhether a looping video is charged for one playthrough or for each time it repeats depends on the caching behavior of the browser and player being used. If the browser is not clearing out its buffers while the video is repeating then subsequent loops are not going to be charged for delivery, because we never see new requests for the video to our infrastructure as the video loops.\n\nIt's difficult to predict and control this browser behavior though. There are also physical limitations as to how much video can be stored in memory before some has to be removed.\n\nIn general, the shorter a video is, and the fewer renditions that are being switched between during playback, the more likely that the video will remain in the browsers buffers. Videos that are longer than roughly 60 seconds are likely to stretch what can fit in a browser's video buffer and lead to more requests (and delivery charges).\n\nConfiguring your player to use a single rendition instead of multiple ones can make it easier for a browser to cache video, but at the cost of forcing a single resolution onto users regardless of their bandwidth. If your videos are particuarly short, you could try using static MP4s instead of the default HLS delivery.\n\nFor more information about Mux video billing see our main pricing page."
  },
  {
    "id": "194-_guides/pricing/optimizing-video-costs",
    "title": "Optimizing your Mux Video costs",
    "path": "_guides/pricing/optimizing-video-costs.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/pricing/optimizing-video-costs",
    "content": "You can find all of our costs on our pricing page, but you may be wondering how you can optimize your costs and potentially find ways to reduce your bill. We’re going to outline a few ways you can optimize your usage of Mux so that you can keep your costs as low as possible.\n\nCost levers you can leverage through the Mux Video product\n\nMux offers a few ways to optimize your costs depending on your use case. We have many features that you can take advantage of that will influence your encoding, storage, and delivery costs. There are also add-ons you can opt-in to using so that you only pay for the features you need.\n\nUse Basic Video Quality\n\nThere is no charge for video encoding when using basic quality. This makes encoding free when uploading videos that use this quality level.\n\nThe basic video quality level uses a reduced encoding ladder with a lower target video quality and is suitable for simpler video use cases, particularly those that have a lot of user generated content.\n\nYou can learn more about video quality and what features are supported.\n\nBasic quality level assets have a minimum storage charge of one month and are prorated thereafter. Storage is prorated by the percentage of the month that the video is stored. For example, if a 10-minute asset is stored for only half a month, you will be charged for only 5 minutes.\n\nAutomatic Cold Storage\n\nWith Automatic Cold Storage, we automatically transition a video or audio-only asset to a different storage level based on how long it has been since it was last viewed. The colder the asset gets, the lower the billing rate becomes.\n\nSee more about Automatic Cold Storage\n\nCapping maximum delivery resolution\n\nBy setting a maximum delivery resolution, you can take advantage of our resolution based pricing.\n\nThe playback URL below with the max_resolution query parameter modifies the resolutions available for the player to choose from.\n\n\n```\nhttps://stream.mux.com/{PLAYBACK_ID}.m3u8?max_resolution=720p\n```\n\n\nThe max_resolution parameter can be set to 720p, 1080p, 1440p, or 2160p. You may want to do this in order to reduce your delivery costs, or build a feature to your product where only certain viewers get lower resolution video.\n\nSee more here\n\nCapping upload resolution\n\nIf the video being captured in your app doesn't need to be played back in full resolution, specify a lower resolution when recording to take advantage of Mux's resolution dependent pricing.\n\nWhen uploading from a mobile device (Android, iOS or iPadOS), you can utilize our upload SDKs to adjust the resolution of your video input locally before it is uploaded to Mux. By default the SDK will adjust the input resolution to 1920 x 1080 for any inputs that are larger.\n\nControl recording resolution\n\nPreload\n\nIf you want to reduce delivery costs for users who might delay watching a video (or not watch it at all), you can set preload=\"none\" in Mux Player (or other compatible player). This means that no video will be pre-loaded until the user plays the video. You could also use preload=\"metadata\" which will only load the minimum amount of data needed for the player to get basic information about the video, like its duration.\n\nThe tradeoff with using preload=\"metadata\" or preload=\"none\" is that when the user plays the video they will experience a slower startup time because the video has to load before playback can start.\n\nMobile browsers, especially on iOS and Android, often ignore auto and metadata due to data-saving policies.\n\nWhile preload serves as a hint, browsers ultimately decide how to handle video loading. If you need precise control, consider managing video loading via JavaScript.\n\n\nLazy loading\n\nLazy loading can be beneficial because you can opt to only load the player when the user is ready to watch the video, like scrolling it into view. If the player isn't loaded, you're not charged for any video delivery yet. See our guide on how to implement lazy loading for Mux Player here.\n\nDelivery Usage API\n\nThis is not a cost optimization feature, but is a way to get asset level delivery visibility. You can utilize the Delivery Usage API to retrieve information about the delivery of a specific video in a given time period. The Delivery Usage API allows you to get delivery and streaming usage details for each asset and across all assets.\n\nDelivery usage details are aggregated every hour at the top of the hour and can be requested for a specified time window within the last 90 days starting at 12 hours prior to when the request is made.\n\nCost levers you can leverage on your own\n\nPlayer buffer length\n\nA player has a buffer for the media it plays. Segments are downloaded into the buffer, decoded, and then played. The forward buffer is the media that has not yet been played. In most modern web players, you can set the buffer length of the playback engine.\n\nThe main tradeoff when customizing these parameters is performance. Shortening the buffer length leaves your player vulnerable to rebuffering and the viewer waiting if there's a temporary network disconnection or hiccup and that buffer runs out. This is an advanced option, so please keep that in mind.\n\nBy reducing this value, you save on the delivered minutes portion of your bill because you're reducing the actual video delivery from the player. The mechanism to control this sometimes differs from player to player but in Mux Player and hls.js, you can set this in a couple of places by:\n\n\n```javascript\nconst player = document.querySelector('mux-player');\nplayer._hls.config.maxBufferLength = { number in seconds }\nplayer._hls.config.maxBufferSize = { bytes }\nplayer._hls.config.maxMaxBufferLength = { number in seconds }\n```\n\nmaxBufferLength = Maximum buffer length in seconds. If buffer length becomes less than this value, a new fragment will be loaded.\n\nmaxBufferSize = 'Minimum' maximum buffer size in bytes. If buffer size upfront is bigger than this value, no fragment will be loaded.\n\nmaxMaxBufferLength = Maximum buffer length in seconds. Hls.js will never exceed this value, even if maxBufferSize is not reached yet. hls.js tries to buffer up to a maximum number of bytes (60 MB by default) rather than to buffer up to a maximum nb of seconds.\n\nFor more information, see the hls.js documentation on these options.\n\nThese options are all via hls.js and Mux Player. Your own player and playback engine will differ.\n\nDelete live stream assets when streaming ends\n\nTo save on storage costs, you can delete the resulting asset that gets created once your live stream has completed. This way you will limit storage charges and prevent further delivery costs. The ingest/encoding cost is still the same once the live stream has completed, this only affects storage.\n\nStorage is calculated by minutes of video stored. Storage is prorated by the percentage of the month that the video is stored. For example, if a 10-minute asset is stored for only half a month, you will be charged for only 5 minutes.\n\nPause when out of viewport\n\nOne way of reducing your delivery costs is to reduce the time viewers spend having your video play and buffer. You could implement a way to pause your video player when the viewer's browser window is out of focus or not visible. This can prevent unnecessary playback and delivery charges.\n\nYou can achieve this by listening to the visibilitychange event on the window object:\n\n\n```javascript\ndocument.addEventListener(\"visibilitychange\", function () {\n    if (document.visibilityState !== \"visible\") {\n        console.log(\"Window is inactive, pausing video player\");\n        // replace the below with the corresponding pause method of the player you're using\n        player.pause()\n    }\n});\n```\n\n\nAre you still watching?\n\nMany streaming services want to reduce their bandwidth and streaming delivery costs so they have implemented an \"Are you still watching?\" dialog popup that interrupts playback when the viewer has been watching on autoplay for an extended period of time with no interaction.\n\nYou could implement this in your own application as well. Below is a small proof of concept on how you might achieve this using React.\n\n\n```jsx\nimport { useState } from \"react\";\nimport MuxPlayer from \"@mux/mux-player-react\";\n\nexport default function App() {\n  const [lastPlayedTimestamp, setLastPlayedTimestamp] = useState();\n\n  const playbackId = \"g11xsFT2MA9E92016CuQTSh8kv01aaUhJK\"\n  const secondsToStopVideo = 10; // timer in seconds\n\n  const handleAllUserActivity = (event) => {\n    setLastPlayedTimestamp(event.target.currentTime) // reset the last played timestamp after each play\n  };\n\n  const handleTimeUpdate = (event) => {\n    const player = event.target;\n    const timeElapsed = player.currentTime - lastPlayedTimestamp;\n    if (!player.paused && timeElapsed > secondsToStopVideo) {\n      player.pause();\n      alert(\"Are you still watching?\");\n    }\n  };\n\n  return (\n    <>\n      <MuxPlayer\n        playbackId={playbackId}\n        onPlaying={handleAllUserActivity}\n        onSeeking={handleAllUserActivity}\n        onRateChange={handleAllUserActivity}\n        onVolumeChange={handleAllUserActivity}\n        onTimeUpdate={handleTimeUpdate}\n      />\n    </>\n  );\n}\n```\n\n\nNot loading multiple videos on one webpage\n\nSince Mux customers are charged for any delivered video, if a video player is loaded on a webpage it _may_ pre-load some amount of video before playback has been initiated.\n\nThis would result in minutes delivered just on page load before the viewer even hits the play button.\n\nIf you're displaying multiple videos on page load for each viewer, this could end up multiplying your bill as many videos are causing delivery charges at once. This could be very costly.\n\nLimit the duration of your uploads\n\nIf you're a looking to put a duration cap on your videos, you can set duration limits upon upload.\n\nThis is done usually by UGC platforms (social media) given the short form content focus, but also by platforms looking to make sure they're not paying for unnecessary ingests costs."
  },
  {
    "id": "195-_guides/pricing/report-on-mux-costs",
    "title": "Report on your Mux costs",
    "path": "_guides/pricing/report-on-mux-costs.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/pricing/report-on-mux-costs",
    "content": "Mux provides a billing breakdown which gives you transparency into your Mux costs, with historical context that helps you spot trends and make informed decisions. From this page, you can chart your costs and purchases over time, track your plan credit spending, and see your credit balances. It includes information about your last six billing cycles. Any invoices that have been issued in the six most recent billing cycles are shown but it does not include usage in the current cycle that has not yet been invoiced.\n\nYou can find the Billing Breakdown in the Billing area of the Mux dashboard.\n\nOverview\n\nThe Last 6 Billing Cycles chart makes it easy to see how the costs of usage fluctuate month-to-month. The billing period can include multiple invoices if more than one was generated by Mux.\n\nIn the bar chart:\n Committed Charges (Orange): Your plan’s committed costs, this can be Video, Data, or general committed amounts. For example, for a Starter Plan, the commitment would be $10 per month.\n Previous Cycle’s Overages (Purple): Costs from usage in the previous month that goes above the committed amount, if any.\n Credits Applied (Purple-striped): Reductions of the dollar amount that is billed in that month from plan credits that were purchased or promotional credits received.\n Tax (Red): Taxes added to the bill, based on your local jurisdiction.\n\nIf you hover over the bar chart, the tooltip shows the exact dollar amounts for each of these values and the total amount that is billed for each month.\n\nThe highlight box on the right side of the page shows the total dollar amount owed in the most recent billing period, the change from the previous month, and any promo credits that were applied.\n\nThe detailed breakdown shows you exactly how your costs break down across the major areas of spending. Not all of these will be present for every customer and they won’t be shown if they don’t apply.\n Video Usage: the dollar amount of consumption-based Video SKUs that were used.\n Data Usage: the dollar amount of consumption-based Data SKUs that were used.\n Video Committed: the dollar amount that was committed to spend on Video usage\n Data Committed: the dollar amount that was committed to spend on Data usage, which is usually Monitored Views.\n Support: the cost for support. For some customers, this is only charged once per year so it may not be included in the table, depending on the date of the charge.\n Plan Credits Purchase: the amount of plan credits that were purchased. These may be used over multiple months and the balance will be shown in the “Plan Credits Remaining”. For some customers, this is only charged once per year so it may not be included in the table, depending on the date of the charge.\n Plan Credits Applied: the dollar amount that was paid from a plan credits balance.\n Total: the total dollar amount that was billed to you from your Mux usage.\n Plan Credits Remaining: the amount of plan credits that remain after the month’s charges were applied to an existing balance.\n\nRows that are highly variable include a percentage below the value which indicates the percentage change, increase or decrease, from the previous month.\n\nWhile the overview gives you the overall picture, we also provide breakdowns at the product-level. The detailed breakdowns show you exactly how your costs break down within each product.\n\nMux Video\n\nMux Video billing is broken down into the major areas of Mux Video usage and spending:\n Input VOD: Input of recorded assets\n Input Live: Input of live streams\n Advanced Static Rendition Generation: Generation of advanced static renditions; generating standard static renditions is free.\n Storage: Storage for all assets, excluding static renditions\n Static Rendition Storage: Storage for standard and advanced static renditions\n Delivery: All delivery, including audio-only and video assets, live streams, and static renditions\n Other: DRM, simulcasting, auto-generated live captions\n\nMux Data\n\nMux Data billing shows the breakdown of pre-committed costs for Data views and consumption-based view pricing.\n\nFor more information about Mux video billing see our main pricing page or refer to the billing breakdown page for your account."
  },
  {
    "id": "196-_guides/pricing/video",
    "title": "Understanding Mux Video Pricing",
    "path": "_guides/pricing/video.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/pricing/video",
    "content": "Mux pricing is split up into three categories: input, storage, and delivery. In other words, you're charged by how much video you upload every month, how much video you store every month, and how much video your users stream every month.\n\nAs you read, keep your eye out for what we call \"pricing levers\": ways you can suit your costs to your use case. For example, we offer discounts based on volume and resolution. More on those near the end.\n\nFinally, Mux charges by minute of video inputted, stored, and delivered. Learn more about why we charge in minutes instead of bytes.\n\nLet's get started by talking about the first category of pricing: Input.\n\nIf you find yourself with higher usage than the tiers described below, we'd love to talk to you about how we can customize your pricing.\n\nVideos can come in all sorts of different formats, containers, codecs, or countless other variations. When a video is uploaded to Mux, we process it and create a high-quality, standardized version of the video through a process called \"encoding.\" We use that standardized version to deliver any number of bitrates and resolutions based on the viewer's needs, but more on that later.\n\nMux supports a configurable video quality level on each asset, with three levels, basic, plus, and premium.\n\nThe basic video quality level uses a reduced encoding ladder, with a lower target video quality, suitable for simpler video use cases. There is no charge for video input when using basic quality. Basic assets are optimized for video use cases with simpler streaming needs, such as social or user-generated content, where high encoding costs may limit your business model.\n\nThe plus video quality level encodes your video at a consistent high-quality level. Assets encoded with the plus quality use an AI-powered per-title encoding technology that boosts bitrates for high-complexity content, ensuring high-quality video, while reducing bitrates for lower-complexity content to save bandwidth without sacrificing on quality. Plus assets are enhanced quality, perfect for professional or branded content. The plus quality level incurs a cost per video minute of encoding.\n\nThe premium video quality level uses the same AI-powered per-title encoding technology as plus, but is tuned to optimize for the presentation of premium media content, where the superior video quality is required, including use cases such as studio or cinematic projects. The premium quality level incurs a higher cost per video minute of encoding.\n\nLive Streams are not available with the basic video quality level; Mux only supports plus and premium video quality levels for Live Streams.\n\nThe default video quality level for assets in new accounts is basic. You can configure your organization's default video quality level in the Settings pane in the dashboard, or after confirming the payment method when you change your plan. This configuration option is only available to account admins. You can also override the default video quality level on a per-asset basis at the time of asset creation.\n\nLearn more about setting video quality levels.\n\nMux charges by minute of video encoded.\n\nBasic quality input\n\nLearn more about setting video quality levels.\n\nOn-demand video only.\n\n| Monthly volume tiers  | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :-------------------- | :--------- | :---- | :------    | :--------- | :---------\n| All volumes | Free | Free | Free | Free | Free\n\nPlus quality input\n\nLearn more about setting video quality levels.\n\nLive video is supported up to 1080p and on-demand video up to 4K.\n\nPricing is per minute.\n\n| Monthly volume tiers | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :------------------- | :--------- | :---- | :--------- | :--------- | :---------\n| First 5,000 minutes | $0.025000 | $0.031250 | $0.050000 | $0.100000 | $0.002500\n| Next 10,000 minutes | $0.023750 | $0.029688 | $0.047500 | $0.095000 | $0.002375\n| Next 10,000 minutes | $0.023125 | $0.028906 | $0.046250 | $0.092500 | $0.002313\n| Over 25,000 minutes | $0.022500 | $0.028125 | $0.045000 | $0.090000 | $0.002250\n\nPremium quality input\n\nLearn more about setting video quality levels.\n\nLive video is supported up to 1080p, on-demand video up to 4K.\n\nPricing is per minute.\n\n| Monthly volume tiers | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :------------------- | :--------- | :---- | :--------- | :--------- | :---------\n| First 5,000 minutes | $0.037500 | $0.046875 | $0.075000 | $0.150000 | $0.002500\n| Next 10,000 minutes | $0.035625 | $0.044531 | $0.071250 | $0.142500 | $0.002375\n| Next 10,000 minutes | $0.034688 | $0.043359 | $0.069375 | $0.138750 | $0.002313\n| Over 25,000 minutes | $0.033750 | $0.042188 | $0.067500 | $0.135000 | $0.002250\n\nAdvanced static rendition (MP4s) preparation\n\nAdvanced static renditions are priced per minute of content, per static rendition, based on the resolution of the static rendition that is generated.\n\nNote that there is no charge for generating standard static rendition MP4s. See the enabling static MP4 renditions guide for more information.\n\nBasic and plus quality advanced static rendition preparation\n\n| Monthly volume tiers | Up to 720p | 1080p | 1440p (2K) | 2160p (4K)\n| :------------------- | :--------- | :---- | :--------- | :---------\n| First 5,000 minutes | $0.008000 | $0.010000 | $0.016000 | $0.032000\n| Next 10,000 minutes | $0.007600 | $0.009500 | $0.015200 | $0.030400\n| Next 10,000 minutes | $0.007400 | $0.009250 | $0.014800 | $0.029600\n| Over 25,000 minutes | $0.007200 | $0.009000 | $0.014400 | $0.028800\n\nPremium quality advanced static rendition preparation\n\n| Monthly volume tiers | Up to 720p | 1080p | 1440p (2K) | 2160p (4K)\n| :------------------- | :--------- | :---- | :--------- | :---------\n| First 5,000 minutes | $0.012000 | $0.015000 | $0.024000 | $0.048000\n| Next 10,000 minutes | $0.011400 | $0.014250 | $0.022800 | $0.045600\n| Next 10,000 minutes | $0.011100 | $0.013875 | $0.022200 | $0.044400\n| Over 25,000 minutes | $0.010800 | $0.013500 | $0.021600 | $0.043200\n\nWhen we talked about input, we mentioned that Mux creates a single, high-quality, standardized version of each video. That step is when most traditional video solutions or providers will create all the different versions of your video for streaming to different devices, which means storing all those different versions indefinitely. Mux, on the other hand, only creates and stores one version of your video because Mux is able to deliver the right versions of the video when your viewers need it.\n\nWith Automatic Cold Storage, Mux automatically applies discounts to infrequently accessed assets.\n\nStorage is calculated by minute of video stored. Storage is prorated by the percentage of the month that the video is stored. For example, if a 10-minute asset is stored for only half a month, you will be charged for only 5 minutes.\n\nThe cost of video storage also includes the storage of primary audio, metadata, and captions. When you pay for the storage of a video, you can also transcode or transmux to normalize inputs, create metadata or thumbnails, and access it in the dashboard or through the API.\n\nMux Live Streams have the choice to use the plus or premium quality level. Mux offers live streaming up to 1080p.\n\nMux will automatically start creating an on-demand asset in the background when you begin broadcasting to your live stream. These assets are created and stored as assets with the video quality level you chose for encoding.\n\nBasic and plus quality storage\n\nLearn more about setting video quality levels.\n\nBasic quality level assets have a minimum storage charge of one month and are prorated thereafter. Basic supports on-demand video only, up to 4K.\nPlus quality level does not have a minimum storage change. Plus supports Live video supported up to 1080p and on-demand video up to 4K.\n\nPricing is per minute per month.\n\n| Monthly volume tiers | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :------------------- | :--------- | :---- | :--------- | :--------- | :---------\n| First 50,000 minutes | $0.002400 | $0.003000 | $0.004800 | $0.009600 | $0.000240\n| Next 100,000 minutes | $0.002320 | $0.002900 | $0.004640 | $0.009280 | $0.000232\n| Next 100,000 minutes | $0.002280 | $0.002850 | $0.004560 | $0.009120 | $0.000228\n| Over 250,000 minutes | $0.002240 | $0.002800 | $0.004480 | $0.008960 | $0.000224\n\nPremium quality storage\n\nLearn more about setting video quality levels.\n\nLive video supported up to 1080p and on-demand video up to 4K.\n\nPricing is per minute per month.\n\n| Monthly volume tiers | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :------------------- | :--------- | :---- | :--------- | :--------- | :---------\n| First 50,000 minutes | $0.003600 | $0.004500 | $0.007200 | $0.014400 | $0.000240\n| Next 100,000 minutes | $0.003480 | $0.004350 | $0.006960 | $0.013920 | $0.000232\n| Next 100,000 minutes | $0.003420 | $0.004275 | $0.006840 | $0.013680 | $0.000228\n| Over 250,000 minutes | $0.003360 | $0.004200 | $0.006720 | $0.013440 | $0.000224\n\nStatic rendition (MP4s) storage\n\nStatic renditions are priced per minute of content, per static rendition, per month stored. The pricing is also based on the resolution of the static rendition.\n\nStatic rendition storage also benefits from the automatic cold storage feature when content is not viewed, see Automatic Cold Storage for more information.\n\nBasic and plus quality static rendition storage\n\n| Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :--------- | :---- | :--------- | :--------- | :---------\n| $0.000600 | $0.000750 | $0.001200 | $0.002400 | $0.000060\n\nPremium quality static rendition storage\n\n| Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :--------- | :---- | :--------- | :--------- | :---------\n| $0.000900 | $0.001125 | $0.001800 | $0.003600 | $0.000060\n\nAutomatic cold storage\n\nWith Automatic Cold Storage, we programmatically transition a video or audio-only asset to a different storage level based on how long it has been since it was last viewed. The colder the asset gets, the lower the billing rate becomes.\n\nAn asset transitions to Infrequent if it has not been played in the last 30 days, and will receive a 40% discount off of the applicable usage-based rate.\n\nAn asset transitions to Cold if it has not been played in the last 90 days, and will receive a 60% discount off of the applicable usage-based rate.\n\nWhen an asset is first created, it instantly transitions into the Cold tier until the first time it is played.\n\nAll assets, including those with static rendition (MP4s) enabled, are eligible for Automatic Cold Storage. Viewing an asset through either the static rendition or the HLS URL will reset the cold storage timer for the entire asset.\n\nNote: Downloading a master of an asset in infrequent or cold storage will cause the asset to be returned to the frequent storage class, and the cold storage timer to be reset.\n\nBasic and plus quality automatic cold storage\n\nPricing is per minute per month.\n\n| Asset last viewed | Storage tier | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :---------------- | :----------- | :--------- | :---- | :--------- | :--------- | :---------\n| 30+ days ago | Infrequent | $0.001440 | $0.001800 | $0.002880 | $0.005760 | $0.000144\n| 90+ days ago | Cold | $0.000960 | $0.001200 | $0.001920 | $0.003840 | $0.000096\n\nPremium quality automatic cold storage\n\nPricing is per minute per month.\n\n| Asset last viewed | Storage tier | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :---------------- | :----------- | :--------- | :---- | :--------- | :--------- | :---------\n| 30+ days ago | Infrequent | $0.002160 | $0.002700 | $0.004320 | $0.008640 | $0.000144\n| 90+ days ago | Cold | $0.001440 | $0.001800 | $0.002880 | $0.005760 | $0.000096\n\nBasic and plus quality static rendition automatic cold storage\n\nPricing is per minute per month.\n\n| Asset last viewed | Storage tier | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :---------------- | :----------- | :--------- | :---- | :--------- | :--------- | :---------\n| 30+ days ago | Infrequent | $0.000360 | $0.000450 | $0.000720 | $0.001440 | $0.000036\n| 90+ days ago | Cold | $0.000240 | $0.000300 | $0.000480 | $0.000960 | $0.000024\n\nPremium quality static rendition automatic cold storage\n\nPricing is per minute per month.\n\n| Asset last viewed | Storage tier | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n| :---------------- | :----------- | :--------- | :---- | :--------- | :--------- | :---------\n| 30+ days ago | Infrequent | $0.000540 | $0.000675 | $0.001080 | $0.002160 | $0.000036\n| 90+ days ago | Cold | $0.000360 | $0.000450 | $0.000720 | $0.001440 | $0.000024\n\nWhen someone wants to watch a video on Mux, we use a process called “just-in-time encoding,” where we turn that standard, single video file into any number of bitrates and resolutions based on the viewer's needs. This process happens instantly.\n\nIn order to deliver video, Mux partners with multiple CDNs. Videos are delivered over HTTP-based streaming formats like HLS. Video can be delivered to all major video players. If you're looking for a place to start with players, we suggest Mux Player. Mux Data is included with delivery, giving you the ability to monitor your video, including user engagement and quality of experience.\n\nCost is per minute of video delivered. To calculate video delivered, we measure the number of seconds of video delivered to a video player. Note that if a segment of video is delivered, it is charged, even if the viewer doesn't actually watch the video. For example, if a video player buffers 20 seconds of video ahead of the player, Mux Video still has to deliver those 20 seconds regardless of whether they are watched, and so those seconds are charged.\n\nMux Live Streams have the choice to use the plus or premium quality level. Mux offers live streaming up to 1080p.\n\nBasic and plus quality delivery\n\nBasic quality level assets support on-demand video only, up to 4K.\nPlus quality level supports live video up to 1080p, on-demand video up to 4K.\n\nThe first 100,000 minutes delivered each month, regardless of quality or resolution, are free.\n\nPricing is per minute.\n\nMonthly volume tiers | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n:------------------- | :--------- | :---- | :--------- | :--------- | :---------\nFirst 500,000 minutes | $0.000800 | $0.001000 | $0.001600 | $0.003200 | $0.000080\nNext 500,000 minutes | $0.000760 | $0.000950 | $0.001520 | $0.003040 | $0.000076\nNext million minutes | $0.000720 | $0.000900 | $0.001440 | $0.002880 | $0.000072\nNext 4 million minutes | $0.000670 | $0.000838 | $0.001340 | $0.002680 | $0.000067\nNext 4 million minutes | $0.000610 | $0.000763 | $0.001220 | $0.002440 | $0.000061\nOver 10 million minutes | $0.000560 | $0.000700 | $0.001120 | $0.002240 | $0.000056\n\nPremium quality delivery\n\nLive video supported up to 1080p, on-demand video up to 4K.\n\nThe first 100,000 minutes delivered each month, regardless of quality or resolution, are free.\n\nPricing is per minute.\n\nMonthly volume tiers | Up to 720p | 1080p | 1440p (2K) | 2160p (4K) | Audio-only\n:------------------- | :--------- | :---- | :--------- | :--------- | :---------\nFirst 500,000 minutes | $0.001200 | $0.001500 | $0.002400 | $0.004800 | $0.000080\nNext 500,000 minutes | $0.001140 | $0.001425 | $0.002280 | $0.004560 | $0.000076\nNext million minutes | $0.001080 | $0.001350 | $0.002160 | $0.004320 | $0.000072\nNext 4 million minutes | $0.001005 | $0.001256 | $0.002010 | $0.004020 | $0.000067\nNext 4 million minutes | $0.000915 | $0.001144 | $0.001830 | $0.003660 | $0.000061\nOver 10 million minutes | $0.000840 | $0.001050 | $0.001680 | $0.003360 | $0.000056\n\nMux offers a few ways to suit your pricing to your use case: pricing levers you can pull to move our standard encoding, storage, and delivery pricing up and down, and add-ons you can use to do more with your assets.\n\nVideo quality level\n\nThe first pricing lever you should consider is video quality level. Whether you should pick basic, plus, or premium video quality depends on your streaming needs. Read more in the Input section.\n\nResolution-based pricing\n\nResolution-based pricing tiers are determined by the number of pixels in the video, calculated by multiplying height by width. Tiers apply to encoding, storage, and delivery. An asset may be delivered in multiple resolutions, in which case it will be billed based on minutes delivered in each resolution. Resolution-based discounts are automatically applied.\n\n| Pricing tier | Pixels | Typical resolution |\n| :----------- | :----- | :----------------- |\n| Up to 720p | Up to 921,600 pixels | 1280x720 |\n| 1080p | Up 921,601 to 2,073,600 pixels | 1920x1080 |\n| 1440p (2K) | 2,073,601 to 4,194,304 pixels | 2560x1440 |\n| 2160p (4K) | 4,194,305 to 8,294,400 pixels | 3840x2160 |\n\nYou can control what resolution gets played with playback modifiers.\n\n2K and 4K resolutions are available for on-demand assets only.\n\nVolume discounts\n\nYou have a total of 300,000 stored minutes. They're broken down into the following:\n\n- 5,000 basic minutes at 720p\n- 55,000 basic minutes at 1080p\n- 100,000 plus minutes at 1080p\n- 140,000 plus minutes at 4K\n\nWith volume discounts automatically applied, your storage discounts would be applied like this:\n\n- 5,000 basic quality minutes at 720p - Because those minutes fall into your “first 50,000 minutes, no volume discounts applicable”\n- 55,000 basic quality minutes at 1080p - The first 50,000 minutes of 1080p assets are charged at the first tier. The rest, 5,000 of those minutes, fall into the next tier.\n- 100,000 plus quality minutes at 1080p - Similarly, discounts aren't available for the first 50,000 minutes of smart 1080p, but are available for the next 50,000 minutes.\n- 140,000 plus quality minutes at 4K - 50,000 of the minutes get no discount, 90,000 do.\n\nIf you find yourself with higher usage than the tiers outlined in the Input, Storage, and Delivery above, we'd love to talk to you about how we can customize your pricing.\n\nAudio-only\n\nAll on-demand audio-only assets and alternate audio tracks are calculated at 1/10th the cost of 720p basic video for encoding, storage, and delivery, no matter quality level assigned to that asset.\n\nWhen an asset is set to the basic quality level, encoding is free for both audio-only and video assets.\n\nYour free first 100,000 minutes delivered each month include video and audio minutes.\n\nAuto-generated live captions\n\n6,000 minutes per month free.\n$0.024 per minute after.\n\nLearn how to add auto-generated live captions.\n\nLive simulcasting\n\n$0.020 per minute per simulcast target.\n\nLearn about simulcasting.\n\nMulti-track audio\n\nThe primary audio track uploaded with your video file will be included with the encoding, storage, and delivery cost as part of your video. Any additional audio tracks uploaded will be charged at the audio-only rates for encoding, storage, and delivery.\n\nLearn more about multi-track audio.\n\nStatic renditions (MP4s)\n\nStatic renditions are a paid add-on feature.\n\nStatic renditions come in two types: standard and advanced. Standard static renditions are free to generate, while advanced static renditions are charged per minute of preparation. See advanced static rendition preparation pricing..\n\nAll static renditions are billed per static rendition, per month stored. Billing is based on the resolution of the static rendition. See static rendition storage pricing in the Storage section.\n\nFor static renditions, each minute downloaded counts as a minute streamed and will be charged according to the video quality level. Learn more about cost of delivery.\n\nLearn more about enabling MP4 renditions.\n\nDigital Rights Management (DRM)\n\nDRM is an add-on feature to Mux Video, with a $100/month access fee + $0.003 \"per license\", and discounts available for high volumes. For more details on DRM licenses, see our DRM pricing documentation.\n\nLearn more about DRM.\n\nWhat's the difference between the pay as you go plan and pre-pay credits?\nWhen you pre-pay for credits you get Mux usage at a discounted rate. For example, with Launch credits you get $100 of monthly usage for $20 a month or Scale credits, $1000 of monthly usage for $500 a month.\n\nCredits are automatically applied to your invoice at the usage rates outlined above. For any usage above your credit amount, you will be billed at pay as you go rates. Credits reset at the beginning of your billing cycle, as long as you’re subscribed to that credits plan.\n\nAPI access, features, etc, are all the same otherwise.\n\nYou don’t need to purchase pre-pay credits, if you expect your spend to be less than $40, we encourage you to stay on pay as you go. You can upgrade to a pre-pay credit at any time.\n\nIf pricing is per minute, what happens if I upload a 30-second video?\nYou pay for the exact number of seconds of video. We don't have a minimum or round to the nearest minute.\n\nDo I pay for every quality/bitrate that is delivered?\nNo - if you encode a two-minute video, you pay for two minutes, even if Mux Video delivers that same video in 8 different formats or qualities.\n\nIs support included in my price?\nOur engineers provide hands-on support via email and chat for everyone. We also offer support packages with Slack and phone support. Reach out to us for more information about support packages.\n\nHow does Mux Data fit in?\nAs a Mux Video user, Mux Data Startup plan is included. When  you integrate Mux Data into your video player, you'll start getting engagement and QoE data for your videos.\n\nDo you offer non-profit discounts?\nWe offer one-time credits for non-profit customers to help them start using Mux. Get in touch to find out more.\n\nDo you offer custom, contract pricing?\nYes! We do have custom plans that are well-suited for scaling and enterprise customers. These plans begin at $3,000/month. Get in touch to find out more.\n\nDo you charge for MP4 downloads?\n\nYes, see the Static Renditions (MP4s) section for more information.\n\nDoes Low-Latency Live Streaming cost extra?\n\nNope! At Mux, all live streamed video, whether it's standard or low latency, have the same pricing."
  },
  {
    "id": "197-_guides/snippets/changelogs/mux-embed",
    "title": "_guides/snippets/changelogs/mux-embed",
    "path": "_guides/snippets/changelogs/mux-embed.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/changelogs/mux-embed",
    "content": "Current release\n\nv5.15.0\n\n- Automatically detect playback mode changes for HTML 5 Video\n\nPrevious releases\n\nv5.14.0\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n\nv5.13.0\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - New playbackmodechange event\n  - Two new metrics, ad_playing_time_ms_cumulative and view_playing_time_ms_cumulative, to track playing time by wall clock time\n\nv5.12.0\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n\nv5.11.0\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n\nv5.10.0\n\n- Adds support for cdnchange events\n\nv5.9.1\n\n- Submit Aggregate Startup Time when autoplay is set\n\nv5.9.0\n\n- Improve scaling calculation accuracy by using more events for tracking\n\nv5.8.3\n\n- add custom 11 through 20 to types\n\nv5.8.2\n\n- remove duplicate video_source_mime_type from types\n\nv5.8.1\n\n- fix typo in types for viewer_plan\n\nv5.8.0\n\n- Add support for video_creator_id\n\nv5.7.0\n\n- Add keys for new customer-defined dimensions\n\nv5.6.0\n\n- Fix issue where firefox did not send beacons, and some final beacons might not be sent\n\nv5.5.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n- Use crypto.randomUUID(), when available, for generating UUID values\n\nv5.4.3\n\n- [chore] internal build process fix (no functional changes)\n\nv5.4.2\n\n- feat(google-ima): Beta implementation of google-ima extension to mux-embed\n- feat(mux-embed): Add methods for post-initialization overrides of functionality (for internal use only).\n- fix(mux-embed): typecheck for dashjs.getSource is incorrect.\n\nv5.4.1\n\n- Expose updateData globally and fix types\n- Fix an issue where views were not ended cleanly on long resume detection\n\nv5.4.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\nv5.3.3\n\n- expose HEARTBEAT and DESTROY under mux.events\n\nv5.3.2\n\n- Fix type issues for error severity and business exception\n\nv5.3.1\n\n- fix(mux-embed): Remove 3rd party dependencies and replace with appropriately equivalent functionality.\n\nv5.3.0\n\n- Ignore request events when emitting heartbeat events\n- Fix an issue where video quality metrics may not be calculated correctly on some devices\n\nv5.2.1\n\n- Send hb events regardless of errors\n\nv5.2.0\n\n- Bug fix to not de-dupe error event metadata\n- Extend errorTranslator to work with player_error_severity and player_error_business_exception\n\nv5.1.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- fix an issue where seeking time before first play attempt counted towards video startup time\n\nv5.0.0\n\n- Add opt-in TypeScript Types to Mux Embed and use + refactor for other dependent data SDKs. Update published dists to include CJS and ESM.\n- Mux Embed now provides (opt in) TypeScript types in its published package, as well as publishes CJS and ESM versions of the package.\n- This allows us to provide a lower risk and iterative roll out of official TypeScript types for mux-embed. The export types updates were required to ensure actual matches between the dist package and corresponding TypeScript types.\n- This _should_ have no direct impact on users, though different build tools will now potentially select one of the new export types (e.g. the ESM \"flavor\" of mux-embed). TypeScript types _should not_ be applied unless they are explicitly referenced in app (discussed in docs updates).\n\nv4.30.0\n\n- fix an issue causing certain network metrics to not be available for dashjs v4.x\n\n- fix an issue where certain IDs used may cause a DOM exception to be raised\n\nv4.29.0\n\n- fix(mux-embed): avoid using element id for muxId. attach muxId to element.\n\nv4.28.1\n\n- fix an issue where beaconDomain deprecation line was incorrectly logged\n\nv4.28.0\n\n- Deprecate beaconDomain in favor of beaconCollectionDomain. The beaconDomain setting will continue to function, but integrations should change to beaconCollectionDomain instead.\n\nv4.27.0\n\n- Fix an issue where playback time was incorrectly counted during seeking and other startup activities\n- Add events for the collection of ad clicks\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n- Add events for the collection of ad skips\n\nv4.26.0\n\n- muxData cookie expiration should be one year\n\nv4.25.1\n\n- Do not deduplicate ad IDs in ad events\n\nv4.25.0\n\n- Include ad watch time in playback time\n\nv4.24.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\nv4.23.0\n\n- Collect Request Id from the response headers, when available, for HLS.js (requestcompleted and requestfailed) and Dash.js (requestcompleted). The following headers are collected: x-request-Id, cf-ray (Cloudflare), x-amz-cf-id (CloudFront), x-akamai-request-id (Akamai)\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update Headers type\n\nv4.22.0\n\n- Send errors, requestfailed, and requestcancelled events on Dash.js. Because of this change, you may see the number of playback failures increase as we now automatically track additional fatal errors.\n\nv4.21.0\n\n- Include Ad metadata in ad events\n\nv4.20.0\n\n- Support for new dimension, view_has_ad\n\nv4.19.0\n\n- End views after 5 minutes of rebuffering\n\nv4.18.0\n\n- Add audio, subtitle, and encryption key request failures for HLS.js\n- Capture ad metadata for Video.js IMA\n- Capture detailed information from HLS.js for fatal errors in the Error Context\n\nv4.17.0\n\n- Extend errorTranslator to work with player_error_context\n\nv4.16.0\n\n- Add new renditionchange fields to Shaka SDK\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n- Add frame drops to Shaka SDK\n- Add new renditionchange info to Web SDKs\n- Adds the new Media Collection Enhancement fields\n\nv4.15.0\n\n- update mux.utils.now to use navigationStart for timing reference\n\n- fix issue where views after videochange might incorrectly accumulate rebuffering duration\n- Resolved issue sending beacons when view is ended\n- Record request_url and request_id with network events\n\nv4.14.0\n\n- Tracking FPS changes if specified in Manifest\n\nv4.13.4\n\n- Resolved issue sending beacons when paused\n\nv4.13.3\n\n- Fixed issue with monitoring network events for hls.js monitor\n\nv4.13.2\n\n- Fix an issue with sending unnecessary heartbeat events on the window visibilitychange event\n\nv4.13.1\n\n- Fixes an issue with accessing the global object\n\nv4.13.0\n\n- Collect the x-request-id header from segment responses to make it easier to correlate client requests to other logs\n- Upgraded internal webpack version\n\n- Flush events on window visibilitychange event\n\nv4.12.1\n\n- Use Fetch API for sending beacons\n\nv4.12.0\n\n- Generate a new unique view if the player monitor has not received any events for over an hour.\n\nv4.11.0\n\n- Detect fullscreen and player language\n\nv4.10.0\n\n- Replace query string dependency to reduce package size\n- Remove ImageBeacon fallback, removing support for IE9\n\nv4.9.4\n\n- Generate all view_id's internally\n\nv4.9.3\n\n- Use common function for generating short IDs\n\nv4.9.2\n\n- Fixed an issue around the disablePlayheadRebufferTracking option\n\nv4.9.1\n\n- Fix issue where getStartDate does not always return a date object\n\nv4.9.0\n\n- Support PDT and player_live_edge_program_time for Native Safari\n\n- Set a max payload size in mux-embed\n\nv4.8.0\n\n- Add option disablePlayheadRebufferTracking to allow players to disable automatic rebuffering metrics.\n  Players can emit their own rebufferstart or rebufferend events and track rebuffering metrics.\n\n- Fix an issue with removing player_error_code and player_error_message when the error code is 1.\n  Also stops emitting MEDIA_ERR_ABORTED as errors.\n- Now leaving Player Software Version for HTML5 Video Element unset rather than \"No Versions\" as it is no longer needed.\n\nv4.7.0\n\n- Add an option to specify beaconCollectionDomain for Data custom domains\n\nv4.6.2\n\n- Fix an issue with emitting heartbeat events while the player is not playing\n\nv4.6.1\n\n- Fix an issue with removing event listeners from window after the player monitor destroy event\n\nv4.6.0\n\n- Update hls.js monitor to record session data with fields prefixed as io.litix.data.\n- Update the manifest parser to parse HLS session data tags\n\nv4.5.0\n\n- Add short codes to support internal video experiments\n- Collect request header prefixed with x-litix-*\n- Capture fatal hls.js errors\n- Make envKey an optional parameter\n\nv4.4.4\n\n- Add a player events enum on the mux object (e.g. mux.events.PLAY)\n- Use the browser visibilitychange listener instead of unload to handle destructuring the player monitor.\n\nv4.4.3\n\n- Fix: Specify video_source_is_live for HLS.js monitor\n\nv4.4.2\n\n- Group events into 10 second batches before sending a beacon\n\nv4.4.1\n\n- Exclude latency metrics from beacons if video_source_is_live is not true\n\nv4.4.0\n\n- Add a lightweight HLS manifest parser to capture latency metrics for player's that don't expose an API for accessing the manifest.\n- Allow players to emit player_program_time instead of calculating internally\n\nv4.3.0\n\n- Add support for calculating latency metrics when streaming using HLS\n\nv4.2.5\n\n- Remove default video_id when not specified by the developer.\n\nv4.2.4\n\n- Add minified keys for latency metrics\n\nv4.2.3\n\n- Add minified keys for new program time metrics\n\nv4.2.2\n\n- Fix bug causing missing bitrate metrics using HLS.js {'>'}v1.0.0\n\nv4.2.1\n\n- (video element monitor) Fix an issue where some non-fatal errors thrown by the video were tracked as playback failures\n\nv4.2.0\n\n- Fix an issue where views triggered by programchange may not report metrics correctly\n- Fix an issue where calling el.mux.destroy() multiple times in a row raised an exception\n\nv4.1.1\n\n- Fix an issue where player_remote_played wasn't functioning correctly\n\nv4.1.0\n\n- Add support for custom dimensions\n\nv4.0.1\n\n- Support HLS.js v1.0.0\n\nv4.0.0\n\n- Enable sending optional ad quartile events through.\n- Move device detection server-side, improving data accuracy and reducing client SDK size.\n- Fix an issue where jank may be experienced in some web applications when the SDK is loaded.\n\nv3.4.0\n\n- Setting to disable rebuffer tracking disableRebufferTracking that defaults to false.\n\nv3.3.0\n\n- Adds viewer_connection_type detection.\n\nv3.2.0\n\n- Adds support for renditionchange.\n\nv3.1.0\n\n- Add checks for window being undefined and expose a way for SDKs to pass in platform information. This work is necessary for compatibility with react-native-video.\n\nv3.0.0\n\n- Setting to disable Mux Data collection when Do Not Track is present now defaults to off\n- Do not submit the source URL when a video is served using the data: protocol\n\nv2.10.0\n\n- Use Performance Timing API, when available, for view event timestamps\n\nv2.9.1\n\n- Fix an issue with server side rendering\n\nv2.9.0\n\n- Support for Dash.js v3\n\nv2.8.0\n\n- Submit Player Instance Id as a unique identifier\n\nv2.7.3\n\n- Fixed a bug when using mux.monitor with Hls.js or Dash.js the source hostname was not being properly collected."
  },
  {
    "id": "198-_guides/snippets/changelogs/videojs-mux",
    "title": "_guides/snippets/changelogs/videojs-mux",
    "path": "_guides/snippets/changelogs/videojs-mux.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/changelogs/videojs-mux",
    "content": "Current release\n\nv4.21.14\n\n- Automatically detect playback mode changes for HTML 5 Video\n  - Updated dependency: mux-embed to v5.15.0\n\nPrevious releases\n\nv4.21.13\n\n- Emit a renditionchange event at the start of views to eanble updated rendition tracking.\n  - Updated dependency: mux-embed to v5.14.0\n\nv4.21.12\n\n- Add ad type metadata to Ad Events\n- Add support for the upcoming Playback Mode changes:\n  - Updated dependency: mux-embed to v5.13.0\n\nv4.21.11\n\n- SDKs will no longer immediately send error events that are flagged as warnings. Fatal errors will still immediately be sent.\n  - Updated dependency: mux-embed to v5.12.0\n\nv4.21.10\n\n- Allow dev to specify page starting load and page finished loading times to calculate Page Load Time\n  - Updated dependency: mux-embed to v5.11.0\n\nv4.21.9\n\n- Adds support for cdnchange events\n  - Updated dependency: mux-embed to v5.10.0\n\nv4.21.8\n\n- Submit Aggregate Startup Time when autoplay is set\n  - Updated dependency: mux-embed to v5.9.1\n\nv4.21.7\n\n- Update mux-embed to v5.9.0\n\nv4.21.6\n\n- Update mux-embed to v5.8.3\n\nv4.21.5\n\n- Update mux-embed to v5.8.2\n\nv4.21.4\n\n- Update mux-embed to v5.8.1\n\nv4.21.3\n\n- Update mux-embed to v5.8.0\n\nv4.21.2\n\n- Update mux-embed to v5.7.0\n\nv4.21.1\n\n- Update mux-embed to v5.6.0\n\nv4.21.0\n\n- Update mechanism for generating unique IDs, used for view_id and others\n\n- Update mux-embed to v5.5.0\n\nv4.20.3\n\n- [chore] internal build process fix (no functional changes)\n- Update mux-embed to v5.4.3\n\nv4.20.2\n\n- Update mux-embed to v5.4.2\n\nv4.20.1\n\n- Update mux-embed to v5.4.1\n\nv4.20.0\n\n- Add updateData function that allows Mux Data metadata to be updated mid-view.\n\n- Update mux-embed to v5.4.0\n\nv4.19.4\n\n- Update mux-embed to v5.3.3\n\nv4.19.3\n\n- Update mux-embed to v5.3.2\n\nv4.19.2\n\n- Update mux-embed to v5.3.1\n\nv4.19.1\n\n- Update mux-embed to v5.3.0\n\nv4.19.0\n\n- utilize onRequest rather than beforeSend for videojs 8.x\n\n- Update mux-embed to v5.2.1\n\nv4.18.1\n\n- Update mux-embed to v5.2.0\n\nv4.18.0\n\n- Target ES5 for bundles and validate bundles are ES5\n\n- Update mux-embed to v5.1.0\n\nv4.17.0\n\n- Refactors for stricter data types (e.g. string vs. number) based on TypeScript types.\n\n- Update mux-embed to v5.0.0\n\nv4.16.4\n\n- Update mux-embed to v4.30.0\n\nv4.16.3\n\n- Update mux-embed to v4.29.0\n\nv4.16.2\n\n- Update mux-embed to v4.28.1\n\nv4.16.1\n\n- Update mux-embed to v4.28.0\n\nv4.16.0\n\n- fix an issue where seek latency could be unexpectedly large\n- fix an issue where seek latency does not include time at end of a view\n\n- Update mux-embed to v4.27.0\n\nv4.15.3\n\n- Update mux-embed to v4.26.0\n\nv4.15.2\n\n- Update mux-embed to v4.25.1\n\nv4.15.1\n\n- Update mux-embed to v4.25.0\n\nv4.15.0\n\n- Fix an issue where beacons over a certain size could get hung and not be sent\n\n- Update mux-embed to v4.24.0\n\nv4.14.0\n\n- Fix an issue where tracking rebuffering can get into an infinite loop\n\n- Update mux-embed to v4.23.0\n\nv4.13.4\n\n- Update mux-embed to v4.22.0\n\nv4.13.3\n\n- Update mux-embed to v4.21.0\n\nv4.13.2\n\n- Update mux-embed to v4.20.0\n\nv4.13.1\n\n- Update mux-embed to v4.19.0\n\nv4.13.0\n\n- Set Mux Error Context with error status from Video.js\n\nv4.12.0\n\n- Capture ad metadata for Video.js IMA\n\n- Update mux-embed to v4.18.0\n\nv4.11.0\n\n- Support player_error_context in errorTranslator\n\n- Update mux-embed to v4.17.0\n\nv4.10.1\n\n- fix issue where VideoJS with hls.js might cause an exception when monitored\n\nv4.10.0\n\n- Adds support for new and updated fields: renditionchange, error, DRM type, dropped frames, and new custom fields\n\n- Update mux-embed to v4.16.0\n\nv4.9.1\n\n- fix an issue where an exception may happen on certain Samsung TVs using videojs-mux\n\nv4.9.0\n\n- Register beforesetup hook to track player_init_time automatically. There is now no need to provide player_init_time in plugin initialization\n\n- Record request_url and request_id with network events\n- Update mux-embed to v4.15.0\n\nv4.8.5\n\n- Update mux-embed to v4.14.0\n\nv4.8.4\n\n- Update mux-embed to v4.13.4\n\nv4.8.3\n\n- Update mux-embed to v4.13.3\n\nv4.8.2\n\n- Update mux-embed to v4.13.2\n\nv4.8.1\n\n- Fixes an issue with accessing the global object\n- Update mux-embed to v4.13.1\n\nv4.8.0\n\n- Upgraded internal webpack version\n\n- Update mux-embed to v4.13.0\n\nv4.7.8\n\n- Update mux-embed to v4.12.1\n\nv4.7.7\n\n- Update mux-embed to v4.12.0\n\nv4.7.6\n\n- Update mux-embed to v4.11.0\n\nv4.7.5\n\n- Update mux-embed to v4.10.0\n\nv4.7.4\n\n- Update mux-embed to v4.9.4\n\nv4.7.3\n\n- Use videojs.Vhs instead of videojs.Hls when available\n\nv4.7.2\n\n- Update mux-embed to v4.9.3\n\nv4.7.1\n\n- Update mux-embed to v4.9.2\n\nv4.7.0\n\n- HLS session and latency metrics\n\nv4.6.6\n\n- Update mux-embed to v4.9.1\n\nv4.6.5\n\n- Update mux-embed to v4.9.0\n\nv4.6.4\n\n- Fix an issue with removing player_error_code and player_error_message when the error code is 1.\n  Also stops emitting MEDIA_ERR_ABORTED as errors.\n- Update mux-embed to v4.8.0\n\nv4.6.3\n\n- Update mux-embed to v4.7.0\n\nv4.6.2\n\n- Update mux-embed to v4.6.2\n\nv4.6.1\n\n- Update mux-embed to v4.6.1\n\nv4.6.0\n\n- Bump mux-embed to 4.6.0\n\nv4.5.0\n\n- Export a register function that takes a videojs instance to install the mux plugin on\n\nv4.4.0\n\n- Update mux-embed to v4.4.2\n\nv4.3.0\n\n- Update mux-embed to v4.3.0\n\nv4.2.0\n\n- Update mux-embed to v4.2.0\n- Fix an issue where views that resulted from programchange may not have been tracked correctly\n- Fix an issue where if destroy was called multiple times, it would raise an exception\n\nv4.1.0\n\n- Update mux-embed to v4.1.1\n- Fix an issue where player_remote_played would not be reported correctly\n\nv4.0.0\n\n- Update mux-embed to v4.0.0\n- Support server-side device detection\n- Internal fixes and improvements\n\nv3.1.4\n\n- update logging around retrieving BANDWIDTH information\n\nv3.1.3\n\n- Bump mux-embed dependency to 3.4.3.\n\nv3.1.2\n\n- Bump mux-embed dependency to 3.4.2."
  },
  {
    "id": "199-_guides/snippets/cms-integration-guide-cards",
    "title": "_guides/snippets/cms-integration-guide-cards",
    "path": "_guides/snippets/cms-integration-guide-cards.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/cms-integration-guide-cards",
    "content": "<GuideCard\n    title=\"Set up playback\"\n    description=\"Set up your iOS application, Android application or web application to start playing your Mux assets\"\n    links={[{ title: 'Read the guide', href: '/docs/guides/play-your-videos' }]}\n  />\n  <GuideCard\n    title=\"Preview your video\"\n    description=\"Now that you have Mux assets, build rich experiences into your application by extracting images from your videos\"\n    links={[{ title: 'Read the guide', href: '/docs/guides/get-images-from-a-video' }]}\n  />\n  <GuideCard\n    title=\"Integrate Mux Data\"\n    description=\"Add the Mux Data SDK to your player and start collecting playback performance metrics.\"\n    links={[{ title: 'Read the guide', href: '/docs/guides/track-your-video-performance' }]}\n  />"
  },
  {
    "id": "200-_guides/snippets/env-key-callout",
    "title": "_guides/snippets/env-key-callout",
    "path": "_guides/snippets/env-key-callout.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/env-key-callout",
    "content": "Get your ENV_KEY from the Mux environments dashboard.\n\nENV_KEY is a client-side key used for Mux Data monitoring. These are not to be confused with API tokens which are created in the admin settings dashboard and meant to access the Mux API from a trusted server."
  },
  {
    "id": "201-_guides/snippets/sdk-web-changing-the-video",
    "title": "_guides/snippets/sdk-web-changing-the-video",
    "path": "_guides/snippets/sdk-web-changing-the-video.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/sdk-web-changing-the-video",
    "content": "There are two cases where the underlying tracking of the video view need to be reset:\n\n1.  New source: When you load a new source URL into an existing player.\n1.  New program: When the program within a singular stream changes (such as a program change within a continuous live stream).\n\nNote: You do not need to change the video info when changing to a different source of the same video content (e.g. different resolution or video format)."
  },
  {
    "id": "202-_guides/snippets/sdk-web-customize-beacon-collection",
    "title": "_guides/snippets/sdk-web-customize-beacon-collection",
    "path": "_guides/snippets/sdk-web-customize-beacon-collection.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/sdk-web-customize-beacon-collection",
    "content": "If you have integrated a custom domain for Data collection, specify your custom domain by setting beaconCollectionDomain."
  },
  {
    "id": "203-_guides/snippets/sdk-web-customize-error-tracking",
    "title": "_guides/snippets/sdk-web-customize-error-tracking",
    "path": "_guides/snippets/sdk-web-customize-error-tracking.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/sdk-web-customize-error-tracking",
    "content": "When triggering an error event, it is important to provide values for player_error_code and player_error_message. The player_error_message should provide a generalized description of the error as it happened. The player_error_code must be an integer, and should provide a category of the error. If the errors match up with the HTML Media Element Error, you can use the same codes as the corresponding HTML errors. However, for custom errors, you should choose a number greater than or equal to 100.\n\nIn general you should not send a distinct code for each possible error message, but rather group similar errors under the same code. For instance, if your library has two different conditions for network errors, both should have the same player_error_code but different messages.\n\nThe error message and code are combined together and aggregated with all errors that occur in your environment in order to find the most common errors that occur. To make error aggregation as useful as possible, these values should be general enough to provide useful information but not specific to each individual error (such as stack trace).\n\nYou can use player_error_context to provide instance-specific information derived from the error such as stack trace or segment-ids where an error occurred. This value is not aggregated with other errors and can be used to provide detailed information. Note: Please do not include any personally identifiable information from the viewer in this data."
  },
  {
    "id": "204-_guides/snippets/sdk-web-disable-auto-error-tracking",
    "title": "_guides/snippets/sdk-web-disable-auto-error-tracking",
    "path": "_guides/snippets/sdk-web-disable-auto-error-tracking.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/sdk-web-disable-auto-error-tracking",
    "content": "In the case that you want full control over what errors are counted as fatal or not, you may want to consider turning off Mux's automatic error tracking completely. This can be done by passing automaticErrorTracking: false in the configuration object."
  },
  {
    "id": "205-_guides/snippets/sdk-web-disable-cookies",
    "title": "_guides/snippets/sdk-web-disable-cookies",
    "path": "_guides/snippets/sdk-web-disable-cookies.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/sdk-web-disable-cookies",
    "content": "By default, Mux plugins for HTML5-based players use a cookie to track playback across subsequent page views in order to understand viewing sessions. This cookie includes information about the tracking of the viewer, such as an anonymized viewer ID that Mux generates for each user. None of this information is personally-identifiable, but you can disable the use of this cookie if desired. For instance, if your site or application is targeted towards children under 13, you should disable the use of cookies. For information about the specific data tracked in the cookie, please refer to: What information is stored in Mux Data HTML cookies.\n\nThis is done by setting disableCookies: true in the options."
  },
  {
    "id": "206-_guides/snippets/sdk-web-do-not-track",
    "title": "_guides/snippets/sdk-web-do-not-track",
    "path": "_guides/snippets/sdk-web-do-not-track.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/sdk-web-do-not-track",
    "content": "By default, Mux plugins for HTML5-based players do not respect Do Not Track when set within browsers. This can be enabled in the options passed to Mux, via a setting named respectDoNotTrack. The default for this is false. If you would like to change this behavior, pass respectDoNotTrack: true."
  },
  {
    "id": "207-_guides/snippets/sdk-web-error-translator-1",
    "title": "_guides/snippets/sdk-web-error-translator-1",
    "path": "_guides/snippets/sdk-web-error-translator-1.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/sdk-web-error-translator-1",
    "content": "If your player emits error events that are not fatal to playback or the errors are unclear and/or do not have helpful information in the default error message and codes you might find it helpful to use an error translator or disable automatic error tracking all together."
  },
  {
    "id": "208-_guides/snippets/sdk-web-error-translator-2",
    "title": "_guides/snippets/sdk-web-error-translator-2",
    "path": "_guides/snippets/sdk-web-error-translator-2.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/sdk-web-error-translator-2",
    "content": "If you return false from your errorTranslator function then the error will not be tracked. Do this for non-fatal errors that you want to ignore. If your errorTranslator function itself raises an error, then it will be silenced and the player's original error will be used."
  },
  {
    "id": "209-_guides/snippets/sdk-web-new-program",
    "title": "_guides/snippets/sdk-web-new-program",
    "path": "_guides/snippets/sdk-web-new-program.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/sdk-web-new-program",
    "content": "In some cases, you may have the program change within a stream, and you may want to track each program as a view on its own. An example of this is a live stream that streams multiple programs back to back, with no interruptions.\n\nIn this case, you emit a programchange event, including the updated metadata for the new program within the continuous stream. This will remove all previous video data and reset all metrics for the video view, creating a new video view. See Metadata for the list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video.\n\nNote: The programchange event is intended to be used _only_ while the player is currently not paused. If you emit this event while the player is paused, the resulting view will not track video startup time correctly, and may also have incorrect watch time. Do not emit this event while the player is paused."
  },
  {
    "id": "210-_guides/snippets/sdk-web-new-source",
    "title": "_guides/snippets/sdk-web-new-source",
    "path": "_guides/snippets/sdk-web-new-source.mdx",
    "sourceUrl": "https://docs.mux.com/_guides/snippets/sdk-web-new-source",
    "content": "If your application plays multiple videos back-to-back in the same video player, you need to signal when a new video starts to the Mux SDK. Examples of when this is needed are:\n\n The player advances to the next video in a playlist\n The user selects a different video to play\n\nIn order to signal the Mux SDK that a new view is starting, you will need to emit a videochange event, along with metadata about the new video. See metadata in Make your data actionable for the full list of video details you can provide. You can include any metadata when changing the video but you should only need to update the values that start with video_.\n\nIt's best to change the video info immediately after telling the player which new source to play."
  },
  {
    "id": "1-README",
    "title": "README",
    "path": "README.md",
    "sourceUrl": "https://docs.mux.com/README",
    "content": "mux.com/docs\n\nDeveloping\n\nTo set up your environment for testing docs, please see the root-level README.\n\nIf you're not a developer but want to contribute to our docs, we have a tutorial for non-technical contributors that walks through how to make changes using GitHub's web interface.\n\nHistory\n\nThe marketing site and docs used to be separate repos. In 2025, the docs site joined the marketing site's Next.js project. We're working to gradually adopt more of the marketing site's patterns and components throughout the docs -- pardon the mess.\n\nCode exclusive to docs lives in this apps/web/app/docs folder. Code shared by the two projects lives one level up, in the apps/web/app folder.\n\nCreating new guides\n\nAdding a new guide\n\n1. Add a guide to the docs/_guides folder.\n   > Guides are written in MDX, meaning you can write in Markdown, and you can include shiny components. (More on the components later)\n2. Add the guide to the sidebar. The sidebar sections are defined in the docs/_config folder.\n   > [!WARNING]\n   > Any guide that is not in the sidebar will not display (unless it has its own docs/**/page.tsx file -- see spaces-to-livekit for example).\n\nUsing our shiny components\n\nWant to add multiple code examples in a single block? Want to highlight some lines of your code example? Want to reuse one markdown file multiple times throughout your guides? Want to add a cool callout? We have components for those and _so much more_.\n\nView docs/_guides/developer/example for info on the shiny components we have. You can also view that example guide at http://localhost:3000/docs/guides/example, once you have your dev server up and running.\n\nWriting good guides\n\n1. Be familiar with the Writing/voice guideline doc\n2. Follow this example to get the tone & feel of how we write guides:\n\n!Guide for Guides\n\nSearch\n\nSearch is powered by Algolia DocSearch. You can view the DocSearch dashboard here.\n\nLogin credentials\n\nYou can find the login credentials in 1Password (search for \"Algolia DocSearch\" in the DevEx Engineering vault).\n\nCustomizing the search results\n\nWe made some changes to the Algolia crawler settings using the editor in the Algolia dashboard. When you open the crawler editor, you'll see an actions entry. The real magic happens in the recordExtractor property. This function takes three items: a Cheerio instance (represented by a $), some custom Algolia helper functions, and the current URL being crawled.\n\nEach page goes through this record extractor to determine which content appears in search results and its ranking priority. We customize this function to prioritize our guides over API references, API references over webhook references or changelogs. Different weights are assigned for this purpose.\n\nWe also use meta tags from our Next.js application to set content and product categories. For example, if a result is from the Mux Data product, we rank it lower than the Mux Video product because our video product might need more guidance for beginners.\n\nThe crawler goes through each record to find important elements and selectors for the search result. lvl0 through lvl3 are assigned different values that will show up in the search results. We always use a value of lvl2 for the type property for the best hierarchy appearance in the UI. Finally, we return all results to get the records configuration we need in Algolia DocSearch.\n\nRecrawls are triggered by pushing to the main branch. See .github/workflows/recrawl_docs.yml for more details.\n\nLinks and Fix Broken Links\n\nExternal links can be added to an .mdx guide like this: thisLink.\n\nTo submit a pull request for this branch, a script is run to check broken links. Before you push your branch to the remote, it's a good idea to run this first which will give a log of the links you need to fix.\n\n\n```\nnpm run check-broken-links-including-external\n```\n\n\nNote that certain encoded URLs can set this off.\n\napi-spec.json and webhook-spec.json\n\nAny changes to the api spec or webhook spec should be submitted to the openapi-specification repo -- this repo is the source of truth for our Open API spec.\n\nAfter changes have been merged into the main branch in that repo, follow these steps for updaing the public/api-spec.json file found in this repo:\n\n1. Clone muxinc/openapi-specification locally. Pull down the latest main branch\n1. On your local machine, openapi-specification and docs.mux.com should be in the same directory (they're siblings)\n1. From openapi-specification run this command: npm install && npm run api:validate:full && cp dist/api-spec.json ../docs.mux.com/public/api-spec.json. This command will generate an api-spec.json file and then it will copy it into the docs.mux.com project to a file in public/api-spec.json\n1. From openapi-specification run this command: npm run webhook:validate && cp dist/webhook-spec.json ../docs.mux.com/public/webhook-spec.json. This command will generate a webhook-spec.json file and then it will copy it into the docs.mux.com project to a file in public/webhook-spec.json\n1. Submit a new PR for docs.mux.com with the changes\n\nSpelling and Grammar Checks\n\n> [!WARNING]\n> Vale currently doesn't work. Sorryyyyyy\n\nWe use a tool called Vale to add spelling and grammar checks to our CI process. Every time you do a push to a branch in this repo, Vale runs the various guides through its spelling and grammar checks. To run them manually (especially before comitting), make sure you have Vale installed locally by running brew bundle (or manually by running brew install vale).\n\nOnce you have Vale installed, you can run vale sync to pull down the latest grammar packages locally, and then npm run spelling to run Vale against the documentation. It should report zero errors and zero warnings, like this:\n\n\n```\n$ npm run spelling\nnpm run v1.22.11\nwarning package.json: No license field\n$ vale guides/ pages/ code-examples/ api-req-examples/\n✔ 0 errors, 0 warnings and 0 suggestions in 132 files.\n✨  Done in 0.79s.\n```\n\n\nIf it does report an error, it will tell you on which line and column the error was found.\n\nThe most common errors are related to capitalization. If the system is complaining about jwplayer instead of JWPlayer, for example, and you really do mean to use jwplayer, simply place backticks () around the word to mark it as a string literal.\n\nIf you really need to add a word to our own custom dictionary, it can be added as a regular expression in vale_styles/Vocab/Docs/accept.txt`. It should be quite self-explanatory if you look at the other entries in that file. Please try to keep the entries in that file in alphabetical order.\n\nIf you have other questions or issues with the spell checking, please reach out to Justin or another member of the Devex Engineering team."
  }
]